Directory structure:
└── landlab/
    ├── README.md
    ├── CITATION.cff
    ├── CONTRIBUTING.md
    ├── LICENSE.md
    ├── MANIFEST.in
    ├── conftest.py
    ├── environment-dev.yml
    ├── environment.yml
    ├── notebooks.py
    ├── noxfile.py
    ├── pyproject.toml
    ├── requirements-testing.in
    ├── requirements.in
    ├── setup.cfg
    ├── setup.py
    ├── docs/
    ├── joss/
    ├── news/
    ├── notebooks/
    │   ├── requirements.in
    │   └── welcome.ipynb
    ├── requirements/
    │   ├── README.md
    │   ├── docs.txt
    │   ├── notebooks.txt
    │   ├── required.txt
    │   └── testing.txt
    ├── scripts/
    ├── src/
    │   └── landlab/
    │       ├── __init__.py
    │       ├── _info.py
    │       ├── _registry.py
    │       ├── _version.py
    │       ├── .gitignore
    │       ├── bmi/
    │       │   ├── __init__.py
    │       │   ├── bmi_bridge.py
    │       │   ├── components.py
    │       │   └── standard_names.py
    │       ├── ca/
    │       │   ├── __init__.py
    │       │   ├── celllab_cts.py
    │       │   ├── cfuncs.pyx
    │       │   ├── hex_cts.py
    │       │   ├── oriented_hex_cts.py
    │       │   ├── oriented_raster_cts.py
    │       │   ├── raster_cts.py
    │       │   └── boundaries/
    │       │       ├── __init__.py
    │       │       └── hex_lattice_tectonicizer.py
    │       ├── cmd/
    │       │   ├── __init__.py
    │       │   ├── authors.py
    │       │   └── landlab.py
    │       ├── components/
    │       ├── core/
    │       │   ├── __init__.py
    │       │   ├── errors.py
    │       │   ├── messages.py
    │       │   ├── model_component.py
    │       │   ├── model_parameter_loader.py
    │       │   └── utils.py
    │       ├── data/
    │       │   └── io/
    │       ├── data_record/
    │       │   ├── __init__.py
    │       │   ├── _aggregators.pyx
    │       │   ├── aggregators.py
    │       │   └── data_record.py
    │       ├── field/
    │       │   ├── __init__.py
    │       │   ├── errors.py
    │       │   └── graph_field.py
    │       ├── framework/
    │       │   ├── __init__.py
    │       │   ├── component.py
    │       │   ├── decorators.py
    │       │   └── interfaces.py
    │       ├── graph/
    │       │   ├── __init__.py
    │       │   ├── dual.py
    │       │   ├── graph.py
    │       │   ├── graph_convention.py
    │       │   ├── ugrid.py
    │       │   ├── ext/
    │       │   │   └── __init__.py
    │       │   ├── framed_voronoi/
    │       │   │   ├── __init__.py
    │       │   │   ├── dual_framed_voronoi.py
    │       │   │   └── framed_voronoi.py
    │       │   ├── hex/
    │       │   │   ├── __init__.py
    │       │   │   ├── dual_hex.py
    │       │   │   ├── hex.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── hex.pyx
    │       │   │       └── perimeternodes.pyx
    │       │   ├── matrix/
    │       │   │   ├── __init__.py
    │       │   │   ├── at_node.py
    │       │   │   ├── at_patch.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── at_patch.pyx
    │       │   │       └── matrix.pyx
    │       │   ├── object/
    │       │   │   ├── __init__.py
    │       │   │   ├── at_node.py
    │       │   │   ├── at_patch.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── at_node.pyx
    │       │   │       └── at_patch.pyx
    │       │   ├── quantity/
    │       │   │   ├── __init__.py
    │       │   │   ├── of_link.py
    │       │   │   ├── of_patch.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── of_element.pyx
    │       │   │       ├── of_link.pyx
    │       │   │       └── of_patch.pyx
    │       │   ├── quasi_spherical/
    │       │   │   ├── __init__.py
    │       │   │   ├── dual_icosphere.py
    │       │   │   └── refinable_icosahedron.py
    │       │   ├── radial/
    │       │   │   ├── __init__.py
    │       │   │   ├── dual_radial.py
    │       │   │   └── radial.py
    │       │   ├── sort/
    │       │   │   ├── __init__.py
    │       │   │   ├── intpair.py
    │       │   │   ├── sort.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── _deprecated_sparse.pyx
    │       │   │       ├── argsort.pxd
    │       │   │       ├── argsort.pyx
    │       │   │       ├── intpair.pyx
    │       │   │       ├── remap_element.pyx
    │       │   │       └── spoke_sort.pyx
    │       │   ├── structured_quad/
    │       │   │   ├── __init__.py
    │       │   │   ├── dual_structured_quad.py
    │       │   │   ├── structured_quad.py
    │       │   │   └── ext/
    │       │   │       ├── __init__.py
    │       │   │       ├── at_cell.pyx
    │       │   │       ├── at_face.pyx
    │       │   │       ├── at_link.pyx
    │       │   │       ├── at_node.pyx
    │       │   │       └── at_patch.pyx
    │       │   └── voronoi/
    │       │       ├── __init__.py
    │       │       ├── dual_voronoi.py
    │       │       ├── voronoi.py
    │       │       ├── voronoi_to_graph.py
    │       │       └── ext/
    │       │           ├── __init__.py
    │       │           ├── delaunay.pyx
    │       │           └── voronoi.pyx
    │       ├── grid/
    │       │   ├── __init__.py
    │       │   ├── base.py
    │       │   ├── create.py
    │       │   ├── create_network.py
    │       │   ├── decorators.py
    │       │   ├── diagonals.py
    │       │   ├── divergence.py
    │       │   ├── framed_voronoi.py
    │       │   ├── gradients.py
    │       │   ├── grid_funcs.py
    │       │   ├── hex.py
    │       │   ├── hex_mappers.py
    │       │   ├── icosphere.py
    │       │   ├── linkorientation.py
    │       │   ├── linkstatus.py
    │       │   ├── mappers.py
    │       │   ├── network.py
    │       │   ├── nodestatus.py
    │       │   ├── radial.py
    │       │   ├── raster.py
    │       │   ├── raster_aspect.py
    │       │   ├── raster_divergence.py
    │       │   ├── raster_funcs.py
    │       │   ├── raster_gradients.py
    │       │   ├── raster_mappers.py
    │       │   ├── raster_set_status.py
    │       │   ├── voronoi.py
    │       │   ├── warnings.py
    │       │   ├── ext/
    │       │   │   ├── raster_divergence.pyx
    │       │   │   └── raster_gradient.pyx
    │       │   └── unstructured/
    │       │       ├── __init__.py
    │       │       ├── base.py
    │       │       ├── cells.py
    │       │       ├── links.py
    │       │       ├── nodes.py
    │       │       └── status.py
    │       ├── io/
    │       │   ├── __init__.py
    │       │   ├── _deprecated_esri_ascii.py
    │       │   ├── esri_ascii.py
    │       │   ├── legacy_vtk.py
    │       │   ├── native_landlab.py
    │       │   ├── obj.py
    │       │   ├── shapefile.py
    │       │   └── netcdf/
    │       │       ├── __init__.py
    │       │       ├── _constants.py
    │       │       ├── dump.py
    │       │       ├── errors.py
    │       │       ├── load.py
    │       │       ├── read.py
    │       │       └── write.py
    │       ├── layers/
    │       │   ├── __init__.py
    │       │   ├── eventlayers.py
    │       │   ├── materiallayers.py
    │       │   └── ext/
    │       │       ├── __init__.py
    │       │       └── eventlayers.pyx
    │       ├── plot/
    │       │   ├── __init__.py
    │       │   ├── colors.py
    │       │   ├── drainage_plot.py
    │       │   ├── event_handler.py
    │       │   ├── graph.py
    │       │   ├── imshow.py
    │       │   ├── imshowhs.py
    │       │   ├── layers.py
    │       │   ├── video_out.py
    │       │   └── network_sediment_transporter/
    │       │       ├── __init__.py
    │       │       ├── locate_parcel_xy.py
    │       │       └── plot_network_and_parcels.py
    │       ├── utils/
    │       │   ├── __init__.py
    │       │   ├── _matrix.pyx
    │       │   ├── add_halo.py
    │       │   ├── count_repeats.py
    │       │   ├── decorators.py
    │       │   ├── depth_dependent_roughness.py
    │       │   ├── distance_to_divide.py
    │       │   ├── fault_facet_finder.py
    │       │   ├── flow__distance.py
    │       │   ├── jaggedarray.py
    │       │   ├── jaggedarray_ma.py
    │       │   ├── matrix.py
    │       │   ├── return_array.py
    │       │   ├── source_tracking_algorithm.py
    │       │   ├── stable_priority_queue.py
    │       │   ├── structured_grid.py
    │       │   ├── suppress_output.py
    │       │   ├── watershed.py
    │       │   ├── window_statistic.py
    │       │   ├── ext/
    │       │   │   ├── __init__.py
    │       │   │   └── jaggedarray.pyx
    │       │   └── geometry/
    │       │       └── spherical.py
    │       ├── values/
    │       │   ├── __init__.py
    │       │   └── synthetic.py
    │       └── .qodo/
    │           └── history.sqlite
    ├── tests/
    └── .github/

================================================
File: README.md
================================================
![[DOI][doi-link]][doi-badge]
![[Documentation][rtd-link]][rtd-badge]
![[Coverage][coveralls-link]][coveralls-badge]
![[Testing][test-link]][test-badge]
![[Lint][lint-link]][lint-badge]


[coveralls-badge]: https://coveralls.io/repos/landlab/landlab/badge.png
[coveralls-link]: https://coveralls.io/r/landlab/landlab
[doi-badge]: https://zenodo.org/badge/DOI/10.5281/zenodo.3776837.svg
[doi-link]: https://doi.org/10.5281/zenodo.3776837
[lint-badge]: https://github.com/landlab/landlab/actions/workflows/lint.yml/badge.svg
[lint-link]: https://github.com/landlab/landlab/actions/workflows/lint.yml
[rtd-badge]:https://readthedocs.org/projects/landlab/badge/?version=latest
[rtd-link]: https://landlab.csdms.io
[test-badge]: https://github.com/landlab/landlab/actions/workflows/test.yml/badge.svg
[test-link]: https://github.com/landlab/landlab/actions/workflows/test.yml

# Landlab

## What does Landlab do?

<!-- start-intro -->

Landlab is an open-source Python-language package for numerical modeling of
Earth surface dynamics. It contains

- A gridding engine which represents the model domain. Regular and irregular
  grids are supported.
- A library of process components, each of which represents a physical process
  (e.g., generation of rain, erosion by flowing water). These components have
  a common interface and can be combined based on a user's needs.
- Utilities that support general numerical methods, file input/output, and
  visualization.

In addition Landlab contains a set of Jupyter notebook tutorials providing
an introduction to core concepts and examples of use.

Landlab was designed for disciplines that quantify Earth surface dynamics such
as geomorphology, hydrology, glaciology, and stratigraphy. It can also be used
in related fields. Scientists who use this type of model often build
their own unique model from the ground up, re-coding the basic building blocks
of their landscape model rather than taking advantage of codes that have
already been written. Landlab saves practitioners from the need for this kind
of re-invention by providing standardized components that they can re-use.

Watch the webinar [Landlab Toolkit Overview](https://csdms.colorado.edu/wiki/Presenters-0407)
at CSDMS to learn more.

<!-- end-intro -->

______________________________________________________________________

[Read the documentation on ReadTheDocs!](https://landlab.csdms.io/)

______________________________________________________________________

## Installation

To install the latest release of *landlab* using *pip*, simply run the following
in your terminal of choice:

```bash
$ pip install landlab
```

For a full description of how to install *Landlab*, including using *mamba*/*conda*,
please see the documentation for our [installation instructions].

## Source code

If you would like to modify or contribute code to *Landlab* or use the very latest
development version, please see the documentation that describes how to
[install landlab from source].

## Are there any examples of using Landlab I can look at?

The Landlab package contains a directory, `landlab/notebooks`, with
Jupyter Notebooks describing core concepts and giving examples of using components.
The file `landlab/notebooks/welcome.ipynb` provides a table of contents to
the notebooks and is the recommended starting place.
Additionally, there are a set of notebooks curated to teach physical processes
located in the directory `landlab/notebooks/teaching`.

### Run on Binder

To launch an instance of
Binder and [explore the notebooks click here].

To launch a Binder instance that goes straight to the [teaching notebooks click here].

### Run on EarthscapeHub

The Landlab notebooks can also be run on [EarthscapeHub].
Visit this link to learn how to sign up for a free account.
Explore the example notebooks on the
[lab](https://lab.openearthscape.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Flandlab%2Flandlab&urlpath=lab%2Ftree%2Flandlab%2Fnotebooks%2Fwelcome.ipynb&branch=master) or [jupyter](https://jupyter.openearthscape.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Flandlab%2Flandlab&urlpath=lab%2Ftree%2Flandlab%2Fnotebooks%2Fwelcome.ipynb&branch=master) Hub instance.
Or, use the teaching notebooks on the
[lab](https://lab.openearthscape.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Flandlab%2Flandlab&urlpath=lab%2Ftree%2Flandlab%2Fnotebooks%2Fteaching%2Fwelcome_teaching.ipynb&branch=master) or [jupyter](https://jupyter.openearthscape.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Flandlab%2Flandlab&urlpath=lab%2Ftree%2Flandlab%2Fnotebooks%2Fteaching%2Fwelcome_teaching.ipynb&branch=master) Hub instance.
Be sure to run all notebooks with the *CSDMS* kernel.

## License

*landlab* is licensed under the MIT License.

## Citing Landlab

If you use any portion of Landlab, please see the documentation for our
[citation guidelines].

## Contact

<!-- start-contact -->

The recommended way to contact the Landlab team is with a
[GitHub Issue](https://github.com/landlab/landlab/issues).

- **Bug reports**: Please make an Issue describing the bug so we can address it, or work
  with you to address it. Please try to provide a [minimal, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example).
- **Documentation**: If something in our documentation is not clear to you, please make an
  issue describing the what isn't clear. Someone will tag
  the most appropriate member of the core Landlab team. We will work to clarify
  your question and revise the documentation so that it is clear for the next user.

Keep in touch with the latest *landlab* news by following us on [Twitter](https://twitter.com/landlabtoolkit).

During workshops and clinics, we sometimes use the
[Landlab Slack channel](https://landlab.slack.com).

<!-- end-contact -->

[citation guidelines]: https://landlab.csdms.io/about/citing.html
[earthscapehub]: https://csdms.colorado.edu/wiki/JupyterHub
[explore the notebooks click here]: https://mybinder.org/v2/gh/landlab/landlab/master?filepath=notebooks/welcome.ipynb
[install landlab from source]: https://landlab.csdms.io/install/
[installation instructions]: https://landlab.csdms.io/installation.html
[teaching notebooks click here]: https://mybinder.org/v2/gh/landlab/landlab/master?filepath=notebooks/teaching/welcome_teaching.ipynb



================================================
File: CITATION.cff
================================================
# YAML 1.2
---
cff-version: "1.2.0"
message: "If you use this software, please cite it using these metadata."
abstract : "Landlab is an open-source Python-language package for numerical modeling of Earth surface dynamics."
type: software
authors:
  -
    family-names: Hutton
    given-names: Eric
    orcid: "https://orcid.org/0000-0002-5864-6459"
  -
    family-names: Barnhart
    given-names: Katy
    orcid: "https://orcid.org/0000-0001-5682-455X"
  -
    family-names: Hobley
    given-names: Dan
    orcid: "https://orcid.org/0000-0003-2371-0534"
  -
    family-names: Tucker
    given-names: Greg
    orcid: "https://orcid.org/0000-0003-0364-5800"
  -
    family-names: Nudurupati
    given-names: Sai
    orcid: "https://orcid.org/0000-0002-2090-7561"
  -
    family-names: Adams
    given-names: Jordan
    orcid: "https://orcid.org/0000-0003-0137-9879"
  -
    family-names: Gasparini
    given-names: Nicole
    orcid: "https://orcid.org/0000-0002-0803-3697"
  -
    family-names: Shobe
    given-names: Charlie
    orcid: "https://orcid.org/0000-0003-3015-1283"
  -
    family-names: Strauch
    given-names: Ronda
    orcid: "https://orcid.org/0000-0003-3093-8449"
  -
    family-names: Knuth
    given-names: Jenny
    orcid: "https://orcid.org/0000-0001-7066-7992"
  -
    family-names: Mouchene
    given-names: Margaux
    orcid: "https://orcid.org/0000-0002-8243-3517"
  -
    family-names: Lyons
    given-names: Nathan
    orcid: "https://orcid.org/0000-0001-6965-3374"
  -
    family-names: Litwin
    given-names: David
    orcid: "https://orcid.org/0000-0002-8097-4029"
  -
    family-names: Glade
    given-names: Rachel
    orcid: "https://orcid.org/0000-0002-0345-1953"
  -
    name: Giuseppecipolla95
  -
    family-names: Manaster
    given-names: Amanda
  -
    family-names: Abby
    given-names: Langston
  -
    family-names: Thyng
    given-names: Kristen
    orcid: "https://orcid.org/0000-0002-8746-614X"
  -
    family-names: Rengers
    given-names: Francis
    orcid: "https://orcid.org/0000-0002-1825-0943"
title: "landlab"
identifiers:
  -
    type: doi
    value: 10.5194/esurf-8-379-2020
    description: >-
      "Short communication: Landlab v2.0: A software package for
      Earth surface dynamics". Earth Surface Dynamics Discussions,
      May 2020, Volume 8, Issue 2
  -
    type: doi
    value: 10.5194/esurf-5-21-2017
    description: >-
      "Creative computing with Landlab: an open-source
       toolkit for building, coupling, and exploring
       two-dimensional numerical models of
       Earth-surface dynamics". Earth Surface Dynamics,
       January 2017, Volume 5, Issue 1
  -
    type: doi
    value: 10.5281/zenodo.3776837
    description: The versioned DOI for the version 2.0.1 of landlab.
  -
    type: doi
    value: 10.5281/zenodo.595872
    description: The concept DOI for the collection containing all versions of landlab.
repository-code: "https://github.com/landlab/landlab"
url: "https://landlab.csdms.io"
date-released: "2020-04-29"
keywords:
  - "bmi"
  - "component modeling"
  - "earth science"
  - "gridding engine"
  - "model coupling"
  - "numerical modeling"
license: MIT
doi: 10.5281/zenodo.595872
...



================================================
File: CONTRIBUTING.md
================================================
# Contributing to landlab

Thank you for contributing to Landlab! We appreciate
your help as this is largely as volunteer effort! :heart: :heart: :heart:

# How to contribute

## Reporting Bugs

Before creating a bug report, please do at least a cursory check that the
bug has not already been reported by searching the Issues portion of the
GitHub repository. If it has, add a comment to the existing issue instead of
opening a new one.

### Submitting a Bug Report

Bugs are tracked as
[GitHub issues](https://guides.github.com/features/issues/). After you've
determined you've found a new bug, please open a
[new issue](https://github.com/landlab/landlab/issues).

Explain the problem and include additional details to help maintainers
reproduce the problem. Here are some items that will make it easier
to track down the source of the problem.

*  **Use a clear and descriptive title** for the issue that identifies the
   problem.
*  **Describe the exact steps that reproduce the problem**.
*  **Provide a [minimal example](https://stackoverflow.com/help/minimal-reproducible-example)
   that demonstrates the steps** as, for example, a bash script
   along with input files. This example should reproduce your
   problem with as few lines of code as possible and easily
   reproducible my another person. Such an example almost certainly will not
   include an input file or any dependencies beyond those required by the
   `landlab_dev` conda environment.
*  **Describe the behavior you are seeing after these steps**.
*  **Describe the behavior you expect to see after these steps**.

Additionally, the answers to the following questions about your run
environment will be helpful.

*  **Which version of landlab are you using?** This could be a specific
   git sha or a release number. The best way to find this information is to
   import landlab and evaluate `landlab.__version__`
*  **What is he name and version of you OS?**
*  **What compiler are you using?**
*  **How did you build landlab (if using the development version)?**


## Submitting Changes

:tada: Whoa! This is great! We love it when folks contibute code! :tada:

Changes to landlab should be submitted as
[pull requests](http://help.github.com/pull-requests/)).

*  Create a GitHub issue that describes what you propose to do.
*  Create a topic branch that contains your changes.
*  Open a new [GitHub pull request](https://github.com/landlab/landlab/pull/new/master).
*  Ensure the pull request description clearly describes the problem
   and solution. Include the relevant issue number.

### Git Commit Messages

* Use the present tense ("Add feature" not "Added feature")
* Use the imperative mood ("Move cursor to..." not "Moves cursor to...")
* Limit the first line to 72 characters or less
* Reference issues and pull requests liberally
* For fun, consider starting the commit message with an applicable emoji:
    * :art: `:art:` when improving the format/structure of the code
    * :racehorse: `:racehorse:` when improving performance
    * :non-potable_water: `:non-potable_water:` when plugging memory leaks
    * :memo: `:memo:` when writing docs
    * :penguin: `:penguin:` when fixing something on Linux
    * :apple: `:apple:` when fixing something on macOS
    * :checkered_flag: `:checkered_flag:` when fixing something on Windows
    * :bug: `:bug:` when fixing a bug
    * :fire: `:fire:` when removing code or files
    * :green_heart: `:green_heart:` when fixing the CI build
    * :white_check_mark: `:white_check_mark:` when adding tests
    * :shirt: `:shirt:` when removing linter warnings

### Pull Request Messages

  * Rename the pull request and provide a comment that synthesizes what
    the pull request changes or adds. This helps us synthesize what
    changes have occured between Landlab releases.

## Adding new components

If you would like to create a new component, we a few conventions that we would
like you to follow.

Please visit [this part](https://landlab.csdms.io/install/)
of the main Landlab documentation page to read about developer installation,
guidelines to contributing code, and our software development practices.

**Landlab 2 is Python >=3.6 only.**

Thanks! :heart: :heart: :heart:

The Landlab team



================================================
File: LICENSE.md
================================================
# The MIT License (MIT)

Copyright (c) `2013` `The Landlab Team`

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
File: MANIFEST.in
================================================
include .credits.toml
include .mailmap
include AUTHORS.rst
include CHANGES.rst
include FUNDING.rst
include LICENSE.rst
include README.rst
include USEDBY.rst
include CITATION.cff
include cython-files.txt
include requirements*
include noxfile.py
include notebooks.py

recursive-include docs *.txt
recursive-include landlab README.md
recursive-include requirements *.md *.txt
recursive-include src/landlab *.pyx *.pxd *.hpp
recursive-include src/landlab/data *
recursive-include tests *py
recursive-include tests *.asc
recursive-include tests *.dbf
recursive-include tests *.nc
recursive-include tests *.shp
recursive-include tests *.shx
recursive-include tests *.txt
recursive-include tests *.yaml
recursive-include tests *.pyx *.pxd *.hpp

exclude .readthedocs.yaml
exclude conftest.py
exclude CONTRIBUTING.md
exclude environment*yml
exclude .pre-commit-config.yaml

recursive-exclude docs *
recursive-exclude joss *
recursive-exclude news *
recursive-exclude notebooks *
recursive-exclude scripts *py
recursive-exclude scripts *sh
recursive-exclude landlab *.c *.cpp
recursive-exclude tests *.c *.cpp

prune */__pycache__
global-exclude *.so *.pyc *.pyo *.pyd *.swp *.bak *~



================================================
File: conftest.py
================================================
import numpy as np
import pytest


@pytest.fixture(scope="session", autouse=True)
def set_numpy_printoptions():
    np.set_printoptions(legacy="1.25")



================================================
File: environment-dev.yml
================================================
name: landlab_dev
dependencies:
- pip
- pip:
  - -r requirements.txt
  - -r requirements-testing.txt
  - -r requirements-dev.txt
  - -r requirements-notebooks.txt
  - -r requirements-docs.txt



================================================
File: environment.yml
================================================
name: landlab_notebooks
channels:
  - conda-forge
dependencies:
- landlab>=2.1
- pip
- pip:
  - -r notebooks/requirements.in



================================================
File: notebooks.py
================================================
"""Get the landlab tutorial and teaching notebooks.

Run this script to fetch the set of *landlab* notebooks compatible with
an installed version of landlab.

Usage
-----

Get notebooks for a currently installed *landlab*,

    $ python -m notebooks

To get notebooks for a particular version of *landlab*, provide
a version number as an argument. For example,

    $ python -m notebooks 2.5.0
"""

import argparse
import os
import pathlib
import sys
import tarfile
from urllib.error import HTTPError
from urllib.parse import urljoin
from urllib.request import urlopen

from packaging.version import Version


def main(version=None):
    if version in ("master", "latest", "dev"):
        version = None

    if not version or (version := Version(version)).is_devrelease:
        tag = "master"
    else:
        tag = "v" + version.base_version

    notebooks = NotebookFetcher(tag)

    out(f"fetching notebooks for landlab {notebooks.version}")
    out(f"{notebooks.url}")

    try:
        stream = notebooks.open()
    except NotebookError as error:
        err(str(error))
        return -1

    with tarfile.open(fileobj=stream, mode="r|gz") as tfile:
        base = NotebookExtractor(tfile).extract()

    out(f"notebooks have been extracted into {base}")
    out("To run the notebooks first install the required dependencies:")
    out("")
    out(f"    $ conda install --file={base}/requirements-notebooks.txt")
    out("")
    out("and then open the welcome notebook:")
    out("")
    out(f"    $ jupyter notebook {base}/notebooks/welcome.ipynb")
    print(base)

    return 0


class NotebookError(Exception):
    def __init__(self, msg):
        self._msg = msg

    def __str__(self):
        return self._msg


class NotebookFetcher:
    URL = "https://github.com/landlab/landlab/archive/refs"

    def __init__(self, version):
        self._version = version

    @property
    def version(self):
        return self._version

    @property
    def url(self):
        return urljoin(NotebookFetcher.URL, f"{self.version}.tar.gz")

    def open(self):
        try:
            stream = urlopen(self.url)
        except HTTPError as error:
            if error.code == 404:
                msg = f"unable to find notebooks for requested landlab version ({self.version})"
            else:
                msg = f"unable to fetch notebooks ({error.reason})"
            raise NotebookError(msg) from error
        else:
            return stream


class NotebookExtractor:
    def __init__(self, tfile):
        self._tfile = tfile
        self._names = []

    def extract(self):
        self._tfile.extractall(members=self._notebooks())
        return self.base

    def _notebooks(self):
        for tarinfo in self._tfile:
            parts = pathlib.Path(tarinfo.name).parts
            if (len(parts) > 1 and parts[1] == "notebooks") or (
                parts[-1] == "requirements-notebooks.txt"
            ):
                self._names.append(tarinfo.name)
                yield tarinfo

    @property
    def names(self):
        return sorted(self._names)

    @property
    def base(self):
        return pathlib.Path(os.path.commonprefix(self.names))


def out(text):
    print("\033[1m" + text + "\033[0m", file=sys.stderr)


def err(text):
    print("\033[91m" + text + "\033[0m", file=sys.stderr)


if __name__ == "__main__":
    try:
        import landlab
    except ModuleNotFoundError:
        version = ""
    else:
        version = landlab.__version__

    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "version",
        metavar="VERSION",
        nargs="?",
        default=version,
        help="a landlab version (e.g. 2.5.0)",
    )
    args = parser.parse_args()

    sys.exit(main(args.version))



================================================
File: noxfile.py
================================================
import difflib
import glob
import json
import os
import pathlib
import shutil

import nox
from packaging.requirements import Requirement

PROJECT = "landlab"
ROOT = pathlib.Path(__file__).parent
PYTHON_VERSION = "3.12"
PATH = {
    "build": ROOT / "build",
    "docs": ROOT / "docs",
    "nox": pathlib.Path(".nox"),
    "requirements": ROOT / "requirements",
    "root": ROOT,
}


@nox.session(python=PYTHON_VERSION)
def build(session: nox.Session) -> str:
    """Build sdist and wheel dists."""
    outdir = str(PATH["build"] / "wheelhouse")

    os.environ["WITH_OPENMP"] = "1"

    session.log(f"CC = {os.environ.get('CC', 'NOT FOUND')}")
    session.install(
        "build",
        *("-r", PATH["requirements"] / "required.txt"),
    )

    session.run("python", "-m", "build", "--outdir", outdir)

    return outdir


@nox.session(python=PYTHON_VERSION)
def install(session: nox.Session) -> None:
    arg = session.posargs[0] if session.posargs else build(session)

    session.install("-r", PATH["requirements"] / "required.txt")

    if os.path.isdir(arg):
        session.install("landlab", f"--find-links={arg}", "--no-deps", "--no-index")
    elif os.path.isfile(arg):
        session.install(arg, "--no-deps")
    else:
        session.error("first argument must be either a wheel or a wheelhouse folder")


@nox.session(python=PYTHON_VERSION)
def test(session: nox.Session) -> None:
    """Run the tests."""
    session.install("-r", PATH["requirements"] / "testing.txt")
    install(session)

    session.run(
        "coverage",
        "run",
        "--source=landlab,tests",
        "--branch",
        "--module",
        "pytest",
        env={"PYTEST_ADDOPTS": os.environ.get("PYTEST_ADDOPTS", "-m 'not richdem'")},
    )
    session.run("coverage", "report", "--ignore-errors", "--show-missing")
    session.run("coverage", "xml", "-o", "coverage.xml")


@nox.session(name="test-notebooks", python=PYTHON_VERSION)
def test_notebooks(session: nox.Session) -> None:
    """Run the notebooks."""
    session.install(
        "git+https://github.com/mcflugen/nbmake.git@v1.5.4-markers",
        *("-r", PATH["requirements"] / "testing.txt"),
        *("-r", PATH["requirements"] / "notebooks.txt"),
    )
    install(session)

    session.run(
        "pytest",
        "notebooks",
        "--nbmake",
        "--nbmake-kernel=python3",
        "--nbmake-timeout=3000",
        *("-n", "auto"),
        "-vvv",
        env={"PYTEST_ADDOPTS": os.environ.get("PYTEST_ADDOPTS", "-m 'not richdem'")},
    )


@nox.session(name="test-richdem", venv_backend="conda")
def test_richdem(session: nox.Session) -> None:
    """Run richdem tests."""
    session.conda_install("richdem", channel=["nodefaults", "conda-forge"])
    session.install(
        "git+https://github.com/mcflugen/nbmake.git@v1.5.4-markers",
        *("-r", PATH["requirements"] / "testing.txt"),
        *("-r", PATH["requirements"] / "notebooks.txt"),
    )
    install(session)

    session.run(
        "coverage",
        "run",
        "--source=landlab,tests",
        "--branch",
        "--module",
        "pytest",
        "tests",
        "notebooks",
        "--nbmake",
        "--nbmake-kernel=python3",
        "--nbmake-timeout=3000",
        *("-m", "richdem"),
        *("-n", "auto"),
        "-vvv",
    )
    session.run("coverage", "report", "--ignore-errors", "--show-missing")
    session.run("coverage", "xml", "-o", "coverage.xml")


@nox.session(name="test-cli")
def test_cli(session: nox.Session) -> None:
    """Test the command line interface."""
    install(session)
    session.run("landlab", "--help")
    session.run("landlab", "--version")
    session.run("landlab", "index", "--help")
    session.run("landlab", "list", "--help")
    session.run("landlab", "provided-by", "--help")
    session.run("landlab", "provides", "--help")
    session.run("landlab", "used-by", "--help")
    session.run("landlab", "uses", "--help")
    session.run("landlab", "validate", "--help")


@nox.session
def lint(session: nox.Session) -> None:
    """Look for lint."""
    skip_hooks = [] if "--no-skip" in session.posargs else ["check-manifest", "pyroma"]

    if session.virtualenv.venv_backend != "none":
        session.install("pre-commit")

    session.run("pre-commit", "run", "--all-files", env={"SKIP": ",".join(skip_hooks)})


@nox.session
def towncrier(session: nox.Session) -> None:
    """Check that there is a news fragment."""
    session.install("towncrier")
    session.run("towncrier", "check", "--compare-with", "origin/master")


@nox.session(name="build-index")
def build_index(session: nox.Session) -> None:
    index_file = ROOT / "docs" / "index.toml"
    header = """
# This file was automatically generated with:
#     nox -s build-index
    """.strip()

    session.install("sphinx")
    session.install(".")

    with open(index_file, "w") as fp:
        print(header, file=fp, flush=True)
        session.run(
            "landlab", "--silent", "index", "components", "fields", "grids", stdout=fp
        )
    session.log(f"generated index at {index_file!s}")


@nox.session(name="docs-build")
def docs_build(session: nox.Session) -> None:
    """Build the docs."""
    docs_build_api(session)
    docs_build_notebook_index(session)

    session.install("-r", PATH["requirements"] / "docs.txt")

    PATH["build"].mkdir(exist_ok=True)
    session.run(
        "sphinx-build",
        *("-j", "auto"),
        *("-b", "html"),
        # "-W",
        "--keep-going",
        PATH["docs"] / "source",
        PATH["build"] / "html",
    )
    session.log(f"generated docs at {PATH['build'] / 'html'!s}")


@nox.session(name="docs-check-links")
def docs_check_links(session: nox.Session) -> None:
    """Check for working links in the docs."""
    docs_build_api(session)
    docs_build_notebook_index(session)

    session.install("-r", PATH["requirements"] / "docs.txt")

    PATH["build"].mkdir(exist_ok=True)
    session.run(
        "sphinx-build",
        *("-j", "auto"),
        *("-b", "linkcheck"),
        "--keep-going",
        PATH["docs"] / "source",
        PATH["build"] / "html",
        success_codes=(0, 1),
    )

    output_json = PATH["build"] / "html" / "output.json"

    broken_links = [
        f"{entry['filename']}:{entry['lineno']}:{entry['uri']}"
        for entry in load_linkcheck_output(output_json)
        if entry["status"] == "broken" and not entry["info"].startswith("403")
    ]

    if broken_links:
        print("\n".join(sorted(broken_links)))
        session.error(
            f"{len(broken_links)} broken links were found."
            f" see {output_json} for a complete log"
        )
    else:
        session.log("no broken links were found")


def load_linkcheck_output(filepath):
    with open(filepath) as stream:
        entries = [json.loads(line) for line in stream.readlines()]
    return entries


@nox.session(name="docs-build-api")
def docs_build_api(session: nox.Session) -> None:
    docs_dir = PATH["docs"] / "source"

    generated_dir = os.path.join(docs_dir, "generated", "api")

    if session.virtualenv.venv_backend != "none":
        session.install("-r", PATH["requirements"] / "docs.txt")

    session.log(f"generating api docs in {generated_dir}")
    session.run(
        "sphinx-apidoc",
        "-e",
        "-force",
        "--no-toc",
        "--module-first",
        *("-d", "2"),
        f"--templatedir={docs_dir / '_templates'}",
        *("-o", generated_dir),
        "src/landlab",
        "*.pyx",
        "*.so",
    )


@nox.session(name="docs-build-gallery-index", python=None)
def docs_build_notebook_index(session: nox.Session) -> None:
    docs_dir = PATH["docs"] / "source"

    for gallery in ("tutorials", "teaching"):
        gallery_index = docs_dir / "generated" / gallery / "index.md"
        os.makedirs(os.path.dirname(gallery_index), exist_ok=True)

        sections = [
            os.path.abspath(f.path)
            for f in os.scandir(docs_dir / gallery)
            if f.is_dir()
        ]

        content = (
            [
                f"""\
({gallery}-gallery)=

# {gallery.title()} Gallery
"""
            ]
            + [
                format_nbgallery(section, str(docs_dir), level=2)
                for section in sorted(sections)
            ]
        )

        with open(gallery_index, "w") as fp:
            print((2 * os.linesep).join(content), file=fp)

        session.log(gallery_index)


def format_nbgallery(path, start, level=1):
    title = pathlib.Path(path).stem.replace("_", " ").title()

    p = os.path.relpath(path, start)

    files = []
    if glob.glob(os.path.join(path, "*.ipynb")):
        files += [f"/{p}/*"]
    if glob.glob(os.path.join(path, "**/*.ipynb")):
        files += [f"/{p}/**"]

    body = "\n".join(files)
    return (
        f"""\
{'#' * level} {title}

```{{nbgallery}}
:glob:

{body}
```
"""
        if files
        else ""
    )


@nox.session(name="check-versions")
def check_package_versions(session, files=("required.txt",)):
    output_lines = session.run("pip", "list", "--format=json", silent=True).splitlines()

    installed_version = {
        p["name"].lower(): p["version"] for p in json.loads(output_lines[0])
    }

    for file_ in files:
        required_version = {}
        with (PATH["requirements"] / file_).open() as fp:
            for line in fp.readlines():
                requirement = Requirement(line)
                required_version[requirement.name.lower()] = requirement.specifier

        mismatch = set()
        for name, version in required_version.items():
            if name not in installed_version or not version.contains(
                installed_version[name]
            ):
                mismatch.add(name)

        session.log(f"Checking installed package versions for {file_}")
        for name in sorted(required_version):
            print(f"[{name}]")
            print(f"requested = {str(required_version[name])!r}")
            if name in installed_version:
                print(f"installed = {installed_version[name]!r}")
            else:
                print("installed = false")

        if mismatch:
            session.warn(
                f"There were package version mismatches for packages required in {file_}"
            )


@nox.session
def locks(session: nox.Session) -> None:
    """Create lock files."""
    folders = session.posargs or [".", "docs", "notebooks"]

    session.install("pip-tools")

    def upgrade_requirements(src, dst="requirements.txt"):
        with open(dst, "wb") as fp:
            session.run("pip-compile", "--upgrade", src, stdout=fp)

    for folder in folders:
        with session.chdir(ROOT / folder):
            upgrade_requirements("requirements.in", dst="requirements.txt")

    for folder in folders:
        session.log(f"updated {ROOT / folder / 'requirements.txt'!s}")

    # session.install("conda-lock[pip_support]")
    # session.run("conda-lock", "lock", "--mamba", "--kind=lock")


@nox.session(name="sync-requirements", python=PYTHON_VERSION, venv_backend="conda")
def sync_requirements(session: nox.Session) -> None:
    """Sync requirements.in with pyproject.toml."""
    with open("requirements.in", "w") as fp:
        session.run(
            "python",
            "-c",
            """
import os, tomllib
with open("pyproject.toml", "rb") as fp:
    print(os.linesep.join(sorted(tomllib.load(fp)["project"]["dependencies"])))
""",
            stdout=fp,
        )


@nox.session(python=False, name="check-cython-files")
def check_cython_files(session: nox.Session) -> None:
    """Find cython files for extension modules."""
    cython_files = {
        str(p.relative_to(PATH["root"]))
        for p in pathlib.Path(PATH["root"] / "src" / "landlab").rglob("**/*.pyx")
    }
    print(os.linesep.join(sorted(cython_files)))

    with open("cython-files.txt") as fp:
        actual = [line.rstrip() for line in fp.readlines()]

    diff = list(
        difflib.unified_diff(
            actual, sorted(cython_files), fromfile="old", tofile="new", lineterm=""
        )
    )
    if diff:
        session.error("\n".join([""] + diff + ["cython-files.txt needs updating"]))


@nox.session
def release(session):
    """Tag, build and publish a new release to PyPI."""
    session.install("zest.releaser[recommended]")
    session.install("zestreleaser.towncrier")
    session.run("fullrelease")


@nox.session(name="publish-testpypi")
def publish_testpypi(session):
    """Publish wheelhouse/* to TestPyPI."""
    session.run("twine", "check", "build/wheelhouse/*")
    session.run(
        "twine",
        "upload",
        "--skip-existing",
        "--repository-url",
        "https://test.pypi.org/legacy/",
        "build/wheelhouse/*.tar.gz",
    )


@nox.session(name="publish-pypi")
def publish_pypi(session):
    """Publish wheelhouse/* to PyPI."""
    session.run("twine", "check", "build/wheelhouse/*")
    session.run(
        "twine",
        "upload",
        "--skip-existing",
        "build/wheelhouse/*.tar.gz",
    )


@nox.session(python=False)
def clean(session):
    """Remove all .venv's, build files and caches in the directory."""
    for folder in _args_to_folders(session.posargs):
        with session.chdir(folder):
            shutil.rmtree("build", ignore_errors=True)
            shutil.rmtree("build/wheelhouse", ignore_errors=True)
            shutil.rmtree(f"src/{PROJECT}.egg-info", ignore_errors=True)
            shutil.rmtree(".pytest_cache", ignore_errors=True)
            shutil.rmtree(".venv", ignore_errors=True)

            for pattern in ["*.py[co]", "__pycache__"]:
                _clean_rglob(pattern)


@nox.session(python=False, name="clean-checkpoints")
def clean_checkpoints(session):
    """Remove jupyter notebook checkpoint files."""
    for folder in _args_to_folders(session.posargs):
        with session.chdir(folder):
            _clean_rglob("*-checkpoint.ipynb")
            _clean_rglob(".ipynb_checkpoints")


@nox.session(python=False, name="clean-docs")
def clean_docs(session: nox.Session) -> None:
    """Clean up the docs folder."""
    if (PATH["build"] / "html").is_dir():
        with session.chdir(PATH["build"]):
            shutil.rmtree("html")

    if PATH["build"].is_dir():
        session.chdir(PATH["build"])
        if os.path.exists("html"):
            shutil.rmtree("html")


@nox.session(python=False, name="clean-ext")
def clean_ext(session: nox.Session) -> None:
    """Clean shared libraries for extension modules."""
    for folder in _args_to_folders(session.posargs):
        with session.chdir(folder):
            _clean_rglob("*.so")


@nox.session(python=False)
def nuke(session):
    """Run all clean sessions."""
    clean_checkpoints(session)
    clean_docs(session)
    clean(session)
    clean_ext(session)


@nox.session(name="list-wheels")
def list_wheels(session):
    print(os.linesep.join(_get_wheels(session)))


@nox.session(name="list-ci-matrix")
def list_ci_matrix(session):
    """Create a matrix entry for a gha workflow that builds wheels"""

    def _os_from_wheel(name):
        if "linux" in name:
            return "ubuntu-" + ("24.04" if name.endswith("x86_64") else "24.04-arm")
        elif "macos" in name:
            return "macos-" + ("13" if name.endswith("x86_64") else "14")
        elif "win" in name:
            return "windows-2022"

    include_lines = [
        f"- {{ os: {_os_from_wheel(wheel)}, cibw-only: {wheel} }}"
        for wheel in _get_wheels(session)
    ]
    print("\n".join(sorted(include_lines)))


def _get_wheels(session):
    platforms = session.posargs or ["linux", "macos", "windows"]
    session.install("cibuildwheel")

    wheels = []
    for platform in platforms:
        wheels += session.run(
            "cibuildwheel",
            "--print-build-identifiers",
            "--platform",
            platform,
            silent=True,
        ).splitlines()
    return wheels


def _args_to_folders(args):
    return [ROOT] if not args else [pathlib.Path(f) for f in args]


def _clean_rglob(pattern):
    for p in pathlib.Path(".").rglob(pattern):
        if PATH["nox"] in p.parents:
            continue
        if p.is_dir():
            p.rmdir()
        else:
            p.unlink()


@nox.session
def credits(session):
    """Update the various authors files."""
    from landlab.cmd.authors import AuthorsConfig

    config = AuthorsConfig()

    with open(".mailmap", "wb") as fp:
        session.run(
            "landlab", "--silent", "authors", "mailmap", stdout=fp, external=True
        )

    contents = session.run(
        "landlab",
        "--silent",
        "authors",
        "create",
        "--update-existing",
        external=True,
        silent=True,
    )
    with open(config["credits_file"], "w") as fp:
        print(contents, file=fp, end="")

    contents = session.run(
        "landlab", "--silent", "authors", "build", silent=True, external=True
    )
    with open(config["authors_file"], "w") as fp:
        print(contents, file=fp, end="")



================================================
File: pyproject.toml
================================================
[build-system]
requires = ["cython", "numpy>=2.0,<3", "setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "landlab"
description = "Open-source Python package for numerical modeling of Earth surface dynamics."
authors = [
  {email = "mcflugen@gmail.com"},
  {name = "The landlab team"}
]
maintainers = [
  {email = "mcflugen@gmail.com"},
  {name = "The landlab team"}
]
keywords = [
  "bmi",
  "component modeling",
  "earth science",
  "gridding engine",
  "model coupling",
  "numerical modeling",
]
classifiers = [
  "Development Status :: 4 - Beta",
  "Intended Audience :: Science/Research",
  "License :: OSI Approved :: MIT License",
  "Operating System :: OS Independent",
  "Programming Language :: Cython",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: 3.13",
  "Programming Language :: Python :: Implementation :: CPython",
  "Topic :: Scientific/Engineering :: Physics",
]
requires-python = ">=3.10"
dependencies = [
  "bmipy",
  "importlib-resources; python_version < '3.12'",
  "matplotlib",
  "netcdf4",
  "numpy >=1.20",
  "pyyaml",
  "pyshp != 2.3.0",
  "rich-click",
  "scipy",
  "statsmodels",
  "pandas",
  "xarray >= 0.16",
]
dynamic = ["readme", "version"]

[project.license]
text = "MIT"

[project.urls]
homepage = "https://github.com/landlab"
documentation = "https://landlab.csdms.io"
repository = "https://github.com/landlab"
changelog = "https://github.com/landlab/landlab/blob/develop/CHANGES.md"

[project.optional-dependencies]
dev = ["nox"]
testing = [
  "coverage",
  "hypothesis",
  "pytest",
  "pytest-datadir",
  "pytest-xdist",
]

[project.scripts]
landlab = "landlab.cmd.landlab:landlab"

[tool.setuptools]
include-package-data = true
package-dir = { "" = "src" }

[tool.setuptools.package-data]
landlab = [
  "tests/*txt",
  "data/*asc",
  "data/*nc",
  "data/*shp",
  "test/*shx",
  "data/*dbf",
  "preciptest.in",
  "test_*/*nc",
  "test_*/*asc",
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.dynamic]
version = {attr = "landlab._version.__version__"}

[tool.setuptools.dynamic.readme]
file = ["README.md", "AUTHORS.md"]
content-type = "text/markdown"

[tool.pytest.ini_options]
minversion = "6.0"
testpaths = ["notebooks", "landlab", "tests"]
norecursedirs = [".*", "*.egg*", "build", "dist", "examples"]
addopts = """
  --ignore setup.py
  --tb native
  --durations 16
  --strict-markers
  --doctest-modules
  -vvv
  --ignore-glob=*/animate-landlab-output.ipynb
  --ignore-glob=*/cellular_automaton_vegetation_flat_domain.ipynb
  --ignore-glob=*/cellular_automaton_vegetation_DEM.ipynb
  --ignore-glob=*/lithology_and_litholayers.ipynb
  --ignore-glob=*/nst_scaling_profiling.ipynb
  --ignore-glob=*/test_networkcreator_otherDEMs.ipynb
  --ignore-glob=*/run_network_generator_OpenTopoDEM.ipynb
"""
doctest_optionflags = [
  "NORMALIZE_WHITESPACE",
  "IGNORE_EXCEPTION_DETAIL"
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "richdem: marks tests that use richdem (deselect with '-m \"not richdem\"')",
    "notebook: marks tests as notebook (deselect with '-m \"not notebook\"')"
]

[tool.isort]
combine_as_imports = true
known_first_party = "landlab"
profile = "black"

[tool.check-manifest]
ignore = [".nox", "build"]

[tool.cibuildwheel]
build = "cp310-* cp311-* cp312-*"
skip = "*-musllinux_* *-win32*"
archs = "x86_64,aarch64,arm64,AMD64,x86"
test-command = [
	"python -c \"import landlab; print(landlab.__version__)\"",
	"python -c \"from landlab import RasterModelGrid; print(RasterModelGrid((3, 3)))\"",
]

[tool.cibuildwheel.linux.environment]
CPPFLAGS = "-fopenmp"

[tool.cibuildwheel.macos.environment]
MACOSX_DEPLOYMENT_TARGET = "12.0"
CC = "clang"
CXX = "clang++"
# CPPFLAGS = "-Xclang -fopenmp"
# LDFLAGS = "-lomp"

[tool.cython-lint]
max-line-length = 88
exclude = "tests/components/flow_router/ext/single_flow/priority_routing/test_breach_c.pyx"

[tool.conda-lock]
channels = ["conda-forge", "defaults"]
platforms = ["osx-arm64", "linux-64", "osx-64", "win-64"]

[tool.towncrier]
directory = "news"
name = "landlab"
filename = "CHANGES.md"
create_add_extension = false
single_file = true
underlines = [
    "",
    "",
    "",
]
start_string = """
<!-- towncrier release notes start -->
"""
template = "news/changelog_template.jinja"
issue_format = "[#{issue}](https://github.com/landlab/landlab/issues/{issue})"
title_format = "## {version} ({project_date})"
type = [
  {name="✨ New Components", directory="component", showcontent=true},
  {name="📚 New Tutorial Notebooks", directory="notebook", showcontent=true},
  {name="🍰 New Features", directory="feature", showcontent=true},
  {name="🛠️ Bug Fixes", directory="bugfix", showcontent=true},
  {name="📖 Documentation Enhancements", directory="docs", showcontent=true},
  {name="🔩 Other Changes and Additions", directory="misc", showcontent=true},
]

[tool.landlab.credits]
exclude = '''
(?x)^(
  \(no\ author\)|
  root|
  .*\[bot\]  # ignore all bots
)
'''
authors_file = "AUTHORS.md"
author_format = "- [{name}](https://github.com/{github})"
start_string = "<!-- credits-roll start-author-list -->"



================================================
File: requirements-testing.in
================================================
# Requirements extracted from pyproject.toml
# [project.optional-dependencies] testing
coverage
flaky
hypothesis
pytest
pytest-datadir
pytest-xdist



================================================
File: requirements.in
================================================
bmipy
importlib-resources; python_version < '3.12'
matplotlib
netcdf4
numpy >=1.20
pandas
pyshp != 2.3.0
pyyaml
rich-click
scipy
statsmodels
xarray >= 0.16



================================================
File: setup.cfg
================================================
[flake8]
exclude = docs, build, .nox
ignore = C901, E203, E266, E501, E704, W503, B905
max-line-length = 88
max-complexity = 18
select = B,C,E,F,W,T4,B9

[zest.releaser]
tag-format = v{version}
python-file-with-version = src/landlab/_version.py

[coverage:run]
relative_files = True



================================================
File: setup.py
================================================
#! /usr/bin/env python
import numpy as np
from Cython.Build import cythonize
from setuptools import Extension
from setuptools import setup

with open("cython-files.txt") as fp:
    cython_files = {fname.strip() for fname in fp.readlines()}

ext_modules = cythonize(
    [
        Extension(
            path[4:-4].replace("/", "."),
            [path],
            define_macros=[("NPY_NO_DEPRECATED_API", "1")],
        )
        for path in cython_files
    ],
    compiler_directives={"embedsignature": True, "language_level": 3},
)

setup(
    include_dirs=[np.get_include()],
    ext_modules=ext_modules,
)






================================================
File: notebooks/requirements.in
================================================
bmi-topography >=0.5,!=0.8.1
dask[array]
holoviews
jupyter
mesa[network] >1



================================================
File: notebooks/welcome.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="http://landlab.github.io"><img style="float: left" src="landlab_header.png"></a>
"""

"""
# Welcome to the Landlab Notebooks

This page is provides an index to the Landlab Jupyter Notebooks. 

If you are not certain where to start, consider either:
- [the Landlab Syllabus](tutorials/syllabus.ipynb) if you are interested in teaching yourself Landlab
- [the Landlab teaching notebooks](teaching/welcome_teaching.ipynb) if you are an educator looking for tutorials to use in the classroom. 

## Other useful links
- [The Landlab Documentation](https://landlab.csdms.io/)
- [The Landlab code base](https://github.com/landlab/landlab)
- [The Landlab user guide](https://landlab.csdms.io/user_guide/)

## Notebooks by topic

### Introduction to python
- [Introduction to Python and NumPy](tutorials/python_intro/Python_intro.ipynb) *Learn about:* The very basics of Python.

### Introduction to Landlab
- [Introduction to Landlab: example model of fault-scarp degradation](tutorials/fault_scarp/landlab-fault-scarp.ipynb) A short overview of some of the things Landlab can do. 
- [Where to get info about Landlab](tutorials/where_to_get_info.ipynb) 
- [Introduction to the model grid object](tutorials/grid_object_demo/grid_object_demo.ipynb) Grid topology; how landlab represents data; connectivity of grid elements.
- [Introduction to Landlab data fields](tutorials/fields/working_with_fields.ipynb) How Landlab stores spatial data on the grid; a little on naming conventions.
- [Introduction to plotting output with Landlab](tutorials/plotting/landlab-plotting.ipynb) The basics of plotting with Landlab; combining matplotlib and out plots; the all-powerful ``imshow_grid()`` function.
- [Introduction to using the Landlab component library](tutorials/component_tutorial/component_tutorial.ipynb) The basics of working with and coupling components, using *diffusion*, *stream power*, and a *storm generator* as examples.
- [Using the gradient and flux-divergence functions](tutorials/gradient_and_divergence/gradient_and_divergence.ipynb) Landlab as solving environment for staggered grid finite difference differential approximations; functions available to help you do this.
- [Mapping values from nodes to links](tutorials/mappers/mappers.ipynb) Options for getting data on links to nodes, nodes to links, etc.; min, max, and mean; upwinding and downwinding schemes; one-to-one, one-to-many, and many-to-one mappings.
- Setting boundary conditions on Landlab grids (several tutorials): How Landlab conceptualises boundary conditions; various ways to interact and work with them.
  - [Raster perimeter](tutorials/boundary_conds/set_BCs_on_raster_perimeter.ipynb)
  - [Based on X-Y values](tutorials/boundary_conds/set_BCs_from_xy.ipynb)
  - [Watersheds](tutorials/boundary_conds/set_watershed_BCs_raster.ipynb)
  - [Voronoi](tutorials/boundary_conds/set_BCs_on_voronoi.ipynb)
- [Reading DEMs into Landlab](tutorials/reading_dem_into_landlab/reading_dem_into_landlab.ipynb) Getting an ARC ESRI ASCII into Landlab; getting the boundary conditions set right.
- [How to write a Landlab component](tutorials/making_components/making_components.ipynb) What makes up a Landlab Component Standard Interface; how to make one for your process model.

### Notebooks about components, models, or utilities

- Flow Direction and Accumulation 
  - [Introduction to the FlowDirector Components](tutorials/flow_direction_and_accumulation/the_FlowDirectors.ipynb)
  - [Introduction to the FlowAccumulator Component](tutorials/flow_direction_and_accumulation/the_FlowAccumulator.ipynb)
  - [Comparison of FlowDirector Components](tutorials/flow_direction_and_accumulation/compare_FlowDirectors.ipynb)
- Flexure
  - [Introduction](tutorials/flexure/flexure_1d.ipynb)
  - [Multiple loads](tutorials/flexure/lots_of_loads.ipynb)
- [OverlandFlow](tutorials/overland_flow/overland_flow_driver.ipynb)
- [Coupled rainfall runoff model with OverlandFlow](tutorials/overland_flow/coupled_rainfall_runoff.ipynb)
- [Diffusion, stream power, and the storm generator](tutorials/component_tutorial/component_tutorial.ipynb)
- Ecohydrology (these components not yet updated for v2.0)
  - [Ecohydrology Model on Flat Domain](tutorials/ecohydrology/cellular_automaton_vegetation_flat_surface/cellular_automaton_vegetation_flat_domain.ipynb)
  - [Ecohydrology Model on Actual Landscape](tutorials/ecohydrology/cellular_automaton_vegetation_DEM/cellular_automaton_vegetation_DEM.ipynb)
- [Spatially variable lithology: Lithology and Litholayers](tutorials/lithology/lithology_and_litholayers.ipynb)
- [NormalFault](tutorials/normal_fault/normal_fault_component_tutorial.ipynb)
- [Flow distance utility](tutorials/flow__distance_utility/application_of_flow__distance_utility.ipynb)
- [TransportLengthHillslopeDiffuser](tutorials/transport-length_hillslope_diffuser/TLHDiff_tutorial.ipynb)
- [Groundwater Hydrology](tutorials/groundwater/groundwater_flow.ipynb)
- NetworkSedimentTransporter
  - [Getting started with a simple synthetic grid](tutorials/network_sediment_transporter/network_sediment_transporter.ipynb)
  - [Using a shapefile of a real river network](tutorials/network_sediment_transporter/network_sediment_transporter_shapefile_network.ipynb)
  - [Plotting the network and parcels](tutorials/network_sediment_transporter/network_plotting_examples.ipynb)
  - [Explore scaling of the NetworkSedimentTransporter](tutorials/network_sediment_transporter/nst_scaling_profiling.ipynb)
  
### Teaching Notebooks

- [Quantifying river channel evolution with Landlab](teaching/geomorphology_exercises/channels_streampower_notebooks/stream_power_channels_class_notebook.ipynb)
- [Modeling Hillslopes and Channels with Landlab](teaching/geomorphology_exercises/drainage_density_notebooks/drainage_density_class_notebook.ipynb)
- [Linear diffusion exercise with Landlab](teaching/geomorphology_exercises/hillslope_notebooks/hillslope_diffusion_class_notebook.ipynb)
- [Using Landlab to explore a diffusive hillslope in the piedmont of North Carolina](teaching/geomorphology_exercises/hillslope_notebooks/north_carolina_piedmont_hillslope_class_notebook.ipynb)
- [Exploring rainfall driven hydrographs with Landlab](teaching/surface_water_hydrology_exercises/overland_flow_notebooks/hydrograph_class_notebook.ipynb)
"""



================================================
File: requirements/README.md
================================================
This directory contains several files that specify the versions of
our dependencies used in our CI workflows. *Landlab* does not require
these exact version numbers to work properly, these are what we
test against to ensure that things don't break as new versions
of our dependencies are released.

## Managed by dependabot

All files with a `.txt` extension are managed by dependabot and **should
not be manually edited** unless you need to add or remove a dependency.



================================================
File: requirements/docs.txt
================================================
furo==2024.8.6
ipython==8.29.0
myst-parser==4.0.0
nbsphinx==0.9.5
numpy==2.1.3
sphinx-copybutton==0.5.2
sphinx-inline-tabs==2023.4.21
sphinx-jinja==2.0.2
sphinx==8.1.3
sphinx_design==0.6.1
sphinxcontrib-towncrier==0.4.0a0
towncrier==23.11.0



================================================
File: requirements/notebooks.txt
================================================
bmi-topography==0.8.3
dask[array]==2024.6.2
holoviews==1.20.0
jupyter==1.1.1
mesa[network]==3.0.3



================================================
File: requirements/required.txt
================================================
bmipy==2.0.1
importlib-resources==6.4.0; python_version < '3.12'
matplotlib==3.10.0
netcdf4==1.7.2
numpy==2.2.3
pandas==2.2.3
pyshp==2.3.1
pyyaml==6.0.2
rich-click==1.8.5
scipy==1.15.1
statsmodels==0.14.4
xarray==2025.1.2



================================================
File: requirements/testing.txt
================================================
coverage==7.6.12
flaky==3.7.0
hypothesis==6.125.3
pytest==8.0.1
pytest-datadir==1.5.0
pytest-xdist==3.5.0




================================================
File: src/landlab/__init__.py
================================================
#! /usr/bin/env python
"""The Landlab.

:Package name: TheLandlab
:Release date: 2018-09-18
:Authors: Greg Tucker, Nicole Gasparini, Erkan Istanbulluoglu, Daniel Hobley,
    Sai Nudurupati, Jordan Adams, Eric Hutton, Katherine Barnhart, Margaux
    Mouchene, Nathon Lyons
:URL: https://landlab.csdms.io/
:License: MIT
"""
from landlab._registry import registry
from landlab._version import __version__
from landlab.core.errors import MissingKeyError
from landlab.core.errors import ParameterValueError
from landlab.core.model_component import Component
from landlab.core.model_parameter_loader import load_params
from landlab.core.utils import ExampleData
from landlab.field.errors import FieldError
from landlab.grid.base import ModelGrid
from landlab.grid.create import create_grid
from landlab.grid.framed_voronoi import FramedVoronoiGrid
from landlab.grid.hex import HexModelGrid
from landlab.grid.icosphere import IcosphereGlobalGrid
from landlab.grid.linkstatus import LinkStatus
from landlab.grid.network import NetworkModelGrid
from landlab.grid.nodestatus import NodeStatus
from landlab.grid.radial import RadialModelGrid
from landlab.grid.raster import RasterModelGrid
from landlab.grid.voronoi import VoronoiDelaunayGrid
from landlab.plot.imshow import imshow_grid
from landlab.plot.imshow import imshow_grid_at_node
from landlab.plot.imshowhs import imshowhs_grid
from landlab.plot.imshowhs import imshowhs_grid_at_node

cite_as = registry.format_citations

__all__ = [
    "__version__",
    "registry",
    "MissingKeyError",
    "ParameterValueError",
    "Component",
    "FieldError",
    "load_params",
    "ExampleData",
    "ModelGrid",
    "HexModelGrid",
    "RadialModelGrid",
    "RasterModelGrid",
    "FramedVoronoiGrid",
    "VoronoiDelaunayGrid",
    "NetworkModelGrid",
    "IcosphereGlobalGrid",
    "LinkStatus",
    "NodeStatus",
    "create_grid",
    "imshow_grid",
    "imshow_grid_at_node",
    "imshowhs_grid",
    "imshowhs_grid_at_node",
]



================================================
File: src/landlab/_info.py
================================================
name = "landlab"
cite_as = [
    """@article{hobley2017creative,
    title={Creative computing with Landlab: an open-source toolkit
        for building, coupling, and exploring two-dimensional
        numerical models of Earth-surface dynamics},
    author={Hobley, Daniel EJ and Adams, Jordan M and Nudurupati,
        Sai Siddhartha and Hutton, Eric WH and Gasparini, Nicole M and
        Istanbulluoglu, Erkan and Tucker, Gregory E},
    journal={Earth Surface Dynamics},
    volume={5},
    number={1},
    pages={21},
    year={2017},
    publisher={Copernicus GmbH}
    }
    @article{barnhart2020short,
    author = {Barnhart, K. R. and Hutton, E. W. H. and Tucker, G. E.
        and Gasparini, N. M. and Istanbulluoglu, E. and Hobley,
        D. E. J. and Lyons, N. J. and Mouchene, M. and Nudurupati,
        S. S. and Adams, J. M. and Bandaragoda, C.},
    title = {Short communication: Landlab v2.0: A software package
        for Earth surface dynamics},
    journal = {Earth Surface Dynamics Discussions},
    volume = {2020},
    year = {2020},
    pages = {1--25},
    url = {https://www.earth-surf-dynam-discuss.net/esurf-2020-12/},
    doi = {10.5194/esurf-2020-12}
    }"""
]



================================================
File: src/landlab/_registry.py
================================================
#! /usr/bin/env python
r"""Registry of landlab components being used.

The landlab registry keeps track of landlab components that have
be instantiated by a user. A user can then get a list of all
the components in use and then print a list of citations for
all of the components they have used.

Examples
--------
>>> from landlab import registry

>>> registry.registered
('landlab',)
>>> print(registry.format_citations())
# Citations
## landlab
    @article{hobley2017creative,
    title={Creative computing with Landlab: an open-source toolkit
        for building, coupling, and exploring two-dimensional
        numerical models of Earth-surface dynamics},
    author={Hobley, Daniel EJ and Adams, Jordan M and Nudurupati,
        Sai Siddhartha and Hutton, Eric WH and Gasparini, Nicole M and
        Istanbulluoglu, Erkan and Tucker, Gregory E},
    journal={Earth Surface Dynamics},
    volume={5},
    number={1},
    pages={21},
    year={2017},
    publisher={Copernicus GmbH}
    }
    @article{barnhart2020short,
    author = {Barnhart, K. R. and Hutton, E. W. H. and Tucker, G. E.
        and Gasparini, N. M. and Istanbulluoglu, E. and Hobley,
        D. E. J. and Lyons, N. J. and Mouchene, M. and Nudurupati,
        S. S. and Adams, J. M. and Bandaragoda, C.},
    title = {Short communication: Landlab v2.0: A software package
        for Earth surface dynamics},
    journal = {Earth Surface Dynamics Discussions},
    volume = {2020},
    year = {2020},
    pages = {1--25},
    url = {https://www.earth-surf-dynam-discuss.net/esurf-2020-12/},
    doi = {10.5194/esurf-2020-12}
    }

When a component contains citation information, and the component has been
instantiated (not just imported) the component citation is also included.

>>> from landlab import RasterModelGrid
>>> from landlab.components import Flexure

>>> grid = RasterModelGrid((4, 5))
>>> _ = grid.add_zeros("lithosphere__overlying_pressure_increment", at="node")
>>> _ = grid.add_zeros("lithosphere_surface__elevation_increment", at="node")
>>> flexure = Flexure(grid)
>>> print(registry.format_citations())
# Citations
## landlab
    @article{hobley2017creative,
    title={Creative computing with Landlab: an open-source toolkit
        for building, coupling, and exploring two-dimensional
        numerical models of Earth-surface dynamics},
    author={Hobley, Daniel EJ and Adams, Jordan M and Nudurupati,
        Sai Siddhartha and Hutton, Eric WH and Gasparini, Nicole M and
        Istanbulluoglu, Erkan and Tucker, Gregory E},
    journal={Earth Surface Dynamics},
    volume={5},
    number={1},
    pages={21},
    year={2017},
    publisher={Copernicus GmbH}
    }
    @article{barnhart2020short,
    author = {Barnhart, K. R. and Hutton, E. W. H. and Tucker, G. E.
        and Gasparini, N. M. and Istanbulluoglu, E. and Hobley,
        D. E. J. and Lyons, N. J. and Mouchene, M. and Nudurupati,
        S. S. and Adams, J. M. and Bandaragoda, C.},
    title = {Short communication: Landlab v2.0: A software package
        for Earth surface dynamics},
    journal = {Earth Surface Dynamics Discussions},
    volume = {2020},
    year = {2020},
    pages = {1--25},
    url = {https://www.earth-surf-dynam-discuss.net/esurf-2020-12/},
    doi = {10.5194/esurf-2020-12}
    }
<BLANKLINE>
## Flexure
    @article{hutton2008sedflux,
    title={Sedflux 2.0: An advanced process-response model that
        generates three-dimensional stratigraphy},
    author={Hutton, Eric WH and Syvitski, James PM},
    journal={Computers \& Geosciences},
    volume={34},
    number={10},
    pages={1319--1337},
    year={2008},
    publisher={Pergamon}
    }

Finally, the component's citation information is accessible through an
attribute called ``cite_as``:

>>> print(Flexure.cite_as)
    @article{hutton2008sedflux,
    title={Sedflux 2.0: An advanced process-response model that
        generates three-dimensional stratigraphy},
    author={Hutton, Eric WH and Syvitski, James PM},
    journal={Computers \& Geosciences},
    volume={34},
    number={10},
    pages={1319--1337},
    year={2008},
    publisher={Pergamon}
    }

"""

import os

from . import _info
from .core.messages import indent_and_wrap


class ComponentRegistry:
    """A registry for instantiated landlab components."""

    def __init__(self, objs=None):
        self._registered = []
        if objs is not None:
            try:
                [self.add(obj) for obj in objs]
            except TypeError:
                self.add(objs)

    def add(self, cls):
        """Add a class to the registry.

        Parameters
        ----------
        cls : Component
            A landlab component to register as used.
        """
        if cls not in self._registered:
            self._registered.append(cls)

    @property
    def registered(self):
        """All registered classes.

        Returns
        -------
        tuple
            The components in the registry.

        Examples
        --------
        >>> from landlab._registry import ComponentRegistry
        >>> registry = ComponentRegistry()
        >>> registry.registered
        ()
        >>> class FooBar(object):
        ...     pass
        ...
        >>> registry.add(FooBar)
        >>> registry.registered
        ('FooBar',)
        """
        return tuple(ComponentRegistry.get_name(obj) for obj in self._registered)

    @staticmethod
    def format_citation(obj):
        """Format a single citation.

        Parameters
        ----------
        obj : Component
            A landlab component class or instance.

        Returns
        -------
        str
            The formatted citation, or "None" if there is no citation
            given.

        Examples
        --------
        >>> from landlab._registry import ComponentRegistry
        >>> registry = ComponentRegistry()
        >>> class DoNothingComponent(object):
        ...     pass
        ...
        >>> print(registry.format_citation(DoNothingComponent))
        ## DoNothingComponent
            None

        >>> class SorterAndSearcher(object):
        ...     _cite_as = '''
        ... @book{knuth1998art,
        ... title={The art of computer programming: sorting and searching},
        ... author={Knuth, Donald Ervin},
        ... volume={3},
        ... year={1998},
        ... publisher={Pearson Education}
        ... }'''
        ...
        >>> print(registry.format_citation(SorterAndSearcher))
        ## SorterAndSearcher
            @book{knuth1998art,
            title={The art of computer programming: sorting and searching},
            author={Knuth, Donald Ervin},
            volume={3},
            year={1998},
            publisher={Pearson Education}
            }
        """
        name = ComponentRegistry.get_name(obj)
        header = [f"## {name}"]

        cite_as = ComponentRegistry.get_citations(obj)

        body = []
        for citation in cite_as:
            body.append(indent_and_wrap(citation, indent=" " * 4))

        return os.linesep.join(header + body)

    @staticmethod
    def get_name(obj):
        """Get the display name for an object.

        Examples
        --------
        >>> from landlab._registry import ComponentRegistry
        >>> class MontyPython(object):
        ...     name = "Eric Idle"
        ...
        >>> ComponentRegistry.get_name(MontyPython)
        'Eric Idle'
        >>> class MontyPython(object):
        ...     _name = "Graham Chapman"
        ...
        >>> ComponentRegistry.get_name(MontyPython)
        'Graham Chapman'
        >>> class MontyPython(object):
        ...     pass
        ...
        >>> ComponentRegistry.get_name(MontyPython)
        'MontyPython'

        """
        name = "Unknown"
        for attr in ("name", "_name", "__name__"):
            try:
                name = getattr(obj, attr)
            except AttributeError:
                pass
            else:
                break
        return name

    @staticmethod
    def get_citations(obj):
        """Get a list of citations from an object."""
        citations = "None"
        for attr in ("cite_as", "_cite_as"):
            try:
                citations = getattr(obj, attr)
            except AttributeError:
                pass
            else:
                break
        if isinstance(citations, str):
            citations = [citations]
        return citations

    def format_citations(self):
        """Format citations for all registered components.

        Returns
        -------
        str
            The formatted citations.

        Examples
        --------
        >>> from landlab._registry import ComponentRegistry
        >>> registry = ComponentRegistry()

        >>> class HolyGrailFinder(object):
        ...     _name = "Monty Python"
        ...     _cite_as = [
        ...         '''@book{python2000holy,
        ...         title={the Holy Grail},
        ...         author={Python, Monty and Chapman, Graham and Cleese, John and Gilliam, Terry and Jones, Terry and Idle, Eric and Palin, Michael},
        ...         year={2000},
        ...         publisher={EMI Records}
        ...         }''',
        ...         '''@book{chapman1989complete,
        ...         title={The Complete Monty Python's Flying Circus: All the Words. Volume one},
        ...         author={Chapman, Graham and Python, Monty},
        ...         volume={1},
        ...         year={1989},
        ...         publisher={Pantheon}
        ...         }''',
        ...     ]
        ...
        >>> class Evolution(object):
        ...     _cite_as = '''
        ...         @book{darwin1859origin,
        ...         title={On the origin of species},
        ...         author={Darwin, Charles},
        ...         year={1859},
        ...         publisher={Lulu. com}
        ...         }'''
        ...
        >>> registry.add(HolyGrailFinder)
        >>> registry.add(Evolution)
        >>> print(registry.format_citations())
        # Citations
        ## Monty Python
            @book{python2000holy,
            title={the Holy Grail},
            author={Python, Monty and Chapman, Graham and Cleese, John and
                Gilliam, Terry and Jones, Terry and Idle, Eric and Palin,
                Michael},
            year={2000},
            publisher={EMI Records}
            }
            @book{chapman1989complete,
            title={The Complete Monty Python's Flying Circus: All the Words.
                Volume one},
            author={Chapman, Graham and Python, Monty},
            volume={1},
            year={1989},
            publisher={Pantheon}
            }
        <BLANKLINE>
        ## Evolution
            @book{darwin1859origin,
            title={On the origin of species},
            author={Darwin, Charles},
            year={1859},
            publisher={Lulu. com}
            }
        """  # noqa: B950
        header = ["# Citations"]
        body = []
        for cls in self._registered:
            body.append(self.format_citation(cls))
        return os.linesep.join(header + [(2 * os.linesep).join(body)])

    def __repr__(self):
        return f"ComponentRegistry({repr(self.registered)})"


registry = ComponentRegistry(_info)



================================================
File: src/landlab/_version.py
================================================
__version__ = "2.9.2.dev0"



================================================
File: src/landlab/.gitignore
================================================
.qodo



================================================
File: src/landlab/bmi/__init__.py
================================================
from .bmi_bridge import TimeStepper
from .bmi_bridge import wrap_as_bmi

__all__ = ["TimeStepper", "wrap_as_bmi"]



================================================
File: src/landlab/bmi/bmi_bridge.py
================================================
"""Wrap landlab component with the Basic Modeling Interface

The `wrap_as_bmi` function wraps a landlab component class so that it
exposes a Basic Modeling Interface.

.. autosummary::

    ~wrap_as_bmi

.. sectionauthor:: Eric Hutton
"""

import inspect

import numpy as np
from bmipy import Bmi

from landlab.core import load_params
from landlab.core.model_component import Component
from landlab.framework.decorators import snake_case
from landlab.grid.create import create_grid
from landlab.grid.hex import HexModelGrid
from landlab.grid.raster import RasterModelGrid

BMI_LOCATION = {
    "node": "node",
    "link": "edge",
    "patch": "face",
    "corner": "node",
    "face": "edge",
    "cell": "face",
    "grid": "none",
}

BMI_GRID = {
    "node": 0,
    "link": 0,
    "patch": 0,
    "corner": 1,
    "face": 1,
    "cell": 1,
    "grid": 2,
}


class TimeStepper:
    """Step through time.

    Parameters
    ----------
    start : float, optional
        Clock start time.
    stop : float, optional
        Stop time.
    step : float, optional
        Time step.

    Examples
    --------
    >>> from landlab.bmi import TimeStepper
    >>> time_stepper = TimeStepper()
    >>> time_stepper.start
    0.0
    >>> time_stepper.stop is None
    True
    >>> time_stepper.step
    1.0
    >>> time_stepper.time
    0.0
    >>> for _ in range(10):
    ...     time_stepper.advance()
    ...
    >>> time_stepper.time
    10.0
    >>> time_stepper = TimeStepper(1.0, 13.0, 2.0)
    >>> [time for time in time_stepper]
    [1.0, 3.0, 5.0, 7.0, 9.0, 11.0]
    """

    def __init__(self, start=0.0, stop=None, step=1.0, units="s"):
        self._start = start
        self._stop = stop
        self._step = step
        self._units = units

        self._time = start

    def __iter__(self):
        if self.stop is None:
            while 1:
                yield self._time
                self._time += self._step
        else:
            while self._time < self._stop:
                yield self._time
                self._time += self._step
        return

    @property
    def time(self):
        """Current time."""
        return self._time

    @property
    def start(self):
        """Start time."""
        return self._start

    @property
    def stop(self):
        """Stop time."""
        return self._stop

    @property
    def step(self):
        """Time Step."""
        return self._step

    @step.setter
    def step(self, new_val):
        """Change the time step."""
        self._step = new_val

    @property
    def units(self):
        """Time units."""
        return self._units

    def advance(self):
        """Advance the time stepper by one time step."""
        self._time += self.step
        if self._stop is not None and self._time > self._stop:
            raise StopIteration()


def wrap_as_bmi(cls):
    """Wrap a landlab class so it exposes a BMI.

    Give a landlab component a Basic Model Interface (BMI). Since landlab
    components have an interface that is already in the style of BMI,
    this function adds just a light wrapping to landlab components. There
    are a number of differences that may cause some confusion to
    landlab users.

    1. Because BMI doesn't have a concept of a dual grid, it only
       defines *nodes* (points), *edges* (vectors), and *faces*
       (areas). The dual-graph of landlab is considered as two
       separate grids by BMI.

    2. It is important to note that BMI has only three grid elements
       (*node*, *edge*, and *face*) while landlab has 6. The names
       used by landlab and BMI are also different.

       Thus, a BMI-wrapped landlab component will always have two
       grids with grid identifiers 0, and 1. Grid 0 will contain
       the landlab *nodes*, *links*, and *patches* while grid 1 will
       contain *corners*, *faces*, and *cells*.landlab and BMI
       refer to grid elements by different names. The mapping from
       landlab to BMI nomenclature is the following:

       ======= ======= ======= ======
       Grid 0 (Primal)  Grid 1 (Dual)
       --------------- --------------
       Landlab   BMI   Landlab   BMI
       ======= ======= ======= ======
       node    node    corner  node
       link    edge    face    edge
       patch   face    cell    face
       ======= ======= ======= ======

    3. In BMI, the *initialize* method requires an input file that is
       used to create and setup the model for time-stepping. landlab
       components generally do not have anything like this; instead
       this task is usually done programmatically. Thus, the
       input file that is used by the BMI *initialize* method is
       a standard landlab input file as used by the landlab :func:`~.create_grid`
       function.

    Parameters
    ----------
    cls : class
        A landlab class that inherits from :class:`Component`.

    Returns
    -------
    class
        A wrapped class that exposes a BMI.

    Examples
    --------
    >>> from landlab.bmi import wrap_as_bmi
    >>> from landlab.components.flexure import Flexure

    >>> BmiFlexure = wrap_as_bmi(Flexure)
    >>> flexure = BmiFlexure()
    >>> sorted(flexure.get_input_var_names())
    ['boundary_condition_flag', 'lithosphere__overlying_pressure_increment']
    >>> flexure.get_var_units("lithosphere__overlying_pressure_increment")
    'Pa'

    >>> config = '''
    ... flexure:
    ...     eet: 10.e+3
    ...     method: flexure
    ... clock:
    ...     start: 0.
    ...     stop: 10.
    ...     step: 2.
    ... grid:
    ...     RasterModelGrid:
    ...     - [20, 40]
    ...     - xy_spacing: [2000., 1000.]
    ...     - fields:
    ...        node:
    ...          lithosphere__overlying_pressure_increment:
    ...            constant:
    ...              - value: 0.0
    ... '''
    >>> flexure.initialize(config)
    >>> sorted(flexure.get_output_var_names())
    ['boundary_condition_flag', 'lithosphere_surface__elevation_increment']
    >>> flexure.get_var_grid("lithosphere_surface__elevation_increment")
    0
    >>> flexure.get_grid_shape(0, np.empty(flexure.get_grid_rank(0), dtype=int))
    array([20, 40])
    >>> dz = np.empty(flexure.get_grid_size(0))
    >>> _ = flexure.get_value("lithosphere_surface__elevation_increment", dz)

    >>> np.all(dz == 0.0)
    True
    >>> flexure.get_current_time()
    0.0

    >>> sorted(flexure.get_input_var_names())
    ['boundary_condition_flag', 'lithosphere__overlying_pressure_increment']
    >>> load = np.zeros((20, 40), dtype=float)
    >>> load[0, 0] = 1.0
    >>> flexure.set_value("lithosphere__overlying_pressure_increment", load)
    >>> flexure.update()
    >>> flexure.get_current_time()
    2.0
    >>> _ = flexure.get_value("lithosphere_surface__elevation_increment", dz)
    >>> np.all(dz == 0.0)
    False
    """
    if not issubclass(cls, Component):
        raise TypeError("class must inherit from Component")

    class BmiWrapper(Bmi):
        __doc__ = """
        Basic Modeling Interface for the {name} component.
        """.format(
            name=cls.__name__
        ).strip()

        _cls = cls

        def __init__(self):
            self._base = None
            self._clock = None
            super().__init__()

            self._input_var_names = tuple(
                set(self._cls.input_var_names) | {"boundary_condition_flag"}
            )
            self._output_var_names = tuple(
                set(self._cls.output_var_names) | {"boundary_condition_flag"}
            )
            self._info = self._cls._info.copy()

            self._info["boundary_condition_flag"] = {
                "mapping": "node",
                "units": "",
                "dtype": int,
                "intent": None,
                "doc": "boundary condition flag of grid nodes",
            }

        def get_component_name(self):
            """Name of the component."""
            return self._cls.name

        def get_input_var_names(self):
            """Names of the input exchange items."""
            return self._input_var_names

        def get_input_item_count(self):
            return len(self._input_var_names)

        def get_output_var_names(self):
            """Names of the output exchange items."""
            return self._output_var_names

        def get_output_item_count(self):
            return len(self._output_var_names)

        def get_current_time(self):
            """Current component time."""
            return self._clock.time

        def get_end_time(self):
            """Stop time for the component."""
            return self._clock.stop

        def get_start_time(self):
            """Start time of the component."""
            return self._clock.start

        def get_time_step(self):
            """Component time step."""
            return self._clock.step

        def get_time_units(self):
            """Time units used by the component."""
            return self._clock.units

        def initialize(self, config_file):
            """Initialize the component from a file.

            BMI-wrapped Landlab components use input files in YAML format.
            Component-specific parameters are listed at the top level,
            followed by grid and then time information. An example input
            file looks like::

                flexure:
                    eet: 15.e+3
                clock:
                    start: 0
                    stop: 100.
                    step: 2.
                grid:
                    type: raster
                    shape: [20, 40]
                    spacing: [1000., 2000.]

            In this case, a `RasterModelGrid` is created (with the given shape
            and spacing) and passed to the underlying landlab component. The
            `eet=15000.` is also given to the component but as a keyword
            parameter. The BMI clock is initialized with the given parameters.

            Parameters
            ----------
            config_file : str or file_like
                YAML-formatted input file for the component.
            """
            grid = create_grid(config_file, section="grid")

            if not grid:
                raise ValueError(f"no grid in config file ({config_file})")
            elif isinstance(grid, list):
                raise ValueError(f"multiple grids in config file ({config_file})")

            params = load_params(config_file)
            params.pop("grid")
            clock_params = params.pop("clock")
            self._clock = TimeStepper(**clock_params)

            self._base = self._cls(grid, **params.pop(snake_case(cls.__name__), {}))
            self._base.grid.at_node["boundary_condition_flag"] = (
                self._base.grid.status_at_node
            )

        def update(self):
            """Update the component one time step."""
            if hasattr(self._base, "update"):
                self._base.update()
            elif hasattr(self._base, "run_one_step"):
                args = []
                for name, arg in inspect.signature(
                    self._base.run_one_step
                ).parameters.items():
                    if arg.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:
                        args.append(name)

                if len(args) == 0 or "dt" not in args:
                    self._base.run_one_step()
                else:
                    self._base.run_one_step(self._clock.step)

            self._clock.advance()

        def update_frac(self, frac):
            """Update the component a fraction of a time step."""
            time_step = self.get_time_step()
            self._clock.step = time_step * frac
            self.update()
            self._clock.step = time_step

        def update_until(self, then):
            """Update the component until a given time."""
            n_steps = (then - self.get_current_time()) / self.get_time_step()
            for _ in range(int(n_steps)):
                self.update()
            self.update_frac(n_steps - int(n_steps))

        def finalize(self):
            """Clean-up the component."""
            pass

        def get_var_grid(self, name):
            """Get the grid id for a variable."""
            at = self._info[name]["mapping"]
            return BMI_GRID[at]

        def get_var_itemsize(self, name):
            """Get the size of elements of a variable."""
            at = self._info[name]["mapping"]
            return self._base.grid[at][name].itemsize

        def get_var_nbytes(self, name):
            """Get the total number of bytes used by a variable."""
            at = self._info[name]["mapping"]
            return self._base.grid[at][name].nbytes

        def get_var_type(self, name):
            """Get the data type for a variable."""
            at = self._info[name]["mapping"]
            return str(self._base.grid[at][name].dtype)

        def get_var_units(self, name):
            """Get the unit used by a variable."""
            return self._info[name]["units"]

        def get_value_ref(self, name):
            """Get a reference to a variable's data."""
            at = self._info[name]["mapping"]
            return self._base.grid[at][name]

        def get_value(self, name, dest):
            """Get a copy of a variable's data."""
            at = self._info[name]["mapping"]
            dest[:] = self._base.grid[at][name]
            return dest

        def set_value(self, name, values):
            """Set the values of a variable."""
            if name in self.get_input_var_names():
                if name == "boundary_condition_flag":
                    self._base.grid.status_at_node = values
                else:
                    at = self._info[name]["mapping"]
                    self._base.grid[at][name][:] = values.flat
            else:
                raise KeyError(f"{name} is not an input item")

        def get_grid_origin(self, grid, origin):
            """Get the origin for a structured grid."""
            if grid == 0:
                origin[:] = (self._base.grid.node_y[0], self._base.grid.node_x[0])
            elif grid == 1:
                origin[:] = (
                    self._base.grid.node_y[0] + self._base.grid.dy * 0.5,
                    self._base.grid.node_x[0] + self._base.grid.dx * 0.5,
                )
            return origin

        def get_grid_rank(self, grid):
            """Get the number of dimensions of a grid."""
            if grid in (0, 1):
                return 2
            else:
                return 0

        def get_grid_shape(self, grid, shape):
            """Get the shape of a structured grid."""
            if grid == 0:
                shape[:] = (
                    self._base.grid.number_of_node_rows,
                    self._base.grid.number_of_node_columns,
                )
            elif grid == 1:
                shape[:] = (
                    self._base.grid.number_of_node_rows - 1,
                    self._base.grid.number_of_node_columns - 1,
                )
            return shape

        def get_grid_spacing(self, grid, spacing):
            """Get the row and column spacing of a structured grid."""
            spacing[:] = (self._base.grid.dy, self._base.grid.dx)
            return spacing

        def get_grid_type(self, grid):
            """Get the type of grid."""
            if grid == 2:
                return "scalar"
            elif isinstance(self._base.grid, RasterModelGrid):
                return "uniform_rectilinear"
            else:
                return "unstructured"

        def get_grid_edge_count(self, grid):
            if grid == 0:
                return self._base.grid.number_of_links
            elif grid == 1:
                return self._base.grid.number_of_faces

        def get_grid_edge_nodes(self, grid, edge_nodes):
            if grid == 0:
                return self._base.grid.nodes_at_link.reshape((-1,))
            elif grid == 1:
                return self._base.grid.corners_at_face.reshape((-1,))

        def get_grid_face_count(self, grid):
            if grid == 0:
                return self._base.grid.number_of_patches
            elif grid == 1:
                return self._base.grid.number_of_cells

        def get_grid_face_nodes(self, grid, face_nodes):
            if grid == 0:
                return self._base.grid.nodes_at_patch
            elif grid == 1:
                return self._base.grid.corners_at_cell

        def get_grid_face_edges(self, grid):
            if grid == 0:
                return self._base.grid.links_at_patch
            elif grid == 1:
                return self._base.grid.faces_at_cell

        def get_grid_node_count(self, grid):
            if grid == 0:
                return self._base.grid.number_of_nodes
            elif grid == 1:
                return self._base.grid.number_of_corners

        def get_grid_nodes_per_face(self, grid, nodes_per_face):
            if grid == 0:
                return np.full(self._base.grid.number_of_nodes, 3, dtype=int)
            elif grid == 1 and isinstance(self._base.grid, HexModelGrid):
                return np.full(self._base.grid.number_of_faces, 6, dtype=int)

        def get_grid_size(self, grid):
            if grid == 0:
                return self._base.grid.number_of_nodes
            elif grid == 1:
                return self._base.grid.number_of_corners

        def get_grid_x(self, grid, x):
            if grid == 0:
                return self._base.grid.x_of_node
            elif grid == 1:
                return self._base.grid.x_of_corner

        def get_grid_y(self, grid, y):
            if grid == 0:
                return self._base.grid.y_of_node
            elif grid == 1:
                return self._base.grid.y_of_corner

        def get_grid_z(self, grid, z):
            raise NotImplementedError("get_grid_z")
            # Only should be implemented for presently non-existant 3D grids.

        def get_value_at_indices(self, name, dest, inds):
            at = self._info[name]["mapping"]
            dest[:] = self._base.grid[at][name][inds]
            return dest

        def get_value_ptr(self, name):
            at = self._info[name]["mapping"]
            return self._base.grid[at][name]

        def get_var_location(self, name):
            return BMI_LOCATION[self._info[name]["mapping"]]

        def set_value_at_indices(self, name, inds, src):
            at = self._info[name]["mapping"]
            self._base.grid[at][name][inds] = src

    BmiWrapper.__name__ = f"{cls.__name__}BMI"
    return BmiWrapper



================================================
File: src/landlab/bmi/components.py
================================================
import sys
import warnings

from ..components import COMPONENTS
from .bmi_bridge import wrap_as_bmi

__all__ = []
for cls in COMPONENTS:
    try:
        as_bmi = wrap_as_bmi(cls)
    except TypeError:
        warnings.warn(f"unable to wrap class {cls.__name__}", stacklevel=2)
    else:
        setattr(sys.modules[__name__], as_bmi.__name__, as_bmi)
        __all__.append(as_bmi.__name__)



================================================
File: src/landlab/bmi/standard_names.py
================================================
#! /usr/bin/env python

STANDARD_NAME = {
    "channel__bed_shear_stress": "channel_bottom_water__shear_stress",
    "channel__chi_index": None,
    "channel__depth": "channel_x-section__mean_of_depth",
    "channel__discharge": "channel_water_x-section__volume_flow_rate",
    "channel__steepness_index": "land_surface__steepness_index",
    "channel__width": "channel_x-section_top__width",
    "channel_sediment__relative_flux": (
        "channel_water_sediment~suspended__time_max_normalized_volume_flux_ratio"
    ),
    # (flux is area/time) or is it flow_rate?
    "channel_sediment__volumetric_flux": "channel_water_sediment~suspended__volume_flux",
    "channel_sediment__volumetric_transport_capacity": (
        "channel_water_sediment~suspended__potential_volume_flow_rate"  # ?
    ),
    "depression__depth": "land_depression__max-fill_depth",
    # necessary? model-specific? does anything need this?
    "depression__outlet_node": "model_grid_node_land_depression_pour-point__id",
    # model_grid_cell__total_contributing_area
    "drainage_area": "basin__total_contributing_area",
    "flow__link_to_receiver_node": "model_grid_node_link~downstream__index",
    "flow__potential": None,
    "flow__receiver_node": None,
    "flow__sink_flag": None,  # model_*__flag boolean?
    "flow__upstream_node_order": None,
    "lithosphere__overlying_pressure_increment": (
        "lithosphere_top_surface__increment_of_static_pressure"
    ),
    "lithosphere_surface__elevation_increment": (
        "lithosphere_top_surface__increment_of_elevation"
    ),
    "plant__age": "plant__age",
    "plant__live_index": None,
    "radiation__incoming_shortwave_flux": (
        "earth_surface_radiation~incoming~shortwave__energy_flux"
    ),
    "radiation__net_flux": "earth_surface_radiation~net~total__energy_flux",
    "radiation__net_longwave_flux": "earth_surface_radiation~net~longwave__energy_flux",
    "radiation__net_shortwave_flux": "earth_surface_radiation~net~shortwave__energy_flux",
    "radiation__ratio_to_flat_surface": (
        "earth_surface_radiation~incoming~shortwave-to-flat_surface__energy_flux"
    ),
    "rainfall__daily_depth": "atmosphere_water__rainfall_volume_flux",
    "sediment_fill__depth": "land_surface_sediment__deposition_depth",
    "soil_moisture__cumulative_water_stress": "land_vegetation__time_integral_of_water_stress",
    "soil_moisture__initial_saturation_fraction": (
        "soil_water__initial_saturated_volume_fraction"
    ),
    "soil_moisture__root_zone_leakage_rate": "soil_water_root-zone__volume_flux",
    "soil_moisture__saturation_fraction": "soil_water__saturated_volume_fraction",
    "soil_moisture__water_stress": "land_vegetation__water_stress",
    "surface__evapotranspiration_rate": "land_surface_water__evaptranspiration_volume_flux",
    "surface__potential_evapotranspiration_30day_mean": (
        "land_surface_water__time_mean_of_potential_evaptranspiration_volume_flux"
    ),
    "surface__potential_evapotranspiration_rate": (
        "land_surface_water__potential_evaptranspiration_volume_flux"
    ),
    "surface__runoff_rate": "land_surface_water__runoff_volume_flux",
    "surface_load__stress": "lithosphere_surface__normal_component_of_stress",
    "topographic__elevation": "land_surface__elevation",
    "topographic__gradient": "land_surface__slope",
    "topographic__slope": "land_surface__slope_angle",
    "topographic__steepest_slope": "model_grid_cell__max_of_d8_slope",
    "hillslope_sediment__unit_volume_flux": None,
    "vegetation__cover_fraction": "land_vegetation__area_fraction",
    "vegetation__dead_biomass": "land_vegetation~biomass~dead__volume_flux",
    "vegetation__dead_leaf_area_index": "land_vegetation~dead__leaf-area_index",
    "vegetation__live_biomass": "land_vegetation~biomass~live__volume_flux",
    "vegetation__live_leaf_area_index": "land_vegetation~live__leaf-area_index",
    "vegetation__plant_functional_type": None,
    "surface_water__depth": "land_surface_water__depth",
    "surface_water__discharge": "land_surface_water__volume_flow_rate",
    "water__unit_flux_in": "model_grid_cell_water~incoming__volume_flow_rate",
    "water_surface__gradient": "land_surface_water_surface__slope",
}


LANDLAB_NAME = {value: key for key, value in STANDARD_NAME.items() if key}



================================================
File: src/landlab/ca/__init__.py
================================================



================================================
File: src/landlab/ca/celllab_cts.py
================================================
#! /usr/env/python
r"""
Landlab's Continuous-Time Stochastic (CTS) cellular automata modeling package.

Overview
--------

A CellLab CTS model implements a particular type of cellular
automaton (CA): a continuous-time stochastic CA. The approach is based on that
of Narteau et al. (2002, 2009) and Rozier and Narteau (2014). Like a normal
CA, the domain consists of a lattice of cells, each of which has a discrete
state. Unlike a conventional CA, the updating process is stochastic, and takes
place in continuous rather than discrete time. Any given pair (or "doublet")
of adjacent cell states has a certain specified probability of transition to a
different pair of states. The transition probability is given in the form of an
average *transition rate*, :math:`\lambda` (with dimensions of 1/T); the actual
time of transition is a random variable drawn from an exponential probability
distribution with mean :math:`1/\lambda`.

Subclasses
----------

Landlab provides for several different lattice and connection types:

-  RasterCTS: regular raster grid with transitions between horizontal and
   vertical cell pairs
-  OrientedRasterCTS: like a RasterLCA, but different transition rates can
   be assigned to vertical and horizontal pairs. This property of
   orientation can be used, for example, to implement rules representing
   gravitational attraction, or flow of a fluid with a particular
   direction.
-  RasterD8CTS: like a RasterLCA, but includes diagonal as well as vertical
   and horizontal cell pairs.
-  OrientedRasterD8CTS: as above but orientation also matters.
-  HexCTS: hexagonal grid
-  OrientedHexCTS: hexagonal grid, with transition rates allowed to vary
   according to orientation.

Encoding of "states"
--------------------
As in any traditional cellular automaton model, a LandlabCellularAutomaton
contains a grid of cells ("nodes" in Landlab parlance), each of which is has a
discrete state. States are represented by integers (0, 1, ... N).

In addition, every active link has an *orientation code* and a *link state
code*. The orientation code represents the orientation of the link in space: is
it "vertical" (aligned with the y axis), "horizontal" (aligned with x), or in
some other orientation? The number of possible orientations depends on the
subclass. The base class has only one orientation code (0) (meaning
"orientation doesn't matter), but this is overridden in some of the subclasses.
For example, the OrientedRasterLCA has two orientation codes (0 and 1, for
vertical and horizontal), while the OrientedHexLCA has three (representing the
three axes in a hex-cell / triagonal grid).

Each active link also has a *link state code*. The *state* of a link refers to
its particular combination of nodes and its orientation. For example, link
state 1 refers to a link in which the tail-node has state 0, the head-node has
state 1, and the orientation code is 0. The number of possible link states is
equal to R N^2, where R is the number of orientations (1 to 3, depending on the
subclass) and N is the number of possible node states. The simplest possible
Landlab CA model would have just one orientation code and two possible cell
states, so that there are four unique link states. These would be represented
by the tuples of (tail-node state, head-node state, orientation) as follows::

    link state 0 = (0, 0, 0)
    link state 1 = (0, 1, 0)
    link state 2 = (1, 0, 0)
    link state 3 = (1, 1, 0)

Main data structures
--------------------
node_state : 1d array of int (x number of nodes in grid)
    Node-based grid of node-state codes. This is the grid of cell (sic) states.

link_state_dict : dictionary
    Keys are 3-element tuples that represent the cell-state pairs and
    orientation code for each possible link type; values are the corresponding
    link-state codes. Allows you to look up the link-state code corresponding
    to a particular pair of adjacent nodes with a particular orientation.

node_pair : list (x number of possible link states)
    List of 3-element tuples representing all the various link states. Allows
    you to look up the node states and orientation corresponding to a
    particular link-state ID.

priority_queue : PriorityQueue object containing event records
    Queue containing all future transition events, sorted by time of occurrence
    (from soonest to latest).

next_update : 1d array (x number of links)
    Time (in the future) at which the link will undergo its next transition.
    You might notice that the update time for every scheduled transition is
    also stored with each event in the event queue. Why store it twice?
    Because a scheduled event might be invalidated after the event has been
    scheduled (because another transition has changed one of a link's two
    nodes, for example). The way to tell whether a scheduled event is still
    valid is to compare its time with the corresponding transition time in the
    *next_update* array. If they are different, the event is discarded.

link_orientation : 1d array of int8 (x number of links)
    Orientation code for each link.

link_state : 1d array of int (x number of links)
    State code for each link.

n_trn : 1d array of int (x number of possible link states)
    Number of transitions ("trn" stands for "transition") from a given link
    state.

trn_to : 1d array of ints (x # transitions)
    Stores the link-state code(s) to which a particular transition ID can
    transition.

trn_rate : 1d array of floats (# transitions)
    Rate associated with each link-state transition.


Created GT Sep 2014, starting from link_cap.py.
"""


import numpy as np
import pylab as plt

import landlab
from landlab.ca.cfuncs import PriorityQueue
from landlab.ca.cfuncs import get_next_event_new
from landlab.ca.cfuncs import push_transitions_to_event_queue
from landlab.ca.cfuncs import run_cts_new
from landlab.grid.nodestatus import NodeStatus

_NEVER = 1e50

_DEBUG = False

_CORE = NodeStatus.CORE


class Transition:
    """A transition from one state to another.

    Represents a transition from one state ("from_state") to another
    ("to_state") at a link. The transition probability is represented by a rate
    parameter "rate", with dimensions of 1/T. The probability distribution of
    time until the transition event occurs is exponentional with mean 1/rate.
    The optional name parameter allows the caller to assign a name to any given
    transition.

    Note that from_state and to_state can now be either integer IDs for the
    standardised ordering of the link states (as before), or tuples explicitly
    describing the node state at each end, and the orientation.
    Orientation is 0: horizontal, L-R; 1: vertical, bottom-top.
    For such a tuple, order is (left/bottom, right/top, orientation).

    Transition() constructor sets 3 required properties and 2 optional
    properties for a transition from one cell pair to another.

    Parameters
    ----------
    from_state : int
        Code for the starting state of the cell pair (link)
    to_state : int
        Code for the new state of the cell pair (link)
    rate : float
        Average rate at which this transition occurs (dimension of 1/time)
    name : string (optional)
        Name for this transition
    swap_properties : bool (optional)
        Flag: should properties be exchanged between the two cells?
    """

    def __init__(
        self,
        from_state,
        to_state,
        rate,
        name=None,
        swap_properties=False,
        prop_update_fn=None,
    ):
        """Transition() constructor sets 3 required properties and 2 optional
        properties for a transition from one cell pair to another.

        Parameters
        ----------
        from_state : int
            Code for the starting state of the cell pair (link)
        to_state : int
            Code for the new state of the cell pair (link)
        rate : float
            Average rate at which this transition occurs (dimension of 1/time)
        name : string (optional)
            Name for this transition
        swap_properties : bool (optional)
            Flag: should properties be exchanged between the two cells?
        """
        self.from_state = from_state
        self.to_state = to_state
        self.rate = rate
        self.name = name
        self.swap_properties = swap_properties
        self.prop_update_fn = prop_update_fn


class CAPlotter:
    """Handle display of a CellLab-CTS grid.

    CAPlotter() constructor keeps a reference to the CA model, and
    optionally a colormap to be used with plots.

    Parameters
    ----------
    ca : LandlabCellularAutomaton object
        Reference to a CA model
    cmap : Matplotlib colormap, optional
        Colormap to be used in plotting

    Examples
    --------
    >>> from landlab import RasterModelGrid, HexModelGrid
    >>> from landlab.ca.celllab_cts import Transition
    >>> from landlab.ca.raster_cts import RasterCTS
    >>> import numpy as np
    >>> grid = RasterModelGrid((3, 5))
    >>> nsd = {0: "zero", 1: "one"}
    >>> trn_list = []
    >>> trn_list.append(Transition((0, 1, 0), (1, 1, 0), 1.0))
    >>> ins = np.arange(15) % 2
    >>> ca = RasterCTS(grid, nsd, trn_list, ins)
    >>> cap = CAPlotter(ca)
    >>> cap.gridtype
    'rast'
    >>> cap._cmap.name
    'jet'

    >>> from landlab.ca.hex_cts import HexCTS
    >>> import matplotlib
    >>> grid = HexModelGrid((3, 3))
    >>> ins = np.zeros(grid.number_of_nodes, dtype=int)
    >>> ca = HexCTS(grid, nsd, trn_list, ins)
    >>> cap = CAPlotter(ca, cmap=matplotlib.cm.pink)
    >>> cap.gridtype
    'hex'
    >>> cap._cmap.name
    'pink'
    """

    def __init__(self, ca, cmap=None, **kwds):
        """CAPlotter() constructor keeps a reference to the CA model, and
        optionally a colormap to be used with plots.

        Parameters
        ----------
        ca : LandlabCellularAutomaton object
            Reference to a CA model
        cmap : Matplotlib colormap, optional
            Colormap to be used in plotting
        """
        import matplotlib

        # Set the colormap; default to matplotlib's "jet" colormap
        if cmap is None:
            self._cmap = matplotlib.cm.jet
        else:
            self._cmap = cmap

        # Keep a reference to the CA model
        self.ca = ca

        # Initialize the plot and remember the grid type
        plt.ion()
        plt.figure(1)
        if type(ca.grid) is landlab.grid.hex.HexModelGrid:
            self.gridtype = "hex"
        else:
            self.gridtype = "rast"

    def update_plot(self):
        """Plot the current node state grid."""
        plt.clf()
        if self.gridtype == "rast":
            nsr = self.ca.grid.node_vector_to_raster(self.ca.node_state)
            plt.imshow(nsr, interpolation="None", origin="lower", cmap=self._cmap)
        else:
            self.ca.grid.hexplot(self.ca.node_state, color_map=self._cmap)

        plt.draw()
        plt.pause(0.001)

    def finalize(self):
        """Wrap up plotting.

        Wrap up plotting by switching off interactive model and showing
        the plot.
        """
        plt.ioff()
        plt.show()


class CellLabCTSModel:
    """Link-type (or doublet-type) cellular automaton model.

    A CellLabCTSModel implements a link-type (or doublet-type) cellular
    automaton model. A link connects a pair of cells. Each cell has a state
    (represented by an integer code), and each link also has a state that is
    determined by the states of the cell pair.

    Parameters
    ----------
    model_grid : Landlab ModelGrid object
        Reference to the model's grid
    node_state_dict : dict
        Keys are node-state codes, values are the names associated with
        these codes
    transition_list : list of Transition objects
        List of all possible transitions in the model
    initial_node_states : array of ints (x number of nodes in grid)
        Starting values for node-state grid
    prop_data : array (x number of nodes in grid), optional
        Array of properties associated with each node/cell
    prop_reset_value : number or object, optional
        Default or initial value for a node/cell property (e.g., 0.0).
        Must be same type as *prop_data*.
    """

    def __init__(
        self,
        model_grid,
        node_state_dict,
        transition_list,
        initial_node_states,
        prop_data=None,
        prop_reset_value=None,
        seed=0,
    ):
        """Initialize the CA model.

        Parameters
        ----------
        model_grid : Landlab ModelGrid object
            Reference to the model's grid
        node_state_dict : dict
            Keys are node-state codes, values are the names associated with
            these codes
        transition_list : list of Transition objects
            List of all possible transitions in the model
        initial_node_states : array of ints (x number of nodes in grid)
            Starting values for node-state grid
        prop_data : array (x number of nodes in grid), optional
            Array of properties associated with each node/cell
        prop_reset_value : number or object, optional
            Default or initial value for a node/cell property (e.g., 0.0).
            Must be same type as *prop_data*.
        seed : int, optional
            Seed for random number generation.
        """

        # Keep a copy of the model grid
        self.grid = model_grid

        # Initialize random number generation
        np.random.seed(seed)

        # Create an array that knows which links are connected to a boundary
        # node
        self.bnd_lnk = np.zeros(self.grid.number_of_links, dtype=np.int8)
        for link_id in range(self.grid.number_of_links):
            if (
                self.grid.status_at_node[self.grid.node_at_link_tail[link_id]] != _CORE
                or self.grid.status_at_node[self.grid.node_at_link_head[link_id]]
                != _CORE
            ):
                self.bnd_lnk[link_id] = True

        # Set up the initial node-state grid
        self.set_node_state_grid(initial_node_states)

        # Current simulation time starts out at zero
        self.current_time = 0.0

        # Figure out how many states there are, and make sure the input data
        # are self consistent.
        #   There are 2 x (N^2) link states, where N is the number of node
        # states. For example, if there are just two node states, 0 and 1, then
        # the possible oriented link pairs are listed below:
        #   0-0 0-1 1-0 1-1  0 0 1 1
        #                    0 1 0 1
        self.num_node_states = len(node_state_dict)
        self.num_node_states_sq = self.num_node_states * self.num_node_states
        self.num_link_states = self.number_of_orientations * self.num_node_states_sq

        assert type(transition_list) is list, "transition_list must be a list!"
        assert transition_list, "Transition list must contain at least one transition"
        last_type = None
        for t in transition_list:
            # TODO: make orientation optional for cases where
            # self.number_of_orientations = 1
            if isinstance(t.from_state, tuple) and isinstance(t.to_state, tuple):
                this_type = tuple
            else:
                this_type = int

            if this_type is tuple:
                # added to allow from and to states to be tuples, not just ids
                for i in t.from_state[:-1]:
                    assert (
                        i < self.num_node_states
                    ), "Transition from_state out of range"
                for i in t.to_state[:-1]:
                    assert i < self.num_node_states, "Transition to_state out of range"
                assert (
                    t.from_state[-1] < self.number_of_orientations
                ), "Encoding for orientation in from_state must be < number of orientations."
                assert (
                    t.to_state[-1] < self.number_of_orientations
                ), "Encoding for orientation in to_state must be < number of orientations."
            else:
                assert (
                    t.from_state < self.num_link_states
                ), "Transition from_state out of range"
                assert (
                    t.to_state < self.num_link_states
                ), "Transition to_state out of range"

            assert (
                last_type == this_type or last_type is None
            ), "All transition types must be either int IDs, or all tuples."
            # this test to ensure all entries are either IDs, or tuples, not
            # mixed
            last_type = this_type

        # Create priority queue for events and next_update array for links
        self.next_update = self.grid.add_zeros("next_update_time", at="link")
        self.priority_queue = PriorityQueue()
        self.next_trn_id = -np.ones(self.grid.number_of_links, dtype=int)

        # Assign link types from node types
        self.create_link_state_dict_and_pair_list()

        # DEJH adds: convert transition_list to IDs if necessary
        # This is the new part that allows Transition from_ and to_ types
        # to be specified either as ints, or as tuples.
        transition_list_as_ID = transition_list[:]
        if isinstance(transition_list[0].from_state, tuple):
            # (then they all are..., because of the assertions in __init__)
            for i in range(len(transition_list)):
                transition_list_as_ID[i].from_state = self.link_state_dict[
                    transition_list[i].from_state
                ]
                transition_list_as_ID[i].to_state = self.link_state_dict[
                    transition_list[i].to_state
                ]

        # Set up the information needed to determine the orientation of links
        # in the lattice. The default method just creates an array of zeros
        # (all orientations considered the same), but this will be overridden
        # in subclasses that do use orientation.
        self.setup_array_of_orientation_codes()

        # Using the grid of node states, figure out all the link states
        self.assign_link_states_from_node_types()

        # Create transition data for links
        self.setup_transition_data(transition_list_as_ID)

        # Put the various transitions on the event queue
        self.push_transitions_to_event_queue()

        # In order to keep track of cell "properties", we create an array of
        # indices that refer to locations in the caller's code where properties
        # are tracked.
        self.propid = np.arange(self.grid.number_of_nodes)
        if prop_data is None:
            self.prop_data = np.zeros(self.grid.number_of_nodes, dtype=int)
            self.prop_reset_value = 0
        else:
            self.prop_data = prop_data
            self.prop_reset_value = prop_reset_value

    def set_node_state_grid(self, node_states):
        """Set the grid of node-state codes to node_states.

        Sets the grid of node-state codes to node_states. Also checks
        to make sure node_states is in the proper format, which is to
        say, it's a Numpy array of the same length as the number of nodes in
        the grid.

        **Creates**:

        *  self.node_state : 1D array of ints (x number of nodes in grid)
           The node-state array

        Parameters
        ----------
        node_states : 1D array of ints (x number of nodes in grid)

        Notes
        -----
        The node-state array is attached to the grid as a field with the name
        'node_state'.
        """
        assert (
            type(node_states) is np.ndarray
        ), "initial_node_states must be a Numpy array"
        assert (
            len(node_states) == self.grid.number_of_nodes
        ), "length of initial_node_states must equal number of nodes in grid"
        self.grid.at_node["node_state"] = node_states
        self.node_state = node_states

    def create_link_state_dict_and_pair_list(self):
        """Create a dict of link-state to node-state.

        Creates a dictionary that can be used as a lookup table to find out
        which link state corresponds to a particular pair of node states. The
        dictionary keys are 3-element tuples, each of which represents the
        state of the TAIL node, the HEAD node, and the orientation of the link.
        The values are integer codes representing the link state numbers.

        Notes
        -----
        Performance note: making self.node_pair a tuple does not appear to
        change time to lookup values in update_node_states. Changing it to a
        2D array of int actually slows it down.
        """
        self.link_state_dict = {}
        self.node_pair = []
        k = 0
        for orientation in range(self.number_of_orientations):
            for tail_state in range(self.num_node_states):
                for head_state in range(self.num_node_states):
                    self.link_state_dict[(tail_state, head_state, orientation)] = k
                    self.node_pair.append((tail_state, head_state, orientation))
                    k += 1

    def setup_array_of_orientation_codes(self):
        """Create array of active link orientation codes.

        Creates and configures an array that contain the orientation code for
        each active link (and corresponding cell pair).

        **creates**:

        * ``self.link_orientation`` : 1D numpy array

        Notes
        -----

        The setup varies depending on the type of LCA. The default is
        non-oriented, in which case we just have an array of zeros. Subclasses
        will override this method to handle lattices in which orientation
        matters (for example, vertical vs. horizontal in an OrientedRasterLCA).
        """
        self.link_orientation = np.zeros(self.grid.number_of_links, dtype=np.int8)

    def assign_link_states_from_node_types(self):
        """Assign link-state code for each link.

        Takes lists/arrays of "tail" and "head" node IDs for each link, and a
        dictionary that associates pairs of node states (represented as a
        3-element tuple, comprising the TAIL state, FROM state, and
        orientation) to link states.

        **creates**:

        * ``self.link_state`` : 1D numpy array
        """
        self.link_state = np.zeros(self.grid.number_of_links, dtype=int)

        for i in self.grid.active_links:
            orientation = self.link_orientation[i]
            node_pair = (
                self.node_state[self.grid.node_at_link_tail[i]],
                self.node_state[self.grid.node_at_link_head[i]],
                orientation,
            )
            self.link_state[i] = self.link_state_dict[node_pair]

    def setup_transition_data(self, xn_list):
        """Create transition data arrays."""

        # First, create an array that stores the number of possible transitions
        # out of each state.
        n_xn = np.zeros(self.num_link_states, dtype=int)
        for xn in xn_list:
            n_xn[xn.from_state] += 1
        self.n_trn = np.zeros(self.num_link_states, dtype=int)

        # Now, create arrays to hold the "to state" and transition rate for each
        # transition. These arrays are dimensioned N x M where N is the number
        # of states, and M is the maximum number of transitions from a single
        # state (for example if state 3 could transition either to state 1 or
        # state 4, and the other states only had one or zero possible
        # transitions, then the maximum would be 2).
        max_transitions = np.max(n_xn)
        self.trn_id = np.zeros((self.num_link_states, max_transitions), dtype=int)
        num_transitions = len(xn_list)
        self.trn_to = np.zeros(num_transitions, dtype=int)
        self.trn_rate = np.zeros(num_transitions)
        self.trn_propswap = np.zeros(num_transitions, dtype=np.int8)
        self.trn_prop_update_fn = np.zeros(num_transitions, dtype=object)

        for trn in range(num_transitions):
            self.trn_to[trn] = xn_list[trn].to_state
            self.trn_rate[trn] = xn_list[trn].rate
            self.trn_propswap[trn] = xn_list[trn].swap_properties
            if xn_list[trn].prop_update_fn is not None:
                self.trn_prop_update_fn[trn] = xn_list[trn].prop_update_fn
                self._use_propswap_or_callback = True
            from_state = xn_list[trn].from_state
            self.trn_id[from_state, self.n_trn[from_state]] = trn
            self.n_trn[from_state] += 1

    def push_transitions_to_event_queue(self):
        """Initializes the event queue by creating transition events for each
        cell pair that has one or more potential transitions and pushing these
        onto the queue. Also records scheduled transition times in the
        self.next_update array.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> from landlab.ca.celllab_cts import Transition
        >>> from landlab.ca.oriented_raster_cts import OrientedRasterCTS
        >>> import numpy as np
        >>> grid = RasterModelGrid((3, 5))
        >>> nsd = {0: "zero", 1: "one"}
        >>> trn_list = []
        >>> trn_list.append(Transition((0, 1, 0), (1, 0, 0), 1.0))
        >>> trn_list.append(Transition((1, 0, 0), (0, 1, 0), 2.0))
        >>> trn_list.append(Transition((0, 1, 1), (1, 0, 1), 3.0))
        >>> trn_list.append(Transition((0, 1, 1), (1, 1, 1), 4.0))
        >>> ins = np.arange(15) % 2
        >>> cts = OrientedRasterCTS(grid, nsd, trn_list, ins)
        >>> ev0 = cts.priority_queue._queue[0]
        >>> np.round(100 * ev0[0])
        12.0
        >>> ev0[2]  # this is the link ID
        16
        >>> ev6 = cts.priority_queue._queue[6]
        >>> np.round(100 * ev6[0])
        27.0
        >>> ev6[2]  # this is the link ID
        6
        >>> cts.next_trn_id[ev0[2]]  # ID of the transition to occur at this link
        3
        >>> cts.next_trn_id[cts.grid.active_links]
        array([-1,  2, -1,  1,  0,  1,  0,  2, -1,  3])
        """
        push_transitions_to_event_queue(
            self.grid.number_of_active_links,
            self.grid.active_links,
            self.n_trn,
            self.link_state,
            self.trn_id,
            self.trn_rate,
            self.next_update,
            self.next_trn_id,
            self.priority_queue,
        )

    def update_link_state_new(self, link, new_link_state, current_time):
        """Implements a link transition by updating the current state of the
        link and (if appropriate) choosing the next transition event and
        pushing it on to the event queue.

        Parameters
        ----------
        link : int
            ID of the link to update
        new_link_state : int
            Code for the new state
        current_time : float
            Current time in simulation
        """

        # If the link connects to a boundary, we might have a different state
        # than the one we planned
        if self.bnd_lnk[link]:
            fns = self.node_state[self.grid.node_at_link_tail[link]]
            tns = self.node_state[self.grid.node_at_link_head[link]]
            orientation = self.link_orientation[link]
            new_link_state = int(
                int(orientation) * self.num_node_states_sq
                + fns * self.num_node_states
                + tns
            )

        self.link_state[link] = new_link_state
        if self.n_trn[new_link_state] > 0:
            (event_time, trn_id) = get_next_event_new(
                link,
                new_link_state,
                current_time,
                self.n_trn,
                self.trn_id,
                self.trn_rate,
            )
            self.priority_queue.push(link, event_time)
            self.next_update[link] = event_time
            self.next_trn_id[link] = trn_id
        else:
            self.next_update[link] = _NEVER
            self.next_trn_id[link] = -1

    def update_component_data(self, new_node_state_array):
        """Update all component data.

        Call this method to update all data held by the component, if, for
        example, another component or boundary conditions modify the node
        statuses outside the component between run steps.

        This method updates all necessary properties, including both node and
        link states.

        *new_node_state_array* is the updated list of node states, which must
        still all be compatible with the state list originally supplied to
        this component.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> from landlab.ca.celllab_cts import Transition
        >>> from landlab.ca.raster_cts import RasterCTS
        >>> import numpy as np
        >>> grid = RasterModelGrid((3, 5))
        >>> nsd = {0: "zero", 1: "one"}
        >>> trn_list = []
        >>> trn_list.append(Transition((0, 1, 0), (1, 1, 0), 1.0))
        >>> ins = np.zeros(15, dtype=int)
        >>> ca = RasterCTS(grid, nsd, trn_list, ins)
        >>> list(ca.node_state[6:9])
        [0, 0, 0]
        >>> list(ca.link_state[9:13])
        [0, 0, 0, 0]
        >>> len(ca.priority_queue._queue)  # there are no transitions
        0
        >>> nns = np.arange(15) % 2  # make a new node-state grid...
        >>> ca.update_component_data(nns)  # ...and assign it
        >>> list(ca.node_state[6:9])
        [0, 1, 0]
        >>> list(ca.link_state[9:13])
        [2, 1, 2, 1]
        >>> len(ca.priority_queue._queue)  # now there are 5 transitions
        5
        """
        self.set_node_state_grid(new_node_state_array)
        self.assign_link_states_from_node_types()
        self.push_transitions_to_event_queue()

    # @profile
    def run(
        self, run_to, node_state_grid=None, plot_each_transition=False, plotter=None
    ):
        """Run the model forward for a specified period of time.

        Parameters
        ----------
        run_to : float
            Time to run to, starting from self.current_time
        node_state_grid : 1D array of ints (x number of nodes) (optional)
            Node states (if given, replaces model's current node state grid)
        plot_each_transition : bool (optional)
            Option to display the grid after each transition
        plotter : CAPlotter object (optional)
            Needed if caller wants to plot after every transition

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> from landlab.ca.celllab_cts import Transition
        >>> from landlab.ca.oriented_raster_cts import OrientedRasterCTS
        >>> import numpy as np
        >>> grid = RasterModelGrid((3, 5))
        >>> nsd = {0: "zero", 1: "one"}
        >>> trn_list = []
        >>> trn_list.append(Transition((0, 1, 0), (1, 0, 0), 1.0))
        >>> trn_list.append(Transition((1, 0, 0), (0, 1, 0), 2.0))
        >>> trn_list.append(Transition((0, 1, 1), (1, 0, 1), 3.0))
        >>> trn_list.append(Transition((0, 1, 1), (1, 1, 1), 4.0))
        >>> ins = np.arange(15) % 2
        >>> cts = OrientedRasterCTS(grid, nsd, trn_list, ins)
        """
        if node_state_grid is not None:
            self.set_node_state_grid(node_state_grid)

        self.current_time = run_cts_new(
            run_to,
            self.current_time,
            self.priority_queue,
            self.next_update,
            self.grid.node_at_link_tail,
            self.grid.node_at_link_head,
            self.node_state,
            self.next_trn_id,
            self.trn_to,
            self.grid.status_at_node,
            self.num_node_states,
            self.num_node_states_sq,
            self.bnd_lnk,
            self.link_orientation,
            self.link_state,
            self.n_trn,
            self.trn_id,
            self.trn_rate,
            self.grid.links_at_node,
            self.grid.active_link_dirs_at_node,
            self.trn_propswap,
            self.propid,
            self.prop_data,
            self.prop_reset_value,
            self.trn_prop_update_fn,
            self,
            plot_each_transition,
            plotter,
        )



================================================
File: src/landlab/ca/cfuncs.pyx
================================================
"""
Created on Thu Jun 30 12:40:39 2016

@author: gtucker
"""
cimport cython
from libc.stdint cimport int8_t
from libc.stdint cimport uint8_t

import numpy as np

cimport numpy as np

from _heapq import heappop
from _heapq import heappush

from landlab.grid.nodestatus import NodeStatus

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


ctypedef fused int_or_float_t:
    cython.floating
    cython.integral
    long long


cdef double _NEVER = 1.0e50
cdef int _CORE = NodeStatus.CORE
cdef char _DEBUG = 0


cdef class PriorityQueue:
    """
    Implements a priority queue.
    """
    cdef public object _queue
    cdef public int _index

    def __init__(self):
        self._queue = []
        self._index = 0

    def push(self, int item, double priority):
        heappush(self._queue, (priority, self._index, item))
        self._index += 1

    def pop(self):
        assert len(self._queue) > 0, "Q is empty"
        return heappop(self._queue)


cdef class Event:
    """
    Represents a transition event at a link. The transition occurs at a given
    link and a given time, and it involves a transition into the state xn_to
    (an integer code representing the new link state; "xn" is shorthand for
    "transition").

    The class overrides the __lt__ (less than operator) method so that when
    Event() objects are placed in a PriorityQueue, the earliest event is
    given the highest priority (i.e., placed at the top of the queue).

    Event() constructor sets 3 required properties and one optional
    property.

    Parameters
    ----------
    time : float
        Time at which the event is scheduled to occur
    link : int
        ID of the link at which event occurs
    xn_to : int
        New state to which this cell pair (link) will transition
    propswap : bool (optional)
        Flag: does this event involve an exchange of properties between
        the two cells?

    Examples
    --------
    >>> from landlab.ca.celllab_cts import Event
    >>> e1 = Event( 10.0, 1, 2)
    >>> e2 = Event( 2.0, 3, 1)
    >>> e1 < e2
    False
    >>> e2 < e1
    True
    """
    cdef public double time
    cdef public int link
    cdef public int xn_to
    cdef public char propswap
    cdef public object prop_update_fn

    def __init__(self, double time, int link, int xn_to, object propswap=False,
                 object prop_update_fn=None):
        """
        Event() constructor sets 3 required properties and one optional
        property.

        Parameters
        ----------
        time : float
            Time at which the event is scheduled to occur
        link : int
            ID of the link at which event occurs
        xn_to : int
            New state to which this cell pair (link) will transition
        propswap : bool (optional)
            Flag: does this event involve an exchange of properties between
            the two cells?
        """
        self.time = time
        self.link = link
        self.xn_to = xn_to
        self.propswap = propswap
        self.prop_update_fn = prop_update_fn

    def __richcmp__(self, Event other, int op):
        """
        Overridden less-than operator: returns true if the event on the left
        has an earlier scheduled time than the event on the right
        """
        return self.time < other.time


@cython.boundscheck(True)
@cython.wraparound(False)
cdef int current_link_state(
    const long link_id,
    const id_t [:] node_state,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    const int8_t [:]  link_orientation,
    const long num_node_states,
    const long num_node_states_sq,
):
    """Get the current state of a link.

    Used to determine whether the link state at link *link_id* has changed
    due to an independent change in the node-state grid. Returns the
    current state of the link based on the states of its two end nodes;
    this can be compared to the entry in self.link_state to determine
    whether the state has changed.

    Parameters
    ----------
    link_id : int
        ID of the active link to test
    node_state : array of int
        State codes of nodes
    node_at_link_tail : array of int
        ID of node at link tails
    node_at_link_head : array of int
        ID of node at link heads
    link_orientation : array of 1-byte int
        Orientation codes: 0, 1, or (with hex) 2
    num_nodes_states : int
        Total number of possible node states
    num_node_states_sq : int
        Square of number of node states (precomputed for speed)

    Returns
    -------
    int
        New link state code
    """
    cdef long tail_node_state
    cdef long head_node_state
    cdef char orientation

    # Find out the states of the two nodes, and the orientation
    tail_node_state = node_state[node_at_link_tail[link_id]]
    head_node_state = node_state[node_at_link_head[link_id]]
    orientation = link_orientation[link_id]

    # Return the corresponding state code.
    return (orientation * num_node_states_sq +
            tail_node_state * num_node_states + head_node_state)


@cython.boundscheck(True)
@cython.wraparound(False)
cpdef update_link_states_and_transitions(
    const id_t [:] active_links,
    const id_t [:] node_state,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    const int8_t [:] link_orientation,
    int8_t [:] bnd_lnk,
    id_t [:] link_state,
    id_t [:] n_xn,
    Event [:] event_queue,
    cython.floating [:] next_update,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    long num_node_states,
    long num_node_states_sq,
    double current_time,
    int8_t [:, :] xn_propswap,
    object [:, :] xn_prop_update_fn,
):
    """
    Following an "external" change to the node state grid, updates link
    states where necessary and creates any needed events.

    Notes
    -----
    **Algorithm**::

        FOR each active link:
            if the actual node pair is different from the link's code:
                change the link state to be correct
                schedule an event
    """
    cdef int current_state
    cdef int i, j

    for j in range(len(active_links)):
        i = active_links[j]
        current_state = current_link_state(
            i,
            node_state,
            node_at_link_tail,
            node_at_link_head,
            link_orientation,
            num_node_states,
            num_node_states_sq,
        )
        if current_state != link_state[i]:
            update_link_state(
                i,
                current_state,
                current_time,
                bnd_lnk,
                node_state,
                node_at_link_tail,
                node_at_link_head,
                link_orientation,
                num_node_states,
                num_node_states_sq,
                link_state,
                n_xn,
                event_queue,
                next_update,
                xn_to,
                xn_rate,
                xn_propswap,
                xn_prop_update_fn,
            )


@cython.boundscheck(True)
@cython.wraparound(False)
cpdef update_link_states_and_transitions_new(
    const id_t [:] active_links,
    const id_t [:] node_state,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    const int8_t [:] link_orientation,
    int8_t [:] bnd_lnk,
    id_t [:] link_state,
    id_t [:] n_trn,
    PriorityQueue priority_queue,
    cython.floating [:] next_update,
    id_t [:] next_trn_id,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
    long num_node_states,
    long num_node_states_sq,
    double current_time,
):
    """
    Following an "external" change to the node state grid, updates link
    states where necessary and creates any needed events.

    Notes
    -----
    **Algorithm**::

        FOR each active link:
            if the actual node pair is different from the link's code:
                change the link state to be correct
                schedule an event
    """
    cdef int current_state
    cdef int i, j

    for j in range(len(active_links)):
        i = active_links[j]
        current_state = current_link_state(
            i,
            node_state,
            node_at_link_tail,
            node_at_link_head,
            link_orientation,
            num_node_states,
            num_node_states_sq,
        )
        if current_state != link_state[i]:
            update_link_state_new(
                i,
                current_state,
                current_time,
                bnd_lnk,
                node_state,
                node_at_link_tail,
                node_at_link_head,
                link_orientation,
                num_node_states,
                num_node_states_sq,
                link_state,
                n_trn,
                priority_queue,
                next_update,
                next_trn_id,
                trn_id,
                trn_rate,
            )


@cython.boundscheck(True)
@cython.wraparound(False)
@cython.cdivision(True)
cpdef update_node_states(
    id_t [:] node_state,
    const uint8_t [:] status_at_node,
    long tail_node,
    long head_node,
    new_link_state,
    num_states,
):
    """Update the states of 2 nodes that underwent a transition."""
    if _DEBUG:
        print(("UNS", tail_node, head_node, new_link_state, num_states))
    # Change to the new states
    if status_at_node[tail_node] == _CORE:
        # assume integer division!!
        node_state[tail_node] = (new_link_state / num_states) % num_states
    if status_at_node[head_node] == _CORE:
        node_state[head_node] = new_link_state % num_states
    if _DEBUG:
        print(("UNS new tail state: ", node_state[tail_node]))
        print(("UNS new head state: ", node_state[head_node]))


@cython.boundscheck(True)
@cython.wraparound(False)
cpdef get_next_event(
    long link,
    long current_state,
    double current_time,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    int8_t [:, :] xn_propswap,
    object [:, :] xn_prop_update_fn,
):
    """Get the next event for a link.

    Returns the next event for link with ID "link", which is in state
    "current state".

    Parameters
    ----------
    link : int
        ID of the link
    current_state : int
        Current state code for the link
    current_time : float
        Current time in simulation (i.e., time of event just processed)
    (see celllab_cts.py for other parameters)

    Returns
    -------
    Event object
        The returned Event object contains the time, link ID, and type of
        the next transition event at this link.

    Notes
    -----
    If there is only one potential transition out of the current state, a
    time for the transition is selected at random from an exponential
    distribution with rate parameter appropriate for this transition.

    If there are more than one potential transitions, a transition time is
    chosen for each, and the smallest of these applied.

    Assumes that there is at least one potential transition from the
    current state.
    """
    cdef int my_xn_to
    cdef int i
    cdef char propswap
    cdef double next_time, this_next
    cdef Event my_event

    # Find next event time for each potential transition
    if n_xn[current_state] == 1:
        my_xn_to = xn_to[current_state, 0]
        propswap = xn_propswap[current_state, 0]
        next_time = np.random.exponential(1.0 / xn_rate[current_state, 0])
        # next_time = -(1.0 / xn_rate[current_state, 0]) * log(1.0 - rand())
        prop_update_fn = xn_prop_update_fn[current_state, 0]
    else:
        next_time = _NEVER
        my_xn_to = 0
        propswap = 0
        for i in range(n_xn[current_state]):
            this_next = np.random.exponential(1.0 / xn_rate[current_state, i])
            # this_next = -(1.0 / xn_rate[current_state, i]) * log(1.0 - rand())
            if this_next < next_time:
                next_time = this_next
                my_xn_to = xn_to[current_state, i]
                propswap = xn_propswap[current_state, i]
                prop_update_fn = xn_prop_update_fn[current_state, i]

    # Create and setup event, and return it
    my_event = Event(next_time + current_time, link, my_xn_to, propswap, prop_update_fn)

    return my_event


@cython.boundscheck(True)
@cython.wraparound(False)
cpdef get_next_event_new(
    long link,
    long current_state,
    double current_time,
    id_t [:] n_trn,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
):
    """Get the next event for a link.

    Returns the next event for link with ID "link", which is in state
    "current state".

    Parameters
    ----------
    link : int
        ID of the link
    current_state : int
        Current state code for the link
    current_time : float
        Current time in simulation (i.e., time of event just processed)
    (see celllab_cts.py for other parameters)

    Returns
    -------
    Event object
        The returned Event object contains the time, link ID, and type of
        the next transition event at this link.

    Notes
    -----
    If there is only one potential transition out of the current state, a
    time for the transition is selected at random from an exponential
    distribution with rate parameter appropriate for this transition.

    If there are more than one potential transitions, a transition time is
    chosen for each, and the smallest of these applied.

    Assumes that there is at least one potential transition from the
    current state.
    """
    cdef int this_trn_id
    cdef int i
    cdef double next_time, this_next

    # Find next event time for each potential transition
    if n_trn[current_state] == 1:
        this_trn_id = trn_id[current_state, 0]
        next_time = np.random.exponential(1.0 / trn_rate[this_trn_id])
    else:
        next_time = _NEVER
        this_trn_id = -1
        for i in range(n_trn[current_state]):
            this_next = np.random.exponential(1.0 / trn_rate[trn_id[current_state][i]])
            if this_next < next_time:
                next_time = this_next
                this_trn_id = trn_id[current_state, i]

    return (next_time + current_time, this_trn_id)


cpdef push_transitions_to_event_queue(
    long number_of_active_links,
    const id_t [:] active_links,
    id_t [:] n_trn,
    id_t [:] link_state,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
    cython.floating [:] next_update,
    id_t [:] next_trn_id,
    PriorityQueue priority_queue,
):
    """
    Initializes the event queue by creating transition events for each
    cell pair that has one or more potential transitions and pushing these
    onto the queue. Also records scheduled transition times in the
    self.next_update array.
    """
    for j in range(number_of_active_links):

        i = active_links[j]
        if n_trn[link_state[i]] > 0:
            (ev_time, this_trn_id) = get_next_event_new(
                i, link_state[i], 0.0, n_trn, trn_id, trn_rate
            )
            priority_queue.push(i, ev_time)
            next_update[i] = ev_time
            next_trn_id[i] = this_trn_id

        else:
            next_update[i] = _NEVER


@cython.boundscheck(True)
@cython.wraparound(False)
cdef void update_link_state(
    long link,
    long new_link_state,
    double current_time,
    int8_t [:] bnd_lnk,
    const id_t [:] node_state,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    const int8_t [:] link_orientation,
    long num_node_states,
    long num_node_states_sq,
    id_t [:] link_state,
    id_t [:] n_xn,
    Event [:] event_queue,
    cython.floating [:] next_update,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    int8_t [:, :] xn_propswap,
    object [:, :] xn_prop_update_fn,
):
    """
    Implements a link transition by updating the current state of the link
    and (if appropriate) choosing the next transition event and pushing it
    on to the event queue.

    Parameters
    ----------
    link : int
        ID of the link to update
    new_link_state : int
        Code for the new state
    current_time : float
        Current time in simulation
    (see celllab_cts.py for other parameters)
    """
    cdef int fns, tns
    cdef int orientation
    cdef Event event

    # If the link connects to a boundary, we might have a different state
    # than the one we planned
    if bnd_lnk[link]:
        fns = node_state[node_at_link_tail[link]]
        tns = node_state[node_at_link_head[link]]
        orientation = link_orientation[link]
        new_link_state = orientation * num_node_states_sq + \
            fns * num_node_states + tns

    link_state[link] = new_link_state
    if n_xn[new_link_state] > 0:
        event = get_next_event(
            link,
            new_link_state,
            current_time,
            n_xn,
            xn_to,
            xn_rate,
            xn_propswap,
            xn_prop_update_fn,
        )
        heappush(event_queue, event)
        next_update[link] = event.time
    else:
        next_update[link] = _NEVER


@cython.boundscheck(True)
@cython.wraparound(False)
cdef void update_link_state_new(
    long link,
    long new_link_state,
    double current_time,
    int8_t [:] bnd_lnk,
    const id_t [:] node_state,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    const int8_t [:] link_orientation,
    long num_node_states,
    long num_node_states_sq,
    id_t [:] link_state,
    id_t [:] n_trn,
    PriorityQueue priority_queue,
    cython.floating [:] next_update,
    id_t [:] next_trn_id,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
):
    """
    Implements a link transition by updating the current state of the link
    and (if appropriate) choosing the next transition event and pushing it
    on to the event queue.

    Parameters
    ----------
    link : int
        ID of the link to update
    new_link_state : int
        Code for the new state
    current_time : float
        Current time in simulation
    (see celllab_cts.py for other parameters)
    """
    cdef int fns, tns
    cdef int this_trn_id
    cdef int orientation

    if _DEBUG:
        print(("ULSN", link, link_state[link], new_link_state, current_time))

    # If the link connects to a boundary, we might have a different state
    # than the one we planned
    if bnd_lnk[link]:
        fns = node_state[node_at_link_tail[link]]
        tns = node_state[node_at_link_head[link]]
        orientation = link_orientation[link]
        new_link_state = orientation * num_node_states_sq + \
            fns * num_node_states + tns
        if _DEBUG:
            print((" bnd True", new_link_state))

    link_state[link] = new_link_state
    if n_trn[new_link_state] > 0:
        (event_time, this_trn_id) = get_next_event_new(
            link, new_link_state, current_time, n_trn, trn_id, trn_rate
        )
        priority_queue.push(link, event_time)
        next_update[link] = event_time
        next_trn_id[link] = this_trn_id
    else:
        next_update[link] = _NEVER
        next_trn_id[link] = -1


@cython.boundscheck(True)
@cython.wraparound(False)
cdef void do_transition(
    Event event,
    cython.floating [:] next_update,
    id_t [:] node_at_link_tail,
    id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] link_state,
    uint8_t [:] status_at_node,
    int8_t [:] link_orientation,
    id_t [:] propid,
    int_or_float_t [:] prop_data,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    long num_node_states,
    long num_node_states_sq,
    int_or_float_t prop_reset_value,
    int8_t [:, :] xn_propswap,
    object [:, :] xn_prop_update_fn,
    int8_t [:] bnd_lnk,
    Event [:] event_queue,
    this_cts_model,
    plot_each_transition=False,
    plotter=None,
):
    """Transition state.

    Implements a state transition.

    Parameters
    ----------
    event : Event object
        Event object containing the data for the current transition event
    plot_each_transition : bool (optional)
        True if caller wants to show a plot of the grid after this
        transition
    plotter : CAPlotter object
        Sent if caller wants a plot after this transition
    (see celllab_cts.py for other parameters)

    Notes
    -----
    First checks that the transition is still valid by comparing the
    link's next_update time with the corresponding update time in the
    event object.

    If the transition is valid, we:

    1. Update the states of the two nodes attached to the link
    2. Update the link's state, choose its next transition, and push
       it on the event queue.
    3. Update the states of the other links attached to the two nodes,
       choose their next transitions, and push them on the event queue.
    """
    cdef int tail_node, head_node  # IDs of tail and head nodes at link
    cdef int old_tail_node_state
    cdef int old_head_node_state
    cdef int this_link_tail_node   # Tail ID for an adjacent link
    cdef int this_link_head_node   # Head ID for an adjacent link
    cdef int link                  # ID of a link
    cdef int new_link_state        # New link state after transition
    cdef int tmp                   # Used to exchange property IDs
    cdef char dir_code             # Direction code for link at node
    cdef char orientation          # Orientation code for link
    cdef int i

    # We'll process the event if its update time matches the one we have
    # recorded for the link in question. If not, it means that the link has
    # changed state since the event was pushed onto the event queue, and
    # in that case we'll ignore it.
    if event.time == next_update[event.link]:

        tail_node = node_at_link_tail[event.link]
        head_node = node_at_link_head[event.link]

        # Remember the previous state of each node so we can detect whether the
        # state has changed
        old_tail_node_state = node_state[tail_node]
        old_head_node_state = node_state[head_node]

        update_node_states(
            node_state,
            status_at_node,
            tail_node,
            head_node,
            event.xn_to,
            num_node_states,
        )
        update_link_state(
            event.link,
            event.xn_to,
            event.time,
            bnd_lnk,
            node_state,
            node_at_link_tail,
            node_at_link_head,
            link_orientation,
            num_node_states,
            num_node_states_sq,
            link_state,
            n_xn,
            event_queue,
            next_update,
            xn_to,
            xn_rate,
            xn_propswap,
            xn_prop_update_fn,
        )

        # Next, when the state of one of the link's nodes changes, we have
        # to update the states of the OTHER links attached to it. This
        # could happen to one or both nodes.
        if node_state[tail_node] != old_tail_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[tail_node, i]
                dir_code = active_link_dirs_at_node[tail_node, i]

                if dir_code != 0 and link != event.link:

                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state(
                        link,
                        new_link_state,
                        event.time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_xn,
                        event_queue,
                        next_update,
                        xn_to,
                        xn_rate,
                        xn_propswap,
                        xn_prop_update_fn,
                    )

        if node_state[head_node] != old_head_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[head_node, i]
                dir_code = active_link_dirs_at_node[head_node, i]

                if dir_code != 0 and link != event.link:
                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state(
                        link,
                        new_link_state,
                        event.time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_xn,
                        event_queue,
                        next_update,
                        xn_to,
                        xn_rate,
                        xn_propswap,
                        xn_prop_update_fn,
                    )

        # If requested, display a plot of the grid
        if plot_each_transition and (plotter is not None):
            plotter.update_plot()

        # If this event involves an exchange of properties (i.e., the
        # event involves motion of an object that posses properties we
        # want to track), implement the swap.
        #   If the event requires a call to a user-defined callback
        # function, we handle that here too.
        if event.propswap:
            tmp = propid[tail_node]
            propid[tail_node] = propid[head_node]
            propid[head_node] = tmp
            if status_at_node[tail_node] != _CORE:
                prop_data[propid[tail_node]] = prop_reset_value
            if status_at_node[head_node] != _CORE:
                prop_data[propid[head_node]] = prop_reset_value
            if event.prop_update_fn is not None:
                event.prop_update_fn(this_cts_model, tail_node, head_node, event.time)


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void do_transition_new(
    long event_link,
    double event_time,
    PriorityQueue priority_queue,
    cython.floating [:] next_update,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] next_trn_id,
    id_t [:] trn_to,
    uint8_t [:] status_at_node,
    long num_node_states,
    long num_node_states_sq,
    int8_t [:] bnd_lnk,
    const int8_t [:] link_orientation,
    id_t [:] link_state,
    id_t [:] n_trn,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
    const id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    int8_t [:] trn_propswap,
    id_t [:] propid,
    int_or_float_t [:] prop_data,
    int_or_float_t prop_reset_value,
    object [:] trn_prop_update_fn,
    object this_cts_model,
    plot_each_transition=False,
    plotter=None,
):
    """Transition state.

    Implements a state transition.

    Parameters
    ----------
    event : Event object
        Event object containing the data for the current transition event
    plot_each_transition : bool (optional)
        True if caller wants to show a plot of the grid after this
        transition
    plotter : CAPlotter object
        Sent if caller wants a plot after this transition
    (see celllab_cts.py for other parameters)

    Notes
    -----
    First checks that the transition is still valid by comparing the
    link's next_update time with the corresponding update time in the
    event object.

    If the transition is valid, we:

    1. Update the states of the two nodes attached to the link
    2. Update the link's state, choose its next transition, and push
       it on the event queue.
    3. Update the states of the other links attached to the two nodes,
       choose their next transitions, and push them on the event queue.
    """
    cdef int tail_node, head_node  # IDs of tail and head nodes at link
    cdef int old_tail_node_state
    cdef int old_head_node_state
    cdef int this_trn_id
    cdef int this_trn_to
    cdef int this_link_tail_node   # Tail ID for an adjacent link
    cdef int this_link_head_node   # Head ID for an adjacent link
    cdef int link                  # ID of a link
    cdef int new_link_state        # New link state after transition
    cdef int tmp                   # Used to exchange property IDs
    cdef char dir_code             # Direction code for link at node
    cdef char orientation          # Orientation code for link
    cdef int i

    if _DEBUG:
        print(
            (
                "DTN",
                event_time,
                event_link,
                link_state[event_link],
                next_update[event_link],
            )
        )

    # We'll process the event if its update time matches the one we have
    # recorded for the link in question. If not, it means that the link has
    # changed state since the event was pushed onto the event queue, and
    # in that case we'll ignore it.
    if event_time == next_update[event_link]:

        tail_node = node_at_link_tail[event_link]
        head_node = node_at_link_head[event_link]

        # DEBUG
        if status_at_node[tail_node] == 4 or status_at_node[head_node] == 4:
            print(
                (
                    "TRN INFO: ",
                    event_time,
                    event_link,
                    link_state[event_link],
                    next_update[event_link],
                )
            )
            print("TAIL " + str(tail_node) + " " + status_at_node[tail_node])
            print("HEAD " + str(head_node) + " " + status_at_node[tail_node])
            # _DEBUG = True

        # Remember the previous state of each node so we can detect whether the
        # state has changed
        old_tail_node_state = node_state[tail_node]
        old_head_node_state = node_state[head_node]

        this_trn_id = next_trn_id[event_link]
        this_trn_to = trn_to[this_trn_id]

        if _DEBUG:
            print((this_trn_id, this_trn_to))
            print(("tail:", tail_node))
            print(("tail state:", old_tail_node_state))
            print(("head:", head_node))
            print(("head state:", old_head_node_state))

        update_node_states(
            node_state,
            status_at_node,
            tail_node,
            head_node,
            this_trn_to,
            num_node_states,
        )
        update_link_state_new(
            event_link,
            this_trn_to,
            event_time,
            bnd_lnk,
            node_state,
            node_at_link_tail,
            node_at_link_head,
            link_orientation,
            num_node_states,
            num_node_states_sq,
            link_state,
            n_trn,
            priority_queue,
            next_update,
            next_trn_id,
            trn_id,
            trn_rate,
        )

        # Next, when the state of one of the link's nodes changes, we have
        # to update the states of the OTHER links attached to it. This
        # could happen to one or both nodes.
        if node_state[tail_node] != old_tail_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[tail_node, i]
                dir_code = active_link_dirs_at_node[tail_node, i]

                if dir_code != 0 and link != event_link:

                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state_new(
                        link,
                        new_link_state,
                        event_time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_trn,
                        priority_queue,
                        next_update,
                        next_trn_id,
                        trn_id,
                        trn_rate,
                    )

        if node_state[head_node] != old_head_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[head_node, i]
                dir_code = active_link_dirs_at_node[head_node, i]

                if dir_code != 0 and link != event_link:
                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state_new(
                        link,
                        new_link_state,
                        event_time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_trn,
                        priority_queue,
                        next_update,
                        next_trn_id,
                        trn_id,
                        trn_rate,
                    )

        # If requested, display a plot of the grid
        if plot_each_transition and (plotter is not None):
            plotter.update_plot()

        # If this event involves an exchange of properties (i.e., the
        # event involves motion of an object that posses properties we
        # want to track), implement the swap.
        #   If the event requires a call to a user-defined callback
        # function, we handle that here too.
        if trn_propswap[this_trn_id]:
            tmp = propid[tail_node]
            propid[tail_node] = propid[head_node]
            propid[head_node] = tmp
            if status_at_node[tail_node] != _CORE:
                prop_data[propid[tail_node]] = prop_reset_value
            if status_at_node[head_node] != _CORE:
                prop_data[propid[head_node]] = prop_reset_value
            if trn_prop_update_fn[this_trn_id] != 0:
                trn_prop_update_fn[this_trn_id](
                    this_cts_model, tail_node, head_node, event_time)

cpdef double run_cts_new(
    double run_to,
    double current_time,
    PriorityQueue priority_queue,
    cython.floating [:] next_update,
    const id_t [:] node_at_link_tail,
    const id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] next_trn_id,
    id_t [:] trn_to,
    uint8_t [:] status_at_node,
    long num_node_states,
    long num_node_states_sq,
    int8_t [:] bnd_lnk,
    const int8_t [:] link_orientation,
    id_t [:] link_state,
    id_t [:] n_trn,
    id_t [:, :] trn_id,
    cython.floating [:] trn_rate,
    const id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    int8_t [:] trn_propswap,
    id_t [:] propid,
    int_or_float_t [:] prop_data,
    int_or_float_t prop_reset_value,
    object [:] trn_prop_update_fn,
    this_cts_model,
    char plot_each_transition,
    object plotter,
):
    """Run the model forward for a specified period of time.

    Parameters
    ----------
    run_to : float
        Time to run to, starting from self.current_time
    node_state_grid : 1D array of ints (x number of nodes) (optional)
        Node states (if given, replaces model's current node state grid)
    plot_each_transition : bool (optional)
        Option to display the grid after each transition
    plotter : CAPlotter object (optional)
        Needed if caller wants to plot after every transition
    (see celllab_cts.py for other parameters)
    """
    cdef double ev_time
    cdef int _ev_idx
    cdef int ev_link

    # Continue until we've run out of either time or events
    while current_time < run_to and priority_queue._queue:

        if _DEBUG:
            print("current time = ", current_time)

        # Is there an event scheduled to occur within this run?
        if priority_queue._queue[0][0] <= run_to:

            # If so, pick the next transition event from the event queue
            (ev_time, _ev_idx, ev_link) = priority_queue.pop()

            # ... and execute the transition
            do_transition_new(
                ev_link,
                ev_time,
                priority_queue,
                next_update,
                node_at_link_tail,
                node_at_link_head,
                node_state,
                next_trn_id,
                trn_to,
                status_at_node,
                num_node_states,
                num_node_states_sq,
                bnd_lnk,
                link_orientation,
                link_state,
                n_trn,
                trn_id,
                trn_rate,
                links_at_node,
                active_link_dirs_at_node,
                trn_propswap,
                propid, prop_data,
                prop_reset_value,
                trn_prop_update_fn,
                this_cts_model,
                plot_each_transition,
                plotter,
            )

            # Update current time
            current_time = ev_time

        # If there is no event scheduled for this span of time, simply
        # advance current_time to the end of the current run period.
        else:
            current_time = run_to

    return current_time


cpdef double run_cts(
    double run_to,
    double current_time,
    char plot_each_transition,
    object plotter,
    Event [:] event_queue,
    cython.floating [:] next_update,
    id_t [:] node_at_link_tail,
    id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] link_state,
    uint8_t [:] status_at_node,
    int8_t [:] link_orientation,
    id_t [:] propid,
    int_or_float_t [:] prop_data,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    long num_node_states,
    long num_node_states_sq,
    int_or_float_t prop_reset_value,
    int8_t [:, :] xn_propswap,
    object [:, :] xn_prop_update_fn,
    int8_t [:] bnd_lnk,
    this_cts_model,
):
    """Run the model forward for a specified period of time.

    Parameters
    ----------
    run_to : float
        Time to run to, starting from self.current_time
    node_state_grid : 1D array of ints (x number of nodes) (optional)
        Node states (if given, replaces model's current node state grid)
    plot_each_transition : bool (optional)
        Option to display the grid after each transition
    plotter : CAPlotter object (optional)
        Needed if caller wants to plot after every transition
    (see celllab_cts.py for other parameters)
    """
    cdef Event ev

    # Continue until we've run out of either time or events
    while current_time < run_to and len(event_queue) > 0:

        # Is there an event scheduled to occur within this run?
        if event_queue[0].time <= run_to:

            # If so, pick the next transition event from the event queue
            ev = heappop(event_queue)

            # ... and execute the transition
            do_transition(
                ev,
                next_update,
                node_at_link_tail,
                node_at_link_head,
                node_state,
                link_state,
                status_at_node,
                link_orientation,
                propid,
                prop_data,
                n_xn,
                xn_to,
                xn_rate,
                links_at_node,
                active_link_dirs_at_node,
                num_node_states,
                num_node_states_sq,
                prop_reset_value,
                xn_propswap,
                xn_prop_update_fn,
                bnd_lnk,
                event_queue,
                this_cts_model,
                plot_each_transition,
                plotter,
            )

            # Update current time
            current_time = ev.time

        # If there is no event scheduled for this span of time, simply
        # advance current_time to the end of the current run period.
        else:
            current_time = run_to

    return current_time


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef get_next_event_lean(
    long link,
    long current_state,
    double current_time,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
):
    """Get the next event for a link.

    Returns the next event for link with ID "link", which is in state
    "current state". This "lean" version omits parameters related to property
    exchange and callback function.

    Parameters
    ----------
    link : int
        ID of the link
    current_state : int
        Current state code for the link
    current_time : float
        Current time in simulation (i.e., time of event just processed)
    (see celllab_cts.py for other parameters)

    Returns
    -------
    Event object
        The returned Event object contains the time, link ID, and type of
        the next transition event at this link.

    Notes
    -----
    If there is only one potential transition out of the current state, a
    time for the transition is selected at random from an exponential
    distribution with rate parameter appropriate for this transition.

    If there are more than one potential transitions, a transition time is
    chosen for each, and the smallest of these applied.

    Assumes that there is at least one potential transition from the
    current state.
    """
    cdef int my_xn_to
    cdef int i
    cdef double next_time, this_next
    cdef Event my_event

    # Find next event time for each potential transition
    if n_xn[current_state] == 1:
        my_xn_to = xn_to[current_state, 0]
        next_time = np.random.exponential(1.0 / xn_rate[current_state, 0])
        # next_time = -(1.0 / xn_rate[current_state, 0]) * log(1.0 - rand())
    else:
        next_time = _NEVER
        my_xn_to = 0
        for i in range(n_xn[current_state]):
            this_next = np.random.exponential(1.0 / xn_rate[current_state, i])
            # this_next = -(1.0 / xn_rate[current_state, i]) * log(1.0 - rand())
            if this_next < next_time:
                next_time = this_next
                my_xn_to = xn_to[current_state, i]

    # Create and setup event, and return it
    my_event = Event(next_time + current_time, link, my_xn_to)

    return my_event


@cython.boundscheck(False)
@cython.wraparound(False)
cdef void update_link_state_lean(
    long link,
    long new_link_state,
    double current_time,
    int8_t [:] bnd_lnk,
    id_t [:] node_state,
    id_t [:] node_at_link_tail,
    id_t [:] node_at_link_head,
    int8_t [:] link_orientation,
    long num_node_states,
    long num_node_states_sq,
    id_t [:] link_state,
    id_t [:] n_xn,
    Event [:] event_queue,
    cython.floating [:] next_update,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
):
    """
    Implements a link transition by updating the current state of the link
    and (if appropriate) choosing the next transition event and pushing it
    on to the event queue. This "lean" version omits parameters related to
    property exchange and callback function.

    Parameters
    ----------
    link : int
        ID of the link to update
    new_link_state : int
        Code for the new state
    current_time : float
        Current time in simulation
    (see celllab_cts.py for other parameters)
    """
    cdef int fns, tns
    cdef int orientation
    cdef Event event

    # If the link connects to a boundary, we might have a different state
    # than the one we planned
    if bnd_lnk[link]:
        fns = node_state[node_at_link_tail[link]]
        tns = node_state[node_at_link_head[link]]
        orientation = link_orientation[link]
        new_link_state = orientation * num_node_states_sq + fns * num_node_states + tns

    link_state[link] = new_link_state
    if n_xn[new_link_state] > 0:
        event = get_next_event_lean(
            link, new_link_state, current_time, n_xn, xn_to, xn_rate
        )
        heappush(event_queue, event)
        next_update[link] = event.time
    else:
        next_update[link] = _NEVER


@cython.boundscheck(False)
@cython.wraparound(False)
cdef void do_transition_lean(
    Event event,
    cython.floating [:] next_update,
    id_t [:] node_at_link_tail,
    id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] link_state,
    uint8_t [:] status_at_node,
    int8_t [:] link_orientation,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    long num_node_states,
    long num_node_states_sq,
    int8_t [:] bnd_lnk,
    Event [:] event_queue,
):
    """Transition state.

    Implements a state transition. This "lean" version omits parameters related
    to property exchange and callback function.

    Parameters
    ----------
    event : Event object
        Event object containing the data for the current transition event
    (see celllab_cts.py for other parameters)

    Notes
    -----
    First checks that the transition is still valid by comparing the
    link's next_update time with the corresponding update time in the
    event object.

    If the transition is valid, we:

    1. Update the states of the two nodes attached to the link
    2. Update the link's state, choose its next transition, and push
       it on the event queue.
    3. Update the states of the other links attached to the two nodes,
       choose their next transitions, and push them on the event queue.
    """
    cdef int tail_node, head_node  # IDs of tail and head nodes at link
    cdef int old_tail_node_state
    cdef int old_head_node_state
    cdef int this_link_tail_node   # Tail ID for an adjacent link
    cdef int this_link_head_node   # Head ID for an adjacent link
    cdef int link                  # ID of a link
    cdef int new_link_state        # New link state after transition
    cdef char dir_code             # Direction code for link at node
    cdef char orientation          # Orientation code for link
    cdef int i

    # print 'dtl'

    # We'll process the event if its update time matches the one we have
    # recorded for the link in question. If not, it means that the link has
    # changed state since the event was pushed onto the event queue, and
    # in that case we'll ignore it.
    if event.time == next_update[event.link]:

        tail_node = node_at_link_tail[event.link]
        head_node = node_at_link_head[event.link]

        # Remember the previous state of each node so we can detect whether the
        # state has changed
        old_tail_node_state = node_state[tail_node]
        old_head_node_state = node_state[head_node]

        update_node_states(
            node_state,
            status_at_node,
            tail_node,
            head_node,
            event.xn_to,
            num_node_states,
        )
        update_link_state_lean(
            event.link,
            event.xn_to,
            event.time,
            bnd_lnk,
            node_state,
            node_at_link_tail,
            node_at_link_head,
            link_orientation,
            num_node_states,
            num_node_states_sq,
            link_state,
            n_xn,
            event_queue,
            next_update,
            xn_to,
            xn_rate,
        )

        # Next, when the state of one of the link's nodes changes, we have
        # to update the states of the OTHER links attached to it. This
        # could happen to one or both nodes.
        if node_state[tail_node] != old_tail_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[tail_node, i]
                dir_code = active_link_dirs_at_node[tail_node, i]

                if dir_code != 0 and link != event.link:

                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state_lean(
                        link,
                        new_link_state,
                        event.time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_xn,
                        event_queue,
                        next_update,
                        xn_to,
                        xn_rate,
                    )

        if node_state[head_node] != old_head_node_state:

            for i in range(links_at_node.shape[1]):

                link = links_at_node[head_node, i]
                dir_code = active_link_dirs_at_node[head_node, i]

                if dir_code != 0 and link != event.link:
                    this_link_tail_node = node_at_link_tail[link]
                    this_link_head_node = node_at_link_head[link]
                    orientation = link_orientation[link]
                    new_link_state = (
                        orientation * num_node_states_sq +
                        node_state[this_link_tail_node] * num_node_states +
                        node_state[this_link_head_node]
                    )
                    update_link_state_lean(
                        link,
                        new_link_state,
                        event.time,
                        bnd_lnk,
                        node_state,
                        node_at_link_tail,
                        node_at_link_head,
                        link_orientation,
                        num_node_states,
                        num_node_states_sq,
                        link_state,
                        n_xn,
                        event_queue,
                        next_update,
                        xn_to,
                        xn_rate,
                    )


@cython.boundscheck(False)
cpdef double run_cts_lean(
    double run_to,
    double current_time,
    Event [:] event_queue,
    cython.floating [:] next_update,
    id_t [:] node_at_link_tail,
    id_t [:] node_at_link_head,
    id_t [:] node_state,
    id_t [:] link_state,
    uint8_t [:] status_at_node,
    int8_t [:] link_orientation,
    id_t [:] n_xn,
    id_t [:, :] xn_to,
    cython.floating [:, :] xn_rate,
    id_t [:, :] links_at_node,
    const int8_t [:, :] active_link_dirs_at_node,
    long num_node_states,
    long num_node_states_sq,
    int8_t [:] bnd_lnk,
):
    """Run the model forward for a specified period of time. This "lean"
    version omits parameters related to property exchange and callback fn.

    Parameters
    ----------
    run_to : float
        Time to run to, starting from self.current_time
    (see celllab_cts.py for other parameters)
    """
    cdef Event ev

    # Continue until we've run out of either time or events
    while current_time < run_to and len(event_queue) > 0:

        # Is there an event scheduled to occur within this run?
        if event_queue[0].time <= run_to:

            # print 'popping'

            # If so, pick the next transition event from the event queue
            ev = heappop(event_queue)

            # ... and execute the transition
            do_transition_lean(
                ev,
                next_update,
                node_at_link_tail,
                node_at_link_head,
                node_state,
                link_state,
                status_at_node,
                link_orientation,
                n_xn,
                xn_to,
                xn_rate,
                links_at_node,
                active_link_dirs_at_node,
                num_node_states,
                num_node_states_sq,
                bnd_lnk,
                event_queue,
            )

            # Update current time
            current_time = ev.time

        # If there is no event scheduled for this span of time, simply
        # advance current_time to the end of the current run period.
        else:
            current_time = run_to

    return current_time



================================================
File: src/landlab/ca/hex_cts.py
================================================
#! /usr/env/python
"""Simple hexagonal Landlab cellular automaton.

This file defines the HexCTS class, which is a sub-class of
CellLabCTSModel that implements a simple, non-oriented, hex-grid
CA. Like its parent class, HexCTS implements a continuous-time, stochastic,
pair-based CA. The hex grid has 3 principal directions, rather than 2 for a
raster. Hex grids are often used in CA models because of their symmetry.

Created GT Sep 2014
"""

from ..grid import HexModelGrid
from .celllab_cts import CellLabCTSModel


class HexCTS(CellLabCTSModel):
    """Class HexCTS implements a non-oriented hex-grid CellLab-CTS model.

    HexCTS constructor: sets number of orientations to 1 and calls
    base-class constructor.

    Parameters
    ----------
    model_grid : Landlab ModelGrid object
        Reference to the model's grid
    node_state_dict : dict
        Keys are node-state codes, values are the names associated with
        these codes
    transition_list : list of Transition objects
        List of all possible transitions in the model
    initial_node_states : array of ints (x number of nodes in grid)
        Starting values for node-state grid
    prop_data : array (x number of nodes in grid) (optional)
        Array of properties associated with each node/cell
    prop_reset_value : number or object, optional
        Default or initial value for a node/cell property (e.g., 0.0).
        Must be same type as *prop_data*.

    Examples
    --------
    >>> from landlab import HexModelGrid
    >>> from landlab.ca.celllab_cts import Transition
    >>> from landlab.ca.hex_cts import HexCTS

    >>> mg = HexModelGrid((4, 3), spacing=1.0)
    >>> nsd = {0: "yes", 1: "no"}
    >>> xnlist = []
    >>> xnlist.append(Transition((0, 1, 0), (1, 1, 0), 1.0, "frogging"))
    >>> nsg = mg.add_zeros("node_state_grid", at="node")
    >>> hcts = HexCTS(mg, nsd, xnlist, nsg)
    """

    def __init__(
        self,
        model_grid,
        node_state_dict,
        transition_list,
        initial_node_states,
        prop_data=None,
        prop_reset_value=None,
        seed=0,
    ):
        """HexCTS constructor: sets number of orientations to 1 and calls base-
        class constructor.

        Parameters
        ----------
        model_grid : Landlab ModelGrid object
            Reference to the model's grid
        node_state_dict : dict
            Keys are node-state codes, values are the names associated with
            these codes
        transition_list : list of Transition objects
            List of all possible transitions in the model
        initial_node_states : array of ints (x number of nodes in grid)
            Starting values for node-state grid
        prop_data : array (x number of nodes in grid) (optional)
            Array of properties associated with each node/cell
        prop_reset_value : number or object, optional
            Default or initial value for a node/cell property (e.g., 0.0).
            Must be same type as *prop_data*.
        seed : int (default 0)
            Seed for random number generator
        """

        # Make sure caller has sent the right grid type
        if not isinstance(model_grid, HexModelGrid):
            raise TypeError("model_grid must be a Landlab HexModelGrid")

        # Define the number of distinct cell-pair orientations: here just 1,
        # because HexCTS represents a non-oriented CA model.
        self.number_of_orientations = 1

        # Call the LandlabCellularAutomaton.__init__() method to do the rest of
        # the initialization
        super().__init__(
            model_grid,
            node_state_dict,
            transition_list,
            initial_node_states,
            prop_data,
            prop_reset_value,
            seed,
        )



================================================
File: src/landlab/ca/oriented_hex_cts.py
================================================
#! /usr/env/python
"""Simple hexagonal Landlab cellular automaton.

This file defines the OrientedHexCTS class, which is a sub-class of
CellLabCTSModel that implements a simple, non-oriented, hex-grid
CA. Like its parent class, OrientedHexCTS implements a continuous-time,
stochastic, pair-based CA. The hex grid has 3 principal directions, rather
than 2 for a raster. Hex grids are often used in CA models because of their
symmetry.

Created GT Sep 2014
"""
import numpy as np

from ..grid import HexModelGrid
from .celllab_cts import CellLabCTSModel


class OrientedHexCTS(CellLabCTSModel):
    """Oriented hex-grid CellLab-CTS model.

    OrientedHexCTS constructor: sets number of orientations to 3 and calls
    base-class constructor.

    Parameters
    ----------
    model_grid : Landlab ModelGrid object
        Reference to the model's grid
    node_state_dict : dict
        Keys are node-state codes, values are the names associated with
        these codes
    transition_list : list of Transition objects
        List of all possible transitions in the model
    initial_node_states : array of ints (x number of nodes in grid)
        Starting values for node-state grid
    prop_data : array (x number of nodes in grid), optional
        Array of properties associated with each node/cell
    prop_reset_value : number or object, optional
        Default or initial value for a node/cell property (e.g., 0.0).
        Must be same type as *prop_data*.
    seed : int (default 0)
        Seed for random number generator

    Examples
    --------
    >>> from landlab import HexModelGrid
    >>> from landlab.ca.oriented_hex_cts import OrientedHexCTS
    >>> from landlab.ca.celllab_cts import Transition

    >>> mg = HexModelGrid((4, 3), spacing=1.0)
    >>> nsd = {0: "yes", 1: "no"}
    >>> xnlist = []
    >>> xnlist.append(Transition((0, 1, 0), (1, 1, 0), 1.0, "frogging"))
    >>> nsg = mg.add_zeros("node_state_grid", at="node")
    >>> ohcts = OrientedHexCTS(mg, nsd, xnlist, nsg)
    """

    def __init__(
        self,
        model_grid,
        node_state_dict,
        transition_list,
        initial_node_states,
        prop_data=None,
        prop_reset_value=None,
        seed=0,
    ):
        """Initialize a OrientedHexCTS.

        OrientedHexCTS constructor: sets number of orientations to 3 and calls
        base-class constructor.

        Parameters
        ----------
        model_grid : Landlab ModelGrid object
            Reference to the model's grid
        node_state_dict : dict
            Keys are node-state codes, values are the names associated with
            these codes
        transition_list : list of Transition objects
            List of all possible transitions in the model
        initial_node_states : array of ints (x number of nodes in grid)
            Starting values for node-state grid
        prop_data : array (x number of nodes in grid), optional
            Array of properties associated with each node/cell
        prop_reset_value : number or object, optional
            Default or initial value for a node/cell property (e.g., 0.0).
            Must be same type as *prop_data*.
        """

        # Make sure caller has sent the right grid type
        if not isinstance(model_grid, HexModelGrid):
            raise TypeError("model_grid must be a Landlab HexModelGrid")

        # Define the number of distinct cell-pair orientations: here 3,
        # representing
        self.number_of_orientations = 3

        # Call the LandlabCellularAutomaton.__init__() method to do the rest of
        # the initialization
        super().__init__(
            model_grid,
            node_state_dict,
            transition_list,
            initial_node_states,
            prop_data,
            prop_reset_value,
            seed,
        )

    def setup_array_of_orientation_codes(self):
        """Creates and configures an array that contain the orientation code
        for each active link (and corresponding cell pair).

        Notes
        -----
        **Creates**:

        * ``self.active_link_orientation``: 1D numpy array

        This overrides the method of the same name in celllab_cts.py. If the
        hex grid is oriented such that one of the 3 axes is vertical (a
        'vertical' grid), then the three orientations are:

        * 0 = vertical (0 degrees clockwise from vertical)
        * 1 = right and up (60 degrees clockwise from vertical)
        * 2 = right and down (120 degrees clockwise from vertical)

        If the grid is oriented with one principal axis horizontal
        ('horizontal' grid), then the orientations are:

        * 0 = up and left (30 degrees counter-clockwise from vertical)
        * 1 = up and right (30 degrees clockwise from vertical)
        * 2 = horizontal (90 degrees clockwise from vertical)
        """
        self.link_orientation = np.zeros(self.grid.number_of_links, dtype=np.int8)
        for i in range(self.grid.number_of_links):
            dy = (
                self.grid.node_y[self.grid.node_at_link_head[i]]
                - self.grid.node_y[self.grid.node_at_link_tail[i]]
            )
            dx = (
                self.grid.node_x[self.grid.node_at_link_head[i]]
                - self.grid.node_x[self.grid.node_at_link_tail[i]]
            )
            if dx <= 0.0:
                self.link_orientation[i] = 0
            elif dy <= 0.0:
                self.link_orientation[i] = 2
            elif dx > 0.0 and dy > 0.0:
                self.link_orientation[i] = 1



================================================
File: src/landlab/ca/oriented_raster_cts.py
================================================
#! /usr/env/python
"""Simple raster Landlab cellular automaton.

Simple raster Landlab cellular automaton, with
cell-pair transitions that depend on orientation (vertical or horizontal)

This file defines the OrientedRasterCTS class, which is a sub-class of
CellLabCTSModel that implements a simple, oriented, raster-grid
CA. Like its parent class, OrientedRasterCTS implements a continuous-time,
stochastic, pair-based CA.

Created GT Sep 2014
"""


import numpy as np

from ..grid import RasterModelGrid
from .celllab_cts import CellLabCTSModel


class OrientedRasterCTS(CellLabCTSModel):
    """Oriented raster CellLab-CTS model.

    RasterCTS constructor: sets number of orientations to 2 and calls
    base-class constructor.

    Parameters
    ----------
    model_grid : Landlab ModelGrid object
        Reference to the model's grid
    node_state_dict : dict
        Keys are node-state codes, values are the names associated with
        these codes
    transition_list : list of Transition objects
        List of all possible transitions in the model
    initial_node_states : array of ints (x number of nodes in grid)
        Starting values for node-state grid
    prop_data : array (x number of nodes in grid) (optional)
        Array of properties associated with each node/cell
    prop_reset_value : number or object, optional
        Default or initial value for a node/cell property (e.g., 0.0).
        Must be same type as *prop_data*.
    seed : int (default 0)
        Seed for random number generator

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.ca.celllab_cts import Transition
    >>> from landlab.ca.oriented_raster_cts import OrientedRasterCTS

    >>> mg = RasterModelGrid((3, 4))
    >>> nsd = {0: "yes", 1: "no"}
    >>> xnlist = []
    >>> xnlist.append(Transition((0, 1, 0), (1, 1, 0), 1.0, "frogging"))
    >>> nsg = mg.add_zeros("node_state_grid", at="node")
    >>> orcts = OrientedRasterCTS(mg, nsd, xnlist, nsg)
    """

    def __init__(
        self,
        model_grid,
        node_state_dict,
        transition_list,
        initial_node_states,
        prop_data=None,
        prop_reset_value=None,
        seed=0,
    ):
        """RasterCTS constructor: sets number of orientations to 2 and calls
        base-class constructor.

        Parameters
        ----------
        model_grid : Landlab ModelGrid object
            Reference to the model's grid
        node_state_dict : dict
            Keys are node-state codes, values are the names associated with
            these codes
        transition_list : list of Transition objects
            List of all possible transitions in the model
        initial_node_states : array of ints (x number of nodes in grid)
            Starting values for node-state grid
        prop_data : array (x number of nodes in grid) (optional)
            Array of properties associated with each node/cell
        prop_reset_value : number or object, optional
            Default or initial value for a node/cell property (e.g., 0.0).
            Must be same type as *prop_data*.
        """

        # Make sure caller has sent the right grid type
        if not isinstance(model_grid, RasterModelGrid):
            raise TypeError("model_grid must be a Landlab RasterModelGrid")

        # Define the number of distinct cell-pair orientations: here just 1,
        # because RasterLCA represents a non-oriented CA model.
        self.number_of_orientations = 2

        # Call the LandlabCellularAutomaton constructor to do the rest of
        # the initialization
        super().__init__(
            model_grid,
            node_state_dict,
            transition_list,
            initial_node_states,
            prop_data,
            prop_reset_value,
            seed,
        )

    def setup_array_of_orientation_codes(self):
        """Creates and configures an array that contain the orientation code
        for each active link (and corresponding cell pair).

        Notes
        -----
        **Creates**:

        * ``self.active_link_orientation``: 1D numpy array of ints
          Array of orientation codes for each cell pair (link)

        This overrides the method of the same name in landlab_ca.py.
        """
        # Create array for the orientation of each active link
        self.link_orientation = np.zeros(self.grid.number_of_links, dtype=np.int8)

        # Set its value according to the different in y coordinate between each
        # link's TO and FROM nodes (the numpy "astype" method turns the
        # resulting array into integer format)
        dy = (
            self.grid.node_y[self.grid.node_at_link_head]
            - self.grid.node_y[self.grid.node_at_link_tail]
        )
        self.link_orientation = dy.astype(np.int8)



================================================
File: src/landlab/ca/raster_cts.py
================================================
#! /usr/env/python
"""
raster_cts.py: simple raster continuous-time stochastic cellular automaton

This file defines the RasterCTS class, which is a sub-class of
CellLabCTSModel that implements a simple, non-oriented, raster-grid
CA. Like its parent class, RasterCTS implements a continuous-time, stochastic,
pair-based CA.

Created GT Sep 2014, starting from link_ca.py.
"""

from ..grid import RasterModelGrid
from .celllab_cts import CellLabCTSModel


class RasterCTS(CellLabCTSModel):
    """Class RasterLCA implements a non-oriented raster CellLab-CTS model.

    RasterLCA constructor: sets number of orientations to 1 and calls
    base-class constructor.

    Parameters
    ----------
    model_grid : Landlab ModelGrid object
        Reference to the model's grid
    node_state_dict : dict
        Keys are node-state codes, values are the names associated with
        these codes
    transition_list : list of Transition objects
        List of all possible transitions in the model
    initial_node_states : array of ints (x number of nodes in grid)
        Starting values for node-state grid
    prop_data : array (x number of nodes in grid) (optional)
        Array of properties associated with each node/cell
    prop_reset_value : number or object, optional
        Default or initial value for a node/cell property (e.g., 0.0).
        Must be same type as *prop_data*.
    seed : int (default 0)
        Seed for random number generator

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.ca.celllab_cts import Transition
    >>> from landlab.ca.raster_cts import RasterCTS

    >>> mg = RasterModelGrid((3, 4))
    >>> nsd = {0: "yes", 1: "no"}
    >>> xnlist = []
    >>> xnlist.append(Transition((0, 1, 0), (1, 1, 0), 1.0, "frogging"))
    >>> nsg = mg.add_zeros("node_state_grid", at="node")
    >>> rcts = RasterCTS(mg, nsd, xnlist, nsg)
    """

    def __init__(
        self,
        model_grid,
        node_state_dict,
        transition_list,
        initial_node_states,
        prop_data=None,
        prop_reset_value=None,
        seed=0,
    ):
        """RasterLCA constructor: sets number of orientations to 1 and calls
        base-class constructor.

        Parameters
        ----------
        model_grid : Landlab ModelGrid object
            Reference to the model's grid
        node_state_dict : dict
            Keys are node-state codes, values are the names associated with
            these codes
        transition_list : list of Transition objects
            List of all possible transitions in the model
        initial_node_states : array of ints (x number of nodes in grid)
            Starting values for node-state grid
        prop_data : array (x number of nodes in grid) (optional)
            Array of properties associated with each node/cell
        prop_reset_value : number or object, optional
            Default or initial value for a node/cell property (e.g., 0.0).
            Must be same type as *prop_data*.
        """
        # Make sure caller has sent the right grid type
        if not isinstance(model_grid, RasterModelGrid):
            raise TypeError("model_grid must be a Landlab RasterModelGrid")

        # Define the number of distinct cell-pair orientations: here just 1,
        # because RasterLCA represents a non-oriented CA model.
        self.number_of_orientations = 1

        # Call the LandlabCellularAutomaton.__init__() method to do the rest of
        # the initialization
        super().__init__(
            model_grid,
            node_state_dict,
            transition_list,
            initial_node_states,
            prop_data,
            prop_reset_value,
            seed,
        )



================================================
File: src/landlab/ca/boundaries/__init__.py
================================================



================================================
File: src/landlab/ca/boundaries/hex_lattice_tectonicizer.py
================================================
"""hex_lattice_tectonicizer.py.

Models discrete normal-fault offset on a 2D hex lattice with a rectangular
node layout and with one orientation of the nodes being vertical.

The intention here is to use a particle (LCA) model to represent the evolution
of a 2D hillslope, with the hex_lattice_tectonicizer serving to shift the nodes
either upward (simple vertical uplift relative to baselevel), or up and
sideways (representing motion on a fault plane).

Created on Mon Nov 17 08:01:49 2014

@author: gtucker
"""

from numpy import amax
from numpy import arange
from numpy import array
from numpy import cos
from numpy import logical_and
from numpy import logical_or
from numpy import logical_xor
from numpy import pi
from numpy import sqrt
from numpy import tan
from numpy import where
from numpy import zeros

from landlab import HexModelGrid
from landlab import LinkStatus
from landlab.core.utils import as_id_array

from ..cfuncs import get_next_event_new  # , update_link_state_new

_DEFAULT_NUM_ROWS = 5
_DEFAULT_NUM_COLS = 5
_TAN60 = 1.732
_NEVER = 1.0e50  # this arbitrarily large val is also defined in ..cfuncs.pyx


def is_interior_link(link, grid):
    """Return True if both nodes are core; False otherwise."""
    return (
        grid.status_at_node[grid.node_at_link_tail[link]] == grid.BC_NODE_IS_CORE
        and grid.status_at_node[grid.node_at_link_head[link]] == grid.BC_NODE_IS_CORE
    )


def is_perim_link(link, grid):
    """Return True if both nodes are boundaries; False otherwise.

    Examples
    --------
    >>> from landlab import HexModelGrid
    >>> import numpy as np
    >>> mg = HexModelGrid(
    ...     (3, 4), spacing=1.0, orientation="vertical", node_layout="rect"
    ... )
    >>> is_perim_link(1, mg)
    True
    >>> is_perim_link(11, mg)
    False
    """
    return (
        grid.status_at_node[grid.node_at_link_tail[link]] != grid.BC_NODE_IS_CORE
        and grid.status_at_node[grid.node_at_link_head[link]] != grid.BC_NODE_IS_CORE
    )


class HexLatticeTectonicizer:
    """Handles tectonics and baselevel for CellLab-CTS models.

    This is the base class from which classes to represent particular
    baselevel/fault geometries are derived.

    Examples
    --------
    >>> hlt = HexLatticeTectonicizer()
    >>> hlt.grid.number_of_nodes
    25
    >>> hlt.nr
    5
    >>> hlt.nc
    5
    """

    def __init__(
        self,
        grid=None,
        node_state=None,
        propid=None,
        prop_data=None,
        prop_reset_value=None,
    ):
        """Create and initialize a HexLatticeTectonicizer.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> hg = HexModelGrid((6, 6), node_layout="rect")
        >>> hlt = HexLatticeTectonicizer()
        >>> hlt.grid.number_of_nodes
        25
        >>> hlt.nr
        5
        >>> hlt.nc
        5
        """
        # If needed, create grid
        if grid is None:
            num_rows = _DEFAULT_NUM_ROWS
            num_cols = _DEFAULT_NUM_COLS
            self.grid = HexModelGrid(
                (num_rows, num_cols),
                spacing=1.0,
                orientation="vertical",
                node_layout="rect",
                reorient_links=True,
            )
        else:
            # Make sure caller passed the right type of grid
            assert grid.orientation == "vertical", "Grid must have vertical orientation"

            # Keep a reference to the grid
            self.grid = grid

        # If needed, create node-state grid
        if node_state is None:
            self.node_state = self.grid.add_zeros(
                "node_state_map", at="node", dtype=int
            )
        else:
            self.node_state = node_state

        # Remember the # of rows and cols
        self.nr = self.grid.number_of_node_rows
        self.nc = self.grid.number_of_node_columns

        # propid should be either a reference to a CA model's "property id"
        # array, or None
        self.propid = propid
        self.prop_data = prop_data
        self.prop_reset_value = prop_reset_value


class LatticeNormalFault(HexLatticeTectonicizer):
    """Handles normal-fault displacement in CellLab-CTS models.

    Represents a 60 degree, left-dipping normal fault, and handles discrete
    offsets for a hex grid with vertical columns and rectangular node_layout.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import HexModelGrid
    >>> from landlab.ca.boundaries.hex_lattice_tectonicizer import LatticeNormalFault
    >>> pid = np.arange(25, dtype=int)
    >>> pdata = np.arange(25)
    >>> ns = np.arange(25, dtype=int)
    >>> grid = HexModelGrid(
    ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
    ... )
    >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
    >>> lnf.first_fw_col
    1
    >>> lnf.num_fw_rows
    array([0, 1, 3, 4, 5])
    >>> lnf.incoming_node
    array([1, 3, 4, 6])
    >>> lnf.outgoing_node
    array([12, 17, 19, 22])

    >>> pid = np.arange(16, dtype=int)
    >>> ns = np.arange(16, dtype=int)
    >>> pdata = np.arange(16)
    >>> grid = HexModelGrid(
    ...     (4, 4), spacing=1.0, orientation="vertical", node_layout="rect"
    ... )
    >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
    >>> lnf.num_fw_rows
    array([0, 1, 3, 4])
    >>> lnf.incoming_node
    array([1, 2, 5])
    >>> lnf.outgoing_node
    array([ 7, 11, 15])
    >>> lnf.do_offset(rock_state=16)
    >>> ns
    array([ 0, 16, 16, 16,  4, 16,  6,  1,  8,  2, 10,  5, 12, 13, 14,  9])
    >>> lnf.propid
    array([ 0,  7, 11,  3,  4, 15,  6,  1,  8,  2, 10,  5, 12, 13, 14,  9])

    >>> pid = np.arange(20, dtype=int)
    >>> ns = np.arange(20, dtype=int)
    >>> pdata = np.arange(20)
    >>> grid = HexModelGrid(
    ...     (4, 5), spacing=1.0, orientation="vertical", node_layout="rect"
    ... )
    >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
    >>> lnf.incoming_node
    array([1, 3, 4, 6])
    >>> lnf.outgoing_node
    array([12, 14, 17, 19])
    >>> lnf.do_offset(rock_state=20)
    >>> ns
    array([ 0, 20, 20, 20, 20,  5, 20, 20,  8,  1, 10,  3,  4, 13,  6, 15, 16,
            9, 18, 11])
    >>> lnf.propid
    array([ 0, 12,  2, 14, 17,  5, 19,  7,  8,  1, 10,  3,  4, 13,  6, 15, 16,
            9, 18, 11])
    """

    def __init__(
        self,
        fault_x_intercept=0.0,
        grid=None,
        node_state=None,
        propid=None,
        prop_data=None,
        prop_reset_value=None,
    ):
        """Create and initialize a LatticeNormalFault object.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.boundaries.hex_lattice_tectonicizer import (
        ...     LatticeNormalFault,
        ... )

        >>> pid = np.arange(25, dtype=int)
        >>> pdata = np.arange(25)
        >>> ns = np.arange(25, dtype=int)
        >>> grid = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(-0.01, grid, ns, pid, pdata, 0.0)
        >>> lnf.first_fw_col
        0
        >>> lnf.num_fw_rows
        array([1, 2, 4, 5, 5])
        >>> lnf.incoming_node
        array([0, 1, 3, 4, 6])
        >>> lnf.outgoing_node
        array([12, 17, 19, 22, 24])

        >>> pid = np.arange(16, dtype=int)
        >>> pdata = np.arange(16)
        >>> ns = np.arange(16, dtype=int)
        >>> grid = HexModelGrid(
        ...     (4, 4), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
        >>> lnf.first_fw_col
        1
        >>> lnf.num_fw_rows
        array([0, 1, 3, 4])
        >>> lnf.incoming_node
        array([1, 2, 5])
        >>> lnf.outgoing_node
        array([ 7, 11, 15])

        >>> pid = np.arange(45, dtype=int)
        >>> pdata = np.arange(45)
        >>> ns = np.arange(45, dtype=int)
        >>> grid = HexModelGrid(
        ...     (5, 9), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
        >>> lnf.first_fw_col
        1
        >>> lnf.num_fw_rows
        array([0, 1, 3, 4, 5, 5, 5, 5, 5])
        >>> lnf.incoming_node
        array([ 1,  2,  3,  5,  6,  7,  8, 10, 11, 12])
        >>> lnf.outgoing_node
        array([22, 31, 33, 34, 35, 38, 39, 40, 43, 44])
        """

        # Do the base class init
        super().__init__(grid, node_state, propid, prop_data, prop_reset_value)
        # Set up data structures:
        #   Make sure the footwall location is such that the fault actually
        #   cuts across the grid. This means the x intercept has to be, at
        #   the very least, no smaller than the biggest x-coordinate, and if
        #   there is an even number of columns, it must be smaller than that
        #   number minus 1/tangent 60 degrees (0.57735)
        assert fault_x_intercept < (amax(self.grid.node_x) - 0.57735), "err"

        #   Figure out which nodes are and are not within the footwall
        in_footwall = self.grid.node_y < _TAN60 * (self.grid.node_x - fault_x_intercept)

        # Set up array of link offsets: when slip occurs, what link's data get
        # copied into the present link? Which links get cut by fault plane and
        # need to have their states reset?
        self._setup_link_offsets(in_footwall)
        self._setup_links_to_update_after_offset(in_footwall)

        # Helpful to have an array of node IDs for the bottom full row. Because
        # the nodes in the bottom row are staggered in a vertical, rectangular
        # hex grid, the IDs go: 0, M, 1, M+1, 2, M+2, ... etc., where M is half
        # the number of columns, rounded up (so, for example, 3 for a 5- or 6-
        # column grid, etc.)
        half_num_cols = (self.nc + 1) // 2
        bottom_row_node_id = (
            arange(self.nc) // 2 + (arange(self.nc) % 2) * half_num_cols
        )

        # Also useful to remember the number of even-numbered columns
        self.n_even_cols = (self.nc + 1) // 2

        #   Find the first of the bottom-row nodes that lies in the footwall.
        # This loop exploits the fact that nodes are numbered in an order
        # sorted by x then y, and that the bottom row is staggered, with node
        # zero being "low", like: ,',', etc.
        self.first_fw_col = 0
        n = 0
        while not in_footwall[bottom_row_node_id[n]]:
            n += 1
            self.first_fw_col += 1
            assert n < self.nc, "overflow in loop"

        #   Remember the number of footwall rows in each column
        self.num_fw_rows = zeros(self.nc, dtype=int)
        for c in range(self.nc):
            current_row = 0
            while (
                current_row < self.nr
                and in_footwall[bottom_row_node_id[c] + self.nc * current_row]
            ):
                self.num_fw_rows[c] += 1
                current_row += 1

        # If we're handling properties and property IDs, we need to do some
        # setup
        if self.propid is not None:
            # We want to remember the node IDs of two sets of nodes: those
            # whose contents will vanish off the right-hand side (and possibly
            # the top) of the grid with each offset step, and those that gain
            # new ("rock") contents with each such step.
            #
            # First, let's find the latter set, which we'll call
            # "incoming_node" because material is flowing into these nodes from
            # below. To do this, we'll go column-by-column, starting with
            # the first column that has nodes in the footwall, and going to
            # the next-to-last column. Even-numbered columns have *two*
            # incoming nodes at their base (if the footwall reaches that high),
            # whereas odd-numbered columns have only one. Note that we'll start
            # with a list (so we can append), and then convert to an array
            # that belongs to this class.
            incoming_node_list = []
            lower_right_node = (self.nc % 2) * (self.nc // 2) + ((self.nc + 1) % 2) * (
                self.nc - 1
            )
            for n in range(0, self.nc + (self.nc + 1) // 2):
                if in_footwall[n] and ((n - lower_right_node) % self.nc) != 0:
                    incoming_node_list.append(n)

            # Convert to a numpy array that belongs to the class (so we can
            # use it in the do_offset() method).
            self.incoming_node = array(incoming_node_list, dtype=int)

            # Next, find the IDs the "outgoing" nodes. There will always be
            # some of these along the right side of the grid. Depending on the
            # height of the grid and the position of the fault, there may or
            # may not also be some along the top.
            #
            # To find out which nodes will be exiting the grid, we use
            # geometry: simply find out which nodes are (1) within the footwall
            # and (2) the tectonic offset would take them beyond the grid
            # perimeter. We already have information about the first condition.
            # For the second, let's start by defining the grid edges. The
            # y coordinates of the top full row of nodes will either be NR - 1
            # (even-numbered columns) or NR - 1/2. So we'll take as a
            # reasonable boundary line NR - 1/4: any node that would move above
            # this point is definitely out of the grid. Note that the vertical
            # offset of nodes during each earthquake will be 1.5, so if we were
            # to offset a top-row node, it would move to y = NR + 1/2 or
            # y = NR + 1. Odd-numbered columns in the next-from-top row will
            # move to y = NR, which is out of bounds, so we want to flag these
            # too, and therefore need our cutoff below this. Even-numbered
            # columns in the next-from-top row will end up at y = NR - 1/2,
            # which is within the grid. So our cutoff must be between NR - 1/2
            # and NR. Hence the choise of NR - 1/4 as the effective "top" of
            # the grid.
            top_grid_edge = self.nr - 0.25

            # The right-hand edge of the grid is a simpler case, because our
            # grid is vertically oriented and there is no stagger on the right
            # and left sides. So we simply make it half a column beyond the
            # right-most column. Column width is sqrt(3), the last column is
            # NC - 1, so the right edge y coordinate is (NC - 1/2) x sqrt(3)/2
            right_grid_edge = (self.nc - 0.5) * (sqrt(3.0) / 2.0)

            # To save a repeated calculation in a loop, we'll find a threshold
            # x and y coordinate beyond which any node offset would take them
            # off the grid.
            x_threshold = right_grid_edge - (sqrt(3.0) / 2.0)
            y_threshold = top_grid_edge - 1.5

            # Actually it turns out there is a third criterion. One or two
            # nodes in the lower-right corner could be counted as both
            # "incoming" (they're at the bottom of the grid) AND outgoing
            # (they're on the right-hand side). We ignored these in setting up
            # incoming, so we should ignore them for outgoing too. This is
            # easy: any nodes on the right side (x > x_threshold) that are also
            # near the bottom (y < 1.25) should be ignored.

            # Now march through all nodes, placing those on the list that meet
            # our criteria. Yes, it's slow to do this as a Python loop, but we
            # only do it once.
            outgoing_node_list = []
            for n in range(self.grid.number_of_nodes):
                if (
                    (self.grid.node_x[n] > x_threshold and self.grid.node_y[n] > 1.25)
                    or self.grid.node_y[n] > y_threshold
                ) and in_footwall[n]:
                    outgoing_node_list.append(n)

            # Finally, convert the outgoing node list to an array stored in
            # this object
            self.outgoing_node = array(outgoing_node_list, dtype=int)

    def _link_in_footwall(self, link, node_in_footwall):
        """Return True of both nodes are in footwall, False otherwise."""
        return (
            node_in_footwall[self.grid.node_at_link_tail[link]]
            and node_in_footwall[self.grid.node_at_link_head[link]]
        )

    def _get_link_orientation(self, link):
        """Return link orientation code for given link."""
        assert self.grid.orientation[0] == "v", "assumes vertical orientation"
        head = self.grid.node_at_link_head[link]
        tail = self.grid.node_at_link_tail[link]
        dx = self.grid.x_of_node[head] - self.grid.x_of_node[tail]
        dy = self.grid.y_of_node[head] - self.grid.y_of_node[tail]
        if dy > dx:
            return 0  # vertical
        elif dy > 0:
            return 1  # right and up
        else:
            return 2  # right and down

    def _setup_link_offsets(self, node_in_footwall):
        """Set up array with link IDs for shifting link data up and right.

        Notes
        -----
        The array contains the ID of the link TO WHICH the contents get
        shifted upon fault slip.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.ca.boundaries.hex_lattice_tectonicizer import (
        ...     LatticeNormalFault,
        ... )
        >>> from landlab import HexModelGrid
        >>> pid = np.arange(25, dtype=int)
        >>> pdata = np.arange(25)
        >>> ns = np.arange(25, dtype=int)
        >>> grid = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(-0.01, grid, ns, pid, pdata, 0.0)
        >>> lnf.link_offset_id[14:22]
        array([35, 15, 16, 17, 38, 19, 20, 41])
        >>> lnf.first_link_shifted_from
        14
        >>> lnf.first_link_shifted_to
        35

        >>> pid = np.arange(36, dtype=int)
        >>> pdata = np.arange(36)
        >>> ns = np.arange(36, dtype=int)
        >>> grid = HexModelGrid(
        ...     (6, 6), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(-0.1, grid, ns, pid, pdata, 0.0)
        >>> lnf.first_link_shifted_from
        17
        >>> lnf.first_link_shifted_to
        42
        >>> lnf.link_offset_id[17:39]
        array([42, 43, 19, 20, 21, 46, 23, 24, 50, 51, 27, 28, 29, 55, 31, 32, 33,
               59, 35, 36, 37, 62])
        """
        self.link_offset_id = arange(self.grid.number_of_links, dtype=int)
        nc = self.grid.number_of_node_columns
        default_offset = 2 * nc + 2 * (nc - 1) + nc // 2
        self.first_link_shifted_from = 0
        self.first_link_shifted_to = 0

        for ln in range(self.grid.number_of_links - (default_offset + 1)):
            if self._link_in_footwall(ln, node_in_footwall) and is_interior_link(
                ln, self.grid
            ):
                tail_node = self.grid.node_at_link_tail[ln]
                (_, c) = self.grid.node_row_and_column(tail_node)
                link_orientation = self._get_link_orientation(ln)
                offset = default_offset
                if nc % 2 == 1:  # odd number of columns
                    if (link_orientation + ((c - 1) % 2)) == 2:
                        offset += 1
                else:  # even number of columns
                    if (c % 2) == 0 and link_orientation == 0:
                        offset -= 1
                if is_interior_link(ln + offset, self.grid):
                    self.link_offset_id[ln] = ln + offset
                    if self.first_link_shifted_from == 0:
                        self.first_link_shifted_from = ln
                        self.first_link_shifted_to = ln + offset

    def _setup_links_to_update_after_offset(self, in_footwall):
        """Create and store array with IDs of links for which to update
        transitions after fault offset.

        These are: all active boundary links with at least one node in the
        footwall, plus the lowest non-boundary links, including the
        next-to-lowest vertical links and those angling that are below them,
        plus the fault-crossing links.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> hg = HexModelGrid((5, 5), orientation="vertical", node_layout="rect")
        >>> lu = LatticeNormalFault(fault_x_intercept=-0.01, grid=hg)
        >>> lu.first_link_shifted_to
        35
        >>> lu.links_to_update
        array([ 5,  8,  9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27,
               28, 29, 31, 34, 36, 40, 42, 44, 48, 49, 51])
        """
        g = self.grid
        lower_active = logical_and(
            arange(g.number_of_links) < self.first_link_shifted_to,
            g.status_at_link == LinkStatus.ACTIVE,
        )
        link_in_fw = logical_or(
            in_footwall[g.node_at_link_tail], in_footwall[g.node_at_link_head]
        )
        lower_active_fw = logical_and(lower_active, link_in_fw)
        active_bnd = logical_and(
            g.status_at_link == LinkStatus.ACTIVE,
            logical_or(
                g.status_at_node[g.node_at_link_tail] != 0,
                g.status_at_node[g.node_at_link_head] != 0,
            ),
        )
        active_bnd_fw = logical_and(active_bnd, link_in_fw)
        crosses_fw = logical_and(
            g.status_at_link == LinkStatus.ACTIVE,
            logical_xor(
                in_footwall[g.node_at_link_tail], in_footwall[g.node_at_link_head]
            ),
        )
        update = logical_or(logical_or(lower_active_fw, active_bnd_fw), crosses_fw)
        self.links_to_update = as_id_array(where(update)[0])

    def assign_new_link_state_and_transition(self, link, ca, current_time):
        """Update state and schedule new transition for given link."""
        tail_state = ca.node_state[self.grid.node_at_link_tail[link]]
        head_state = ca.node_state[self.grid.node_at_link_head[link]]
        orientation = ca.link_orientation[link]
        new_link_state = int(
            orientation * ca.num_node_states_sq
            + tail_state * ca.num_node_states
            + head_state
        )
        ca.update_link_state_new(link, new_link_state, current_time)

    def shift_scheduled_transitions(self, ca, current_time):
        """Update link IDs in scheduled events at offset links.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.oriented_hex_cts import OrientedHexCTS
        >>> from landlab.ca.celllab_cts import Transition
        >>> import numpy as np

        >>> mg = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> nsd = {0: "yes", 1: "no"}
        >>> xnlist = []
        >>> xnlist.append(Transition((0, 0, 0), (1, 1, 0), 1.0, "test"))
        >>> xnlist.append(Transition((0, 0, 1), (1, 1, 1), 1.0, "test"))
        >>> xnlist.append(Transition((0, 0, 2), (1, 1, 2), 1.0, "test"))
        >>> nsg = mg.add_zeros("node_state_grid", at="node")
        >>> pid = np.arange(25, dtype=int)
        >>> pdata = np.arange(25)
        >>> ohcts = OrientedHexCTS(mg, nsd, xnlist, nsg)
        >>> lnf = LatticeNormalFault(-0.1, grid=mg)
        >>> pq = ohcts.priority_queue._queue
        >>> (int(1000 * pq[11][0]), pq[11][1:])
        (752, (11, 21))
        >>> (int(1000 * pq[12][0]), pq[12][1:])
        (483, (9, 18))
        >>> (int(1000 * pq[30][0]), pq[30][1:])
        (575, (6, 14))
        >>> lnf.do_offset(ca=ohcts)
        >>> (int(1000 * pq[48][0]), pq[48][1:])
        (752, (11, 41))
        >>> (int(1000 * pq[54][0]), pq[54][1:])
        (483, (9, 38))
        >>> (int(1000 * pq[61][0]), pq[61][1:])
        (575, (6, 35))
        """
        for i in range(len(ca.priority_queue._queue)):
            link = ca.priority_queue._queue[i][2]
            if self.link_offset_id[link] != link:
                ca.priority_queue._queue[i] = (
                    ca.priority_queue._queue[i][0],
                    ca.priority_queue._queue[i][1],
                    self.link_offset_id[link],
                )

    def shift_link_states(self, ca, current_time):
        """Shift link data up and right.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.oriented_hex_cts import OrientedHexCTS
        >>> from landlab.ca.celllab_cts import Transition
        >>> import numpy as np

        >>> mg = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> nsd = {0: "yes", 1: "no"}
        >>> xnlist = []
        >>> xnlist.append(Transition((1, 0, 0), (1, 1, 0), 1.0, "frogging"))
        >>> xnlist.append(Transition((1, 0, 1), (1, 1, 1), 1.0, "frogging"))
        >>> xnlist.append(Transition((1, 0, 2), (1, 1, 2), 1.0, "frogging"))
        >>> nsg = mg.add_zeros("node_state_grid", at="node")
        >>> nsg[:10] = 1
        >>> pid = np.arange(25, dtype=int)
        >>> pdata = np.arange(25)
        >>> ohcts = OrientedHexCTS(mg, nsd, xnlist, nsg)
        >>> ohcts.link_state
        array([ 0,  0,  0,  0,  0,  3,  0,  0,  7, 11,  0,  3,  3,  7, 11,  7, 11,
                0,  2,  0,  9,  6,  9,  6,  2,  2,  4,  8,  4,  8,  0,  0,  0,  8,
                4,  8,  4,  0,  0,  4,  8,  4,  8,  0,  0,  0,  8,  4,  8,  4,  0,
                0,  0,  0,  0,  0])
        >>> lnf = LatticeNormalFault(-0.01, mg, nsg, pid, pdata, 0.0)
        >>> lnf.first_link_shifted_from
        14
        >>> lnf.link_offset_id
        array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 35, 15, 16,
               17, 38, 19, 20, 41, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,
               34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
               51, 52, 53, 54, 55])
        >>> lnf.shift_link_states(ohcts, 0.0)
        >>> ohcts.link_state
        array([ 0,  0,  0,  0,  0,  3,  0,  0,  7, 11,  0,  3,  3,  7, 11,  7, 11,
                0,  2,  0,  9,  6,  9,  6,  2,  2,  4,  8,  4,  8,  0,  0,  0,  8,
                4, 11,  4,  0,  2,  4,  8,  6,  8,  0,  0,  0,  8,  4,  8,  4,  0,
                0,  0,  0,  0,  0])
        """
        num_links = self.grid.number_of_links
        for lnk in range(num_links - 1, self.first_link_shifted_from - 1, -1):
            link_offset = self.link_offset_id[lnk]
            if link_offset != lnk:
                ca.link_state[link_offset] = ca.link_state[lnk]
                ca.next_trn_id[link_offset] = ca.next_trn_id[lnk]
                ca.next_update[link_offset] = ca.next_update[lnk]

        self.shift_scheduled_transitions(ca, current_time)

        for lnk in self.links_to_update:
            self.assign_new_link_state_and_transition(lnk, ca, current_time)

    def do_offset(self, ca=None, current_time=0.0, rock_state=1):
        """Apply 60-degree normal-fault offset.

        Offset is applied to a hexagonal grid with vertical node orientation
        and rectangular arrangement of nodes.

        Parameters
        ----------
        rock_state : int
            State code to apply to new cells introduced along bottom row.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.ca.boundaries.hex_lattice_tectonicizer import (
        ...     LatticeNormalFault,
        ... )
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.oriented_hex_cts import OrientedHexCTS
        >>> from landlab.ca.celllab_cts import Transition

        >>> pid = np.arange(25, dtype=int)
        >>> pdata = np.arange(25)
        >>> ns = np.arange(25, dtype=int)
        >>> grid = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
        >>> lnf.do_offset(rock_state=25)
        >>> ns
        array([ 0, 25, 25, 25, 25,  5, 25, 25,  8,  1, 10,  3,  4, 13,  6, 15, 16,
                9, 18, 11, 20, 21, 14, 23, 24])
        >>> lnf.propid
        array([ 0, 12,  2, 17, 19,  5, 22,  7,  8,  1, 10,  3,  4, 13,  6, 15, 16,
                9, 18, 11, 20, 21, 14, 23, 24])

        >>> ns[5:] = 0
        >>> ns[:5] = 1
        >>> nsd = {0: "yes", 1: "no"}
        >>> xnlist = []
        >>> xnlist.append(Transition((0, 0, 0), (1, 1, 0), 1.0, "test"))
        >>> ohcts = OrientedHexCTS(grid, nsd, xnlist, ns)
        >>> lnf = LatticeNormalFault(0.0, grid, ns, pid, pdata, 0.0)
        >>> ohcts.link_state[5:33]
        array([2, 0, 0, 6, 9, 0, 2, 2, 4, 8, 4, 8, 0, 0, 0, 8, 4, 8, 4, 0, 0, 4,
               8, 4, 8, 0, 0, 0])
        >>> lnf.do_offset(ca=ohcts, current_time=0.0, rock_state=1)
        >>> ohcts.link_state[5:33]
        array([ 3,  0,  0,  7, 11,  0,  2,  3,  4,  9,  7, 11,  0,  3,  0,  8,  5,
               11,  7,  0,  2,  4,  9,  6,  9,  0,  2,  0])
        """

        # If we need to shift the property ID numbers, we'll first need to
        # record the property IDs in those nodes that are about to "shift off
        # the grid" (or rather, their contents will shift) due to tectonic
        # motion. We'll call these "nodes to replace".
        if self.propid is not None:
            # Now, remember the property IDs of the nodes along the right side
            # and possibly top that are about to shift off the grid
            propids_for_incoming_nodes = self.propid[self.outgoing_node]

        # We go column-by-column, starting from the right side
        for c in range(self.grid.number_of_node_columns - 1, self.first_fw_col - 1, -1):
            # Odd-numbered rows are shifted up in the hexagonal, vertically
            # oriented lattice
            row_offset = 2 - (c % 2)

            # Number of base nodes in the footwall in this column (1 or 2).
            n_base_nodes = min(self.num_fw_rows[c], row_offset)

            # ID of the bottom footwall node in this column
            bottom_node = (c // 2) + ((c % 2) * self.n_even_cols)

            # The bottom 1 or 2 nodes in this column are set to rock
            self.node_state[bottom_node] = rock_state
            if n_base_nodes == 2:
                self.node_state[bottom_node + self.nc] = rock_state

            # "indices" here contains the array indices of those nodes in this
            # column that are to be replaced by the ones in the column to the
            # left and down one or two nodes. We do this replacement if indices
            # contains any data.
            first_repl = bottom_node + n_base_nodes * self.nc
            last_repl = (
                first_repl + (self.num_fw_rows[c] - (n_base_nodes + 1)) * self.nc
            )
            indices = arange(first_repl, last_repl + 1, self.nc)

            if len(indices) > 0:
                offset = (
                    self.nc + ((self.nc + 1) // 2) + ((c + 1) % 2) * ((self.nc + 1) % 2)
                )
                self.node_state[indices] = self.node_state[indices - offset]
                if self.propid is not None:
                    self.propid[indices] = self.propid[indices - offset]

        if self.propid is not None:
            self.propid[self.incoming_node] = propids_for_incoming_nodes
            self.prop_data[self.propid[self.incoming_node]] = self.prop_reset_value

        if ca is not None:
            self.shift_link_states(ca, current_time)


class LatticeUplifter(HexLatticeTectonicizer):
    """Handles vertical uplift of interior (not edges) for a hexagonal lattice
    with vertical node orientation and rectangular node arrangement."""

    def __init__(
        self,
        grid=None,
        node_state=None,
        propid=None,
        prop_data=None,
        prop_reset_value=None,
        opt_block_layer=False,
        block_ID=9,
        block_layer_dip_angle=0.0,
        block_layer_thickness=1.0,
        layer_left_x=0.0,
        y0_top=0.0,
    ):
        """Create and initialize a LatticeUplifter.

        Examples
        --------
        >>> lu = LatticeUplifter()
        >>> lu.inner_base_row_nodes
        array([1, 3, 4])

        >>> hg = HexModelGrid(
        ...     (5, 6), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> lu = LatticeUplifter(grid=hg)
        >>> lu.inner_base_row_nodes
        array([1, 2, 3, 4])
        """
        # Do the base class init
        super().__init__(grid, node_state, propid, prop_data, prop_reset_value)

        # Remember the IDs of nodes on the bottom row
        self.inner_base_row_nodes = zeros(self.nc - 2, dtype=int)
        n_in_lower = (self.nc // 2) - 1  # num inner nodes bottom row
        upper_start = (self.nc + 1) // 2
        n_in_upper = upper_start - 1
        self.inner_base_row_nodes[:n_in_lower] = arange(1, n_in_lower + 1)
        self.inner_base_row_nodes[n_in_lower:] = arange(
            upper_start, upper_start + n_in_upper
        )

        if self.propid is not None:
            self.inner_top_row_nodes = self.inner_base_row_nodes + (
                (self.nr - 1) * self.nc
            )

        self._setup_links_to_update_after_uplift()

        # Handle option for a layer of "blocks"
        self.opt_block_layer = opt_block_layer
        if opt_block_layer:
            self.cum_uplift = 0.0
            self.block_ID = block_ID
            self.block_layer_thickness = block_layer_thickness
            self.block_layer_dip_angle = block_layer_dip_angle
            self.layer_left_x = layer_left_x
            self.y0_top = y0_top

    def _setup_links_to_update_after_uplift(self):
        """Create and store array with IDs of links for which to update
        transitions after uplift.

        These are: all active boundary links, plus the lowest non-boundary
        links, including the next-to-lowest vertical links and those angling
        that are below them.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> hg = HexModelGrid((6, 6), orientation="vertical", node_layout="rect")
        >>> lu = LatticeUplifter(grid=hg)
        >>> lu.links_to_update
        array([ 6,  7,  9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 28,
               32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 70, 71, 72, 73, 74, 75, 77,
               78])
        >>> hg = HexModelGrid((5, 5), orientation="vertical", node_layout="rect")
        >>> lu = LatticeUplifter(grid=hg)
        >>> lu.links_to_update
        array([ 5,  8,  9, 11, 12, 13, 14, 15, 16, 18, 20, 23, 26, 29, 33, 36, 39,
               42, 44, 46, 47, 48, 49, 50, 51])
        """
        g = self.grid
        nc = g.number_of_node_columns
        max_link_id = 3 * (nc - 1) + 2 * ((nc + 1) // 2) + nc // 2
        lower_active = logical_and(
            arange(g.number_of_links) < max_link_id, g.status_at_link == 0
        )
        boundary = logical_or(
            g.status_at_node[g.node_at_link_tail] != 0,
            g.status_at_node[g.node_at_link_head] != 0,
        )
        active_bnd = logical_and(boundary, g.status_at_link == 0)
        self.links_to_update = as_id_array(
            where(logical_or(lower_active, active_bnd))[0]
        )

    def _get_new_base_nodes(self, rock_state):
        """Return an array (or scalar) of states for the newly uplifted bottom
        inner row.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.hex_cts import HexCTS
        >>> from landlab.ca.celllab_cts import Transition
        >>> mg = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> nsd = {}  # node state dict
        >>> for i in range(10):
        ...     nsd[i] = i
        ...
        >>> xnlist = []
        >>> xnlist.append(Transition((0, 0, 0), (1, 1, 0), 1.0, "frogging"))
        >>> nsg = mg.add_zeros("node_state_grid", at="node")
        >>> ca = HexCTS(mg, nsd, xnlist, nsg)

        >>> lu = LatticeUplifter(opt_block_layer=True)
        >>> lu._get_new_base_nodes(rock_state=7)
        array([9, 9, 9])
        >>> lu.uplift_interior_nodes(ca, current_time=0.0, rock_state=7)
        >>> lu.node_state[:5]
        array([0, 9, 0, 9, 9])
        >>> lu = LatticeUplifter(
        ...     opt_block_layer=True,
        ...     block_layer_thickness=2,
        ...     block_layer_dip_angle=90.0,
        ...     layer_left_x=1.0,
        ... )
        >>> lu._get_new_base_nodes(rock_state=7)
        array([9, 7, 9])
        >>> lu.uplift_interior_nodes(ca, current_time=0.0, rock_state=7)
        >>> lu.node_state[:5]
        array([0, 9, 0, 7, 9])
        >>> lu = LatticeUplifter(
        ...     opt_block_layer=True,
        ...     block_layer_thickness=1,
        ...     block_layer_dip_angle=45.0,
        ...     y0_top=-1.0,
        ... )
        >>> lu._get_new_base_nodes(rock_state=7)
        array([9, 7, 9])
        >>> lu.uplift_interior_nodes(ca, current_time=0.0, rock_state=7)
        >>> lu.node_state[:5]
        array([0, 9, 0, 7, 9])
        """

        new_base_nodes = zeros(len(self.inner_base_row_nodes), dtype=int)

        if self.block_layer_dip_angle == 0.0:  # horizontal
            if self.cum_uplift < self.block_layer_thickness:
                new_base_nodes[:] = self.block_ID
            else:
                new_base_nodes[:] = rock_state

        elif self.block_layer_dip_angle == 90.0:  # vertical
            layer_right_x = self.layer_left_x + self.block_layer_thickness
            inside_layer = where(
                logical_and(
                    self.grid.x_of_node[self.inner_base_row_nodes] >= self.layer_left_x,
                    self.grid.x_of_node[self.inner_base_row_nodes] <= layer_right_x,
                )
            )[0]
            new_base_nodes[:] = rock_state
            new_base_nodes[inside_layer] = self.block_ID

        else:
            x = self.grid.x_of_node[self.inner_base_row_nodes]
            y = self.grid.y_of_node[self.inner_base_row_nodes]
            m = tan(pi * self.block_layer_dip_angle / 180.0)
            y_top = m * x + self.y0_top
            y_bottom = y_top - (
                self.block_layer_thickness
                / cos(pi * self.block_layer_dip_angle / 180.0)
            )
            inside_layer = where(logical_and(y >= y_bottom, y <= y_top))
            new_base_nodes[:] = rock_state
            new_base_nodes[inside_layer] = self.block_ID

        return new_base_nodes

    def shift_link_and_transition_data_upward(self, ca, current_time):
        """Applies uplift to links and transitions.

        For each link that lies above the y = 1.5 cells line, assign the
        properties of the link one row down.

        (For an example, see unit test:
            test_shift_link_and_transition_data_upward)
        """

        # Find the ID of the first link above the y = 1.5 line
        nc = self.grid.number_of_node_columns
        first_link = (
            ((nc - 1) // 2)  # skip bottom horizontals
            + (3 * (nc - 1))  # skip 3 sets of diagonals
            + nc  # skip a full row of verticals
            + ((nc + 1) // 2)
        )  # skip a an even row of verticals

        # Define the offset in ID between a link and its neighbor one row up
        # (or down)
        shift = nc + 2 * (nc - 1)

        # Loop from top to bottom of grid, shifting the following link data
        # upward: state of link, ID of its next transition, and time of its
        # next transition.
        for lnk in range(self.grid.number_of_links - 1, first_link - 1, -1):
            ca.link_state[lnk] = ca.link_state[lnk - shift]
            ca.next_trn_id[lnk] = ca.next_trn_id[lnk - shift]
            ca.next_update[lnk] = ca.next_update[lnk - shift]

        # Sweep through event queue, shifting links upward. Do NOT shift links
        # with IDs greater than NL - [SHIFT + (NC - 1)], because these are so
        # close to the top of the grid that either the events would refer to
        # non-existent links (>= NL) or would involve shifting an event onto
        # an upper-boundary link. Note that because the event data are stored
        # in a tuple, we have to replace the entire tuple (can't simply change
        # the one item, because tuples are immutable)
        first_no_shift_id = self.grid.number_of_links - (shift + (nc - 1))
        for i in range(len(ca.priority_queue._queue)):
            if ca.priority_queue._queue[i][2] < first_no_shift_id:
                ca.priority_queue._queue[i] = (
                    ca.priority_queue._queue[i][0],
                    ca.priority_queue._queue[i][1],
                    (ca.priority_queue._queue[i][2] + shift),
                )

        # Update state of links along the boundaries.
        for lk in self.links_to_update:
            # Update link state
            fns = self.node_state[self.grid.node_at_link_tail[lk]]
            tns = self.node_state[self.grid.node_at_link_head[lk]]
            orientation = ca.link_orientation[lk]
            new_link_state = (
                int(orientation) * ca.num_node_states_sq
                + fns * ca.num_node_states
                + tns
            )

            # Schedule a new transition, if applicable
            ca.link_state[lk] = new_link_state
            if ca.n_trn[new_link_state] > 0:
                (event_time, this_trn_id) = get_next_event_new(
                    lk, new_link_state, current_time, ca.n_trn, ca.trn_id, ca.trn_rate
                )
                ca.priority_queue.push(lk, event_time)
                ca.next_update[lk] = event_time
                ca.next_trn_id[lk] = this_trn_id
            else:
                ca.next_update[lk] = _NEVER
                ca.next_trn_id[lk] = -1

    def uplift_property_ids(self):
        """Shift property IDs upward by one row."""
        top_row_propid = self.propid[self.inner_top_row_nodes]
        for r in range(self.nr - 1, 0, -1):
            self.propid[self.inner_base_row_nodes + self.nc * r] = self.propid[
                self.inner_base_row_nodes + self.nc * (r - 1)
            ]
        self.propid[self.inner_base_row_nodes] = top_row_propid
        self.prop_data[self.propid[self.inner_base_row_nodes]] = self.prop_reset_value

    def uplift_interior_nodes(self, ca, current_time, rock_state=1):
        """Simulate 'vertical' displacement by shifting contents of node_state.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import HexModelGrid
        >>> from landlab.ca.hex_cts import HexCTS
        >>> from landlab.ca.celllab_cts import Transition
        >>> mg = HexModelGrid(
        ...     (5, 5), spacing=1.0, orientation="vertical", node_layout="rect"
        ... )
        >>> nsd = {}
        >>> for i in range(26):
        ...     nsd[i] = i
        ...
        >>> xnlist = []
        >>> xnlist.append(Transition((0, 0, 0), (1, 1, 0), 1.0, "frogging", True))
        >>> nsg = mg.add_zeros("node_state_grid", at="node")
        >>> ca = HexCTS(mg, nsd, xnlist, nsg)
        >>> pd = mg.add_zeros("propdata", at="node")
        >>> lu = LatticeUplifter(propid=ca.propid, prop_data=pd)
        >>> lu.node_state[:] = np.arange(len(lu.node_state))
        >>> lu.uplift_interior_nodes(ca, rock_state=25, current_time=0.0)
        >>> lu.node_state
        array([ 0, 25,  2, 25, 25,
                5,  1,  7,  3,  4,
               10,  6, 12,  8,  9,
               15, 11, 17, 13, 14,
               20, 16, 22, 18, 19])
        >>> lu.propid
        array([ 0, 21,  2, 23, 24,
                5,  1,  7,  3,  4,
               10,  6, 12,  8,  9,
               15, 11, 17, 13, 14,
               20, 16, 22, 18, 19])
        """

        # Shift the node states up by a full row. A "full row" includes two
        # staggered rows.
        for r in range(self.nr - 1, 0, -1):
            # This row gets the contents of the nodes 1 row down
            self.node_state[self.inner_base_row_nodes + self.nc * r] = self.node_state[
                self.inner_base_row_nodes + self.nc * (r - 1)
            ]

        # Fill the bottom rows with "fresh material" (code = rock_state), or
        # if using a block layer, with the right pattern of states.
        if self.opt_block_layer:
            new_base_nodes = self._get_new_base_nodes(rock_state)
            self.cum_uplift += 1.0
            self.y0_top += 1.0
        else:
            new_base_nodes = rock_state
        self.node_state[self.inner_base_row_nodes] = new_base_nodes

        # If propid (property ID) is defined, shift that too.
        if self.propid is not None:
            self.uplift_property_ids()

        self.shift_link_and_transition_data_upward(ca, current_time)


if __name__ == "__main__":
    import doctest

    doctest.testmod()



================================================
File: src/landlab/cmd/__init__.py
================================================



================================================
File: src/landlab/cmd/authors.py
================================================
import itertools
import os
import subprocess
import textwrap
from collections import ChainMap
from collections import UserDict

try:
    import tomllib
except ModuleNotFoundError:
    import tomli as tomllib


class AuthorsSubprocessError(Exception):
    pass


class AuthorsConfig(UserDict):
    _FILES = [".credit-roll.toml", "credit-roll.toml", "pyproject.toml"]
    _DEFAULTS = {
        "authors_file": "AUTHORS.rst",
        "ignore": (),
        "author_format": "{name}",
        "credits_file": ".credits.toml",
        "start_string": ".. credits-roll start-author-list",
    }

    def __init__(self, *args, **kwds):
        user_data = {
            k: v for k, v in dict(*args, **kwds).items() if k in self._DEFAULTS
        }

        self.data = ChainMap(
            user_data, AuthorsConfig._load_first_of(self._FILES), self._DEFAULTS
        )

    def __str__(self):
        lines = ["[tool.landlab.credits]"]
        for key, value in sorted(self.data.items(), key=lambda item: item[0]):
            lines.append(f"{key} = {value!r}")
        return os.linesep.join(lines)

    @classmethod
    def from_toml(cls, toml_file):
        with open(toml_file, mode="rb") as fp:
            config = tomllib.load(fp)["tool"]["landlab"]["credits"]
        return cls(config)

    @staticmethod
    def _load_toml(name):
        with open(name, mode="rb") as fp:
            config = tomllib.load(fp)["tool"]["landlab"]["credits"]
        return config

    @staticmethod
    def _load_first_of(files):
        for name in files:
            try:
                config = AuthorsConfig._load_toml(name)
            except (OSError, KeyError):
                pass
            else:
                break
        else:
            config = {}

        try:
            config.pop("author")
        except KeyError:
            pass
        return config


class GitLog:
    def __init__(self, format):
        self._format = f"{format}"
        self._args = ["git", "log", f"--format={self._format}"]

    def __call__(self):
        process = subprocess.run(
            self._args,
            text=True,
            capture_output=True,
            stdin=subprocess.PIPE,
        )
        if process.returncode != 0:
            raise AuthorsSubprocessError(
                f"`{self} did not run successfully` (exit code was {process.returncode})\n"
                + textwrap.indent(process.stderr, prefix="  ")
                + "This error originates from a subprocess."
            )
        return process.stdout

    def __str__(self):
        return " ".join(self._args)

    def __repr__(self):
        return f"GitLog({self._format!r})"


class Author:
    def __init__(self, name, email, aliases=None, alternate_emails=None):
        self._name = name
        self._email = email
        self._aliases = set() if not aliases else set(aliases)
        self._alternate_emails = (
            set() if not alternate_emails else set(alternate_emails)
        )
        self._aliases.discard(self.name)
        self._alternate_emails.discard(self.email)
        self._extras = {}

    @classmethod
    def from_dict(cls, attrs):
        attrs = dict(attrs)
        author = cls(
            attrs.pop("name"),
            attrs.pop("email"),
            aliases=attrs.pop("aliases", None),
            alternate_emails=attrs.pop("alternate_emails", None),
        )
        for k, v in attrs.items():
            author._extras[k] = v
        return author

    @property
    def name(self):
        return self._name

    @property
    def names(self):
        return (self.name,) + self.aliases

    @property
    def email(self):
        return self._email

    @property
    def emails(self):
        return (self.email,) + self.alternate_emails

    @property
    def aliases(self):
        return tuple(self._aliases)

    @property
    def alternate_emails(self):
        return tuple(self._alternate_emails)

    def add_alias(self, alias):
        if alias != self.name:
            self._aliases.add(alias)

    def to_toml(self):
        lines = [
            "[[tool.landlab.credits.author]]",
            f"name = {self.name!r}",
            f"email = {self.email!r}",
        ]
        lines += (
            ["aliases = ["]
            + [f"  {alias!r}," for alias in sorted(self.aliases)]
            + ["]"]
        )
        lines += (
            ["alternate_emails = ["]
            + [f"  {email!r}," for email in sorted(self.alternate_emails)]
            + ["]"]
        )
        for k, v in sorted(self._extras.items(), key=lambda x: x[0]):
            lines += [f"{k} = {v!r}"]

        return os.linesep.join(lines)

    def update(self, other):
        if other.name != self.name:
            self._aliases.add(other.name)
        if other.email != self.email:
            self._alternate_emails.add(other.email)
        self._aliases |= set(other.aliases)
        self._alternate_emails |= set(other.alternate_emails)
        self._extras.update(other._extras)

    def __repr__(self):
        aliases = None if not self.aliases else self.aliases
        alternate_emails = None if not self.alternate_emails else self.alternate_emails
        return (
            f"Author({self.name!r}, {self.email!r},"
            f" aliases={aliases!r}, alternate_emails={alternate_emails!r})"
        )


class AuthorList:
    def __init__(self, authors=None):
        authors = [] if authors is None else authors
        self._name = {}
        self._email = {}

        for author in authors:
            for name in author.names:
                self._name[name] = author
            for email in author.emails:
                self._email[email] = author

    def __iter__(self):
        names = {author.name for author in self._name.values()}
        for name in sorted(names):
            yield self._name[name]

    def __len__(self):
        names = {author.name for author in self._name.values()}
        return len(names)

    def find_author(self, name_or_email):
        if name_or_email in self._name:
            author = self._name[name_or_email]
        elif name_or_email in self._email:
            author = self._email[name_or_email]
        else:
            raise KeyError(f"unknown author: {name_or_email!r}")
        return author

    @classmethod
    def from_toml(cls, toml_file):
        with open(toml_file, "rb") as fp:
            authors = [
                Author.from_dict(author)
                for author in tomllib.load(fp)["tool"]["landlab"]["credits"]["author"]
            ]

        return cls(authors=authors)

    @classmethod
    def from_csv(cls, csv):
        authors = cls()
        for line in csv.splitlines():
            name, email = (item.strip() for item in line.rsplit(",", maxsplit=1))
            authors.add(name, email)
        return authors

    def update(self, other):
        for author in other:
            for name, email in itertools.product(author.names, author.emails):
                self.add(name, email)

    def add(self, name, email):
        have_name = name in self._name
        have_email = email in self._email

        new_author = Author(name, email)

        if not (have_name or have_email):
            author = new_author
            self._name[name] = new_author
            self._email[email] = new_author
        elif have_name and not have_email:
            author = self._name[name]
            author.update(new_author)
            self._email[email] = author
        elif have_email and not have_name:
            author = self._email[email]
            author.update(new_author)
            self._name[name] = author
        elif self._name[name].name != self._email[email].name:
            other = self._email[email]
            author = self._name[name]
            author.update(other)
            for name in other.names:
                self._name[name] = author
            for email in other.emails:
                self._email[email] = author
        else:
            author = self._name[name]



================================================
File: src/landlab/cmd/landlab.py
================================================
import contextlib
import inspect
import itertools
import os
import pathlib
import re
import sys
import textwrap
from collections import Counter
from collections import defaultdict
from collections.abc import Iterable
from functools import partial

import numpy as np
import rich_click as click

from landlab import FramedVoronoiGrid
from landlab import HexModelGrid
from landlab import ModelGrid
from landlab import RadialModelGrid
from landlab import RasterModelGrid
from landlab import VoronoiDelaunayGrid

from .authors import AuthorList
from .authors import AuthorsConfig
from .authors import AuthorsSubprocessError
from .authors import GitLog

GRIDS = [
    ModelGrid,
    RasterModelGrid,
    VoronoiDelaunayGrid,
    HexModelGrid,
    RadialModelGrid,
    FramedVoronoiGrid,
]

CATEGORIES = {
    "boundary-condition",
    "connectivity",
    "deprecated",
    "field-add",
    "field-io",
    "gradient",
    "info-cell",
    "info-corner",
    "info-face",
    "info-field",
    "info-grid",
    "info-link",
    "info-node",
    "info-patch",
    "map",
    "quantity",
    "subset",
    "surface",
    "uncategorized",
}


click.rich_click.ERRORS_SUGGESTION = (
    "Try running the '--help' flag for more information."
)
click.rich_click.ERRORS_EPILOGUE = (
    "To find out more, visit https://github.com/landlab/landlab"
)
click.rich_click.STYLE_ERRORS_SUGGESTION = "yellow italic"
click.rich_click.SHOW_ARGUMENTS = True
click.rich_click.GROUP_ARGUMENTS_OPTIONS = False
click.rich_click.SHOW_METAVARS_COLUMN = True
click.rich_click.USE_MARKDOWN = True

out = partial(click.secho, bold=True, file=sys.stderr)
err = partial(click.secho, fg="red", file=sys.stderr)


@click.group()  # chain=True)
@click.version_option()
@click.option(
    "--cd",
    default=".",
    type=click.Path(exists=True, file_okay=False, dir_okay=True, readable=True),
    help="chage to directory, then execute",
)
@click.option(
    "-s",
    "--silent",
    is_flag=True,
    help="Suppress status status messages, including the progress bar.",
)
@click.option(
    "-v", "--verbose", is_flag=True, help="Also emit status messages to stderr."
)
def landlab(cd, silent, verbose) -> None:
    os.chdir(cd)


@landlab.command(name="list")
def _list():
    for cls in get_all_components():
        print(cls.__name__)


@landlab.command()
@click.argument("component", type=str, nargs=-1)
def used_by(component):
    for name in _used_by(get_components(component)):
        print(name)


@landlab.command()
@click.argument("component", type=str, nargs=-1)
def provided_by(component):
    for name in _provided_by(get_components(component)):
        print(name)


@landlab.command()
@click.argument("var", type=str)
def uses(var):
    for name in get_users_of(var):
        print(name)


@landlab.command()
@click.argument("var", type=str)
def provides(var):
    for name in get_providers_of(var):
        print(name)


@landlab.command()
@click.argument("component", type=str, nargs=-1)
def validate(component):
    failures = 0
    classes = get_components(component)
    for cls in classes:
        out(cls.__name__)
        errors = _validate_component(cls)
        if errors:
            failures += 1
            for error in errors:
                err(f"Error: {cls.__name__}: {error}")
    if failures:
        click.Abort()
    else:
        out("💥 All good! 💥")


@landlab.group()
@click.option(
    "--authors-file",
    type=click.Path(exists=False, file_okay=True, dir_okay=False, readable=True),
    help="existing authors file",
)
@click.option(
    "--credits-file",
    default=".credits.toml",
    type=click.Path(exists=False, file_okay=True, dir_okay=False, readable=True),
    help="The file that contains a list of authors",
)
@click.pass_context
def authors(ctx, authors_file, credits_file):
    """Commands for working with lists of authors."""
    verbose = ctx.parent.params["verbose"]
    silent = ctx.parent.params["silent"]

    config = AuthorsConfig(**{k: v for k, v in ctx.params.items() if v})

    for k, v in config.items():
        ctx.params[k] = v

    if verbose and not silent:
        config_str = textwrap.indent(str(config), prefix="  ")
        out("using the following configuration:")
        out(f"{config_str}")


@authors.command()
@click.option("--update-existing/--no-update-existing", default=True)
@click.pass_context
def create(ctx, update_existing):
    """Create a database of contributors."""
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]
    credits_file = pathlib.Path(ctx.parent.params["credits_file"])

    git_log = GitLog("%an, %ae")
    try:
        names_and_emails = git_log()
    except AuthorsSubprocessError as error:
        err(error)
        raise click.Abort() from error
    else:
        if verbose and not silent:
            out(f"{git_log}")

    if not silent and update_existing:
        if not credits_file.is_file():
            err(f"nothing to update ({credits_file})")
        else:
            out(f"updating existing author credits ({credits_file})")

    authors = (
        AuthorList.from_toml(credits_file)
        if update_existing and credits_file.is_file()
        else AuthorList()
    )

    authors.update(AuthorList.from_csv(names_and_emails))
    lines = [author.to_toml() for author in sorted(authors, key=lambda item: item.name)]

    print((2 * os.linesep).join(lines))


@authors.command()
@click.pass_context
def build(ctx):
    """Build an authors file."""
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]
    exclude = ctx.parent.params["exclude"]
    authors_file = pathlib.Path(ctx.parent.params["authors_file"])
    author_format = ctx.parent.params["author_format"]
    credits_file = pathlib.Path(ctx.parent.params["credits_file"])
    start_string = ctx.parent.params["start_string"]

    git_log = GitLog("%aN")
    try:
        commit_authors = git_log()
    except AuthorsSubprocessError as error:
        err(error)
        raise click.Abort() from error
    else:
        if verbose and not silent:
            out(f"{git_log}")

    intro = (
        _read_until(authors_file, until=start_string) if authors_file.is_file() else ""
    )
    if len(intro) == 0:
        err(f"empty or missing authors file ({authors_file})")

    authors = (
        AuthorList.from_toml(credits_file) if credits_file.is_file() else AuthorList()
    )

    if len(authors) == 0:
        err(f"missing or empty credits file ({credits_file})")

    commits = Counter()
    for author in commit_authors.splitlines():
        canonical_name = authors.find_author(author.strip()).name
        commits[canonical_name] += 1

    lines = [intro]
    for author in sorted(authors, key=lambda a: commits[a.name], reverse=True):
        github = _guess_github_user(author)
        if github is None:
            github = "landlab"
        author.github = github
        if not exclude_matches_any(author.names, exclude):
            lines.append(
                author_format.format(
                    name=author.name, github=author.github, email=author.email
                )
            )

    print(os.linesep.join(lines))


def _read_until(path_to_file, until=None):
    """Read a file until a line starting with a given string.

    Parameters
    ----------
    path_to_file : str or path-like
        The file to read.
    until : str, optional
        Read lines until reaching a line that starts with ``until``.
        If not provided, read the entire file.

    Returns
    -------
    str
        The contents of the file up to, and including, the search
        string.
    """
    with open(path_to_file) as fp:
        if until is None:
            return fp.read()

        lines = []
        for line in fp.readlines():
            if line.startswith(until):
                lines.append(line)
                break
            lines.append(line)
    return "".join(lines)


def _guess_github_user(author):
    """Guess an author's github username."""
    github = None

    try:
        github = author.github
    except AttributeError:
        pass

    try:
        github = author._extras["github"]
    except KeyError:
        pass

    if github is None:
        for email in sorted(author.emails):
            if email.endswith("github.com"):
                github, _ = email.split("@")
                if "+" in github:
                    _, github = github.split("+")
                break

    if github is None:
        for name in sorted(author.names):
            if name.isalnum():
                github = name
                break

    return github


@authors.command()
@click.pass_context
def mailmap(ctx):
    """Create a mailmap file from an author list."""
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]
    credits_file = ctx.parent.params["credits_file"]

    if verbose and not silent:
        out(f"reading author list: {credits_file}")
    print(
        textwrap.dedent(
            """
            # Prevent git from showing duplicate names with commands like "git shortlog"
            # See the manpage of git-shortlog for details.
            # The syntax is:
            #
            #   Name that should be used <email that should be used> Bad name <bad email>
            #
            # You can skip Bad name if it is the same as the one that should be used,
            # and is unique.
            #
            # This file is up-to-date if the command,
            #
            #   git log --format="%aN <%aE>" | sort -u
            #
            # gives no duplicates.
            """
        ).lstrip()
    )
    authors = AuthorList.from_toml(credits_file)
    for author in authors:
        good_name, good_email = author.name, author.email
        for bad_name, bad_email in itertools.product(
            sorted(author.names), sorted(author.emails)
        ):
            print(f"{good_name} <{good_email}> {bad_name} <{bad_email}>")


@authors.command(name="list")
@click.option(
    "--file",
    default="authors.toml",
    type=click.Path(exists=True, file_okay=True, dir_okay=False, readable=True),
    help="existing authors file",
)
@click.pass_context
def authors_list(ctx, file):
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]
    exclude = ctx.parent.params["exclude"]

    git_log = GitLog("%aN")
    try:
        commit_authors = git_log()
    except AuthorsSubprocessError as error:
        err(error)
        raise click.Abort() from error
    else:
        if verbose and not silent:
            out(f"{git_log}")

    if verbose and not silent:
        out(f"reading authors from {file}")
    authors = AuthorList.from_toml(file)

    commits = Counter()
    for author in commit_authors.splitlines():
        canonical_name = authors.find_author(author.strip()).name
        commits[canonical_name] += 1

    for name, n_commits in sorted(commits.items(), key=lambda x: x[1], reverse=True):
        author = authors.find_author(name)
        if not exclude_matches_any(author.names, exclude):
            print(f"{author.name} <{author.email}> ({n_commits})")


def exclude_matches_any(names: Iterable[str], exclude: str):
    exclude_re = re.compile(exclude)
    for name in names:
        if exclude_re.search(name):
            return True
    return False


@landlab.group(chain=True)
@click.pass_context
def index(ctx):
    pass


@index.command()
@click.pass_context
def grids(ctx):
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]

    index = {"grids": {}}
    for cls in GRIDS:
        index["grids"][cls.__name__] = _categorize_class(cls)
        index["grids"][cls.__name__]["field-io"] += [
            f"{cls.__module__}.{cls.__name__}.at_node",
            f"{cls.__module__}.{cls.__name__}.at_link",
            f"{cls.__module__}.{cls.__name__}.at_patch",
            f"{cls.__module__}.{cls.__name__}.at_corner",
            f"{cls.__module__}.{cls.__name__}.at_face",
            f"{cls.__module__}.{cls.__name__}.at_cell",
        ]

    print("")
    print("# Generated using `landlab index grids`")
    print("[grids]")
    for grid, cats in sorted(index["grids"].items()):
        print("")
        print(f"[grids.{grid}]")
        for cat, funcs in sorted(cats.items()):
            print(f"{cat} = [")
            print(
                textwrap.indent(
                    os.linesep.join([repr(f) + "," for f in sorted(funcs)]), "  "
                )
            )
            print("]")

    if verbose and not silent:
        summary = Counter()
        for cats in index["grids"].values():
            for cat, funcs in cats.items():
                summary[cat] += len(funcs)

        out("[summary]")
        out(f"grids = [{', '.join(sorted(index['grids']))}]")
        out(f"entries = {sum(summary.values())}")
        out("")
        out("[summary.categories]")
        for cat in sorted(summary):
            out(f"{cat} = {summary[cat]}")


@index.command()
@click.pass_context
def components(ctx):
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]

    from sphinx.util.docstrings import prepare_docstring

    index = {"components": {}}
    for cls in get_all_components():
        if verbose and not silent:
            out(f"indexing: {cls.__name__}")
        index["components"][cls.__name__] = {
            "name": f"{cls.__module__}.{cls.__name__}",
            "unit_agnostic": cls._unit_agnostic,
            "info": cls._info,
            "summary": prepare_docstring(cls.__doc__)[0],
        }

    print("")
    print("# Generated using `landlab index components`")
    print("[components]")
    for component, info in sorted(index["components"].items()):
        print("")
        print(f"[components.{component}]")
        print(f"name = {info['name']!r}")
        print(f"unit_agnostic = {'true' if info['unit_agnostic'] else 'false'}")
        print(f"summary = {info['summary']!r}")

        for name, values in sorted(info["info"].items()):
            print("")
            print(f"[components.{component}.info.{name}]")
            print(f"doc = {values['doc']!r}")
            print(f"dtype = {str(np.dtype(values['dtype']))!r}")
            print(f"intent = {values['intent']!r}")
            print(f"mapping = {values['mapping']!r}")
            print(f"optional = {'true' if values['optional'] else 'false'}")
            print(f"units = {values['units']!r}")

    if not silent:
        out("[summary]")
        out(f"count = {len(index['components'])}")


@index.command()
@click.pass_context
def fields(ctx):
    verbose = ctx.parent.parent.params["verbose"]
    silent = ctx.parent.parent.params["silent"]

    fields = defaultdict(lambda: defaultdict(list))
    for cls in get_all_components():
        if verbose and not silent:
            out(f"checking {cls.__name__}... {len(cls._info)} fields")

        for name, desc in cls._info.items():
            fields[name]["desc"].append(desc["doc"])
            if desc["intent"].startswith("in"):
                fields[name]["used_by"].append(f"{cls.__module__}.{cls.__name__}")
            if desc["intent"].endswith("out"):
                fields[name]["provided_by"].append(f"{cls.__module__}.{cls.__name__}")

    print("")
    print("# Generated using `landlab index fields`")
    print("[fields]")
    for field, info in sorted(fields.items()):
        print("")
        print(f"[fields.{field}]")
        print(f"desc = {info['desc'][0]!r}")
        if info["used_by"]:
            # used_by = [repr(f) for f in info["used_by"]]
            # print(f"used_by = [{', '.join(used_by)}]")
            print("used_by = [")
            for component in sorted(info["used_by"]):
                print(f"  {component!r},")
            print("]")
        else:
            print("used_by = []")
        if info["provided_by"]:
            print("provided_by = [")
            for component in sorted(info["provided_by"]):
                print(f"  {component!r},")
            print("]")

        else:
            print("provided_by = []")

    if not silent:
        out("[summary]")
        out(f"count = {len(fields)}")


def get_all_components():
    from landlab.components import COMPONENTS
    from landlab.core.model_component import Component

    components = []
    for cls in COMPONENTS:
        if issubclass(cls, Component):
            components.append(cls)

    return components


def get_all_components_by_name():
    return {cls.__name__: cls for cls in get_all_components()}


def get_components(*args):
    """Get components by name.

    Parameters
    ----------
    names : list of str, optional
        Component names.

    Returns
    -------
    list of class
        Components with any of the given names.
    """
    if len(args) == 0 or len(args[0]) == 0:
        components = get_all_components()
    else:
        components_by_name = get_all_components_by_name()
        components = []
        for name in args[0]:
            try:
                components.append(components_by_name[name])
            except KeyError:
                print(f"{name}: not a component", file=sys.stderr)

    return components


def get_users_of(var):
    """Get components that use a variable."""
    users = []
    for cls in get_all_components():
        try:
            if var in cls.input_var_names:
                users.append(cls.__name__)
        except (AttributeError, TypeError):
            print(
                f"Warning: {cls.__name__}: unable to get input vars",
                file=sys.stderr,
            )

    return users


def get_providers_of(var):
    """Get components that provide a variable."""
    providers = []
    for cls in get_all_components():
        try:
            if var in cls.output_var_names:
                providers.append(cls.__name__)
        except (AttributeError, TypeError):
            print(
                f"Warning: {cls.__name__}: unable to get output vars",
                file=sys.stderr,
            )

    return providers


def _used_by(classes):
    """Get variables used by components."""
    used = []
    for cls in classes:
        with contextlib.suppress(TypeError):
            used += cls.input_var_names

    return used


def _provided_by(classes):
    """Get variables provided by components."""
    provided = []
    for cls in classes:
        with contextlib.suppress(TypeError):
            provided += cls.output_var_names

    return provided


def _test_input_var_names(cls):
    errors = []
    try:
        names = cls.input_var_names
    except AttributeError:
        errors.append("no input_var_names attribute")
    else:
        if not isinstance(names, tuple):
            errors.append("input_var_names is not a tuple")
    return errors


def _test_output_var_names(cls):
    errors = []
    try:
        names = cls.output_var_names
    except AttributeError:
        errors.append("no output_var_names attribute")
    else:
        if not isinstance(names, tuple):
            errors.append("output_var_names is not a tuple")
    return errors


def _validate_component(cls):
    from landlab.core.model_component import Component

    errors = []
    if not issubclass(cls, Component):
        errors.append("not a subclass of Component")
    else:
        errors += _test_input_var_names(cls)
        errors += _test_output_var_names(cls)

    return errors


def _validate(args):
    failures = 0
    classes = get_components(args.name)
    for cls in classes:
        errors = _validate_component(cls)
        if errors:
            failures += 1
            for error in errors:
                print(f"Error: {cls.__name__}: {error}")

    return failures


def _categorize_class(cls):
    funcs = {cat: [] for cat in CATEGORIES}

    for name, func in inspect.getmembers(cls):
        if not name.startswith("_"):
            full_name = ".".join([cls.__module__, cls.__name__, name])
            for cat in _extract_landlab_category(inspect.getdoc(func)):
                funcs[cat].append(full_name)
    return funcs


def _extract_landlab_category(s: str):
    from sphinx.util.docstrings import separate_metadata

    return [
        cat.strip() or "uncategorized"
        for cat in separate_metadata(s)[1].get("landlab", "").split(",")
    ]




================================================
File: src/landlab/core/__init__.py
================================================
from .model_parameter_loader import load_params

__all__ = ["load_params"]



================================================
File: src/landlab/core/errors.py
================================================
class Error(Exception):
    """Base class for exceptions raised from this module."""

    pass


class MissingKeyError(Error):
    """Error to indicate a missing parameter key.

    Raise this error if the parameter dictionary file does not contain a
    requested *key*.
    """

    def __init__(self, key):
        self._key = key

    def __str__(self):
        return self._key


class ParameterValueError(Error):
    """Error to indicate a bad parameter values.

    Raise this error if a parameter value given by *key* is not of the
    expected type.
    """

    def __init__(self, key, val, expected_type):
        self._key = key
        self._val = val
        self._type = expected_type

    def __str__(self):
        return f"{self._key}: {self._val} is not of type {self._type}"



================================================
File: src/landlab/core/messages.py
================================================
#! /usr/bin/env python
"""Print user messages formatted landlab-style.

This module provides functions for printing nicely-formatted
messages to the user.  Messages are formatted in a particular
style so that all of landlab messages will have a similar
look. Anytime landlab prints something for an end-user to see,
this module should be used.

This module also provides convenience functions for print
particular types of messages. Warning and error messages,
for instance.

Oftentimes when writing code we may need to print a lengthy
message for the user. This may result in code that looks like
the following.

>>> message = (
...     "Lorem ipsum dolor sit amet, consectetur "
...     "adipiscing elit, sed do eiusmod tempor "
...     "incididunt ut labore et dolore magna aliqua. "
...     "Ut enim ad minim veniam, quis nostrud exercitation "
...     "ullamco laboris nisi ut aliquip ex ea commodo "
...     "consequat."
... )

Printing this message string would result in one long line that
would, most likely, extend beyond the user's terminal and be
difficult to read. One solution would be to join the lines
by line separators but then that would result in a bunch of really
short lines.

To help with this, landlab provides a set of functions with the
most basic being `format_message`.

>>> from landlab.core.messages import format_message
>>> print(format_message(message))
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad
minim veniam, quis nostrud exercitation ullamco laboris nisi ut
aliquip ex ea commodo consequat.

landlab also provides functions for printing warning and error
messages.


>>> from landlab.core.messages import warning_message
>>> message = (
...     "Lorem ipsum dolor sit amet, consectetur\\n"
...     "adipiscing elit, sed do eiusmod tempor\\n"
...     "incididunt ut labore et dolore magna aliqua."
... )
>>> print(warning_message(message))
WARNING
=======
<BLANKLINE>
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
eiusmod tempor incididunt ut labore et dolore magna aliqua.

>>> from landlab.core.messages import error_message
>>> print(error_message(message))
ERROR
=====
<BLANKLINE>
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
eiusmod tempor incididunt ut labore et dolore magna aliqua.

Another common design pattern used in landlab is to allow the
user, usually through a keyword, to control what happens
if a particular assertion fails. For instance, the user
may want the code to raise an error, or print a warning
message, or do nothing at all. The `assert_or_print` function
should be used in these cases.

>>> from landlab.core.messages import assert_or_print

>>> dt = 1e6
>>> assert_or_print(dt < 1, "Unstable time step!", onerror="pass")
>>> assert_or_print(dt < 1, "Unstable time step!", onerror="warn")
... # doctest: +SKIP
WARNING
=======

Unstable time step!

>>> assert_or_print(dt < 1, "Unstable time step!", onerror="raise")
Traceback (most recent call last):
...
AssertionError
"""


import os
import re
import sys
import textwrap


def indent_and_wrap(content, indent=""):
    """Indent and wrap some text.

    Lines are first dedented to remove common leading whitespace,
    then indented according to the value of *indent*, and then
    wrapped at 70 characters (indenting if necessary with subsequent
    indent being twice *indent*).

    Note that when looking for common whitespace, the first line is
    ignored.

    Parameters
    ----------
    content : str
        The content to wrap.

    Returns
    -------
    str
        The content properly wrapped and indented.

    Examples
    --------
    >>> from landlab.core.messages import indent_and_wrap
    >>> content = '''@book{knuth1998art,
    ...     title={The art of computer programming: sorting and searching},
    ...     author={Knuth, Donald Ervin},
    ...     volume={3},
    ...     year={1998},
    ...     publisher={Pearson Education}
    ...     }'''
    >>> print(indent_and_wrap(content))
    @book{knuth1998art,
    title={The art of computer programming: sorting and searching},
    author={Knuth, Donald Ervin},
    volume={3},
    year={1998},
    publisher={Pearson Education}
    }
    """
    wrapper = textwrap.TextWrapper(initial_indent=indent, subsequent_indent=2 * indent)
    lines = content.splitlines()
    first_line, the_rest = [lines[0].strip()], lines[1:]
    if the_rest:
        the_rest = textwrap.dedent(os.linesep.join(the_rest)).splitlines()
    if first_line[0]:
        lines = first_line + the_rest
    else:
        lines = the_rest
    return os.linesep.join([os.linesep.join(wrapper.wrap(line)) for line in lines])


def split_paragraphs(msg, linesep=os.linesep):
    """Split text into paragraphs.

    Split a block of text into paragraphs. A paragraph is
    defined as adjacent new-line characters (possibly separated
    by some whitespace).

    Parameters
    ----------
    msg : str
        Text to split into paragraphs.
    linesep : str, optional
        Line separator used in the message string.

    Returns
    -------
    list of str
        List of paragraphs.

    Examples
    --------
    >>> from landlab.core.messages import split_paragraphs
    >>> text = '''
    ... Pharetra pharetra massa massa ultricies mi quis hendrerit.
    ...
    ... Dictumst vestibulum rhoncus est pellentesque.
    ... '''
    >>> split_paragraphs(text, linesep="\\n")
    ['Pharetra pharetra massa massa ultricies mi quis hendrerit.',
     'Dictumst vestibulum rhoncus est pellentesque.']

    >>> text = '''
    ... Pharetra pharetra massa massa ultricies mi quis hendrerit.
    ... Dictumst vestibulum rhoncus est pellentesque.
    ... '''
    >>> len(split_paragraphs(text, linesep="\\n"))
    1
    """
    pattern = linesep + r"\s*" + linesep
    parsep = linesep * 2
    return re.sub(pattern, parsep, msg.strip()).split(parsep)


def format_message(msg, header=None, footer=None, linesep=os.linesep):
    """Format a message, landlab-style.

    Create a nicely formatted message that splits paragraphs,
    dedents paragraphs, and wraps text at 70 characters.
    Optionally, add a header and footer to the resulting message.


    Parameters
    ----------
    msg : str
        The message to be formatted.
    header : str or list of str, optional
        String to add before *msg*.
    footer : str or list of str, optional
        String to add after *msg*.

    Returns
    -------
    str
        The formatted message.

    Examples
    --------
    >>> from landlab.core.messages import format_message
    >>> text = '''
    ... Lorem ipsum dolor sit amet, consectetur
    ... adipiscing elit, sed do eiusmod tempor
    ... incididunt ut labore et dolore magna aliqua.
    ...
    ... Pharetra pharetra massa massa ultricies mi
    ... quis hendrerit.
    ...
    ... Dictumst vestibulum rhoncus est pellentesque.
    ... Sed viverra tellus in hac habitasse platea
    ... dictumst vestibulum rhoncus.'''
    >>> print(format_message(text))
    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
    eiusmod tempor incididunt ut labore et dolore magna aliqua.
    <BLANKLINE>
    Pharetra pharetra massa massa ultricies mi quis hendrerit.
    <BLANKLINE>
    Dictumst vestibulum rhoncus est pellentesque. Sed viverra tellus in
    hac habitasse platea dictumst vestibulum rhoncus.
    """
    if isinstance(header, str):
        header = [header]
    header = header or []

    if isinstance(footer, str):
        footer = [footer]
    footer = footer or []

    paragraphs = header
    if msg is not None:
        for paragraph in split_paragraphs(msg.strip(), linesep=linesep):
            paragraphs.append(
                os.linesep.join(textwrap.wrap(textwrap.dedent(paragraph)))
            )
    paragraphs += footer

    return (os.linesep * 2).join(paragraphs)


def deprecation_message(msg=None, **kwds):
    """Create a deprecation message, landlab-style.

    Parameters
    ----------
    msg : str, optional
        Warning message.

    Returns
    -------
    str
        The formatted warning message.

    Examples
    --------
    >>> from landlab.core.messages import deprecation_message
    >>> print(deprecation_message("Dictumst vestibulum rhoncus est pellentesque."))
    DEPRECATION WARNING
    ===================
    <BLANKLINE>
    Dictumst vestibulum rhoncus est pellentesque.

    >>> print(
    ...     deprecation_message(
    ...         "Dictumst vestibulum rhoncus est pellentesque.",
    ...         use="Lorem ipsum dolor sit amet",
    ...     )
    ... )
    DEPRECATION WARNING
    ===================
    <BLANKLINE>
    Dictumst vestibulum rhoncus est pellentesque.
    <BLANKLINE>
    Example
    -------
    Lorem ipsum dolor sit amet
    """
    use = kwds.pop("use", None)
    if use:
        footer = os.linesep.join(["Example", "-------", use])
    else:
        footer = None
    header = "Deprecation warning".upper()
    return format_message(
        msg, header=os.linesep.join([header, "=" * len(header)]), footer=footer, **kwds
    )


def warning_message(msg=None, **kwds):
    """Create a warning message, landlab-style.

    Parameters
    ----------
    msg : str, optional
        Warning message.

    Returns
    -------
    str
        The formatted warning message.

    Examples
    --------
    >>> from landlab.core.messages import warning_message
    >>> print(warning_message("Dictumst vestibulum rhoncus est pellentesque."))
    WARNING
    =======
    <BLANKLINE>
    Dictumst vestibulum rhoncus est pellentesque.
    """
    header = "Warning".upper()
    return format_message(
        msg, header=os.linesep.join([header, "=" * len(header)]), **kwds
    )


def error_message(msg=None, **kwds):
    """Create an error  message, landlab-style.

    Parameters
    ----------
    msg : str, optional
        Warning message.

    Returns
    -------
    str
        The formatted warning message.

    Examples
    --------
    >>> from landlab.core.messages import error_message
    >>> print(error_message("Dictumst vestibulum rhoncus est pellentesque."))
    ERROR
    =====
    <BLANKLINE>
    Dictumst vestibulum rhoncus est pellentesque.
    """
    header = "Error".upper()
    return format_message(
        msg, header=os.linesep.join([header, "=" * len(header)]), **kwds
    )


def assert_or_print(cond, msg=None, onerror="raise", file=sys.stdout):
    """Make an assertion printing a message if it fails.

    Specify an action to take if an assertion fails, depending on
    the values of *onerror*. *onerror* must be one of:

    * "pass": do nothing if the assertion passes or fails.
    * "warn": print a warning message if the assertion fails.
    * "error": print an error message and raise an `AssertionError`
      on failure.

    Parameters
    ----------
    cond : expression
        An expression to test.
    msg : str, optional
        Message to print if the condition is not met.
    onerror: {'pass', 'warn', 'raise'}, optional
        What to do if the condition evaluates to `False`.
    file : file_like, optional
        File-like object where the message is printed.

    Examples
    --------
    >>> from landlab.core.messages import assert_or_print

    >>> assert_or_print(True, "Lorem ipsum", onerror="pass")
    >>> assert_or_print(False, "Lorem ipsum", onerror="pass")

    >>> assert_or_print(True, "Lorem ipsum", onerror="warn")
    >>> assert_or_print(False, "Lorem ipsum", onerror="warn")

    >>> assert_or_print(True, "Lorem ipsum", onerror="raise")
    >>> assert_or_print(False, "Lorem ipsum", onerror="raise")
    Traceback (most recent call last):
    ...
    AssertionError
    """
    if onerror not in ("pass", "warn", "raise"):
        raise ValueError("onerror must be one of 'pass', 'warn', or 'raise'")

    try:
        assert cond
    except AssertionError:
        if onerror == "warn":
            print(warning_message(msg), file=file, end="")
        elif onerror == "raise":
            print(error_message(msg), file=file, end="")
            raise



================================================
File: src/landlab/core/model_component.py
================================================
#! /usr/bin/env python
"""Defines the base component class from which Landlab components inherit.

Base component class methods
++++++++++++++++++++++++++++

.. autosummary::

    ~Component.name
    ~Component.from_path
    ~Component.unit_agnostic
    ~Component.units
    ~Component.definitions
    ~Component.input_var_names
    ~Component.output_var_names
    ~Component.optional_var_names
    ~Component.var_type
    ~Component.var_units
    ~Component.var_definition
    ~Component.var_mapping
    ~Component.var_loc
    ~Component.var_help
    ~Component.initialize_output_fields
    ~Component.initialize_optional_output_fields
    ~Component.shape
    ~Component.grid
    ~Component.coords
"""

import os
import textwrap

import numpy as np

from .. import registry
from ..field import FieldError
from .model_parameter_loader import load_params

_VAR_HELP_MESSAGE = """
name: {name}
description:
{desc}
units: {units}
unit agnostic: {unit_agnostic}
at: {loc}
intent: {intent}
"""


class classproperty(property):
    def __get__(self, cls, owner):
        return self.fget.__get__(None, owner)()


class Component:
    """Base component class from which Landlab components inherit."""

    _info = {}
    _name = None
    _cite_as = ""
    _unit_agnostic = None

    def __new__(cls, *args, **kwds):
        registry.add(cls)
        return object.__new__(cls)

    def __init__(self, grid):
        self._grid = grid
        self._current_time = None
        # ensure that required input fields exist
        for name in self._info.keys():
            at = self._info[name]["mapping"]
            optional = self._info[name]["optional"]
            in_true = "in" in self._info[name]["intent"]
            if (in_true) and (not optional):
                # if required input, verify that it exists.
                if name not in self._grid[at]:
                    raise FieldError(
                        "{component} is missing required input field: {name} at {at}".format(
                            component=self._name, name=name, at=at
                        )
                    )

                # if required input exists, check dtype.
                field = self._grid[at][name]
                dtype = self._info[name]["dtype"]

                if field.dtype != dtype:
                    raise FieldError(
                        f"{self._name} required input variable: {name!r} at {at!r} "
                        f"has incorrect dtype. dtype must be {dtype!r} and is "
                        f"{field.dtype!r}"
                    )

            # if optional input exists, check dtype
            if in_true and optional and name in self._grid[at]:
                field = self._grid[at][name]
                dtype = self._info[name]["dtype"]

                if field.dtype != dtype:
                    raise FieldError(
                        f"{self._name} optional input variable: {name} at {at} has "
                        f"incorrect dtype. dtype must be {dtype} and is {field.dtype}"
                    )

    @classmethod
    def from_path(cls, grid, path):
        """Create a component from an input file.

        Parameters
        ----------
        grid : ModelGrid
            A landlab grid.
        path : str or file_like
            Path to a parameter file, contents of a parameter file, or
            a file-like object.

        Returns
        -------
        Component
            A newly-created component.
        """
        if os.path.isfile(path):
            with open(path) as fp:
                params = load_params(fp)
        else:
            params = load_params(path)
        return cls(grid, **params)

    @classproperty
    @classmethod
    def cite_as(cls):
        """Citation information for component.

        Return required software citation, if any. An empty string indicates
        that no citations other than the standard Landlab package citations are
        needed for the component.

        Citations are provided in BibTeX format.

        Returns
        -------
        cite_as
        """
        return cls._cite_as

    @property
    def current_time(self):
        """Current time.

        Some components may keep track of the current time. In this case, the
        ``current_time`` attribute is incremented. Otherwise it is set to None.

        Returns
        -------
        current_time
        """
        return self._current_time

    @current_time.setter
    def current_time(self, new_time):
        if self._current_time is not None:
            assert new_time > self._current_time
        self._current_time = new_time

    @classproperty
    @classmethod
    def input_var_names(cls):
        """Names of fields that are used by the component.

        Returns
        -------
        tuple of str
            Tuple of field names.
        """
        input_var_names = [
            name
            for name in cls._info.keys()
            if (not cls._info[name]["optional"]) and ("in" in cls._info[name]["intent"])
        ]
        return tuple(sorted(input_var_names))

    @classproperty
    @classmethod
    def output_var_names(cls):
        """Names of fields that are provided by the component.

        Returns
        -------
        tuple of str
            Tuple of field names.
        """
        output_var_names = [
            name
            for name in cls._info.keys()
            if (not cls._info[name]["optional"])
            and ("out" in cls._info[name]["intent"])
        ]
        return tuple(sorted(output_var_names))

    @classproperty
    @classmethod
    def optional_var_names(cls):
        """Names of fields that are optionally provided by the component, if
        any.

        Returns
        -------
        tuple of str
            Tuple of field names.
        """
        optional_var_names = [
            name for name in cls._info.keys() if cls._info[name]["optional"]
        ]
        return tuple(sorted(optional_var_names))

    @classmethod
    def var_type(cls, name):
        """Returns the dtype of a field (float, int, bool, str...).

        Parameters
        ----------
        name : str
            A field name.

        Returns
        -------
        dtype
            The dtype of the field.
        """
        return cls._info[name]["dtype"]

    @classproperty
    @classmethod
    def name(cls):
        """Name of the component.

        Returns
        -------
        str
            Component name.
        """
        return cls._name

    @classproperty
    @classmethod
    def unit_agnostic(cls):
        """Whether the component is unit agnostic.

        If True, then the component is unit agnostic. Under this condition a
        user must still provide consistent units across all input arguments,
        keyword arguments, and fields. However, when ``unit_agnostic`` is True
        the units specified can be interpreted as dimensions.

        When False, then the component requires inputs in the specified units.

        Returns
        -------
        bool

        """
        return cls._unit_agnostic

    @classproperty
    @classmethod
    def units(cls):
        """Get the units for all field values.

        Returns
        -------
        tuple or str
            Units for each field.
        """
        return tuple(
            sorted((name, cls._info[name]["units"]) for name in cls._info.keys())
        )

    @classmethod
    def var_units(cls, name):
        """Get the units of a particular field.

        Parameters
        ----------
        name : str
            A field name.

        Returns
        -------
        str
            Units for the given field.
        """
        return cls._info[name]["units"]

    @classproperty
    @classmethod
    def definitions(cls):
        """Get a description of each field.

        Returns
        -------
        tuple of (*name*, *description*)
            A description of each field.
        """
        return tuple(
            sorted((name, cls._info[name]["doc"]) for name in cls._info.keys())
        )

    @classmethod
    def var_definition(cls, name):
        """Get a description of a particular field.

        Parameters
        ----------
        name : str
            A field name.

        Returns
        -------
        tuple of (*name*, *description*)
            A description of each field.
        """
        return cls._info[name]["doc"]

    @classmethod
    def var_help(cls, name):
        """Print a help message for a particular field.

        Parameters
        ----------
        name : str
            A field name.
        """
        desc = os.linesep.join(
            textwrap.wrap(
                cls._info[name]["doc"], initial_indent="  ", subsequent_indent="  "
            )
        )
        units = cls._info[name]["units"]
        loc = cls._info[name]["mapping"]
        intent = cls._info[name]["intent"]

        help = _VAR_HELP_MESSAGE.format(
            name=name,
            desc=desc,
            units=units,
            loc=loc,
            intent=intent,
            unit_agnostic=cls._unit_agnostic,
        )

        print(help.strip())

    @classproperty
    @classmethod
    def var_mapping(cls):
        """Location where variables are defined.

        Returns
        -------
        tuple of (name, location)
            Tuple of variable name and location ('node', 'link', etc.) pairs.
        """
        return tuple(
            sorted((name, cls._info[name]["mapping"]) for name in cls._info.keys())
        )

    @classmethod
    def var_loc(cls, name):
        """Location where a particular variable is defined.

        Parameters
        ----------
        name : str
            A field name.

        Returns
        -------
        str
            The location ('node', 'link', etc.) where a variable is defined.
        """
        return cls._info[name]["mapping"]

    def initialize_output_fields(self, values_per_element=None):
        """Create fields for a component based on its input and output var
        names.

        This method will create new fields (without overwrite) for any fields
        output by, but not supplied to, the component. New fields are
        initialized to zero. Ignores optional fields. New fields are created as
        arrays of floats, unless the component specifies the variable type.

        Parameters
        ----------
        values_per_element: int (optional)
            On occasion, it is necessary to create a field that is of size
            (n_grid_elements, values_per_element) instead of the default size
            (n_grid_elements,). Use this keyword argument to acomplish this
            task.
        """
        for name in self._info.keys():
            at = self._info[name]["mapping"]
            optional = self._info[name]["optional"]
            out_true = "out" in self._info[name]["intent"]
            if (out_true) and (not optional) and (name not in self._grid[at]):
                type_in = self.var_type(name)
                num_elements = self._grid.size(at)

                if values_per_element is None:
                    size = num_elements
                else:
                    size = (num_elements, values_per_element)

                init_vals = np.zeros(size, dtype=type_in)
                units_in = self.var_units(name)

                self.grid.add_field(name, init_vals, at=at, units=units_in, copy=False)

    def initialize_optional_output_fields(self):
        """Create fields for a component based on its optional field outputs,
        if declared in _optional_var_names.

        This method will create new fields (without overwrite) for any
        fields output by the component as optional. New fields are
        initialized to zero. New fields are created as arrays of floats,
        unless the component also contains the specifying property
        _var_type.
        """

        for name in self._info.keys():
            at = self._info[name]["mapping"]
            optional = self._info[name]["optional"]
            out_true = "out" in self._info[name]["intent"]
            if (out_true) and (optional) and (name not in self._grid[at]):
                type_in = self.var_type(name)
                init_vals = self.grid.zeros(at=at, dtype=type_in)
                units_in = self.var_units(name)

                self.grid.add_field(name, init_vals, at=at, units=units_in, copy=False)

    @property
    def shape(self):
        """Return the grid shape attached to the component, if defined."""
        return self.grid._shape

    @property
    def grid(self):
        """Return the grid attached to the component."""
        return self._grid

    @property
    def coords(self):
        """Return the coordinates of nodes on grid attached to the
        component."""
        return (self.grid.node_x, self.grid.node_y)



================================================
File: src/landlab/core/model_parameter_loader.py
================================================
import os
import re

import yaml

_loader = yaml.SafeLoader
_loader.add_implicit_resolver(
    "tag:yaml.org,2002:float",
    re.compile(
        """^(?:
               [-+]?(?:[0-9][0-9_]*)\\.[0-9_]*(?:[eE][-+]?[0-9]+)?
               |[-+]?(?:[0-9][0-9_]*)(?:[eE][-+]?[0-9]+)
               |\\.[0-9_]+(?:[eE][-+][0-9]+)?
               |[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*
               |[-+]?\\.(?:inf|Inf|INF)
               |\\.(?:nan|NaN|NAN))$""",
        re.X,
    ),
    list("-+0123456789."),
)


def load_file_contents(file_like):
    """Load the contents of a file or file-like object.

    Parameters
    ----------
    file_like : file_like or str
        File to load either as a file-like object, path to an existing file,
        or the contents of a file.

    Returns
    -------
    str
        The contents of the file.
    """
    try:
        contents = file_like.read()
    except AttributeError:  # was a str
        if os.path.isfile(file_like):
            with open(file_like) as fp:
                contents = fp.read()
        else:
            contents = file_like

    return contents


def load_params(file_like):
    """Load parameters from a YAML style file.

    Parameters
    ----------
    file_like : file_like or str
        Contents of a parameter file, a file-like object, or the path to
        a parameter file.

    Returns
    -------
    dict
        Parameters as key-value pairs.

    Examples
    --------
    >>> from landlab.core import load_params
    >>> contents = '''
    ... start: 0.
    ... stop: 10.
    ... step: 2.
    ... '''
    >>> params = load_params(contents)
    >>> isinstance(params, dict)
    True
    >>> params["start"], params["stop"], params["step"]
    (0.0, 10.0, 2.0)
    """
    contents = load_file_contents(file_like)

    params = yaml.load(contents, Loader=_loader)

    if not isinstance(params, dict):
        raise ValueError("parsing of parameter file did not produce a dict-like object")

    return params



================================================
File: src/landlab/core/utils.py
================================================
#! /usr/bin/env python
"""Some utilities for the landlab package.

Landlab utilities
+++++++++++++++++

.. autosummary::

    ~radians_to_degrees
    ~as_id_array
    ~make_optional_arg_into_id_array
    ~get_functions_from_module
    ~add_functions_to_class
    ~add_module_functions_to_class
    ~strip_grid_from_method_docstring
    ~argsort_points_by_x_then_y
    ~sort_points_by_x_then_y
    ~anticlockwise_argsort_points
    ~get_categories_from_grid_methods
"""
import errno
import importlib
import inspect
import os
import pathlib
import re
import shutil
import sys

import numpy as np

if sys.version_info >= (3, 12):  # pragma: no cover (PY12+)
    import importlib.resources as importlib_resources
else:  # pragma: no cover (<PY312)
    import importlib_resources

SIZEOF_INT = np.dtype(int).itemsize


class ExampleData:
    def __init__(self, example, case=""):
        self._example = example
        self._case = case

        self._base = pathlib.Path(
            importlib_resources.files("landlab") / "data" / example / case
        )

    @property
    def base(self):
        return self._base

    def fetch(self):
        """Fetch landlab example data files.

        Examples
        --------
        >>> data = ExampleData("io/shapefile")
        >>> sorted(data)
        ['methow', 'redb', 'soque']

        >>> import os
        >>> data.fetch()  # doctest: +SKIP
        >>> sorted(os.listdir())  # doctest: +SKIP
        ['methow', 'redb', 'soque']
        """
        dstdir, srcdir = pathlib.Path("."), self.base

        for dst in (dstdir / p for p in self):
            if dst.exists():
                raise FileExistsError(
                    "[Errno {errno}] File exists: {name}".format(
                        errno=errno.EEXIST, name=repr(dst.name)
                    )
                )

        for src in (srcdir / p for p in self):
            if src.is_file():
                shutil.copy2(src, ".")
            elif src.is_dir():
                shutil.copytree(src, src.name)

    def __iter__(self):
        for p in self.base.iterdir():
            yield p.name

    def __truediv__(self, path):
        return self.base / path

    def __str__(self):
        return str(self.base)

    def __repr__(self):
        return f"ExampleData({self._example!r}, case={self._case!r})"


def degrees_to_radians(degrees):
    """Convert compass-style degrees to radians.

    Convert angles in degrees measured clockwise starting from north to
    angles measured counter-clockwise from the positive x-axis in radians

    Parameters
    ----------
    degrees : float or ndarray
        Converted angles in degrees.

    Returns
    -------
    rads : float or ndarray
        Angles in radians.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import degrees_to_radians

    >>> degrees_to_radians(90.0)
    0.0
    >>> degrees_to_radians(0.0) == np.pi / 2.0
    True
    >>> degrees_to_radians(-180.0) == 3.0 * np.pi / 2.0
    True
    >>> np.testing.assert_array_almost_equal(
    ...     [np.pi, np.pi], degrees_to_radians([-90.0, 270.0])
    ... )
    """
    rads = np.pi * np.array(degrees) / 180.0

    return (5.0 * np.pi / 2.0 - rads) % (2.0 * np.pi)


def radians_to_degrees(rads):
    """Convert radians to compass-style degrees.

    Convert angles (measured counter-clockwise from the positive x-axis) in
    radians to angles in degrees measured clockwise starting from north.

    Parameters
    ----------
    rads : float or ndarray
        Angles in radians.

    Returns
    -------
    degrees : float or ndarray
        Converted angles in degrees.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import radians_to_degrees

    >>> radians_to_degrees(0.0)
    90.0
    >>> radians_to_degrees(np.pi / 2.0)
    0.0
    >>> radians_to_degrees(-3 * np.pi / 2.0)
    0.0
    >>> radians_to_degrees(np.array([-np.pi, np.pi]))
    array([270., 270.])
    """
    degrees = (5.0 * np.pi / 2.0 - rads) % (2.0 * np.pi)
    return 180.0 / np.pi * degrees


def as_id_array(array):
    """Convert an array to an array of ids.

    Parameters
    ----------
    array : ndarray
        Array of IDs.

    Returns
    -------
    ndarray
        A, possibly new, array of IDs.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import as_id_array
    >>> x = np.arange(5)
    >>> y = as_id_array(x)
    >>> y
    array([0, 1, 2, 3, 4])

    >>> x = np.arange(5, dtype=int)
    >>> y = as_id_array(x)
    >>> y
    array([0, 1, 2, 3, 4])

    >>> x = np.arange(5, dtype=np.int32)
    >>> y = as_id_array(x)
    >>> y
    array([0, 1, 2, 3, 4])
    >>> y.dtype == int
    True

    >>> x = np.arange(5, dtype=np.int64)
    >>> y = as_id_array(x)
    >>> y
    array([0, 1, 2, 3, 4])
    >>> y.dtype == int
    True

    >>> x = np.arange(5, dtype=np.intp)
    >>> y = as_id_array(x)
    >>> y
    array([0, 1, 2, 3, 4])
    >>> y.dtype == int
    True

    >>> x = np.arange(5, dtype=np.intp)
    >>> y = np.where(x < 3)[0]
    >>> y.dtype == np.intp
    True
    >>> as_id_array(y).dtype == int
    True
    """
    try:
        if array.dtype == int:
            return array.view(int)
        else:
            return array.astype(int)
    except AttributeError:
        return np.asarray(array, dtype=int)


def make_optional_arg_into_id_array(number_of_elements, *args):
    """Transform an optional argument into an array of element ids.

    Many landlab functions an optional argument of element ids that tells the
    function to operate only on the elements provided. However, if the argument
    is absent, all of the elements are to be operated on. This is a convenience
    function that converts such an arguments list into an array of elements
    ids.

    Parameters
    ----------
    number_of_elements : int
        Number of elements in the grid.
    array : array_like
        Iterable to convert to an array.

    Returns
    -------
    ndarray
        Input array converted to a numpy array, or a newly-created numpy
        array.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import make_optional_arg_into_id_array
    >>> make_optional_arg_into_id_array(4)
    array([0, 1, 2, 3])
    >>> make_optional_arg_into_id_array(4, [0, 0, 0, 0])
    array([0, 0, 0, 0])
    >>> make_optional_arg_into_id_array(4, (1, 1, 1, 1))
    array([1, 1, 1, 1])
    >>> make_optional_arg_into_id_array(4, np.ones(4))
    array([1, 1, 1, 1])
    >>> make_optional_arg_into_id_array(4, 0)
    array([0])
    >>> make_optional_arg_into_id_array(4, np.array([[1, 2], [3, 4]]))
    array([1, 2, 3, 4])
    """
    if len(args) == 0:
        ids = np.arange(number_of_elements, dtype=int)
    elif len(args) == 1:
        ids = as_id_array(np.asarray(args[0])).reshape((-1,))
    else:
        raise ValueError("Number of arguments must be 0 or 1.")

    return ids


def get_functions_from_module(mod, pattern=None, exclude=None):
    """Get all the function in a module.

    Parameters
    ----------
    mod : module
        An instance of a module.
    pattern : str, optional
        Only get functions whose name match a regular expression.
    exclude : str, optional
        Only get functions whose name exclude the regular expression.

    *Note* if both pattern and exclude are provided both conditions must be met.

    Returns
    -------
    dict
        Dictionary of functions contained in the module. Keys are the
        function names, values are the functions themselves.
    """
    funcs = {}
    for name, func in inspect.getmembers(mod, inspect.isroutine):
        if (pattern is None or re.search(pattern, name)) and (
            exclude is None or re.search(exclude, name) is None
        ):
            funcs[name] = func
    return funcs


def add_functions_to_class(cls, funcs):
    """Add functions as methods of a class.

    Parameters
    ----------
    cls : class
        A class.
    funcs : dict
        Dictionary of function names and instances.
    """
    for name, func in funcs.items():
        setattr(cls, name, func)


def add_module_functions_to_class(cls, module, pattern=None, exclude=None):
    """Add functions from a module to a class as methods.

    Parameters
    ----------
    cls : class
        A class.
    module : module
        An instance of a module.
    pattern : str, optional
        Only get functions whose name match a regular expression.
    exclude : str, optional
        Only get functions whose name exclude the regular expression.

    *Note* if both pattern and exclude are provided both conditions must be met.
    """
    (module, _) = os.path.splitext(os.path.basename(module))

    mod = importlib.import_module("." + module, package="landlab.grid")

    funcs = get_functions_from_module(mod, pattern=pattern, exclude=exclude)
    strip_grid_from_method_docstring(funcs)
    add_functions_to_class(cls, funcs)


def strip_grid_from_method_docstring(funcs):
    """Remove 'grid' from the parameters of a dict of functions' docstrings.

    Note that the docstring must be close to numpydoc standards for this to
    work.

    Parameters
    ----------
    funcs : dict
        Dictionary of functions to modify. Keys are the function names,
        values are the functions themselves.

    Examples
    --------
    >>> def dummy_func(grid, some_arg):
    ...     '''A dummy function.
    ...
    ...     Parameters
    ...     ----------
    ...     grid : ModelGrid
    ...         A landlab grid.
    ...     some_arg:
    ...         An argument.
    ...     '''
    ...     pass
    ...
    >>> funcs = {"dummy_func_to_demonstrate_docstring_modification": dummy_func}
    >>> print(dummy_func.__doc__)
    A dummy function.
    <BLANKLINE>
    Parameters
    ----------
    grid : ModelGrid
        A landlab grid.
    some_arg:
        An argument.
    <BLANKLINE>
    >>> strip_grid_from_method_docstring(funcs)
    >>> print(dummy_func.__doc__)
    A dummy function.
    <BLANKLINE>
    Parameters
    ----------
    some_arg:
        An argument.
    <BLANKLINE>
    """
    import re

    for func in funcs.values():
        # strip the entry under "Parameters":
        func.__doc__ = re.sub("grid *:.*?\n.*?\n *", "", func.__doc__)
        # # cosmetic magic to get a two-line signature to line up right:
        match_2_lines = re.search(
            func.__name__ + r"\(grid,[^\)]*?\n.*?\)", func.__doc__
        )
        try:
            lines_were = match_2_lines.group()
        except AttributeError:  # no successful match
            pass
        else:
            end_chars = re.search(r"    .*?\)", lines_were).group()[4:]
            lines_are_now = re.sub(r"    .*?\)", "         " + end_chars, lines_were)
            func.__doc__ = (
                func.__doc__[: match_2_lines.start()]
                + lines_are_now
                + func.__doc__[match_2_lines.end() :]
            )
        # Move "grid" in signature from an arg to the class position
        func.__doc__ = re.sub(
            func.__name__ + r"\(grid, ", "grid." + func.__name__ + "(", func.__doc__
        )


def argsort_points_by_x_then_y(points):
    """Sort points by coordinates, first x then y, returning sorted indices.

    Parameters
    ----------
    points : tuple of ndarray or ndarray of float, shape `(*, 2)`
        Coordinates of points to be sorted. Sort by first coordinate, then
        second.

    Returns
    -------
    ndarray of int, shape `(n_points, )`
        Indices of sorted points.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import argsort_points_by_x_then_y

    >>> points = np.zeros((10, 2))
    >>> points[:, 0] = np.array([0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0])
    >>> points[:, 1] = np.array([0.0, 1.0, 2.0, -0.5, 0.5, 1.5, 2.5, 0.0, 1.0, 2.0])
    >>> argsort_points_by_x_then_y(points)
    array([3, 0, 7, 4, 1, 8, 5, 2, 9, 6])

    >>> x = [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0]
    >>> y = [0.0, 1.0, 2.0, -0.5, 0.5, 1.5, 2.5, 0.0, 1.0, 2.0]
    >>> indices = argsort_points_by_x_then_y((x, y))
    >>> indices
    array([3, 0, 7, 4, 1, 8, 5, 2, 9, 6])

    >>> argsort_points_by_x_then_y(np.array((x, y)))
    array([3, 0, 7, 4, 1, 8, 5, 2, 9, 6])
    """
    if isinstance(points, np.ndarray):
        if points.shape[0] > points.shape[1]:
            points = points.T
        try:
            return argsort_points_by_x_then_y((points[0, :], points[1, :]))
        except IndexError:
            return as_id_array([0])
    else:
        points = [np.asarray(coord) for coord in points]
        a = points[0].argsort(kind="mergesort")
        b = points[1][a].argsort(kind="mergesort")
        return as_id_array(a[b])


def sort_points_by_x_then_y(pts):
    """Sort points by coordinates, first x then y.

    Parameters
    ----------
    pts : Nx2 NumPy array of float
        (x,y) points to be sorted

    Returns
    -------
    pts : Nx2 NumPy array of float
        sorted (x,y) points

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import sort_points_by_x_then_y
    >>> pts = np.zeros((10, 2))
    >>> pts[:, 0] = np.array([0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0])
    >>> pts[:, 1] = np.array([0.0, 1.0, 2.0, -0.5, 0.5, 1.5, 2.5, 0.0, 1.0, 2.0])
    >>> pts = sort_points_by_x_then_y(pts)
    >>> pts
    array([[ 1. , -0.5],
           [ 0. ,  0. ],
           [ 2. ,  0. ],
           [ 1. ,  0.5],
           [ 0. ,  1. ],
           [ 2. ,  1. ],
           [ 1. ,  1.5],
           [ 0. ,  2. ],
           [ 2. ,  2. ],
           [ 1. ,  2.5]])
    """
    indices = argsort_points_by_x_then_y(pts)
    pts[:, 0] = pts[indices, 0]
    pts[:, 1] = pts[indices, 1]
    return pts


def anticlockwise_argsort_points(pts, midpt=None):
    """Argort points into anticlockwise order around a supplied center.

    Sorts CCW from east. Assumes a convex hull.

    Parameters
    ----------
    pts : Nx2 NumPy array of float
    (x,y) points to be sorted
    midpt : len-2 NumPy array of float (optional)
    (x, y) of point about which to sort. If not provided, mean of pts is
    used.

    Returns
    -------
    pts : N NumPy array of int
        sorted (x,y) points

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import anticlockwise_argsort_points
    >>> pts = np.zeros((4, 2))
    >>> pts[:, 0] = np.array([-3.0, -1.0, -1.0, -3.0])
    >>> pts[:, 1] = np.array([-1.0, -3.0, -1.0, -3.0])
    >>> sortorder = anticlockwise_argsort_points(pts)
    >>> np.all(sortorder == np.array([2, 0, 3, 1]))
    True
    """
    if midpt is None:
        midpt = pts.mean(axis=0)
    assert len(midpt) == 2
    theta = np.arctan2(pts[:, 1] - midpt[1], pts[:, 0] - midpt[0])
    theta = theta % (2.0 * np.pi)
    sortorder = np.argsort(theta)
    return sortorder


def anticlockwise_argsort_points_multiline(pts_x, pts_y, out=None):
    """Argort multi lines of points into CCW order around the geometric center.

    This version sorts columns of data in a 2d array. Sorts CCW from east
    around the geometric center of the points in the row.
    Assumes a convex hull.

    Parameters
    ----------
    pts_x : rows x n_elements array of float
        rows x points_to_sort x x_coord of points
    pts_y : rows x n_elements array of float
        rows x points_to_sort x y_coord of points
    out : rows x n_elements (optional)
        If provided, the ID array to be sorted

    Returns
    -------
    sortorder : rows x n_elements NumPy array of int
        sorted (x,y) points

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.core.utils import anticlockwise_argsort_points_multiline
    >>> pts = np.array([[1, 3, 0, 2], [2, 0, 3, 1]])
    >>> pts_x = np.array([[-3.0, -1.0, -1.0, -3.0], [-3.0, -1.0, -1.0, -3.0]])
    >>> pts_y = np.array([[-1.0, -3.0, -1.0, -3.0], [-3.0, -1.0, -3.0, -1.0]])
    >>> sortorder = anticlockwise_argsort_points_multiline(pts_x, pts_y, out=pts)
    >>> np.all(sortorder == np.array([[2, 0, 3, 1], [1, 3, 0, 2]]))
    True
    >>> np.all(pts == np.array([[0, 1, 2, 3], [0, 1, 2, 3]]))
    True
    """
    nrows = pts_x.shape[0]
    midpt = np.empty((nrows, 2), dtype=float)
    midpt[:, 0] = pts_x.mean(axis=1)
    midpt[:, 1] = pts_y.mean(axis=1)
    theta = np.arctan2(
        pts_y - midpt[:, 1].reshape((nrows, 1)), pts_x - midpt[:, 0].reshape((nrows, 1))
    )
    theta = theta % (2.0 * np.pi)
    sortorder = np.argsort(theta)
    if out is not None:
        out[:] = out[np.ogrid[:nrows].reshape((nrows, 1)), sortorder]
    return sortorder


def get_categories_from_grid_methods(grid_type):
    """Create a dict of category:[method_names] for a LL grid type.

    Looks in the final line of the docstrings
    of class methods and properties for a catgory declaration, "LLCATS: ".
    It then creates and returns a dict with keys found as categories and
    values that are lists of the names of methods that have that category.

    Currently defined LLCATS are:

        - DEPR : deprecated
        - GINF : information about the grid as a whole
        - NINF : information about nodes
        - LINF : information about links
        - PINF : information about patches
        - CINF : information about cells
        - FINF : information about faces
        - CNINF : information about corners
        - FIELDIO : methods to access and change fields
        - FIELDADD : methods to create new fields/delete old fields
        - FIELDINF : information about fields (keys, names, etc)
        - GRAD : methods for gradients, fluxes, divergences and slopes
        - MAP : methods to map from one element type to another
        - BC : methods to interact with BCs
        - SURF : methods for surface analysis (slope, aspect, hillshade)
        - SUBSET : methods to indentify part of the grid based on conditions
        - CONN : method describing the connectivity of one element to another
          (i.e., 'links_at_node')
        - MEAS : method describing a quantity defined on an element (i.e.,
          'length_of_link')
        - OTHER : anything else

    Parameters
    ----------
    grid_type : str
        String of grid to inspect. Options are 'ModelGrid', 'RasterModelGrid',
        'HexModelGrid', 'RadialModelGrid', 'VoronoiDelaunayGrid', or
        'NetworkModelGrid'.

    Returns
    -------
    cat_dict : dict
        Dictionary with cats as keys and lists of method name strings as
        values.
    grid_dict : dict
        Dictionary with method name strings as keys and lists of cats as
        values.
    FAILS : dict of dicts
        contains any problematic LLCAT entries. Keys: 'MISSING' - list of names
        of any public method or property without an LLCAT declared.
    """
    import inspect
    import re
    from copy import copy

    from landlab import FramedVoronoiGrid
    from landlab import HexModelGrid
    from landlab import ModelGrid
    from landlab import NetworkModelGrid
    from landlab import RadialModelGrid
    from landlab import RasterModelGrid
    from landlab import VoronoiDelaunayGrid

    grid_str_to_grid = {
        "ModelGrid": ModelGrid,
        "RasterModelGrid": RasterModelGrid,
        "HexModelGrid": HexModelGrid,
        "RadialModelGrid": RadialModelGrid,
        "VoronoiDelaunayGrid": VoronoiDelaunayGrid,
        "NetworkModelGrid": NetworkModelGrid,
        "FramedVoronoiGrid": FramedVoronoiGrid,
    }
    grid_dict = {}
    cat_dict = {}
    FAILS = {"MISSING": []}
    grid = grid_str_to_grid[grid_type]
    funcs = {}
    for name, func in inspect.getmembers(grid):
        funcs[name] = func
    for method_name in funcs.keys():
        if method_name[0] == "_":
            continue
        else:
            method_doc = funcs[method_name].__doc__
            try:
                cat_str = re.search("LLCATS:.+", method_doc)
            except TypeError:
                pass
            else:
                if cat_str is None:
                    FAILS["MISSING"].append(method_name)
                    continue
                cats = cat_str.group().split()[1:]
                grid_dict[method_name] = copy(cats)
                for cat in cats:
                    try:
                        cat_dict[cat].append(method_name)
                    except KeyError:
                        cat_dict[cat] = [method_name]

    return cat_dict, grid_dict, FAILS


if __name__ == "__main__":
    import doctest

    doctest.testmod()




================================================
File: src/landlab/data_record/__init__.py
================================================
from .data_record import DataRecord

__all__ = ["DataRecord"]



================================================
File: src/landlab/data_record/_aggregators.pyx
================================================
cimport cython
from cython.parallel cimport prange
from libc.stdlib cimport free
from libc.stdlib cimport malloc

ctypedef fused id_t:
    cython.integral
    long long


ctypedef fused integral_out_t:
    cython.integral
    long long


ctypedef fused float_or_int:
    cython.integral
    long long
    cython.floating


ctypedef fused float_or_int_weights:
    cython.integral
    long long
    cython.floating


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void aggregate_items_as_count(
    integral_out_t [:] out,
    const id_t [:] element_of_item,
) noexcept nogil:
    cdef long number_of_elements = len(out)
    cdef long number_of_items = len(element_of_item)
    cdef int item, element

    for element in prange(number_of_elements, nogil=True, schedule="static"):
        out[element] = 0

    for item in range(number_of_items):
        element = element_of_item[item]
        if element >= 0:
            out[element] = out[element] + 1


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void aggregate_items_as_sum(
    cython.floating [:] out,
    const id_t [:] element_of_item,
    const float_or_int [:] value_of_item,
) noexcept nogil:
    cdef long number_of_elements = len(out)
    cdef long number_of_items = len(element_of_item)
    cdef int item, element

    for element in prange(number_of_elements, nogil=True, schedule="static"):
        out[element] = 0

    for item in range(number_of_items):
        element = element_of_item[item]
        if element >= 0:
            out[element] = out[element] + value_of_item[item]


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void aggregate_items_as_mean(
    cython.floating [:] out,
    const id_t [:] element_of_item,
    const float_or_int [:] value_of_item,
    const float_or_int_weights [:] weight_of_item,
) noexcept nogil:
    cdef long number_of_elements = len(out)
    cdef long number_of_items = len(element_of_item)
    cdef int item, element
    cdef double * total_weight_at_element = <double *>malloc(
        number_of_elements * sizeof(double)
    )

    try:
        for element in prange(number_of_elements, nogil=True, schedule="static"):
            out[element] = 0.0
            total_weight_at_element[element] = 0.0

        for item in range(number_of_items):
            element = element_of_item[item]
            if element >= 0:
                out[element] = out[element] + value_of_item[item] * weight_of_item[item]
                total_weight_at_element[element] = (
                    total_weight_at_element[element] + weight_of_item[item]
                )

        for element in range(number_of_elements):
            if total_weight_at_element[element] > 0:
                out[element] = out[element] / total_weight_at_element[element]
    finally:
        free(total_weight_at_element)



================================================
File: src/landlab/data_record/aggregators.py
================================================
from __future__ import annotations

import numpy as np
from numpy.typing import ArrayLike
from numpy.typing import NDArray

from landlab.data_record._aggregators import (
    aggregate_items_as_count as _aggregate_items_as_count,
)
from landlab.data_record._aggregators import (
    aggregate_items_as_mean as _aggregate_items_as_mean,
)
from landlab.data_record._aggregators import (
    aggregate_items_as_sum as _aggregate_items_as_sum,
)


def aggregate_items_as_sum(
    ids: ArrayLike, values: ArrayLike, size: int | None = None
) -> NDArray[np.floating]:
    """Find the sum of values associated with an id.

    Parameters
    ----------
    ids : array_like of int
        An array of ids.
    values : array_like
        The value associated with the corresponding id in the `id` array.
    size : int, optional
        The size of the output array. This is useful if the `ids`
        array doesn't contain all possible ids.

    Returns
    -------
    ndarray of int
        The sum of the values at each id.

    Examples
    --------
    >>> from landlab.data_record.aggregators import aggregate_items_as_sum
    >>> aggregate_items_as_sum([0, 0, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5])
    array([3., 3., 0., 3., 1., 5.])
    >>> aggregate_items_as_sum([0, 0, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5], size=8)
    array([3., 3., 0., 3., 1., 5., 0., 0.])

    Negative ids are ignored.

    >>> aggregate_items_as_sum([0, -1, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5])
    array([1., 3., 0., 3., 1., 5.])
    """
    values = np.asarray(values, dtype=float)
    ids = np.asarray(ids, dtype=int)

    size = _validate_size(ids, size=size)

    out = np.empty(size, dtype=float)

    _aggregate_items_as_sum(out, ids, values)

    return out


def aggregate_items_as_mean(
    ids: ArrayLike,
    values: ArrayLike,
    weights: ArrayLike | None = None,
    size: int | None = None,
) -> NDArray[np.floating]:
    """Find the mean of values associated with an id.

    Parameters
    ----------
    ids : array_like of int
        An array of ids.
    values : array_like
        The value associated with the corresponding id in the `id` array.
    size : int, optional
        The size of the output array. This is useful if the `ids`
        array doesn't contain all possible ids.

    Returns
    -------
    ndarray of int
        The mean of the values at each id.

    Examples
    --------
    >>> from landlab.data_record.aggregators import aggregate_items_as_mean
    >>> aggregate_items_as_mean([0, 0, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5])
    array([1.5, 3. , 0. , 3. , 1. , 5. ])
    >>> aggregate_items_as_mean([0, 0, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5], size=8)
    array([1.5, 3. , 0. , 3. , 1. , 5. , 0. , 0. ])

    Negative ids are ignored.

    >>> aggregate_items_as_mean([0, -1, 1, 3, 4, 5], [1, 2, 3, 3, 1, 5])
    array([1., 3., 0., 3., 1., 5.])
    """
    values = np.asarray(values)
    if weights is None:
        weights = np.ones_like(values)
    else:
        weights = np.asarray(weights, dtype=values.dtype)
    ids = np.asarray(ids, dtype=int)

    size = _validate_size(ids, size=size)

    out = np.empty(size, dtype=float)

    assert len(values) == len(weights)

    _aggregate_items_as_mean(out, ids, values, weights)

    return out


def aggregate_items_as_count(
    ids: ArrayLike, size: int | None = None
) -> NDArray[np.int_]:
    """Count the number of time an id appears in an array.

    Parameters
    ----------
    ids : array_like of int
        An array of ids.
    size : int, optional
        The size of the output array. This is useful if the `ids`
        array doesn't contain all possible ids.

    Returns
    -------
    ndarray of int
        The number of times each id appears.

    Examples
    --------
    >>> from landlab.data_record.aggregators import aggregate_items_as_count
    >>> aggregate_items_as_count([1, 2, 3, 3, 1, 5])
    array([0, 2, 1, 2, 0, 1])
    >>> aggregate_items_as_count([1, 2, 3, 3, 1, 5], size=8)
    array([0, 2, 1, 2, 0, 1, 0, 0])

    Negative ids are ignored.

    >>> aggregate_items_as_count([1, 2, 3, 3, -1, 5])
    array([0, 1, 1, 2, 0, 1])
    """
    ids = np.asarray(ids, dtype=int)

    size = _validate_size(ids, size=size)

    out = np.empty(size, dtype=int)

    _aggregate_items_as_count(out, ids)

    return out


def _validate_size(ids: NDArray[np.int_], size: int | None = None):
    if size is None:
        size = ids.max() + 1
    else:
        assert (
            size >= ids.max() + 1
        ), "size must be greater than or equal to the largest input id"
    return size



================================================
File: src/landlab/data_record/data_record.py
================================================
#!/usr/bin/env python3

import numpy as np
import xarray as xr


class DataRecord:
    """Data structure to store variables in time and/or space dimensions.

    This class uses a xarray Dataset to store variables. This datastructure is
    located at the property ``dataset``. The DataRecord expands xarray Dataset
    with additional attributes and functions, including the ability to
    aggregate values on Landlab grid elements.

    DataRecord uses the concept of an "item", a physical thing that is located
    on the grid and has some properties, stored as variables. DataRecord tracks
    variables through time, variables associated with a Landlab grid across
    items, or both.

    Thus data variables can vary along one or both of the following dimensions:

        - time (model time)
        - item_id: variables can characterize a set of items (each identified
          by an individual id) that reside on the grid.

    If an item or set of items is defined, each item must be defined by the
    grid element and the element id at which it resides, e.g.:

        grid_element = 'node'
        element_id = 9.

    When items are defined, each item is given a unique id and the underlying
    Dataset uses a dimension "item_id". **Items are assigned ids beginning with
    0 followed by consecutively increasing integers.**

    Examples:

        - the variable 'mean_elevation' characterizes the grid and varies with
          time,
        - the variable 'clast__rock_type' characterizes a set of items (clasts)
          and varies with item_id,
        - the variable 'clast__size' can vary with both time and item_id

    In the above case, `grid_element` and `element_id` are default data
    variables (in addition to any user-specified variables).

    For each item, `element_id` must be less than the number of this item's
    grid_element that exist on the grid or be one of the dummy element values.
    For example, if the grid has 100 links, and no dummy link values are
    indicated, then, no item can live at link 100 or link -3 because only links
    0 to 99 exist in this example.

    Anything that the DataRecord keeps track of is considered a "record",
    whether it uses one or both of the two standard dimensions (**time** and
    **item_id**).

    DataRecord provides two method to assist with adding new records. The
    method ``add_item`` should be used when no new variables are being added.
    The method ``add_record`` should be used when new variables are being
    added or when a variable is only tracked over the **time** dimension.
    """

    _name = "DataRecord"

    def __init__(
        self,
        grid,
        dummy_elements=None,
        time=None,
        items=None,
        data_vars=None,
        attrs=None,
    ):
        """
        Parameters
        ----------
        grid : ModelGrid
        dummy_elements : dict
            Dictionary indicating valid values for dummy grid elements. For
            example, if you need an "exit" off of a grid with  100 links, you
            could indicate `dummy_elements = {"link": [9999]}`
            to set a link id of 9999 as a dummy link. Multiple dummy elements
            are possible and we recommend using values larger than the number
            of grid elements for the dummy values.
        time : list or 1-D array of float or int (optional)
            The initial time(s) to add to the record. A time dimension is not
            created if the value is 'None' (default).
        items : dict (optional)
            Generic items that live on grid elements. No item is created if the
            value is 'None' (default). Otherwise, dictionary describes the
            position of generic items on the grid. The structure is:

            .. code-block:: python

                {"grid_element": [grid_element], "element_id": [element_id]}

            where:

                - [grid_element] is a str or number-of-items-long array
                  containing strings of the grid element(s) on which the items
                  live. Valid locations depend on the grid type. If provided as a
                  string it is assumed that all items live on the same type of
                  grid element.
                - [element_id] is an array of integers identifying the grid
                  element ID on which each item resides.

            An example argument would be:

            .. code-block:: python

                {
                    "grid_element": numpy.array(["node"], ["node"], ["link"]),
                    "element_id": numpy.array([1], [5], [1]),
                }

        data_vars : dict (optional)
            Dictionary of the data variables to be recorded. The structure is:

            .. code-block:: python

                {
                    "variable_name_1": (["dimensions"], variable_data_1),
                    "variable_name_2": (["dimensions"], variable_data_2),
                }

            where:

                - 'variable_name...' is a string of the variable name (label)
                - ['dimensions'] is the dimension(s) over which the variable
                  exists: can be ['time'], ['item_id'] or ['item_id', 'time'].
                - variable_data is an array containing the data, its size must
                  match that of the variable dimension(s).
        attrs : dict (optional)
            Dictionary of global attributes on the DataRecord (metadata).
            Example: {'time_units' : 'y'}

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with time as the only dimension:

        >>> dr1 = DataRecord(
        ...     grid,
        ...     time=[0.0],
        ...     data_vars={"mean_elevation": (["time"], np.array([100]))},
        ...     attrs={"time_units": "y"},
        ... )

        DataRecord builds off of xarray Dataset, a multi-dimensional, in
        memory, array  database. Dataset implements the mapping interface with
        keys given by variable names and values given by DataArray objects for
        each variable name.

        A DataRecord can have dimensions 'time' and/or 'item_id'.

        The xarray Dataset is stored in the public attribute ``dataset``.

        Coordinates are one dimensional arrays used for label-based indexing.
        DataRecord inherits all the methods and attributes from
        ``xarray.Dataset``.

        >>> dr1.dataset.to_dataframe()
              mean_elevation
        time
        0.0              100
        >>> dr1.dataset.time.values
        array([0.])
        >>> dr1.variable_names
        ['mean_elevation']
        >>> dr1.dataset["mean_elevation"].values
        array([100])
        >>> list(dr1.dataset.attrs.items())
        [('time_units', 'y')]

        >>> list(dr1.dataset.attrs.items())
        [('time_units', 'y')]

        Example of a DataRecord with item_id as the only dimension:

        >>> my_items2 = {
        ...     "grid_element": np.array(("node", "link"), dtype=str),
        ...     "element_id": np.array([1, 3]),
        ... }
        >>> dr2 = DataRecord(grid, items=my_items2)

        Note that both arrays (grid_element and element_id) have 1 dimension
        as they only vary along the dimension 'item_id'.

        >>> dr2.dataset.to_dataframe()[["grid_element", "element_id"]]
                grid_element  element_id
        item_id
        0               node           1
        1               link           3

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items3 = {
        ...     "grid_element": np.array([["node"], ["link"]]),
        ...     "element_id": np.array([[1], [3]]),
        ... }
        >>> dr3 = DataRecord(grid, time=[0.0], items=my_items3)

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> dr3.dataset.to_dataframe()[["grid_element", "element_id"]]
                     grid_element  element_id
        item_id time
        0       0.0          node           1
        1       0.0          link           3

        """

        # save a reference to the grid
        self._grid = grid

        # depending on the grid type, permitted locations for items vary
        self._permitted_locations = self._grid.groups

        # save dummy elements reference
        # check dummies and reformat into {"node": [0, 1, 2]}
        self._dummy_elements = dummy_elements or {}
        for at in self._permitted_locations:
            for item in self._dummy_elements.get(at, []):
                if (item < self._grid[at].size) and (item >= 0):
                    raise ValueError(f"Dummy id {at} {item} invalid")

        # set initial time coordinates, if any
        if isinstance(time, (list, np.ndarray)):
            self._times = np.array(time)
            self._number_of_times = len(self._times)
        elif time is not None:
            raise TypeError("time must be a list or numpy array")

        # set initial items, if any
        if items is not None:
            try:
                items.keys()
            except AttributeError as exc:
                # items is not a dict
                raise TypeError(
                    "You must provide an `items` dictionary "
                    "(see documentation for required format)"
                ) from exc
            try:
                _grid_elements, _element_ids = (
                    items["grid_element"],
                    items["element_id"],
                )
            except KeyError as exc:
                # grid_element and/or element_id not provided
                raise TypeError(
                    "You must provide an `items` dictionary,"
                    "(see documentation for required format)"
                ) from exc

            self._number_of_items = len(_element_ids)
            if len(_grid_elements) != self._number_of_items:
                if isinstance(_grid_elements, str):
                    pass
                else:
                    raise ValueError(
                        "The number of grid_element passed "
                        "to DataRecord must be 1 or equal "
                        "to the number of element_id."
                    )

            # check that grid_element and element_id exist on the grid and
            # have valid format:
            _grid_elements, _element_ids = self._check_grid_element_and_id(
                _grid_elements, _element_ids
            )

            # check that element IDs do not exceed number of elements
            # on the grid:
            self._check_element_id_values(_grid_elements, _element_ids)

            # create coordinates for the dimension 'item_id':
            self._item_ids = np.array(range(self._number_of_items), dtype=int)

            # create initial dictionaries of variables:
            if time is not None:
                data_vars_dict = {
                    "grid_element": (["item_id", "time"], _grid_elements),
                    "element_id": (
                        ["item_id", "time"],
                        _element_ids,
                        {"dtype": int},
                    ),
                }
                coords = {"time": self._times, "item_id": self._item_ids}
            else:
                # no time
                data_vars_dict = {
                    "grid_element": (["item_id"], _grid_elements),
                    "element_id": (["item_id"], _element_ids, {"dtype": int}),
                }
                coords = {"item_id": self._item_ids}

        else:
            # no items, initial dictionary of variables is empty:
            data_vars_dict = {}
            if time is not None:
                coords = {"time": self._times}
            else:  # no item and no time = no dimension
                coords = {}

        # set variables, if any
        if data_vars is not None:
            try:
                # check format (dict)
                data_vars.keys()
            except AttributeError as exc:
                raise TypeError(
                    "Data variables (data_vars) passed to "
                    "DataRecord must be a dictionary (see "
                    "documentation for valid structure)"
                ) from exc
            for key in data_vars.keys():
                # check dict structure and dims:
                if data_vars[key][0] not in (
                    ["time"],
                    ["item_id"],
                    ["time", "item_id"],
                    ["item_id", "time"],
                ):
                    raise ValueError(
                        "Data variable dimensions must be " "time and/or item_id"
                    )

            # create complete dictionary of variables
            # (= initial data_vars_dict + additional user-defined data_vars):
            data_vars_dict.update(data_vars)

        # set attributes, if any
        attrs = attrs or {}
        if not isinstance(attrs, dict):
            raise TypeError(
                "Attributes (attrs) passed to DataRecord" "must be a dictionary"
            )

        # create an xarray Dataset:
        self._dataset = xr.Dataset(data_vars=data_vars_dict, coords=coords, attrs=attrs)

    def _check_grid_element_and_id(self, grid_element, element_id):
        """Check the location and size of grid_element and element_id."""
        if isinstance(grid_element, str):
            # create list of grid_element for all items
            ge_name = grid_element
            if hasattr(self, "_number_of_times"):
                # if time
                grid_element = np.array(
                    np.empty(
                        (self._number_of_items, self._number_of_times), dtype=object
                    )
                )

                if element_id.shape != grid_element.shape:
                    element_id = np.broadcast_to(element_id, grid_element.shape)

            else:
                # no time
                grid_element = np.array(
                    np.empty((self._number_of_items,), dtype=object)
                )
            grid_element.fill(ge_name)

        # verify all grid elements are valid.
        for loc in grid_element.flatten():
            if loc not in self._permitted_locations:
                raise ValueError(
                    "One or more of the grid elements"
                    " provided is/are not permitted location"
                    " for this grid type"
                )

        return grid_element, element_id

    def _check_element_id_values(self, grid_element, element_id):
        """Check that element_id values are valid."""
        for at in self._permitted_locations:
            max_size = self._grid[at].size

            # this needs to work with 2d arrays (rows, col = np.where (so grid
            # element always needs to be at least 2d.))
            ind = np.nonzero(grid_element == at)
            selected_elements = element_id[ind]

            if selected_elements.size > 0:
                dummy_values = self._dummy_elements.get(at, [])
                index_values = np.arange(0, max_size)
                valid_values = np.concatenate((dummy_values, index_values))

                valid_elements = np.isin(selected_elements, valid_values)

                if not np.all(valid_elements):
                    raise ValueError("Invalid element_ids provided.")

        if not np.issubdtype(element_id.dtype, np.integer):
            raise ValueError(
                "You have passed a non-integer element_id to "
                "DataRecord, this is not permitted"
            )

    def add_record(self, time=None, item_id=None, new_item_loc=None, new_record=None):
        """Add a new record to the DataRecord.

        Unlike add_item, this method can support adding records that include
        new variables to the DataRecord. It can also support adding records
        that do not include time.

        Parameters
        ----------
        time : list or 1-D array of float or int
            Time step at which the record is to be added.
        item_id : list or 1-D array of int (optional)
            ID of the item to which the new record relates.
        new_item_loc: dict (optional)
            Dictionary of the new item location. If the new record is a change
            in the item location (grid_element and/or element_id), this field
            must be provided as:

            .. code-block:: python

                {"grid_element": [grid_element], "element_id": [element_id]}

            Both must be provided even if only one is being changed.

        new_record : dict
            Dictionary containing the new record. Structure should be:
            {'variable_name_1' : (['dimensions'], variable_data_1)}
            with:

                - 'variable_name_1' : name of the (potentially new) variable
                - ['dimensions'] : dimension(s) along which the new record
                  varies; can be ['time'], ['item_id] or ['item_id', 'time']
                - variable_data_1 : new data array, size must match the
                  variable dimension(s)

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items3 = {
        ...     "grid_element": np.array([["node"], ["link"]]),
        ...     "element_id": np.array([[1], [3]]),
        ... }

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> dr3 = DataRecord(grid, time=[0.0], items=my_items3)

        Records relating to pre-existing items can be added to the DataRecord
        using the method 'add_record':

        >>> dr3.add_record(
        ...     time=[2.0],
        ...     item_id=[0],
        ...     new_item_loc={
        ...         "grid_element": np.array([["node"]]),
        ...         "element_id": np.array([[6]]),
        ...     },
        ...     new_record={"item_size": (["item_id", "time"], np.array([[0.2]]))},
        ... )
        >>> dr3.dataset["element_id"].values
        array([[ 1.,  6.],
               [ 3., nan]])
        >>> dr3.get_data([2.0], [0], "item_size")
        array([0.2])

        The 'add_record' method can also be used to add a non item-related
        record:

        >>> dr3.add_record(time=[50.0], new_record={"mean_elev": (["time"], [110])})
        >>> dr3.dataset["mean_elev"].to_dataframe()
              mean_elev
        time
        0.0         NaN
        2.0         NaN
        50.0      110.0
        """
        if time is not None:
            try:
                # check that time is a dim of the DataRecord
                self._dataset["time"]
            except KeyError as exc:
                raise KeyError("This DataRecord does not record time") from exc

            if not isinstance(time, (list, np.ndarray)):
                # check input type
                raise TypeError(
                    "You have passed a time that is"
                    " not permitted, must be list or array"
                )
            else:
                if item_id is not None:
                    try:
                        # check that DataRecord holds items
                        self._dataset["item_id"]
                    except KeyError as exc:
                        raise KeyError("This DataRecord does not hold items") from exc
                    try:
                        # check that item_id is list or array
                        len(item_id)
                    except TypeError as exc:
                        raise TypeError("item_id must be a list or a 1D array") from exc
                    if not all(i in self._dataset["item_id"].values for i in item_id):
                        # check that item_id already exist
                        raise ValueError(
                            "One or more of the value(s) you "
                            "passed as item_id is/are not "
                            "currently in the DataRecord. Change"
                            " the input values create a new item"
                            "using the method add_item"
                        )
                    coords_to_add = {"time": np.array(time), "item_id": item_id}

                    # if item location is changed by this new record, check
                    # that both grid_element and element_id are provided:
                    if new_item_loc is not None:
                        try:
                            new_grid_element = new_item_loc["grid_element"]
                            new_element_id = new_item_loc["element_id"]
                        except KeyError as exc:
                            raise KeyError(
                                "You must provide a "
                                "new_item_loc dictionary with both "
                                "grid_element and element_id"
                            ) from exc
                        # check that grid_element and element_id exist
                        # on the grid and have valid format:
                        (
                            new_grid_element,
                            new_element_id,
                        ) = self._check_grid_element_and_id(
                            new_grid_element, new_element_id
                        )

                        # check that element IDs do not exceed number
                        # of elements on this grid:
                        self._check_element_id_values(new_grid_element, new_element_id)

                        _new_data_vars = {
                            "grid_element": (["item_id", "time"], new_grid_element),
                            "element_id": (["item_id", "time"], new_element_id),
                        }
                    else:
                        # new_item_loc is `None`
                        _new_data_vars = {}
                else:
                    # no item
                    coords_to_add = {"time": np.array(time)}
                    _new_data_vars = {}

        else:
            # no time
            if item_id is not None:
                if not all(i in self._dataset["item_id"].values for i in item_id):
                    # check that item_id already exist
                    raise ValueError(
                        "One or more of the value(s) you "
                        "passed as item_id is/are not "
                        "currently in the DataRecord. Change"
                        " the input values create a new item"
                        "using the method add_item"
                    )

                coords_to_add = {"item_id": np.array(item_id)}
                _new_data_vars = {}

                # no time so if item location needs to be changed,
                # user should use set_data
                if new_item_loc is not None:
                    raise ValueError(
                        "Use the method set_data to change the "
                        "location of an item in this DataRecord"
                    )
            else:
                # no item
                _new_data_vars = {}
                coords_to_add = {}

        if new_record is not None:
            # add new_record to dict of variables to add
            _new_data_vars.update(new_record)

        # create dataset of new record
        ds_to_add = xr.Dataset(data_vars=_new_data_vars, coords=coords_to_add)

        # merge new record and original dataset
        self._dataset = xr.merge((self._dataset, ds_to_add), compat="no_conflicts")

    def add_item(self, time=None, new_item=None, new_item_spec=None):
        """Add new item(s) to the current DataRecord.

        Parameters
        ----------
        time : list or 1-D array of float or int
            Time step at which the items are to be added.
        new_item : dict
            Structure is:

            .. code-block:: python

                {"grid_element": [grid_element], "element_id": [element_id]}

            where:

                - [grid_element] is str or number-of-items long array
                  containing strings of the grid element(s) on which the items
                  live. Valid locations depend on the grid type. If provided as
                  a string it is assumed that all items live on the same type of
                  grid element.
                - [element_id] is an array of integers identifying the grid
                  element ID on which each item resides.

            An example argument would be:

            .. code-block:: python

                {
                    "grid_element": numpy.array([["node"], ["node"], ["link"]]),
                    "element_id": numpy.array([[1], [5], [1]]),
                }

        new_item_spec : dict (optional)
            Dictionary containing any data variables (other than
            'grid_element' and 'element_id') relating to the new item(s) to be
            added. Structure is:

            .. code-block:: python

                {"variable_name_1": (["dimensions"], variable_data_1)}

            where:

                - 'variable_name_1' : name of the (potentially new) variable
                - ['dimensions'] : dimension(s) along which the new record
                  varies; can be ['time'], ['item_id] or ['item_id', 'time']
                - variable_data_1 : new data array, size must match the
                  variable dimension(s)

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items3 = {
        ...     "grid_element": np.array([["node"], ["link"]]),
        ...     "element_id": np.array([[1], [3]]),
        ... }

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> dr3 = DataRecord(grid, time=[0.0], items=my_items3)

        Items can be added to a DataRecord that already holds similar items,
        using the method 'add_item':

        >>> dr3.add_item(
        ...     time=[1.0],
        ...     new_item={
        ...         "grid_element": np.array([["node"], ["node"]]),
        ...         "element_id": np.array([[4], [4]]),
        ...     },
        ...     new_item_spec={"size": (["item_id", "time"], [[10], [5]])},
        ... )

        Two items have been added at a new timestep 1.0:

        >>> dr3.number_of_items
        4
        >>> dr3.time_coordinates
        [0.0, 1.0]

        If a data variable is also added with the new items ('size' in this
        example), the values for this variable are filled with 'nan' for the
        pre-existing items:

        >>> dr3.dataset["size"][:, 1].values
        array([nan, nan, 10.,  5.])

        The previous line calls the values of the variable 'size', for all
        items, at time=1; the first two items don't have a value for the
        variable 'size'.
        """
        if time is None and "time" in self._dataset["grid_element"].coords:
            raise ValueError(
                "The items previously defined in this DataRecord"
                ' have dimensions "time" and "item_id", '
                'you must provide a "time" for the new item(s)'
            )

        if not isinstance(new_item, dict):
            raise TypeError(
                "You must provide an new_item dictionary "
                "(see documentation for required format)"
            )

        try:
            # check that dict contains correct entries
            _grid_elements, _element_ids = (
                new_item["grid_element"],
                new_item["element_id"],
            )

        except KeyError as exc:
            raise KeyError(
                "You must provide a new_item dictionary "
                "(see documentation for required format)"
            ) from exc

        number_of_new_items = len(new_item["element_id"])
        # first id of new item = last item in existing datarecord+1
        new_first_item_id = self._dataset["item_id"][-1].values + 1
        new_item_ids = np.array(
            range(new_first_item_id, new_first_item_id + number_of_new_items)
        )

        if time is not None:
            try:
                self._dataset["time"]
            except KeyError as exc:
                raise KeyError("This DataRecord does not record time") from exc
            if not isinstance(time, (list, np.ndarray)):
                raise TypeError(
                    "You have passed a time that is not "
                    "permitted, must be list or a 1-D array"
                )
            else:
                coords_to_add = {
                    "time": np.array(time),
                    "item_id": np.array(new_item_ids),
                }
                # check that grid_element and element_id exist
                # on the grid and have valid format
                _grid_elements, _element_ids = self._check_grid_element_and_id(
                    _grid_elements, _element_ids
                )

                # check that element IDs do not exceed number
                # of elements on this grid
                self._check_element_id_values(_grid_elements, _element_ids)

                data_vars_dict = {
                    "grid_element": (["item_id", "time"], _grid_elements),
                    "element_id": (["item_id", "time"], _element_ids),
                }

        else:
            # no time
            coords_to_add = {"item_id": np.array(new_item_ids)}
            # check that grid_element and element_id exist on
            # the grid and have valid format:
            _grid_elements, _element_ids = self._check_grid_element_and_id(
                _grid_elements, _element_ids
            )
            # check that element IDs do not exceed number of
            # elements on this grid
            self._check_element_id_values(_grid_elements, _element_ids)

            data_vars_dict = {
                "grid_element": (["item_id"], _grid_elements),
                "element_id": (["item_id"], _element_ids),
            }

        # other variables:
        if new_item_spec is not None:
            data_vars_dict.update(new_item_spec)

        # Dataset of new record:
        ds_to_add = xr.Dataset(data_vars=data_vars_dict, coords=coords_to_add)

        # Merge new record and original dataset:
        self._dataset = xr.merge((self._dataset, ds_to_add), compat="no_conflicts")

    def get_data(self, time=None, item_id=None, data_variable=None):
        """Get the value of a variable at a model time and/or for an item.

        Parameters
        ----------
        time : list or 1-D array of float or int (optional)
            The time coordinate of the record to get.
        item_id : list or 1-D array of int (optional)
            The item id of the record to get.
        data_variable : string
            The label of the variable to get.

        Returns
        -------
        object
            The value of *variable* at *time* and/or for *item_id*. The type of
            the returned object is dependent on the type of the variable value.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items4 = {
        ...     "grid_element": "node",
        ...     "element_id": np.array([[1], [3], [3], [7]]),
        ... }

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> my_data4 = {
        ...     "item_size": (
        ...         ["item_id", "time"],
        ...         np.array([[0.3], [0.4], [0.8], [0.4]]),
        ...     )
        ... }
        >>> dr4 = DataRecord(grid, time=[50.0], items=my_items4, data_vars=my_data4)
        >>> dr4.get_data([50.0], [2], "element_id")
        array([3])
        >>> dr4.get_data(time=[50.0], data_variable="item_size")
        array([0.3, 0.4, 0.8, 0.4])
        >>> dr4.get_data(item_id=[1, 2], data_variable="grid_element")
        array([['node'],
               ['node']], dtype=object)
        """
        try:
            self._dataset[data_variable]
        except KeyError as exc:
            raise KeyError(
                f"the variable {data_variable!r} is not in the DataRecord"
            ) from exc
        if time is None:
            if item_id is None:
                return self._dataset[data_variable].values
            else:
                try:
                    self._dataset["item_id"]
                except KeyError as exc:
                    raise KeyError("This DataRecord does not hold items") from exc
                try:
                    len(item_id)
                except TypeError as exc:
                    raise TypeError("item_id must be a list or a 1-D array") from exc
                try:
                    self._dataset["item_id"].values[item_id]
                except IndexError as exc:
                    raise IndexError(
                        "The item_id you passed does not exist " "in this DataRecord"
                    ) from exc

                return self._dataset.isel(item_id=item_id)[data_variable].values

        else:  # time is not None
            try:
                self._dataset["time"]
            except KeyError as exc:
                raise KeyError("This DataRecord does not record time") from exc
            try:
                len(time)
            except TypeError as exc:
                raise TypeError("time must be a list or a 1-D array") from exc
            try:
                time_index = int(self.time_coordinates.index(time[0]))
            except ValueError as exc:
                raise IndexError(
                    "The time you passed is not currently"
                    " in the DataRecord, you must change the value"
                    " you pass or first create the new time "
                    " coordinate using the add_record method"
                ) from exc
            if item_id is None:
                return self._dataset.isel(time=time_index)[data_variable].values
            else:
                try:
                    self._dataset["item_id"]
                except KeyError as exc:
                    raise KeyError("This DataRecord does not hold items") from exc
                try:
                    len(item_id)
                except TypeError as exc:
                    raise TypeError("item_id must be a list or a 1-D array") from exc
                try:
                    self._dataset["item_id"].values[item_id]
                except IndexError as exc:
                    raise IndexError(
                        "The item_id you passed does not exist " "in this DataRecord"
                    ) from exc
                return self._dataset.isel(time=time_index, item_id=item_id)[
                    data_variable
                ].values

    def set_data(self, time=None, item_id=None, data_variable=None, new_value=np.nan):
        """Set a variable value at a model time and/or an item to a new value.

        The value of only one variable can be changed at a time using this
        method.

        Parameters
        ----------
        time : list or 1-D array of float or int
            The time coordinate of the record to set.
        item_id : list or 1-D array of int
            The item id of the record to set.
        data_variable : string
            The label of the variable to set.
        new_value : list or 1-D array
            The new value to give to the variable data.

        Returns
        -------
        DataRecord with updated data.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items4 = {
        ...     "grid_element": "node",
        ...     "element_id": np.array([[1], [3], [3], [7]]),
        ... }

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> my_data4 = {
        ...     "item_size": (
        ...         ["item_id", "time"],
        ...         np.array([[0.3], [0.4], [0.8], [0.4]]),
        ...     )
        ... }
        >>> dr4 = DataRecord(grid, time=[50.0], items=my_items4, data_vars=my_data4)
        >>> dr4.dataset["item_size"].values
        array([[0.3],
               [0.4],
               [0.8],
               [0.4]])
        >>> dr4.set_data([50.0], [2], "item_size", [0.5])
        >>> dr4.dataset["item_size"].values
        array([[0.3],
               [0.4],
               [0.5],
               [0.4]])
        """
        if data_variable not in self.variable_names:
            raise KeyError(
                "the variable '{}' is not in the " "DataRecord".format(data_variable)
            )

        # If record to be changed is 'grid_element' or 'element_id',
        # check that provided grid_element is valid and that new
        # grid_element+element_id combination exist on the grid and
        # have valid format:
        if data_variable in ("grid_element", "element_id"):
            if data_variable == "grid_element":
                assoc_grid_element = new_value
                assoc_element_id = self.get_data(time, item_id, "element_id")[0]
            if data_variable == "element_id":
                if not isinstance(new_value, int):
                    raise ValueError(
                        "You have passed a non-integer "
                        "element_id to DataRecord, this is not "
                        "permitted"
                    )
                if new_value < 0:
                    raise ValueError(
                        "You have passed an element id below "
                        "zero. This is not permitted"
                    )
                assoc_element_id = new_value
                assoc_grid_element = self.get_data(time, item_id, "grid_element")[0]
            self._check_grid_element_and_id(assoc_grid_element, assoc_element_id)
            if assoc_element_id >= self._grid[assoc_grid_element].size:
                raise ValueError(
                    "The location "
                    + assoc_grid_element
                    + " "
                    + str(assoc_element_id)
                    + " does not exist on this grid"
                )

        if time is None:
            self._dataset[data_variable].values[item_id] = new_value
        else:
            try:
                len(time)
            except TypeError as exc:
                raise TypeError("time must be a list or a 1-d array") from exc
            try:
                # check that time coordinate already exists
                time_index = np.where(self._dataset.time.values == time)[0][0]
            except IndexError as exc:
                raise IndexError(
                    "The time you passed is not currently"
                    " in the DataRecord, you must change the value"
                    " you pass or first create the new time "
                    " coordinate using the add_record method"
                ) from exc

            if item_id is None:
                self._dataset[data_variable].values[time_index] = new_value
            else:
                try:
                    len(item_id)
                except TypeError as exc:
                    raise TypeError("item_id must be a list or a 1-d array") from exc
                try:
                    self._dataset["item_id"]
                    self._dataset[data_variable].values[item_id, time_index] = new_value
                except KeyError as exc:
                    raise KeyError("This DataRecord does not hold items") from exc

    def calc_aggregate_value(
        self,
        func,
        data_variable,
        at="node",
        filter_array=None,
        fill_value=np.nan,
        args=(),
        **kwargs,
    ):
        """Apply a function to a variable aggregated at grid elements.

        Parameters
        ----------
        func : function
            Function to apply to be aggregated.
        data_variable : str
            Name of variable on which to apply the function.
        at : str, optional
            Name of grid element at which to apply the function.
            Default is "node".
        filter_array: boolean array with dimensions matching that of the
            DataRecord (optional)
            Array to filter the DataRecord before aggregation.
        fill_value: float
            Fill value for array. Default is np.nan.
        args : tuple (optional)
            Additional positional arguments to pass to the function.
        **kwargs : key value pairs (optional)
            Additional keyword arguments to pass to func.

        Returns
        -------
        out : ndarray
            Array of size number-of-grid_elements (grid_elements is the group
            passed as 'at' argument).

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.data_record import DataRecord
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 3))
        >>> element_id = [0, 0, 0, 0, 1, 2, 3, 4, 5, 9999]
        >>> volumes = [4, 5, 1, 2, 3, 4, 5, 6, 7, 1234]
        >>> ages = [10, 11, 12, 13, 14, 15, 16, 8, 10, 3456]
        >>> grid_element = "node"
        >>> data = {"ages": ages, "volumes": volumes}
        >>> dr = DataRecord(
        ...     grid,
        ...     dummy_elements={"node": [9999]},
        ...     items={"grid_element": "node", "element_id": np.array(element_id)},
        ...     data_vars={
        ...         "ages": (["item_id"], np.array(ages)),
        ...         "volumes": (["item_id"], np.array(volumes)),
        ...     },
        ... )
        >>> s = dr.calc_aggregate_value(func=xr.Dataset.sum, data_variable="ages")
        >>> s
        array([46., 14., 15., 16.,  8., 10., nan, nan, nan])
        >>> len(s) == grid.number_of_nodes
        True

        If you want to first filter the DataRecord and then aggregate, first
        create a filter array with dimensions matching that of the DataRecord
        and has `True` for entries that should be retained and False for
        entries that should be ignored.

        For example, if we wanted to aggregate volume for items with an age
        greater than 10 we would to the following:

        >>> f = dr.dataset["ages"] > 10.0
        >>> v_f = dr.calc_aggregate_value(
        ...     func=xr.Dataset.sum, data_variable="volumes", filter_array=f
        ... )
        >>> v_f
        array([ 8.,  3.,  4.,  5., nan, nan, nan, nan, nan])

        If we wanted the value for elements with no volume to be zero instead
        of np.nan we could use the keyword argument ``fill_value``.

        >>> f = dr.dataset["ages"] > 10.0
        >>> v_f = dr.calc_aggregate_value(
        ...     func=xr.Dataset.sum,
        ...     data_variable="volumes",
        ...     filter_array=f,
        ...     fill_value=0.0,
        ... )
        >>> v_f
        array([8., 3., 4., 5., 0., 0., 0., 0., 0.])

        An array of ``fill_value`` is returned when ``filter_array`` is all
        ``False`` (np.nan is the default value).

        >>> f = dr.dataset["ages"] > 4000.0
        >>> v_f = dr.calc_aggregate_value(
        ...     func=xr.Dataset.sum, data_variable="volumes", filter_array=f
        ... )
        >>> v_f
        array([nan, nan, nan, nan, nan, nan, nan, nan, nan])

        Other values can be specified for ``fill_value``.

        >>> f = dr.dataset["ages"] > 4000.0
        >>> v_f = dr.calc_aggregate_value(
        ...     func=xr.Dataset.sum,
        ...     data_variable="volumes",
        ...     filter_array=f,
        ...     fill_value=0.0,
        ... )
        >>> v_f
        array([0., 0., 0., 0., 0., 0., 0., 0., 0.])
        """
        filter_at = self._dataset["grid_element"] == at

        filter_valid_element = (self._dataset["element_id"] >= 0) * (
            self._dataset["element_id"] < self._grid[at].size
        )

        if filter_array is None:
            my_filter = filter_at * filter_valid_element
        else:
            my_filter = filter_at * filter_valid_element * filter_array

        if np.any(my_filter):
            # Filter DataRecord with my_filter and groupby element_id:
            filtered = self._dataset.where(my_filter).groupby("element_id")

            # Calculate values
            vals = filtered.map(func, *args, **kwargs)  # .reduce

            # Create a nan array that we will fill with the results of the sum
            # this should be the size of the number of elements, even if there are
            # no items living at some grid elements.
            out = fill_value * np.ones(self._grid[at].size)

            # put the values of the specified variable into the correct location
            # of the out array.
            out[vals.element_id.values.astype(int)] = vals[data_variable]

            return out
        else:
            return np.repeat(fill_value, self._grid[at].size)

    def ffill_grid_element_and_id(self):
        """Fill NaN values of the fields 'grid_element' and 'element_id'.

        Fields are filled by propagating values forward in time.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> from landlab.data_record import DataRecord
        >>> grid = RasterModelGrid((3, 3))

        Example of a DataRecord with dimensions time and item_id:

        >>> my_items3 = {
        ...     "grid_element": np.array([["node"], ["link"]]),
        ...     "element_id": np.array([[1], [3]]),
        ... }

        Note that both arrays have 2 dimensions as they vary along dimensions
        'time' and 'item_id'.

        >>> dr3 = DataRecord(grid, time=[0.0], items=my_items3)

        Records relating to pre-existing items can be added to the DataRecord
        using the method 'add_record':

        >>> dr3.add_record(
        ...     time=[2.0, 3.0],
        ...     new_record={"mean_elevation": (["time"], np.array([200.0, 250.0]))},
        ... )

        Adding this data record created two new time coordinates. The
        grid_element and element_id of the items has been filled with 'nan'
        for these time coordinates.

        >>> dr3.dataset["grid_element"].values
        array([['node', nan, nan],
               ['link', nan, nan]], dtype=object)
        >>> dr3.dataset["element_id"].values
        array([[ 1., nan, nan],
               [ 3., nan, nan]])

        To fill these values with the last valid value, use the method
        ffill_grid_element_and_id:

        >>> dr3.ffill_grid_element_and_id()
        >>> dr3.dataset["grid_element"].values
        array([['node', 'node', 'node'],
               ['link', 'link', 'link']], dtype=object)
        >>> dr3.dataset["element_id"].values
        array([[1., 1., 1.],
               [3., 3., 3.]])

        In some applications, there may be no prior valid value. Under these
        circumstances, those values will stay as NaN. That is, this only
        forward fills, and does not backfill.

        >>> my_items3 = {
        ...     "grid_element": np.array([["node"], ["link"]]),
        ...     "element_id": np.array([[1], [3]]),
        ... }
        >>> dr3 = DataRecord(grid, time=[0.0], items=my_items3)
        >>> dr3.dataset["element_id"].values
        array([[1], [3]])
        >>> dr3.dataset["grid_element"].values
        array([['node'],
               ['link']],
              dtype='<U4')

        Next add some new items at a new time.

        >>> dr3.add_item(
        ...     time=[1.0],
        ...     new_item={
        ...         "grid_element": np.array([["node"], ["node"]]),
        ...         "element_id": np.array([[4], [4]]),
        ...     },
        ...     new_item_spec={"size": (["item_id", "time"], [[10], [5]])},
        ... )

        Two items have been added at a new timestep 1.0:

        >>> dr3.number_of_items
        4
        >>> dr3.time_coordinates
        [0.0, 1.0]
        >>> dr3.dataset["element_id"].values
        array([[ 1., nan],
               [ 3., nan],
               [nan,  4.],
               [nan,  4.]])
        >>> dr3.dataset["grid_element"].values
        array([['node', nan],
               ['link', nan],
               [nan, 'node'],
               [nan, 'node']], dtype=object)

        We expect that the NaN's to the left of the 4.s will stay NaN. And they
        do.

        >>> dr3.ffill_grid_element_and_id()
        >>> dr3.dataset["element_id"].values
        array([[ 1.,  1.],
               [ 3.,  3.],
               [nan,  4.],
               [nan,  4.]])
        >>> dr3.dataset["grid_element"].values
        array([['node', 'node'],
               ['link', 'link'],
               [nan, 'node'],
               [nan, 'node']], dtype=object)

        Finally, if we add a new time, we see that we need to fill in the
        full time column.

        >>> dr3.add_record(time=[2])
        >>> dr3.dataset["element_id"].values
        array([[ 1.,  1., nan],
               [ 3.,  3., nan],
               [nan,  4., nan],
               [nan,  4., nan]])
        >>> dr3.dataset["grid_element"].values
        array([['node', 'node', nan],
               ['link', 'link', nan],
               [nan, 'node', nan],
               [nan, 'node', nan]], dtype=object)

        And that forward filling fills everything as expected.

        >>> dr3.ffill_grid_element_and_id()
        >>> dr3.dataset["element_id"].values
        array([[ 1.,  1.,  1.],
               [ 3.,  3.,  3.],
               [nan,  4.,  4.],
               [nan,  4.,  4.]])

        >>> dr3.dataset["grid_element"].values
        array([['node', 'node', 'node'],
               ['link', 'link', 'link'],
               [nan, 'node', 'node'],
               [nan, 'node', 'node']], dtype=object)
        """

        ei = self._dataset["element_id"].values

        for i in range(ei.shape[0]):
            for j in range(1, ei.shape[1]):
                if np.isnan(ei[i, j]):
                    ei[i, j] = ei[i, j - 1]

        self._dataset["element_id"] = (["item_id", "time"], ei)

        ge = self._dataset["grid_element"].values
        for i in range(ge.shape[0]):
            for j in range(1, ge.shape[1]):
                if ge[i, j] not in self._permitted_locations:
                    ge[i, j] = ge[i, j - 1]
        self._dataset["grid_element"] = (["item_id", "time"], ge)

    @property
    def dataset(self):
        """The xarray Dataset that serves as the core datastructure."""
        return self._dataset

    @property
    def variable_names(self):
        """Return the name(s) of the data variable(s) in the record as a
        list."""
        _keys = []
        for key in self._dataset.to_dataframe().keys():
            _keys.append(key)
        return _keys

    @property
    def number_of_items(self):
        """Return the number of items in the DataRecord."""
        return len(self._dataset.item_id)

    @property
    def item_coordinates(self):
        """Return a list of the item_id coordinates in the DataRecord."""
        return self._dataset.item_id.values.tolist()

    @property
    def number_of_timesteps(self):
        """Return the number of time steps in the DataRecord."""
        return len(self._dataset.time)

    @property
    def time_coordinates(self):
        """Return a list of the time coordinates in the DataRecord."""
        return self._dataset.time.values.tolist()

    @property
    def earliest_time(self):
        """Return the earliest time coordinate in the DataRecord."""
        return min(self._dataset.time.values)

    @property
    def latest_time(self):
        """Return the latest time coordinate in the DataRecord."""
        return max(self._dataset.time.values)

    @property
    def prior_time(self):
        """Return the penultimate time coordinate in the DataRecord."""
        if self.number_of_timesteps < 2:
            return np.nan
        else:
            return sorted(self.time_coordinates)[-2]



================================================
File: src/landlab/field/__init__.py
================================================
from .errors import FieldError
from .errors import GroupError
from .errors import GroupSizeError
from .graph_field import GraphFields

__all__ = [
    "FieldError",
    "GroupError",
    "GroupSizeError",
    "GraphFields",
]



================================================
File: src/landlab/field/errors.py
================================================
class Error(Exception):
    """Base class for errors in this module."""

    pass


class FieldError(Error, KeyError):
    """Raise this error for a missing field name."""

    def __init__(self, field):
        self._field = field

    def __str__(self):
        return self._field


class GroupError(Error, KeyError):
    """Raise this error for a missing group name."""

    def __init__(self, group):
        self._group = group

    def __str__(self):
        return self._group


class GroupSizeError(Error, KeyError):
    """Raise this error if a group has changed sizes."""

    def __init__(self, group, old_size, new_size):
        self._group = group
        self._old_size = old_size
        self._new_size = new_size

    def __str__(self):
        return (
            "number of {group} elements has changed. "
            "(was = {was}, now={now})".format(
                group=self._group, was=self._old_size, now=self._new_size
            )
        )



================================================
File: src/landlab/field/graph_field.py
================================================
"""Define collections of fields that are attached to a *Landlab*
:class:`~landlab.graph.graph.Graph`.
"""

import inspect
import warnings

import numpy as np
import xarray as xr

from landlab.field.errors import FieldError
from landlab.field.errors import GroupError


def reshape_for_storage(array, field_size=None):
    """Reshape an array to be stored as a field.

    For reshaping rules, see :func:`~.shape_for_storage`.

    Parameters
    ----------
    array : numpy.ndarray
        The array to be stored.
    field_size : int, optional
        The size of the field.

    Returns
    -------
    ndarray
        The (possibly) reshaped array.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.field.graph_field import reshape_for_storage

    The shape will be such that the first dimension in the field size.

    >>> data = np.arange(6)
    >>> reshape_for_storage(data, 3)
    array([[0, 1],
           [2, 3],
           [4, 5]])
    >>> reshape_for_storage(data, 2)
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> reshape_for_storage(data, 6)
    array([0, 1, 2, 3, 4, 5])

    If the array is already the correct shape, just return that array.

    >>> data = np.arange(6).reshape((2, 3))
    >>> reshape_for_storage(data, 2) is data
    True

    :meta private:
    """
    shape = shape_for_storage(array, field_size)
    if shape == array.shape or array.ndim == 0:
        return array
    else:
        return array.reshape(shape)


def shape_for_storage(array, field_size=None):
    """Return the shape an array will be stored as.

    :meta private:

    Parameters
    ----------
    array : numpy.ndarray
        The array to be stored.
    field_size : int, optional
        The size of the field.

    Returns
    -------
    tuple of int
        The shape the array will be stored as.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.field.graph_field import shape_for_storage

    The shape will be such that the first dimension in the field size.

    >>> data = np.arange(6)
    >>> shape_for_storage(data, 3) == (3, 2)
    True
    >>> shape_for_storage(data, 2) == (2, 3)
    True
    >>> shape_for_storage(data, 6) == (6,)
    True

    If a field size is not given, the array will be stored as a
    flattened array.

    >>> shape_for_storage(data) == (6,)
    True
    >>> data = np.arange(6).reshape((3, 2))
    >>> shape_for_storage(data) == (6,)
    True

    For field sizes of 1, the array is always flattened.

    >>> shape_for_storage(data, 1) == (1, 6)
    True

    For scalar arrays, the field size must be 1.

    >>> data = np.array(1.0)
    >>> shape_for_storage(data) == (1,)
    True
    >>> shape_for_storage(data, field_size=1) == (1,)
    True

    If the array cannot be shaped into a storage shape, a ``ValueError``
    is raised.

    >>> data = np.array(1.0)
    >>> shape_for_storage(data, field_size=4)
    Traceback (most recent call last):
    ...
    ValueError: unable to reshape array to field size
    >>> data = np.arange(6.0)
    >>> shape_for_storage(data, field_size=4)
    Traceback (most recent call last):
    ...
    ValueError: unable to reshape array to field size
    """
    if field_size is None:
        field_size = array.size

    if array.size % field_size != 0:
        raise ValueError(
            "unable to reshape array to field size ({} != {})".format(
                array.size, field_size
            )
        )

    if field_size == array.size:
        shape = (array.size,)
    else:
        shape = (field_size, array.size // field_size)

    return shape


class FieldDataset(dict):
    """Wrap an xarray.Dataset as a landlab field.

    This is a light wrapping of xarray.Dataset. The main differences
    are that a `FieldDataset` can be created with a size but not
    allocate any memory for data arrays until an array is actually
    needed. The setitem method is also overriden so that when arrays
    are added they are stored reshaped in the landlab style. That
    is, shaped as `(n_elements, values_per_element)`.

    :meta private:

    Examples
    --------
    >>> from landlab.field.graph_field import FieldDataset

    >>> ds = FieldDataset("node")
    >>> ds.size is None
    True
    >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0, 1.0])
    >>> ds["air_temperature"]
    array([1., 1., 1., 1.])
    >>> ds.size
    4
    >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0])
    Traceback (most recent call last):
    ValueError: unable to reshape array to field size (3 != 4)

    >>> ds = FieldDataset("node", fixed_size=False)
    >>> ds.size is None
    True
    >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0, 1.0])
    >>> ds.size
    4
    >>> ds.set_value("air_temperature", [0.0, 0.0])
    >>> ds.size
    2
    >>> ds["air_temperature"]
    array([0., 0.])
    """

    def __init__(self, name, size=None, fixed_size=True):
        """Create a container to hold a collection of *Landlab* fields.

        Parameters
        ----------
        name : str
            The name of the group that identifies the dataset of fields.
        size : int, optional
            The size of fields that will be held within the dataset.
            If not provided, the size will be set later.
        fixed_size : bool, optional
            The size of fields held within the dataset cannot change.
        """
        self._name = name
        self._size = None
        self._fixed_size = bool(fixed_size)
        self._ds = xr.Dataset()
        self._units = {}

        self.size = size

        super().__init__()

    @property
    def size(self):
        """Size of the field dataset as number of elements.

        Examples
        --------
        >>> from landlab.field.graph_field import FieldDataset

        >>> ds = FieldDataset("grid", size=1)
        >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0])
        >>> ds.set_value("ground_temperature", [0.0, 0.0])
        >>> ds["ground_temperature"]
        array([[0.,  0.]])

        >>> ds = FieldDataset("grid", size=1)
        >>> ds.set_value("air_temperature", 0.1)
        >>> ds["air_temperature"]
        array(0.1)
        """
        return self._size

    @size.setter
    def size(self, size):
        if self._size != size:
            if self._size is not None and self.fixed_size:
                raise ValueError(
                    "size has already been set ({size}) and fixed_size is True".format(
                        size=self._size
                    )
                )
            elif not isinstance(size, int) or size < 0:
                raise ValueError(f"size must be a positive integer or None ({size})")
            self._size = size

    @property
    def fixed_size(self):
        """Flag that indicates if arrays added to the dataset must be of a fixed size.

        Examples
        --------
        >>> from landlab.field.graph_field import FieldDataset

        >>> ds = FieldDataset("node", fixed_size=False)
        >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0, 1.0])
        >>> ds.set_value("air_temperature", [0.0, 0.0])
        >>> ds["air_temperature"]
        array([0.,  0.])

        >>> ds.fixed_size = True
        >>> ds.size
        2
        >>> ds.set_value("air_temperature", [1.0, 1.0, 1.0])
        Traceback (most recent call last):
        ValueError: unable to reshape array to field size (4 != 2)
        """
        return self._fixed_size

    @fixed_size.setter
    def fixed_size(self, fixed_size):
        self._fixed_size = bool(fixed_size)
        if self._fixed_size:
            self.size = self._ds.sizes[self._name]

    @property
    def units(self):
        """Return units for each of the fields of the dataset."""
        return self._units

    def set_units(self, name, new_units):
        """Assign units to a field.

        Parameters
        ----------
        name : str
            The name of the field.
        new_units : str
            The new units of the field.
        """
        self._units[name] = self._ds[name].attrs["units"] = new_units

    @property
    def dataset(self):
        """Return the dataset as an :class:`xarray.Dataset`."""
        return self._ds

    def keys(self):
        """Return the name of the fields held in the dataset."""
        return list(self._ds.variables)

    def set_value(self, name, value_array, attrs=None):
        """Assign values to a field.

        Parameters
        ----------
        name : str
            Name of the field in the dataset.
        value_array : numpy.ndarray
            Array of values to assign to the field.
        attrs : dict, optional
            A `dict` holding attributes to save with the field.
        """
        attrs = attrs or {}
        attrs.setdefault("units", "?")

        value_array = np.asarray(value_array)

        if name in self._ds and self._ds[name].values is value_array:
            self._ds[name].values.shape = shape_for_storage(value_array, self.size)
            return

        if self.fixed_size:
            value_array = reshape_for_storage(value_array, self.size)
        else:
            value_array = reshape_for_storage(value_array, None)

        if value_array.ndim > 0:
            self.size = value_array.shape[0]
        else:
            self.size = value_array.size

        if value_array.ndim == 0:
            dims = ()
        elif value_array.ndim == 1:
            dims = (self._name,)
        else:
            dims = (self._name, name + "_per_" + self._name)

        if name in self._ds:
            self._ds = self._ds.drop_vars(name)

        self._ds.update({name: xr.DataArray(value_array, dims=dims, attrs=attrs)})
        self._units[name] = attrs["units"]

    def pop(self, name):
        """Remove a field from the dataset.

        Parameters
        ----------
        name : str
            The name of the field to remove.

        Returns
        -------
        numpy.ndarray
            The values of the field that was removed.
        """
        array = self._ds[name].values
        self._ds = self._ds.drop_vars(name)
        return array

    def __getitem__(self, name):
        """Get a field's values by name."""
        if isinstance(name, str):
            try:
                return self._ds[name].values
            except KeyError as exc:
                raise FieldError(name) from exc
        else:
            raise TypeError("field name not a string")

    def __setitem__(self, name, value_array):
        """Assign values to a field by name."""
        self.set_value(name, value_array)

    def __contains__(self, name):
        """Return if the dataset contains a named field.

        Parameters
        ----------
        name : str
            A field name.

        Returns
        -------
        bool
            `True` if the dataset contains the field, otherwise `False`.
        """
        return name in self._ds

    def __str__(self):
        """Return a human-readable string of the dataset."""
        return str(self._ds)

    def __repr__(self):
        """Return a string representation of the dataset."""
        return "FieldDataset({name}, size={size}, fixed_size={fixed_size})".format(
            name=repr(self._name),
            size=repr(self.size),
            fixed_size=repr(self.fixed_size),
        )

    def __len__(self):
        """Return the number of fields held in the dataset."""
        return len(self._ds.variables)

    def __iter__(self):
        """Iterate through the fields in the dataset."""
        return iter(self._ds.variables)


class GraphFields:
    """Collection of grouped data-fields.

    The :class:`GraphFields` class holds a set of data fields that are
    separated into *groups*. A typical use for this class would be to define
    the groups as being locations on a grid where the values are defined.
    For instance, the groups could be *node*, *cell*, *link*, and *face*.

    Examples
    --------
    Create two groups of data fields defined at *node* and *cell*. Each set can
    have a different number of values.

    >>> from landlab.field import GraphFields
    >>> fields = GraphFields()
    >>> fields.new_field_location("node", 12)
    >>> fields.new_field_location("cell", 2)

    Create some new value arrays for each of the data fields.

    >>> fields.ones("node")
    array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
    >>> fields.zeros("cell")
    array([0., 0.])

    Create new value arrays and add them to the data fields. Because the data
    fields are in different groups (node and cell), they can have the same
    name.

    >>> fields.add_ones("topographic__elevation", at="node")
    array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
    >>> fields.at_node["topographic__elevation"]
    array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])

    >>> fields.add_ones("topographic__elevation", at="cell")
    array([1., 1.])
    >>> fields.at_cell["topographic__elevation"]
    array([1., 1.])

    Each group acts as a :class:`dict` so, for instance, to get the variables names
    in a group use the :meth:`keys` method,

    >>> list(fields.at_cell.keys())
    ['topographic__elevation']

    If the size of the new field location is ``None``, the field will be
    unsized. This means that fields added to this location can be of any
    size.

    >>> fields = GraphFields()
    >>> fields.new_field_location("grid", None)
    >>> fields.at_grid["g"] = 9.81
    >>> fields.at_grid["g"]
    array(9.81)
    >>> fields.at_grid["w"] = (3.0, 4.0)
    >>> fields.at_grid["w"]
    array([3., 4.])

    The dimensions of groups can also be specified when the object is
    instantiated. In this case, group sizes are specified as a dictionary
    with keys being group names and values group sizes.

    >>> fields = GraphFields({"node": 6, "grid": None})
    >>> fields.at_grid["g"] = 9.81
    >>> fields.at_node["x"] = [0, 1, 2, 3, 4, 5]
    >>> fields.at_grid["g"]
    array(9.81)
    >>> fields.at_node["x"]
    array([0, 1, 2, 3, 4, 5])
    """

    def __init__(self, *args, **kwds):
        """Create a new collection of field groups."""
        try:
            dims = args[0]
        except IndexError:
            dims = {}

        self._groups = set()
        for loc in dims:
            self.new_field_location(loc, dims[loc])

        self.default_group = kwds.get("default_group", None)

    def __getitem__(self, name):
        """Get the collection of fields from the named group."""
        try:
            return getattr(self, "at_" + name)
        except AttributeError as exc:
            raise GroupError(name) from exc

    @property
    def default_group(self):
        """Return the name of the group into which fields are put by default."""
        return self._default_group

    @default_group.setter
    def default_group(self, loc):
        if self.has_group(loc) or loc is None:
            self._default_group = loc
        else:
            groups = ", ".join([repr(name) for name in sorted(self._groups)])
            raise ValueError(f"{loc!r}: Group does not exists. Not one of {groups}.")

    def new_field_location(self, loc, size=None):
        """Add a new quantity to a field.

        Create an empty group into which new fields can be added. The new group
        is created but no memory allocated yet. The dictionary of the new group
        can be through a new *at_* attribute of the class instance.

        Parameters
        ----------
        loc: str
            Name of the new group to add to the field.
        size: int, optional
            Number of elements in the new quantity. If not provided, the
            size is set to be the size of the first field added to the group.

        Raises
        ------
        ValueError
            If the field already contains the group.

        Examples
        --------
        Create a collection of fields and add two groups, *node* and *cell*,
        to it.

        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 12)
        >>> fields.new_field_location("cell", 2)

        The group names in the collection are retrieved with the *groups*
        attribute as a :class:`set`.

        >>> names = list(fields.groups)
        >>> names.sort()
        >>> names
        ['cell', 'node']

        Access the new (empty) groups with the *at_* attributes.

        >>> fields.at_cell
        FieldDataset('cell', size=2, fixed_size=True)
        >>> fields.at_node
        FieldDataset('node', size=12, fixed_size=True)

        >>> fields.new_field_location("core_node")
        >>> fields.at_core_node.size is None
        True
        >>> fields.at_core_node["air__temperature"] = [0, 1]
        >>> fields.at_core_node.size
        2

        :meta landlab: field-add
        """
        dataset_name = "at_" + loc
        if loc not in self._groups:
            setattr(
                self, dataset_name, FieldDataset(loc, size, fixed_size=size is not None)
            )
            self._groups.add(loc)
        else:
            raise ValueError(f"{loc!r} location already exists")

    @property
    def groups(self):
        """List of group names.

        Returns
        -------
        set
            Names of field groupings.
        """
        return self._groups

    def has_group(self, name):
        """Check if a group exists.

        Parameters
        ----------
        name: str
            Name of the group.

        Returns
        -------
        bool
            ``True`` if the field contains *group*, otherwise ``False``.

        Examples
        --------
        Check if the field has the groups named *node* or *cell*.

        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 12)
        >>> fields.has_group("node")
        True
        >>> fields.has_group("cell")
        False

        :meta landlab: info-field
        """
        return name in self._groups

    def has_field(self, *args, **kwds):
        """has_field(field, at=None)

        Check if a field is in a group.

        Parameters
        ----------
        field: str
            Name of the field.
        at: str, optional
            Name of the group.

        Returns
        -------
        bool
            ``True`` if the group contains the field, otherwise ``False``.

        Examples
        --------
        Check if the field named ``topographic__elevation`` is contained
        in a group.

        >>> from landlab.field import GraphFields

        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 12)
        >>> _ = fields.add_ones("topographic__elevation", at="node")
        >>> fields.has_field("topographic__elevation", at="node")
        True
        >>> fields.has_field("topographic__elevation", at="cell")
        False

        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 12)
        >>> _ = fields.add_ones("topographic__elevation", at="node")
        >>> fields.has_field("node", "topographic__elevation")
        True
        >>> fields.has_field("cell", "topographic__elevation")
        False

        :meta landlab: info-field
        """
        kwds.setdefault("at", self.default_group)
        args, group = _parse_args_and_location(1, *args, **kwds)
        field = args[0]

        try:
            return field in self[group]
        except KeyError:
            return False

    def keys(self, group):
        """Return the field names in a group.

        Parameters
        ----------
        group : str
            Group name.

        Returns
        -------
        list
            Names of fields held in the given group.

        Examples
        --------
        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 4)
        >>> list(fields.keys("node"))
        []
        >>> _ = fields.add_empty("topographic__elevation", at="node")
        >>> list(fields.keys("node"))
        ['topographic__elevation']

        :meta landlab: info-field
        """
        return self[group].keys()

    def size(self, group):
        """Return the size of the arrays stored in a group.

        Parameters
        ----------
        group : str
            Group name.

        Returns
        -------
        int
            Array size.

        Examples
        --------
        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 4)
        >>> fields.size("node")
        4

        :meta landlab: info-grid, info-field
        """
        return self[group].size

    def field_values(self, *args, **kwds):
        """field_values(field, at=None)

        Return the values of a field.

        Given a *group* and a *field*, return a reference to the associated
        data array.

        Parameters
        ----------
        field: str
            Name of the field within *group*.
        at: str, optional
            Name of the group.

        Returns
        -------
        array
            The values of the field.

        Raises
        ------
        landlab.field.errors.GroupError
            If *group* does not exist
        landlab.field.errors.FieldError
            If *field* does not exist

        Examples
        --------
        Create a group of fields called *node*.

        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 4)

        Add a field, initialized to ones, called *topographic__elevation*
        to the *node* group. The *field_values* method returns a reference
        to the field's data.

        >>> _ = fields.add_ones("topographic__elevation", at="node")
        >>> fields.field_values("topographic__elevation", at="node")
        array([1., 1., 1., 1.])

        Raise FieldError if *field* does not exist in *group*.

        >>> fields.field_values("planet_surface__temperature", at="node")
        Traceback (most recent call last):
        ...
        FieldError: planet_surface__temperature

        If *group* does not exists, raise :class:`~landlab.field.errors.GroupError`.

        >>> fields.field_values("topographic__elevation", at="cell")
        Traceback (most recent call last):
        ...
        GroupError: cell

        :meta landlab: field-io
        """
        kwds.setdefault("at", self.default_group)
        args, group = _parse_args_and_location(1, *args, **kwds)
        field = args[0]

        try:
            fields = self[group]
        except KeyError as exc:
            groups = ", ".join([repr(g) for g in sorted(self._groups)])
            raise GroupError(f"{group!r}: Not one of {groups}.") from exc
        try:
            return fields[field]
        except KeyError as exc:
            raise FieldError(f"{field!r}") from exc

    def return_array_or_field_values(self, *args, **kwds):
        """return_array_or_field_values(field, at=None)

        Return field given a field name, or array of with the correct shape.

        Given a *group* and a *field*, return a reference to the associated
        data array. *field* is either a string that is a field in the group
        or an array of the correct size.

        This function is meant to serve like the
        :class:`~landlab.utils.decorators.use_field_name_or_array` decorator for
        bound functions.

        Parameters
        ----------
        field: str or array
            Name of the field withing *group*.
        at: str, optional
            Name of the group.

        Returns
        -------
        numpy.ndarray
            The values of the field.

        Raises
        ------
        landlab.field.errors.GroupError
            If *group* does not exist
        landlab.field.errors.FieldError
            If *field* does not exist

        Examples
        --------
        Create a group of fields called *node*.

        >>> import numpy as np
        >>> from landlab.field import GraphFields
        >>> fields = GraphFields()
        >>> fields.new_field_location("node", 4)

        Add a field, initialized to ones, called *topographic__elevation*
        to the *node* group. The *field_values* method returns a reference
        to the field's data.

        >>> _ = fields.add_ones("topographic__elevation", at="node")
        >>> fields.field_values("topographic__elevation", at="node")
        array([1., 1., 1., 1.])

        Alternatively, if the second argument is an array, its size is
        checked and returned if correct.

        >>> vals = np.array([4.0, 5.0, 7.0, 3.0])
        >>> fields.return_array_or_field_values(vals, at="node")
        array([4., 5., 7., 3.])

        Raise FieldError if *field* does not exist in *group*.

        >>> fields.return_array_or_field_values("surface__temperature", at="node")
        Traceback (most recent call last):
        ...
        FieldError: surface__temperature

        If *group* does not exists, Raise GroupError.

        >>> fields.return_array_or_field_values("topographic__elevation", at="cell")
        Traceback (most recent call last):
        ...
        GroupError: cell

        And if the array of values provided is incorrect, raise a :class:`ValueError`.

        >>> vals = np.array([3.0, 2.0, 1.0])
        >>> fields.return_array_or_field_values(vals, at="node")
        Traceback (most recent call last):
        ...
        ValueError: Array has incorrect size.

        :meta landlab: field-io
        """
        kwds.setdefault("at", self.default_group)
        args, group = _parse_args_and_location(1, *args, **kwds)
        field = args[0]

        if isinstance(field, str):
            vals = self.field_values(field, at=group)
        else:
            vals = np.asarray(field)
            if vals.size != self[group].size:
                raise ValueError(
                    f"Incorrect array size. The array size of {vals.size} does not "
                    "match that of the group, {group!r}, which has a size of "
                    f"{self[group].size}."
                )
        return vals

    def field_units(self, *args, **kwds):
        """field_units(field, at=None)

        Get units for a field.

        Returns the unit string associated with the data array in *group* and
        *field*.

        Parameters
        ----------
        field: str
            Name of the field withing *group*.
        at: str, optional
            Name of the group.

        Returns
        -------
        str
            The units of the field.

        Raises
        ------
        KeyError
            If either *field* or *group* does not exist.


        :meta landlab: info-field
        """
        kwds.setdefault("at", self.default_group)
        args, group = _parse_args_and_location(1, *args, **kwds)
        field = args[0]

        return self[group]._ds[field].attrs["units"]

    def empty(self, *args, **kwds):
        """Uninitialized array whose size is that of the field.

        Return a new array of the data field size, without initializing
        entries. Keyword arguments are the same as that for the equivalent
        *numpy* function.

        Parameters
        ----------
        group : str
            Name of the group.

        See Also
        --------
        numpy.empty : See for a description of optional keywords.
        :meth:`~.ones` : Equivalent method that initializes the data to 1.
        :meth:`~.zeros` : Equivalent method that initializes the data to 0.

        Examples
        --------
        >>> from landlab.field import GraphFields
        >>> field = GraphFields()
        >>> field.new_field_location("node", 4)
        >>> field.empty("node")  # doctest: +SKIP
        array([  2.31584178e+077,  -2.68156175e+154,   9.88131292e-324,
        ... 2.78134232e-309]) # Uninitialized memory

        Note that a new field is *not* added to the collection of fields.

        >>> list(field.keys("node"))
        []

        :meta landlab: field-add
        """
        kwds.setdefault("at", kwds.pop("centering", "node"))
        args, group = _parse_args_and_location(0, *args, **kwds)
        kwds.pop("at")

        if group == "grid":
            raise ValueError(
                "ones is not supported for at='grid', if you "
                "want to create a field at the grid, use\n"
                "grid.at_grid['value_name']=value\n"
                "instead.\nAlternatively, if you want ones"
                "of the shape stored at_grid, use np.array(1)."
            )

        size = getattr(self, f"at_{group}").size
        if size is None:
            raise ValueError("{group!r}: Group is not yet sized.")

        return np.empty(size, **kwds)

    def ones(self, *args, **kwds):
        """Array, initialized to 1, whose size is that of the field.

        Return a new array of the data field size, filled with ones. Keyword
        arguments are the same as that for the equivalent *numpy* function.

        Parameters
        ----------
        group : str
            Name of the group.

        See Also
        --------
        numpy.ones : See for a description of optional keywords.
        :meth:`~.empty` : Equivalent method that does not initialize the new array.
        :meth:`~.zeros` : Equivalent method that initializes the data to 0.

        Examples
        --------
        >>> from landlab.field import GraphFields
        >>> field = GraphFields()
        >>> field.new_field_location("node", 4)
        >>> field.ones("node")
        array([1., 1., 1., 1.])
        >>> field.ones("node", dtype=int)
        array([1, 1, 1, 1])

        Note that a new field is *not* added to the collection of fields.

        >>> list(field.keys("node"))
        []

        :meta landlab: field-add
        """
        allocated = self.empty(*args, **kwds)
        allocated.fill(1)
        return allocated

    def zeros(self, *args, **kwds):
        """Array, initialized to 0, whose size is that of the field.

        Parameters
        ----------
        group : str
            Name of the group.

        Return a new array of the data field size, filled with zeros. Keyword
        arguments are the same as that for the equivalent *numpy* function.

        This method is not valid for the group *grid*.

        See Also
        --------
        numpy.zeros : See for a description of optional keywords.
        :meth:`~.empty` : Equivalent method that does not initialize the new array.
        :meth:`~.ones` : Equivalent method that initializes the data to 1.

        Examples
        --------
        >>> from landlab.field import GraphFields
        >>> field = GraphFields()
        >>> field.new_field_location("node", 4)
        >>> field.zeros("node")
        array([0., 0., 0., 0.])

        Note that a new field is *not* added to the collection of fields.

        >>> list(field.keys("node"))
        []

        :meta landlab: field-add
        """
        allocated = self.empty(*args, **kwds)
        allocated.fill(0)
        return allocated

    def add_field(self, *args, **kwds):
        """add_field(name, value_array, at='node', units='-', copy=False, clobber=False)

        Add an array of values to the field.

        Add an array of data values to a collection of fields and associate it
        with the key, *name*. Use the *copy* keyword to, optionally, add a
        copy of the provided array.

        In the case of adding to the collection *grid*, the added field is a
        *numpy* scalar rather than a *numpy* array.

        Parameters
        ----------
        name : str
            Name of the new field to add.
        value_array : numpy.array
            Array of values to add to the field.
        at : str, optional
            Grid location to store values. If not given, values are
            assumed to be on `node`.
        units : str, optional
            Optionally specify the units of the field.
        copy : bool, optional
            If True, add a *copy* of the array to the field. Otherwise save add
            a reference to the array.
        clobber : bool, optional
            Raise an exception if adding to an already existing field.

        Returns
        -------
        numpy.ndarray
            The data array added to the field. Depending on the *copy*
            keyword, this could be a copy of *value_array* or *value_array*
            itself.

        Raises
        ------
        ValueError
            If *value_array* has a size different from the field.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.field import GraphFields
        >>> field = GraphFields()
        >>> field.new_field_location("node", 4)
        >>> values = np.ones(4, dtype=int)
        >>> field.add_field("topographic__elevation", values, at="node")
        array([1, 1, 1, 1])

        A new field is added to the collection of fields. The saved value
        array is the same as the one initially created.

        >>> field.at_node["topographic__elevation"] is values
        True

        If you want to save a copy of the array, use the *copy* keyword. In
        addition, adding values to an existing field will remove the reference
        to the previously saved array. The *clobber=False* keyword changes this
        behavior to raise an exception in such a case.

        >>> field.add_field(
        ...     "topographic__elevation", values, at="node", copy=True, clobber=True
        ... )
        array([1, 1, 1, 1])
        >>> field.at_node["topographic__elevation"] is values
        False
        >>> field.add_field("topographic__elevation", values, at="node", clobber=False)
        Traceback (most recent call last):
        ...
        FieldError: topographic__elevation

        :meta landlab: field-add
        """
        kwds.setdefault("at", "node")
        args, at = _parse_args_and_location(2, *args, **kwds)
        name, value_array = args
        kwds.pop("at")

        units = kwds.get("units", "?")
        copy = kwds.get("copy", False)
        clobber = kwds.get("clobber", False)
        value_array = np.asarray(value_array)

        at = at or self.default_group
        if at is None:
            raise ValueError("no group specified")

        attrs = {"long_name": name, "units": units}

        if copy:
            value_array = value_array.copy()

        ds = getattr(self, "at_" + at)

        if not clobber and name in ds:
            raise FieldError(
                f"Unable to add the field, {name!r}, to the group, {at!r}, because a "
                "field with that name already exists in that group. "
                "Use `clobber=True` to replace the existing field. "
                f"For example, grid.add_field({name!r}, at={at!r}, clobber=True)"
            )

        dims = (at,)
        if value_array.ndim > 1:
            dims += (name + "_per_" + at,)
            value_array = value_array.reshape((value_array.shape[0], -1))

        ds.set_value(name, value_array, attrs=attrs)
        # ds[name] = value_array
        return ds[name]

    def delete_field(self, loc, name):
        """Erases an existing field.

        Parameters
        ----------
        loc : str
            Name of the group.
        name: str
            Name of the field.

        Raises
        ------
        KeyError
            If the named field does not exist.


        :meta landlab: field-add
        """
        try:
            ds = getattr(self, "at_" + loc)
        except AttributeError as exc:
            raise KeyError(loc) from exc
        ds._ds = ds._ds.drop_vars(name)

    def add_empty(self, *args, **kwds):
        """add_empty(name, at='node', units='-', clobber=False)

        Create and add an uninitialized array of values to the field.

        Create a new array of the data field size, without initializing
        entries, and add it to the field as *name*. The *units* keyword gives
        the units of the new fields as a string. Remaining keyword arguments
        are the same as that for the equivalent *numpy* function.

        This method is not valid for the group *grid*.

        Parameters
        ----------
        name : str
            Name of the new field to add.
        at : str, optional
            Grid location to store values. If not given, values are
            assumed to be on `node`.
        units : str, optional
            Optionally specify the units of the field.
        clobber : bool, optional
            Raise an exception if adding to an already existing field.

        Returns
        -------
        numpy.ndarray
            A reference to the newly-created array.

        See Also
        --------
        numpy.empty : See for a description of optional keywords.
        :meth:`~.empty` : Equivalent method that does not initialize the new array.
        :meth:`~.zeros` : Equivalent method that initializes the data to 0.


        :meta landlab: field-add
        """
        kwds.setdefault("at", "node")
        args, loc = _parse_args_and_location(1, *args, **kwds)
        name = args[0]
        kwds.pop("at")

        units = kwds.pop("units", "?")
        copy = kwds.pop("copy", False)
        clobber = kwds.pop("clobber", False)
        return self.add_field(
            name,
            self.empty(at=loc, **kwds),
            at=loc,
            units=units,
            copy=copy,
            clobber=clobber,
        )

    def add_ones(self, *args, **kwds):
        """add_ones(name, at='node', units='-', clobber=False)

        Create and add an array of values, initialized to 1, to the field.

        Create a new array of the data field size, filled with ones, and
        add it to the field as *name*. The *units* keyword gives the units of
        the new fields as a string. Remaining keyword arguments are the same
        as that for the equivalent *numpy* function.

        This method is not valid for the group *grid*.

        Parameters
        ----------
        name : str
            Name of the new field to add.
        at : str, optional
            Grid location to store values. If not given, values are
            assumed to be on `node`.
        units : str, optional
            Optionally specify the units of the field.
        clobber : bool, optional
            Raise an exception if adding to an already existing field.

        Returns
        -------
        numpy.ndarray
            A reference to the newly-created array.

        See Also
        --------
        numpy.ones : See for a description of optional keywords.
        :meth:`~.add_empty` : Equivalent method that does not initialize the new array.
        :meth:`~.add_zeros` : Equivalent method that initializes the data to 0.

        Examples
        --------
        Add a new, named field to a collection of fields.

        >>> from landlab.field import GraphFields
        >>> field = GraphFields()
        >>> field.new_field_location("node", 4)
        >>> field.add_ones("topographic__elevation", at="node")
        array([1., 1., 1., 1.])
        >>> list(field.keys("node"))
        ['topographic__elevation']
        >>> field["node"]["topographic__elevation"]
        array([1., 1., 1., 1.])
        >>> field.at_node["topographic__elevation"]
        array([1., 1., 1., 1.])

        :meta landlab: field-add
        """
        data = self.add_empty(*args, **kwds)
        data.fill(1)
        return data

    def add_zeros(self, *args, **kwds):
        """add_zeros(name, at='node', units='-', clobber=False)

        Create and add an array of values, initialized to 0, to the field.

        Create a new array of the data field size, filled with zeros, and
        add it to the field as *name*. The *units* keyword gives the units of
        the new fields as a string. Remaining keyword arguments are the same
        as that for the equivalent *numpy* function.

        :meta landlab: field-add

        Parameters
        ----------
        name : str
            Name of the new field to add.
        at : str, optional
            Grid location to store values. If not given, values are
            assumed to be on `node`.
        units : str, optional
            Optionally specify the units of the field.
        clobber : bool, optional
            Raise an exception if adding to an already existing field.

        Returns
        -------
        array :
            A reference to the newly-created array.

        See also
        --------
        numpy.zeros : See for a description of optional keywords.
        :meth:`~.GraphFields.add_empty` : Equivalent method that does not initialize
            the new array.
        :meth:`~.GraphFields.add_ones` : Equivalent method that initializes the data
            to 1.


        :meta landlab: field-add
        """
        data = self.add_empty(*args, **kwds)
        data.fill(0)
        return data

    def add_full(self, *args, **kwds):
        """Create and add an array of values, fill with `fill_value`.

        Parameters
        ----------
        name : str
            Name of the new field to add.
        fill_value : scalar
            Fill value.
        at : str, optional
            Grid location to store values. If not given, values are
            assumed to be on `node`.
        units : str, optional
            Optionally specify the units of the field.
        copy : bool, optional
            If True, add a *copy* of the array to the field. Otherwise save add
            a reference to the array.
        clobber : bool, optional
            Raise an exception if adding to an already existing field.

        Returns
        -------
        numpy.ndarray
            A reference to the newly-created array.


        :meta landlab: field-add
        """
        kwds.setdefault("at", "node")
        args, at = _parse_args_and_location(2, *args, **kwds)
        name, fill_value = args
        kwds.pop("at")

        data = self.add_empty(name, at=at, **kwds)
        data.fill(fill_value)
        return data


def _parse_args_and_location(n_args: int, *args, **kwds) -> tuple[str, str]:
    """Parse arguments for backward compatibility.

    Parameters
    ----------
    n_args : int
        The new number of expected arguments.
    *args : tuple
        The passed arguments.
    **kwds : dict
        The passed keyword arguments.

    Returns
    -------
    tuple of tuple, str
        The arguments as expect with the new signature followed by
        the location string.

    Examples
    --------
    >>> from landlab.field.graph_field import _parse_args_and_location
    >>> _parse_args_and_location(0, "node")
    ((), 'node')
    >>> _parse_args_and_location(1, "node", "z")
    (('z',), 'node')
    >>> _parse_args_and_location(2, "cell", "z", [1, 2, 3])
    (('z', [1, 2, 3]), 'cell')
    >>> _parse_args_and_location(2, "cell", "z", [1, 2, 3], at="node")
    (('z', [1, 2, 3]), 'cell')
    >>> _parse_args_and_location(2, "z", [1, 2, 3], at="node")
    (('z', [1, 2, 3]), 'node')
    """
    if len(args) == n_args:
        return args, kwds.get("at", None)
    elif len(args) == n_args + 1:
        caller_name = inspect.stack()[1].function
        sig = f"at={args[0]!r}"
        if n_args > 0:
            sig = ", ".join([f"arg{n}" for n in range(n_args)] + [sig])

        warnings.warn(
            f"Calling `{caller_name}` with the field location as the first argument"
            " is deprecated and will be removed in future versions. Instead, please use"
            " the `at` keyword to specify the location:"
            f" {caller_name}({sig}).",
            FutureWarning,
            stacklevel=3,
        )

        return args[1:], args[0]
    else:
        raise ValueError(f"number of arguments must be {n_args} or {n_args + 1}")



================================================
File: src/landlab/framework/__init__.py
================================================
"""The Landlab modeling framework."""



================================================
File: src/landlab/framework/component.py
================================================
#! /usr/bin/env python
"""Utility functions for loading components for The Landlab."""

import os

from landlab.framework.interfaces import BmiBase

_COMPONENT_PATH = [os.path.join(os.path.dirname(__file__), "..", "components")]

try:
    paths = os.environ["LANDLAB_PATH"].split(os.pathsep)
except KeyError:
    pass
else:
    _COMPONENT_PATH = paths + _COMPONENT_PATH


def iscomponent(value, cls):
    """Check if *value* is a component for The Landlab. *value* is a component
    if it implements the *cls* or it is an instance of *cls*.

    Returns ``True`` if *value* is a component, otherwise ``False``.
    """
    try:
        return (
            cls in value.__implements__
            or cls.__name__ in value.__implements__
            or isinstance(value, cls)
        )
    except AttributeError:
        return False


def load_components_from_dir(path, cls):
    """Look for components for Landlab in *path*.

    Identify components as being an instance of *cls*. Returns a
    dictionary of discovered component names as keys and component
    classes as values.
    """
    import imp
    import sys

    components = {}

    sys.path.insert(0, path)
    cwd = os.getcwd()

    os.chdir(path)
    for file_name in os.listdir("."):
        if os.path.isfile(file_name) and file_name.endswith(".py"):
            (mod_name, _) = os.path.splitext(file_name)
            mod = imp.load_module(mod_name, *imp.find_module(mod_name))
            for name, value in mod.__dict__.items():
                if iscomponent(value, cls):
                    components[name] = value

    os.chdir(cwd)
    sys.path.pop(0)

    return components


def load_components(cls, paths=None):
    """Load components from a series of directories.

    Components found earlier in the search path order override those
    discovered later. Use the *paths* keyword to specify a list of paths to
    search for components.

    .. seealso::

        :func:`load_components_from_dir`
    """
    if not paths:
        paths = _COMPONENT_PATH

    components = {}
    for path in paths[::-1]:
        components.update(load_components_from_dir(path, cls))
    return components


def load_landlab_components(paths=None):
    """Load components for The Landlab. These are classes that implement
    BmiBase. See :func:`load_components_from_dir` for the meaning of *paths*
    keyword.

    .. seealso::

        :func:`load_components_from_dir`
    """
    return load_components(BmiBase, paths=paths)



================================================
File: src/landlab/framework/decorators.py
================================================
#! /usr/bin/env python
"""Decorators for TheLandlab package."""
import re


def camel_case(text, sep=None):
    """Convert to camel case.

    Convert *text* to camel case. Use the *sep* keyword to specify the word
    separator. The default is to split on whitespace.

    >>> from landlab.framework.decorators import camel_case
    >>> camel_case("eric idle")
    'EricIdle'
    >>> camel_case("terry_gilliam", sep="_")
    'TerryGilliam'
    >>> camel_case("MONTY Python")
    'MONTYPython'
    >>> camel_case("GrahamChapman")
    'GrahamChapman'
    """
    return "".join([word[0].upper() + word[1:] for word in text.split(sep)])


def snake_case(text):
    """Convert camel case to snake case.

    Examples
    --------
    >>> from landlab.framework.decorators import snake_case
    >>> snake_case("EricIdle")
    'eric_idle'
    >>> snake_case("MONTYPython")
    'monty_python'
    """
    s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", text)
    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1).lower()



================================================
File: src/landlab/framework/interfaces.py
================================================
"""The Basic Modeling Interface."""


class Error(Exception):
    """Base class for BMI exceptions."""

    pass


class FatalError(Exception):
    """Raise this exception if an unrecoverable error was found."""

    pass


class BadVarNameError(Error):
    """Exception to indicate a bad input/output variable name."""

    def __init__(self, name):
        super().__init__()
        self.name = name

    def __str__(self):
        return self.name


class MissingModelAttributeError(Error):
    """Raise this exception if a component is missing a required attribute."""

    def __init__(self, attrib):
        super().__init__()
        self.attrib = attrib

    def __str__(self):
        return self.attrib


class TimeBoundsError(Error):
    """Raise this exception if a component updates beyond its time horizon."""

    pass


class BmiGridType(int):
    """Base type to indicate the type of a BMI model's grid.

    :code: Grid type code as an int
    :name: Name of the grid type as a string
    """

    def __new__(cls, code, name):
        obj = super().__new__(cls, code)
        obj.name = name
        return obj

    def __str__(self):
        return self.name

    def __repr__(self):
        return "BmiGridType(%d, %s)" % (self, self.name)


GRID_TYPE_UNKNOWN = BmiGridType(-1, "Unknown")
GRID_TYPE_NONE = BmiGridType(0, "No grid")
GRID_TYPE_UNIFORM = BmiGridType(1, "Uniform rectilinear")
GRID_TYPE_RECTILINEAR = BmiGridType(2, "Rectilinear")
GRID_TYPE_STRUCTURED = BmiGridType(3, "Structured")
GRID_TYPE_UNSTRUCTURED = BmiGridType(4, "Unstructured")


class BmiBase:
    """Definition of the Basic Modeling Interface."""

    def initialize(self, file_name):
        """Initialize model.

        :file_name: String of configuration file
        """
        pass

    def update(self, **kwds):
        """Update model by one time step."""
        pass

    def finalize(self):
        """Clean-up model."""
        pass

    def get_input_var_names(self):
        """Get names of input variables to the model as standard names.

        :returns: A list of input standard names as strings
        """
        pass

    def get_output_var_names(self):
        """Get names of output variables to the model as standard names.

        :returns: A list of output standard names as strings
        """
        pass

    def get_var_type(self, var_name):
        """Get type of an exchange item."""
        pass

    def get_var_units(self, var_name):
        """Get units of an exchange item."""
        pass

    def get_var_rank(self, var_name):
        """Rank of exchange item."""
        pass

    def get_time_step(self):
        """Model time step."""
        pass

    def get_start_time(self):
        """Model start time."""
        pass

    def get_current_time(self):
        """Current time of model."""
        pass

    def get_end_time(self):
        """Model stop time."""
        pass


class BmiExtendedBase:
    """An extension interface for a BMI."""

    def update_until(self, time):
        """Update model until some time.

        :time: Update duration
        """
        pass

    def run_model(self):
        """Initialize, run, and finalize a model."""
        pass


class BmiUnstructured:
    """BMI for a model that uses an unstructured grid."""

    def get_x(self, name):
        """Get x-coordinates of grid nodes."""
        pass

    def get_y(self, name):
        """Get y-coordinates of grid nodes."""
        pass

    def get_connectivity(self, name):
        """Get cell connectivity."""
        pass

    def get_offset(self, name):
        """Get cell offset."""
        pass


class BmiStructured:
    """BMI for a model that uses a structured grid."""

    def get_grid_shape(self, name):
        """Get shape of grid for variable, name.

        :name: Standard name
        """
        pass

    def get_x(self, name):
        """Get x-coordinates of grid nodes."""
        pass

    def get_y(self, name):
        """Get y-coordinates of grid nodes."""
        pass


class BmiRectilinear:
    """BMI for a model that uses a rectilinear grid."""

    def get_grid_shape(self, name):
        """Get shape of grid for variable, name.

        :name: Standard name
        """
        pass

    def get_columns(self, name):
        """Get coordinates of grid columns."""
        pass

    def get_rows(self, name):
        """Get coordinates of grid rows."""
        pass


class BmiUniformRectilinear:
    """BMI for a model that exposes a uniform rectilinear grid."""

    def get_grid_shape(self, name):
        """Get shape of grid for variable, name.

        :name: Standard name
        """
        pass

    def get_grid_spacing(self, name):
        """Get spacing of grid for variable, name.

        :name: Standard name
        """
        pass

    def get_grid_origin(self, name):
        """Get origin of grid for variable, name.

        :name: Standard name
        """
        pass


class BmiNoGrid:
    """BMI for a model that does not have a grid."""



================================================
File: src/landlab/graph/__init__.py
================================================
from landlab.graph.dual import DualGraph
from landlab.graph.framed_voronoi.dual_framed_voronoi import DualFramedVoronoiGraph
from landlab.graph.framed_voronoi.framed_voronoi import FramedVoronoiGraph
from landlab.graph.graph import Graph
from landlab.graph.graph import NetworkGraph
from landlab.graph.graph_convention import ConventionConverter
from landlab.graph.graph_convention import GraphConvention
from landlab.graph.hex.dual_hex import DualHexGraph
from landlab.graph.hex.hex import TriGraph
from landlab.graph.radial.dual_radial import DualRadialGraph
from landlab.graph.radial.radial import RadialGraph
from landlab.graph.structured_quad.dual_structured_quad import DualRectilinearGraph
from landlab.graph.structured_quad.dual_structured_quad import DualStructuredQuadGraph
from landlab.graph.structured_quad.dual_structured_quad import (
    DualUniformRectilinearGraph,
)
from landlab.graph.structured_quad.structured_quad import RectilinearGraph
from landlab.graph.structured_quad.structured_quad import StructuredQuadGraph
from landlab.graph.structured_quad.structured_quad import UniformRectilinearGraph
from landlab.graph.voronoi.dual_voronoi import DualVoronoiGraph
from landlab.graph.voronoi.voronoi import DelaunayGraph

__all__ = [
    "Graph",
    "NetworkGraph",
    "DualGraph",
    "StructuredQuadGraph",
    "RectilinearGraph",
    "UniformRectilinearGraph",
    "DualUniformRectilinearGraph",
    "DualRectilinearGraph",
    "DualStructuredQuadGraph",
    "DelaunayGraph",
    "DualVoronoiGraph",
    "TriGraph",
    "DualHexGraph",
    "RadialGraph",
    "DualRadialGraph",
    "FramedVoronoiGraph",
    "DualFramedVoronoiGraph",
    "ConventionConverter",
    "GraphConvention",
]



================================================
File: src/landlab/graph/dual.py
================================================
"""Define a graph of nodes-links-patches and its dual.

This class should not be used directly. Instead, it should be used as a
base class when defining other types of graphs.
"""

import inspect
from functools import cached_property

import numpy as np

from ..core.utils import as_id_array
from .graph import Graph
from .graph_convention import ConventionConverter
from .sort.sort import reverse_one_to_one


class DualGraphMeta(type):
    def __init__(cls, name, bases, dct):
        type.__init__(cls, name, bases, dct)

        converter = ConventionConverter("cfc")
        # for name, prop in inspect.getmembers(cls, inspect.isdatadescriptor):
        for name, prop in inspect.getmembers(
            cls, lambda o: inspect.isdatadescriptor(o) or inspect.ismethoddescriptor(o)
        ):
            new_name = converter.conform(name, "nlp")
            if hasattr(cls, new_name):
                continue

            fdoc = inspect.getdoc(prop)
            if fdoc:
                fdoc = inspect.cleandoc(
                    """{}

                    See Also
                    --------
                    :attr:`~{}`
                    """.format(
                        converter.conform(fdoc.splitlines()[0], "nlp"), name
                    )
                )

            setattr(
                cls,
                new_name,
                property(lambda x, name=name: getattr(x._dual, name), None, None, fdoc),
            )


class DualGraph(metaclass=DualGraphMeta):
    @property
    def dual(self):
        return self._dual

    @property
    def node_at_cell(self):
        return self.ds["node_at_cell"].values

    @property
    def nodes_at_face(self):
        return self.ds["nodes_at_face"].values

    @cached_property
    def cell_at_node(self):
        return reverse_one_to_one(self.node_at_cell, minlength=self.number_of_nodes)

    @cached_property
    def link_at_face(self):
        return self._create_link_at_face()

    def _create_link_at_face(self):
        link_at_nodes = {}
        for link, pair in enumerate(self.nodes_at_link):
            # pair.sort()
            link_at_nodes[tuple(np.sort(pair))] = link

        link_at_face = np.full((self.number_of_faces,), -1, dtype=int)
        # for face, pair in enumerate(self._nodes_at_face):
        for face, pair in enumerate(self.nodes_at_face):
            # pair.sort()
            link_at_face[face] = link_at_nodes[tuple(np.sort(pair))]
        self._link_at_face = link_at_face

        return self._link_at_face

    @cached_property
    def face_at_link(self):
        return reverse_one_to_one(self.link_at_face, minlength=self.number_of_links)

    def sort(self):
        from .sort.ext.remap_element import remap_graph_element

        sorted_nodes, sorted_links, sorted_patches = Graph.sort(self)
        sorted_corners, sorted_faces, sorted_cells = self.dual.sort()

        with self.thawed():
            self.node_at_cell[:] = self.node_at_cell[sorted_cells]
            self.nodes_at_face[:] = self.nodes_at_face[sorted_faces]

            remap_graph_element(
                as_id_array(self.node_at_cell), as_id_array(np.argsort(sorted_nodes))
            )
            remap_graph_element(
                as_id_array(self.nodes_at_face).reshape((-1,)),
                as_id_array(np.argsort(sorted_nodes)),
            )



================================================
File: src/landlab/graph/graph.py
================================================
"""Define a graph of nodes-links-patches.

Nodes and links are required. If no patches are provided, no patches will
be created.

Examples
--------

>>> from landlab.graph import NetworkGraph, Graph

>>> node_x, node_y = [0, 0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 2, 0, 1, 2, 0, 1, 2]
>>> graph = NetworkGraph((node_y, node_x), sort=True)
>>> graph.x_of_node
array([0., 1., 2., 0., 1., 2., 0., 1., 2.])
>>> graph.y_of_node
array([0., 0., 0., 1., 1., 1., 2., 2., 2.])
>>> graph.ndim
2

>>> links = [
...     (0, 1),
...     (1, 2),
...     (0, 3),
...     (1, 4),
...     (2, 5),
...     (3, 4),
...     (4, 5),
...     (3, 6),
...     (4, 7),
...     (5, 8),
...     (6, 7),
...     (7, 8),
... ]
>>> graph = Graph((node_y, node_x), links=links, sort=True)
>>> graph.nodes_at_link
array([[0, 1], [1, 2],
       [0, 3], [1, 4], [2, 5],
       [3, 4], [4, 5],
       [3, 6], [4, 7], [5, 8],
       [6, 7], [7, 8]])
>>> graph.node_at_link_head
array([1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 7, 8])
>>> graph.node_at_link_tail
array([0, 1, 0, 1, 2, 3, 4, 3, 4, 5, 6, 7])

>>> graph.links_at_node
array([[ 0,  2, -1, -1], [ 1,  3,  0, -1], [ 4,  1, -1, -1],
       [ 5,  7,  2, -1], [ 6,  8,  5,  3], [ 9,  6,  4, -1],
       [10,  7, -1, -1], [11, 10,  8, -1], [11,  9, -1, -1]])

>>> graph.link_dirs_at_node
array([[-1, -1,  0,  0], [-1, -1,  1,  0], [-1,  1,  0,  0],
       [-1, -1,  1,  0], [-1, -1,  1,  1], [-1,  1,  1,  0],
       [-1,  1,  0,  0], [-1,  1,  1,  0], [ 1,  1,  0,  0]],
      dtype=int8)

>>> patches = ((5, 3, 0, 2), (6, 4, 1, 3), (10, 8, 5, 7), (11, 9, 6, 8))
>>> graph = Graph((node_y, node_x), links=links, patches=patches, sort=True)
>>> graph.links_at_patch
array([[ 3,  5,  2,  0],
       [ 4,  6,  3,  1],
       [ 8, 10,  7,  5],
       [ 9, 11,  8,  6]])
>>> graph.nodes_at_patch
array([[4, 3, 0, 1],
       [5, 4, 1, 2],
       [7, 6, 3, 4],
       [8, 7, 4, 5]])
"""

import json
from functools import cached_property

import numpy as np
import xarray as xr

from ..core.utils import as_id_array
from ..utils.decorators import read_only_array
from .object.at_node import get_links_at_node
from .object.at_patch import get_nodes_at_patch
from .quantity.of_link import get_angle_of_link
from .quantity.of_link import get_length_of_link
from .quantity.of_link import get_midpoint_of_link
from .quantity.of_patch import get_area_of_patch
from .quantity.of_patch import get_centroid_of_patch
from .sort import reindex_by_xy
from .sort.sort import reorient_link_dirs
from .sort.sort import reverse_one_to_many
from .sort.sort import sort_spokes_at_hub
from .ugrid import ugrid_from_unstructured


def find_perimeter_nodes(graph):
    """Find nodes on the perimeter of a graph.

    Uses a convex hull to locate the perimeter nodes of a graph.

    Parameters
    ----------
    graph : graph_like
        A Graph of nodes (just requires *xy_of_node*).

    Returns
    -------
    ndarray of int
        Identifiers of the perimeter nodes.
    """
    from scipy.spatial import ConvexHull

    hull = ConvexHull(graph.xy_of_node, qhull_options="Qt")
    return as_id_array(hull.vertices)


class thawed:
    def __init__(self, graph):
        self._graph = graph
        self._initially_frozen = graph.frozen

    def __enter__(self):
        self._graph.thaw()

    def __exit__(self, ex_type, ex_value, traceback):
        if self._initially_frozen:
            self._graph.freeze()


def _update_node_at_cell(ugrid, node_at_cell):
    node_at_cell = xr.DataArray(
        data=as_id_array(node_at_cell),
        dims=("cell",),
        attrs={
            "cf_role": "cell_node_connectivity",
            "long_name": "nodes centered at cells",
            "start_index": 0,
        },
    )
    ugrid.update({"node_at_cell": node_at_cell})


def _update_nodes_at_face(ugrid, nodes_at_face):
    nodes_at_face = xr.DataArray(
        data=as_id_array(nodes_at_face),
        dims=("face", "Two"),
        attrs={
            "cf_role": "face_node_connectivity",
            "long_name": "nodes on either side of a face",
            "start_index": 0,
        },
    )
    ugrid.update({"nodes_at_face": nodes_at_face})


class NetworkGraph:
    """Define the connectivity of a graph of nodes and links.

    Unlike Graph, NetworkGraph does not have patches.
    """

    def __init__(self, node_y_and_x, links=None, sort=False):
        """Define a graph of connected nodes.

        Parameters
        ----------
        mesh : Dataset
            xarray Dataset that defines the topology in ugrid format.
        """
        self._ds = ugrid_from_unstructured(node_y_and_x, links=links)

        self._frozen = False
        self.freeze()

        if sort:
            (
                self._sorted_nodes,
                self._sorted_links,
                self._sorted_patches,
            ) = NetworkGraph.sort(self)

        self._origin = (0.0, 0.0)

    @property
    def frozen(self):
        return self._frozen

    def thawed(self):
        return thawed(self)

    def sort(self):
        """Sort graph elements."""
        with self.thawed():
            reorient_link_dirs(self)
            sorted_nodes, sorted_links, sorted_patches = reindex_by_xy(self)
            if "links_at_patch" in self.ds:
                sort_spokes_at_hub(
                    self.links_at_patch,
                    np.round(self.xy_of_patch, decimals=4),
                    np.round(self.xy_of_link, decimals=4),
                    inplace=True,
                )

        return sorted_nodes, sorted_links, sorted_patches

    def freeze(self):
        """Freeze the graph by making arrays read-only."""
        for var in self.ds.variables:
            array = self.ds[var].values
            while array is not None:
                array.flags.writeable = False
                array = array.base
        self._frozen = True

    def thaw(self):
        """Thaw the graph by making arrays writable."""
        for var in self.ds.variables:
            arrays = []
            array = self.ds[var].values
            while array is not None:
                arrays.append(array)
                array = array.base
            for array in arrays[::-1]:
                array.flags.writeable = True
        self._frozen = False

    def _add_variable(self, name, var, dims=None, attrs=None):
        kwds = {"data": var, "dims": dims, "attrs": attrs}
        self.ds.update({name: xr.DataArray(**kwds)})
        if self._frozen:
            self.freeze()

    @property
    def ds(self):
        return self._ds

    def to_dict(self):
        return self.ds.to_dict()

    def to_json(self):
        return json.dumps(self.ds.to_dict())

    def to_netcdf(self, *args, **kwds):
        """Write graph contents to a netCDF file.

        See xarray.Dataset.to_netcdf for a complete list of parameters.
        Below are only the most common.

        Parameters
        ----------
        path : str, optional
            Path to which to save this graph.
        mode : {'w', 'a'}, optional
            Write ('w') or append ('a') mode. If mode='w', any
            existing file at this location will be overwritten.
        format : {'NETCDF4', 'NETCDF4_CLASSIC', 'NETCDF3_64BIT', 'NETCDF3_CLASSIC'}, optional
            File format for the resulting netCDF file:

            * NETCDF4: Data is stored in an HDF5 file, using netCDF4 API
              features.
            * NETCDF4_CLASSIC: Data is stored in an HDF5 file, using only
              netCDF 3 compatible API features.
            * NETCDF3_64BIT: 64-bit offset version of the netCDF 3 file format,
              which fully supports 2+ GB files, but is only compatible with
              clients linked against netCDF version 3.6.0 or later.
            * NETCDF3_CLASSIC: The classic netCDF 3 file format. It does not
              handle 2+ GB files very well.

            All formats are supported by the netCDF4-python library.
            scipy.io.netcdf only supports the last two formats.

            The default format is NETCDF4 if you are saving a file to disk and
            have the netCDF4-python library available. Otherwise, xarray falls
            back to using scipy to write netCDF files and defaults to the
            NETCDF3_64BIT format (scipy does not support netCDF4).
        """
        self.ds.to_netcdf(*args, **kwds)

    @classmethod
    def from_netcdf(cls, fname):
        return cls.from_dataset(xr.open_dataset(fname))

    @classmethod
    def from_dict(cls, meta):
        return cls(
            (meta["y_of_node"], meta["x_of_node"]),
            links=meta.get("nodes_at_link", None),
            patches=meta.get("links_at_patch", None),
        )

    @classmethod
    def load(cls, source):
        if isinstance(source, str):
            return cls.from_netcdf(source)
        elif isinstance(source, (dict, xr.Dataset)):
            return cls.from_dict(source)
        else:
            raise ValueError(f"source must be dict-like or NetCDF ({type(source)})")

    def __str__(self):
        return str(self.ds)

    def __repr__(self):
        return repr(self.ds)

    @property
    def ndim(self):
        return 2

    @cached_property
    @read_only_array
    def xy_of_node(self):
        """Get x and y-coordinates of node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> graph.xy_of_node[:, 0]
        array([0., 1., 2., 0., 1., 2.])
        >>> graph.xy_of_node[:, 1]
        array([0., 0., 0., 1., 1., 1.])

        :meta landlab: info-node
        """
        return np.stack((self.x_of_node, self.y_of_node)).T.copy()

    @property
    def x_of_node(self):
        """Get x-coordinate of node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> graph.x_of_node
        array([0., 1., 2., 0., 1., 2.])

        :meta landlab: info-node
        """
        return self.ds["x_of_node"].values

    @property
    def y_of_node(self):
        """Get y-coordinate of node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> graph.y_of_node
        array([0., 0., 0., 1., 1., 1.])

        :meta landlab: info-node
        """
        return self.ds["y_of_node"].values

    @cached_property
    def node_x(self):
        return self.x_of_node

    @cached_property
    def node_y(self):
        return self.y_of_node

    @property
    def nodes(self):
        """Get identifier for each node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> graph.nodes
        array([0, 1, 2, 3, 4, 5])

        :meta landlab: info-node
        """
        return self.ds["node"].values

    @cached_property
    @read_only_array
    def perimeter_nodes(self):
        """Get nodes on the convex hull of a Graph.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> np.sort(graph.perimeter_nodes)
        array([0, 2, 3, 5])

        :meta landlab: info-node, boundary-condition, subset
        """
        return find_perimeter_nodes(self)

    @property
    def number_of_nodes(self):
        """Get total number of nodes.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]
        >>> graph = Graph((node_y, node_x))
        >>> graph.number_of_nodes == 6
        True

        :meta landlab: info-node
        """
        return self.ds.sizes["node"]

    @property
    def nodes_at_link(self):
        """Get nodes at either end of links.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.nodes_at_link
        array([[0, 1], [1, 2],
               [0, 3], [1, 4], [2, 5],
               [3, 4], [4, 5],
               [3, 6], [4, 7], [5, 8],
               [6, 7], [7, 8]])

        :meta landlab: info-node
        """
        return self.ds["nodes_at_link"].values

    @property
    def node_at_link_tail(self):
        """Get nodes at link tail.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.node_at_link_tail
        array([0, 1, 0, 1, 2, 3, 4, 3, 4, 5, 6, 7])

        :meta landlab: info-node
        """
        return self.nodes_at_link[:, 0]

    @property
    def node_at_link_head(self):
        """Get nodes at link head.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.node_at_link_head
        array([1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 7, 8])

        :meta landlab: info-node
        """
        return self.nodes_at_link[:, 1]

    @property
    def number_of_links(self):
        """Get nodes at link head.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.number_of_links == 12
        True
        """
        try:
            return self.ds.sizes["link"]
        except KeyError:
            return 0

    @cached_property
    @read_only_array
    def links_at_node(self):
        """Get links touching a node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x = [0, 1, 2, 0, 1, 2, 0, 1, 2]
        >>> node_y = [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.links_at_node
        array([[ 0,  2, -1, -1], [ 1,  3,  0, -1], [ 4,  1, -1, -1],
               [ 5,  7,  2, -1], [ 6,  8,  5,  3], [ 9,  6,  4, -1],
               [10,  7, -1, -1], [11, 10,  8, -1], [11,  9, -1, -1]])

        :meta landlab: info-link
        """
        try:
            return self._links_at_node
        except AttributeError:
            (
                self._links_at_node,
                self._link_dirs_at_node,
            ) = self._create_links_and_dirs_at_node()
            return self._links_at_node

    def _create_links_and_dirs_at_node(self):
        return get_links_at_node(self, sort=True)

    @cached_property
    @read_only_array
    def link_dirs_at_node(self):
        """Return link directions into each node.

        A value of 1 indicates a link points toward a given node, while a value
        of -1 indicates a link points away from a node.

        Returns
        -------
        (n_nodes, max_links_per_node) ndarray of int
            Link directions relative to the nodes of a grid. The shape of the
            matrix will be number of nodes by the maximum number of links per
            node. A zero indicates no link at this position.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.link_dirs_at_node
        array([[-1, -1,  0,  0], [-1, -1,  1,  0], [-1,  1,  0,  0],
               [-1, -1,  1,  0], [-1, -1,  1,  1], [-1,  1,  1,  0],
               [-1,  1,  0,  0], [-1,  1,  1,  0], [ 1,  1,  0,  0]],
              dtype=int8)
        """
        try:
            return self._link_dirs_at_node
        except AttributeError:
            (
                self._links_at_node,
                self._link_dirs_at_node,
            ) = self._create_links_and_dirs_at_node()
            return self._link_dirs_at_node

    @cached_property
    @read_only_array
    def angle_of_link(self):
        """Get the angle of each link.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import Graph

        >>> node_x, node_y = ([0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1])
        >>> links = ((0, 1), (1, 2), (0, 3), (1, 4), (2, 5), (3, 4), (4, 5))
        >>> graph = Graph((node_y, node_x), links=links)
        >>> graph.angle_of_link * 180.0 / np.pi
        array([ 0.,  0., 90., 90., 90.,  0.,  0.])

        :meta landlab: info-link
        """
        return get_angle_of_link(self)

    @cached_property
    @read_only_array
    def length_of_link(self):
        """Get the length of links.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import UniformRectilinearGraph

        >>> graph = UniformRectilinearGraph((2, 3), spacing=(1, 2))
        >>> graph.length_of_link
        array([2., 2., 1., 1., 1., 2., 2.])

        :meta landlab: info-link
        """
        return get_length_of_link(self)

    @cached_property
    @read_only_array
    def midpoint_of_link(self):
        """Get the middle of links.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import UniformRectilinearGraph

        >>> graph = UniformRectilinearGraph((2, 3), spacing=(1, 2))
        >>> graph.midpoint_of_link
        array([[1. , 0. ], [3. , 0. ],
               [0. , 0.5], [2. , 0.5], [4. , 0.5],
               [1. , 1. ], [3. , 1. ]])

        :meta landlab: info-link
        """
        return get_midpoint_of_link(self)

    @cached_property
    @read_only_array
    def xy_of_link(self):
        return get_midpoint_of_link(self)

    @cached_property
    @read_only_array
    def adjacent_nodes_at_node(self):
        """Get adjacent nodes.

        Examples
        --------
        >>> from landlab.graph import Graph

        First, a simple example with no diagonals.

        >>> node_x, node_y = [0, 0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 2, 0, 1, 2, 0, 1, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> graph = Graph((node_y, node_x), links=links, sort=True)
        >>> graph.adjacent_nodes_at_node
        array([[ 1,  3, -1, -1],
               [ 2,  4,  0, -1],
               [ 5,  1, -1, -1],
               [ 4,  6,  0, -1],
               [ 5,  7,  3,  1],
               [ 8,  4,  2, -1],
               [ 7,  3, -1, -1],
               [ 8,  6,  4, -1],
               [ 7,  5, -1, -1]])

        Next, we add the diagonal from node 0 to node 4.

        >>> node_x, node_y = [0, 0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 2, 0, 1, 2, 0, 1, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ...     (0, 4),
        ... )
        >>> graph = Graph((node_y, node_x), links=links, sort=True)
        >>> graph.adjacent_nodes_at_node
        array([[ 1,  4,  3, -1, -1],
               [ 2,  4,  0, -1, -1],
               [ 5,  1, -1, -1, -1],
               [ 4,  6,  0, -1, -1],
               [ 5,  7,  3,  0,  1],
               [ 8,  4,  2, -1, -1],
               [ 7,  3, -1, -1, -1],
               [ 8,  6,  4, -1, -1],
               [ 7,  5, -1, -1, -1]])

        :meta landlab: info-node
        """
        node_is_at_tail = np.choose(
            self.link_dirs_at_node + 1, np.array((1, -1, 0), dtype=np.int8)
        )
        out = self.nodes_at_link[self.links_at_node, node_is_at_tail]
        out[node_is_at_tail == -1] = -1

        return out

    @cached_property
    @read_only_array
    def adjacent_links_at_link(self):
        from .object.ext.at_link import find_adjacent_links_at_link

        adjacent_links_at_link = np.empty((self.number_of_links, 2), dtype=int)

        find_adjacent_links_at_link(
            self.nodes_at_link, self.links_at_node, adjacent_links_at_link
        )

        return adjacent_links_at_link

    @cached_property
    @read_only_array
    def unit_vector_at_link(self):
        """Make arrays to store the unit vectors associated with each link.

        For each link, the x and y components of the link's unit vector (that
        is, the link's x and y dimensions if it were shrunk to unit length but
        retained its orientation).

        Examples
        --------

        The example below is a seven-node hexagonal grid, with six nodes around
        the perimeter and one node (#3) in the interior. There are four
        horizontal links with unit vector (1,0), and 8 diagonal links with
        unit vector (+/-0.5, +/-sqrt(3)/2) (note: sqrt(3)/2 ~ 0.866).

        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 2), spacing=2.0, node_layout="hex", sort=True)

        >>> np.round(graph.unit_vector_at_link[:, 0], decimals=5)
        array([ 1. , -0.5,  0.5, -0.5,  0.5,  1. ,  1. ,  0.5, -0.5,  0.5, -0.5,
                1. ])
        >>> np.round(graph.unit_vector_at_link[:, 1], decimals=5)
        array([0.     , 0.86603, 0.86603, 0.86603, 0.86603, 0.     ,
               0.     , 0.86603, 0.86603, 0.86603, 0.86603, 0.     ])
        """
        u = np.diff(self.xy_of_node[self.nodes_at_link], axis=1).reshape((-1, 2))
        return u / np.linalg.norm(u, axis=1).reshape((-1, 1))

    @cached_property
    @read_only_array
    def unit_vector_at_node(self):
        """Get a unit vector for each node.

        Examples
        --------
        >>> from landlab.graph import UniformRectilinearGraph
        >>> graph = UniformRectilinearGraph((3, 3))
        >>> graph.unit_vector_at_node
        array([[1., 1.],
               [2., 1.],
               [1., 1.],
               [1., 2.],
               [2., 2.],
               [1., 2.],
               [1., 1.],
               [2., 1.],
               [1., 1.]])

        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 2), spacing=2.0, node_layout="hex", sort=True)

        >>> unit_vector_at_node = np.round(graph.unit_vector_at_node, decimals=5)
        >>> unit_vector_at_node[:, 0]
        array([2., 2., 2., 4., 2., 2., 2.])
        >>> unit_vector_at_node[:, 1]
        array([1.73205, 1.73205, 1.73205, 3.4641 , 1.73205, 1.73205, 1.73205])
        """
        unit_vector_at_link = np.vstack((self.unit_vector_at_link, [0.0, 0.0]))
        return np.abs(unit_vector_at_link[self.links_at_node]).sum(axis=1)


class Graph(NetworkGraph):
    """Define the connectivity of a graph of nodes, links, and patches."""

    def __init__(self, node_y_and_x, links=None, patches=None, sort=False):
        if patches is not None and len(patches) == 0:
            patches = None
        self._ds = ugrid_from_unstructured(node_y_and_x, links=links, patches=patches)

        self._frozen = False
        self.freeze()

        if sort:
            Graph.sort(self)

        self._origin = (0.0, 0.0)

    def merge(self, dual, node_at_cell=None, nodes_at_face=None):
        self._dual = dual

        if node_at_cell is not None:
            _update_node_at_cell(self.ds, node_at_cell)
        if nodes_at_face is not None:
            _update_nodes_at_face(self.ds, nodes_at_face)

    def sort(self):
        with self.thawed():
            reorient_link_dirs(self)
            sorted_nodes, sorted_links, sorted_patches = reindex_by_xy(self)
            # reorder_links_at_patch(self)
            if "links_at_patch" in self.ds:
                sort_spokes_at_hub(
                    self.links_at_patch,
                    np.round(self.xy_of_patch, decimals=4),
                    np.round(self.xy_of_link, decimals=4),
                    inplace=True,
                )

        return sorted_nodes, sorted_links, sorted_patches

    @cached_property
    @read_only_array
    def xy_of_patch(self):
        """Get the centroid of each patch.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches)
        >>> graph.xy_of_patch
        array([[0.5, 0.5],
               [1.5, 0.5]])

        :meta landlab: info-patch
        """
        return get_centroid_of_patch(self)

    @cached_property
    @read_only_array
    def area_of_patch(self):
        """Get the area of each patch.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches)
        >>> graph.area_of_patch
        array([1.,  1.])

        :meta landlab: info-patch
        """
        return get_area_of_patch(self)

    @property
    def number_of_patches(self):
        """Get the number of patches.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches)
        >>> graph.number_of_patches == 2
        True

        :meta landlab: info-patch
        """
        try:
            return self.ds.sizes["patch"]
        except KeyError:
            return 0

    @property
    def links_at_patch(self):
        """Get the links that define a patch.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = [0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2]
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches, sort=True)
        >>> graph.links_at_patch
        array([[3, 5, 2, 0],
               [4, 6, 3, 1]])

        :meta landlab: info-link
        """
        return self.ds["links_at_patch"].values

    @cached_property
    @read_only_array
    def nodes_at_patch(self):
        """Get the nodes that define a patch.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = ([0, 1, 2, 0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1, 2, 2, 2])
        >>> links = (
        ...     (0, 1),
        ...     (1, 2),
        ...     (0, 3),
        ...     (1, 4),
        ...     (2, 5),
        ...     (3, 4),
        ...     (4, 5),
        ...     (3, 6),
        ...     (4, 7),
        ...     (5, 8),
        ...     (6, 7),
        ...     (7, 8),
        ... )
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches, sort=True)
        >>> graph.nodes_at_patch
        array([[4, 3, 0, 1],
               [5, 4, 1, 2]])

        :meta landlab: info-node
        """
        nodes_at_patch = get_nodes_at_patch(self)
        sort_spokes_at_hub(
            nodes_at_patch, self.xy_of_patch, self.xy_of_node, inplace=True
        )
        return nodes_at_patch

    @cached_property
    @read_only_array
    def patches_at_node(self):
        """Get the patches that touch each node.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = ([0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1])
        >>> links = ((0, 1), (1, 2), (0, 3), (1, 4), (2, 5), (3, 4), (4, 5))
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches, sort=True)
        >>> graph.patches_at_node
        array([[ 0, -1], [ 1,  0], [ 1, -1],
               [ 0, -1], [ 0,  1], [ 1, -1]])

        :meta landlab: info-patch
        """
        patches_at_node = reverse_one_to_many(self.nodes_at_patch)
        sort_spokes_at_hub(
            patches_at_node, self.xy_of_node, self.xy_of_patch, inplace=True
        )
        return patches_at_node

    @cached_property
    @read_only_array
    def patches_at_link(self):
        """Get the patches on either side of each link.

        Examples
        --------
        >>> from landlab.graph import Graph
        >>> node_x, node_y = ([0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1])
        >>> links = ((0, 1), (1, 2), (0, 3), (1, 4), (2, 5), (3, 4), (4, 5))
        >>> patches = ((0, 3, 5, 2), (1, 4, 6, 3))
        >>> graph = Graph((node_y, node_x), links=links, patches=patches)
        >>> graph.patches_at_link
        array([[ 0, -1], [ 1, -1],
               [ 0, -1], [ 0,  1], [ 1, -1],
               [ 0, -1], [ 1, -1]])

        :meta landlab: info-patch
        """
        return reverse_one_to_many(self.links_at_patch, min_counts=2)



================================================
File: src/landlab/graph/graph_convention.py
================================================
import re
from collections import OrderedDict


class GraphConvention:
    """Define a naming convention for graph elements."""

    def __init__(self, node, edge, face, nodes=None, edges=None, faces=None):
        """Define a graph element naming convention.

        Parameters
        ----------
        node : str
            Name to use for "nodes".
        edge : str
            Name to use for "edges".
        face : str
            Name to use for "faces".
        nodes : str, optional
            Plural of "nodes"
        edges : str, optional
            Plural of "edges"
        faces : str, optional
            Plural of "faces"

        Examples
        --------
        >>> from landlab.graph import GraphConvention
        >>> convention = GraphConvention("node", "edge", "face")
        >>> convention.node
        'node'
        >>> convention.edge
        'edge'
        >>> convention.edges
        'edges'

        >>> convention = GraphConvention("node", "link", "patch", faces="patches")
        >>> convention.face
        'patch'
        >>> convention.faces
        'patches'
        """
        self._node = node
        self._edge = edge
        self._face = face
        self._nodes = nodes or node + "s"
        self._edges = edges or edge + "s"
        self._faces = faces or face + "s"

    @property
    def node(self):
        """The name of things that are points."""
        return self._node

    @property
    def nodes(self):
        """The plural name for node."""
        return self._nodes

    @property
    def edge(self):
        """The name of lines that connect two nodes."""
        return self._edge

    @property
    def edges(self):
        """The plural name of edge."""
        return self._edges

    @property
    def face(self):
        """The name of objects made up of a closed set of edges."""
        return self._face

    @property
    def faces(self):
        """The plural name for face."""
        return self._faces


class ConventionConverter:
    """Convert between graph element naming conventions."""

    CONVENTION = {
        "nlp": GraphConvention("node", "link", "patch", faces="patches"),
        "nef": GraphConvention("node", "edge", "face"),
        "cfc": GraphConvention("corner", "face", "cell"),
    }

    def __init__(self, convention="nlp"):
        """

        Parameters
        ----------
        convention : {"nlp", "nef", "cfc"}
            Naming convention to which to conform.
        """
        self.convention = convention

    @property
    def convention(self):
        """Name of the convention to conform to."""
        return self._convention

    @convention.setter
    def convention(self, val):
        if val not in ("nlp", "cfc", "nef"):
            raise ValueError(f"convention not understood ({val})")
        self._convention = val

    @staticmethod
    def _convention_mapper(from_convention, to_convention):
        """Create a mapper to convert names between conventions."""
        elements = ("nodes", "edges", "faces", "node", "edge", "face")

        from_elements = [getattr(from_convention, name) for name in elements]
        to_elements = [getattr(to_convention, name) for name in elements]

        return OrderedDict(
            list(zip(to_elements, from_elements))
            + list(zip(from_elements, to_elements))
        )

    @classmethod
    def _as_convention(cls, name):
        """Get a named convention as a GraphConvention object."""
        try:
            return cls.CONVENTION[name]
        except KeyError as exc:
            raise ValueError(f"convention not understood ({name})") from exc

    def conform(self, name, from_convention):
        """Convert a name to a new convention.

        Parameters
        ----------
        name : str
            A name in the given convention.
        from_convention : {"nlp", "nef", "cfc"}
            Naming convention of the provided string.

        Returns
        -------
        str
            The name converted to the convention.

        Examples
        --------
        >>> from landlab.graph import ConventionConverter

        >>> converter = ConventionConverter("nlp")

        >> converter.conform("nodes_at_edge", "nef")
        'nodes_at_link'

        >>> converter.conform("node_at_cell", "cfc")
        'corner_at_patch'

        >>> converter = ConventionConverter("nef")
        >>> converter.conform("faces_at_cell", "cfc")
        'edges_at_face'
        """
        if from_convention is self.convention:
            return name

        mapping = ConventionConverter._convention_mapper(
            ConventionConverter._as_convention(from_convention),
            ConventionConverter._as_convention(self.convention),
        )

        def rename_words(m):
            key = m.group(0)
            return mapping[key]

        pattern = "|".join(mapping.keys())
        return re.sub(pattern, rename_words, name)



================================================
File: src/landlab/graph/ugrid.py
================================================
import numpy as np
import xarray as xr

from ..utils.jaggedarray import flatten_jagged_array

_MESH_ATTRS = {
    "cf_role": "mesh_topology",
    "long_name": "Topology data of 2D unstructured mesh",
    "topology_dimension": 2,
    "node_coordinates": "x_of_node y_of_node",
    "face_node_connectivity": "nodes_at_patch",
    "face_dimension": "patch",
    "face_edge_connectivity": "links_at_patch",
    "edge_node_connectivity": "nodes_at_link",
    "edge_dimension": "link",
}


def ugrid_from_unstructured(node_y_and_x, links=None, patches=None):
    ugrid = xr.Dataset({"mesh": xr.DataArray(data="a", attrs=_MESH_ATTRS)})

    _update_node_coords(ugrid, node_y_and_x)

    if links is not None:
        _update_nodes_at_link(ugrid, links)

    if patches is not None and "nodes_at_link" in ugrid:
        _update_links_at_patch(ugrid, patches)

    return ugrid


def _update_node_coords(ugrid, node_y_and_x):
    node_y, node_x = (
        np.asarray(node_y_and_x[0], dtype=float),
        np.asarray(node_y_and_x[1], dtype=float),
    )
    y_of_node = xr.DataArray(
        data=node_y.reshape((-1,)),
        coords={"node": np.arange(node_y.size)},
        dims=("node",),
        attrs={"long_name": "y", "units": "m"},
    )
    x_of_node = xr.DataArray(
        data=node_x.reshape((-1,)),
        coords={"node": np.arange(node_x.size)},
        dims=("node",),
        attrs={"long_name": "x", "units": "m"},
    )
    ugrid.update({"y_of_node": y_of_node, "x_of_node": x_of_node})

    return ugrid


def _update_nodes_at_link(ugrid, node_links):
    node_links = np.asarray(node_links, dtype=int).reshape((-1, 2))
    nodes_at_link = xr.DataArray(
        data=node_links,
        dims=("link", "Two"),
        attrs={
            "cf_role": "edge_node_connectivity",
            "long_name": "nodes a link tail and head",
            "start_index": 0,
        },
    )
    ugrid.update({"nodes_at_link": nodes_at_link})


def _update_links_at_patch(ugrid, patches):
    from .matrix.at_patch import links_at_patch

    if len(patches) > 0:
        patches = flatten_jagged_array(patches, dtype=int)
    patch_links = links_at_patch(patches)
    links_at_patch = xr.DataArray(
        data=patch_links,
        dims=("patch", "max_patch_links"),
        attrs={
            "cf_role": "face_edge_connectivity",
            "long_name": "Maps every face to its edges",
            "start_index": 0,
        },
    )
    ugrid.update({"links_at_patch": links_at_patch})



================================================
File: src/landlab/graph/ext/__init__.py
================================================



================================================
File: src/landlab/graph/framed_voronoi/__init__.py
================================================
from .dual_framed_voronoi import DualFramedVoronoiGraph
from .framed_voronoi import FramedVoronoiGraph

__all__ = ["FramedVoronoiGraph", "DualFramedVoronoiGraph"]



================================================
File: src/landlab/graph/framed_voronoi/dual_framed_voronoi.py
================================================
"""Implement the DualFramedVoronoiGraph

@author sebastien lenard
@date 2022, Aug
"""

from ..dual import DualGraph
from ..voronoi.dual_voronoi import DualVoronoiGraph
from .framed_voronoi import FramedVoronoiGraph


class DualFramedVoronoiGraph(DualGraph, FramedVoronoiGraph):
    """Graph of a unstructured grid of Voronoi Delaunay cells and
    irregular patches. It is a special type of VoronoiDelaunay graph in which
    the initial set of points is arranged in a fixed lattice (e.g. like a rectangular
    raster grid) named here "layout" and the core points are then moved aroung their
    initial position by a random distance, lower than a certain threshold.

    Examples
    --------
    >>> from landlab.graph import DualFramedVoronoiGraph

    >>> graph = DualFramedVoronoiGraph((3, 3), seed=200)
    >>> graph.number_of_nodes
    9

    >>> graph.x_of_node[2:4]
    array([2., 0.])
    >>> graph.y_of_node[2:4]
    array([0.   , 0.749])
    >>> graph.y_of_node[5]
    1.251
    """

    def __init__(
        self,
        shape,
        xy_spacing=(1.0, 1.0),
        xy_of_lower_left=(0.0, 0.0),
        sort=False,
        xy_min_spacing=(0.5, 0.5),
        seed=200,
    ):
        """Create the graph.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of nodes.
        xy_spacing : float or tuple of float, optional
            Node spacing along x and y coordinates. If float, same spacing at x and y.
        xy_of_lower_left : tuple, optional
            Minimum *x*-of-node and *y*-of-node values. Depending on the grid,
            there may not be a node present at this location.
        sort: bool
            If ``True``, nodes, links and patches are re-numbered according to
            their position.
        xy_min_spacing: float or tuple of float, optional
            Final minimal spacing between nodes. Random moves of the core nodes
            around their position cannot be above this threshold:
            ``(xy_spacing - xy_min_spacing) / 2``
            If ``float``, same minimal spacing for *x* and *y*.
        seed: int, optional
            Seed used to generate the random *x* and *y* moves. When set,
            controls a pseudo-randomness of moves to ensure reproducibility.
            When ``None``, seed is random and the moves of coordinates are
            completely random.

        Returns
        -------
        DualFramedVoronoiGraph
            A newly-created graph.

        Examples
        --------
        Create a grid with 3 rows and 2 columns of nodes.

        >>> from landlab.graph import DualFramedVoronoiGraph
        >>> graph = DualFramedVoronoiGraph((3, 2), xy_spacing=1.0)
        >>> graph.number_of_nodes
        6
        """
        FramedVoronoiGraph.__init__(
            self,
            shape,
            xy_spacing=xy_spacing,
            xy_of_lower_left=xy_of_lower_left,
            sort=True,
            xy_min_spacing=xy_min_spacing,
            seed=seed,
        )

        DualVoronoiGraph.__init__(
            self,
            (self._y_of_node, self._x_of_node),
            perimeter_links=self._perimeter_links,
            sort=False,
        )

        if sort:
            self.sort()



================================================
File: src/landlab/graph/framed_voronoi/framed_voronoi.py
================================================
"""Implementation of the FramedVoronoiGraph and its static layout:
HorizontalRectVoronoiGraph. This pattern is inspired from the developments of the HexModelGrid

.. codeauthor:: sebastien lenard
"""

from functools import cached_property

import numpy as np

from ...utils.decorators import make_return_array_immutable
from ..graph import Graph
from ..voronoi.voronoi import DelaunayGraph


class HorizontalRectVoronoiGraph:
    """The horizontal rectangular frame for the FramedVoronoiGraph."""

    @staticmethod
    def number_of_nodes(shape):
        """
        Parameters
        ----------
        shape: tuple of int
            Number of rows and number of columns

        Returns
        -------
        int
            Number of nodes

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )
        >>> HorizontalRectVoronoiGraph.number_of_nodes((3, 2))
        6
        """
        n_rows, n_cols = shape
        return n_rows * n_cols

    @staticmethod
    def xy_of_node(
        shape,
        xy_spacing=(1.0, 1.0),
        xy_of_lower_left=(0.0, 0.0),
        xy_min_spacing=(0.5, 0.5),
        seed=200,
    ):
        """The x and y coordinates of the graph's nodes.

        Calculation of the x-y coordinates is done following these steps:

        1. Generate a rectangular, regular meshgrid.
        2. Move the coordinates of the core nodes over a random distance around their
           initial position, within a threshold calculated from *xy_spacing* and
           *xy_min_spacing*.
        3. Rectify the y-coordinates of the nodes of the left and right to ensure
           that the leftmost node of a row has a lower y than the rightmost node.
           This ensures that the ids of these nodes are not modified by subsequent
           sorting operations on the graph and make it possible to get the
           perimeter nodes in simple way.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of nodes.
        xy_spacing : float or tuple of float, optional
            Node spacing along x and y coordinates. If ``float``, same spacing at *x* and *y*.
        xy_of_lower_left : tuple, optional
            Minimum *x*-of-node and *y*-of-node values. Depending on the grid,
            a node may not be present at this location.
        xy_min_spacing: float or tuple of float, optional
            Final minimal spacing between nodes. Random moves of the core nodes
            around their initial positions cannot be above this threshold:
            ``(xy_spacing - xy_min_spacing) / 2``.  If ``float``, same minimal
            spacing for *x* and *y*.
        seed: int, optional
            Seed used to generate the random *x* and *y* moves. When set, controls a
            pseudo-randomness of moves to ensure reproducibility.
            When ``None``, seed is random and the moves of coordinates are
            completely random.

        Returns
        -------
        x_of_node, y_of_node : ndarray of float
            The arrays of *x* and *y* coordinates.

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )

        >>> x_of_node, y_of_node = HorizontalRectVoronoiGraph.xy_of_node(
        ...     (3, 3), seed=200
        ... )

        Coordinates of the lower left node,

        >>> x_of_node[0], y_of_node[0]
        (0.0, 0.0)

        *x* coordinates of the left and right edges,

        >>> x_of_node[3], x_of_node[5]
        (0.0, 2.0)

        *y* coordinate of the middle row of the left edge,

        >>> y_of_node[3]
        0.749
        """

        n_rows, n_cols = shape
        max_move = (
            (xy_spacing[0] - xy_min_spacing[0]) / 2,
            (xy_spacing[1] - xy_min_spacing[1]) / 2,
        )

        if max_move[0] < 0.0 or max_move[1] < 0.0:
            raise ValueError("minimum spacing must be greater than node spacing")
        if np.allclose(max_move, 0.0):
            raise ValueError("at least one of x and y moves must be greater than zero")

        # Generation of a rectangular grid, coordinates must be float
        x_of_node, y_of_node = np.meshgrid(
            np.arange(n_cols, dtype=float) * xy_spacing[0] + xy_of_lower_left[0],
            np.arange(n_rows, dtype=float) * xy_spacing[1] + xy_of_lower_left[1],
        )
        # Randomly move the coordinates of the core nodes of the grid. Move
        # below +/- (spacing - min_spacing) / 2
        xy_random_generator = np.random.default_rng(seed=seed)

        x_moves = xy_random_generator.uniform(-max_move[0], max_move[0], shape)
        y_moves = xy_random_generator.uniform(-max_move[1], max_move[1], shape)

        x_of_node[1:-1, 1:-1] += x_moves[1:-1, 1:-1]
        y_of_node[1:-1, 1:-1] += y_moves[1:-1, 1:-1]
        # Control the node id attribution for left and right edge. For instance, for a 3x3 grid,
        # make sure that node 3 is at the left of the 2nd row and node 5 at the right.
        # For this, for each core row, set y of the leftmost node as the minimal y of the row
        # and set y of the rightmost node as the maximal y of the row
        for i in range(1, n_rows - 1):
            y_of_node[i, 0] -= max_move[1] + 1.0e-3
            y_of_node[i, n_cols - 1] += max_move[1] + 1.0e-3

        return x_of_node.reshape(-1), y_of_node.reshape(-1)

    @staticmethod
    def corner_nodes(shape):
        """
        Parameters
        ----------
        shape: tuple of int
            Number of rows and number of columns

        Returns
        -------
        ndarray of int
            Ids of the corner nodes

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )
        >>> HorizontalRectVoronoiGraph.corner_nodes((3, 4))
        (11, 8, 0, 3)
        """
        n_rows, n_cols = shape
        return (n_rows * n_cols - 1, n_cols * (n_rows - 1), 0, n_cols - 1)

    @staticmethod
    def number_of_perimeter_nodes(shape):
        """
        Parameters
        ----------
        shape: tuple of int
            Number of rows and number of columns

        Returns
        -------
        int
            Number of perimeter nodes

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )
        >>> HorizontalRectVoronoiGraph.number_of_perimeter_nodes((3, 4))
        10
        """
        if 1 in shape:
            return np.prod(shape)
        return 2 * shape[0] + 2 * (shape[1] - 2)

    @staticmethod
    def perimeter_nodes(shape):
        """
        Parameters
        ----------
        shape: tuple of int
            Number of rows and number of columns

        Returns
        -------
        ndarray of int
            Ids of the perimeter nodes

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )
        >>> HorizontalRectVoronoiGraph.perimeter_nodes((3, 3))
        array([2, 5, 8, 7, 6, 3, 0, 1])
        """
        return np.concatenate(HorizontalRectVoronoiGraph.nodes_at_edge(shape))

    @staticmethod
    def nodes_at_edge(shape):
        """
        Parameters
        ----------
        shape: tuple of int
            Number of rows and number of columns

        Returns
        -------
        right, top, left, bottom : ndarray of int
            For each edge give the ids of the nodes present at the edge

        Examples
        --------
        >>> from landlab.graph.framed_voronoi.framed_voronoi import (
        ...     HorizontalRectVoronoiGraph,
        ... )
        >>> HorizontalRectVoronoiGraph.nodes_at_edge((3, 3))
        (array([2, 5]), array([8, 7]), array([6, 3]), array([0, 1]))
        """
        n_rows, n_cols = shape
        if n_rows == n_cols == 1:
            return (np.array([0]),) + (np.array([], dtype=int),) * 3
        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = HorizontalRectVoronoiGraph.corner_nodes(shape)

        if n_rows > 1:
            south = np.arange(southwest, southeast)
        else:
            south = np.array([southwest], dtype=int)

        if n_cols > 1:
            west = np.arange(northwest, southwest, -n_cols)
        else:
            west = np.array([northwest], dtype=int)

        return (
            np.arange(southeast, northeast, n_cols),
            np.arange(northeast, northwest, -1),
            west,
            south,
        )


class FramedVoronoiGraph(DelaunayGraph):
    """VoronoiDelaunay graph based on a fixed lattice.

    Graph of an unstructured grid of Voronoi Delaunay cells and
    irregular patches. It is a special type of :class`~.VoronoiDelaunayGraph` in which
    the initial set of points is arranged in a fixed lattice (e.g. like a
    :class:`~.RasterModelGrid`) named here "layout" and the core points are
    then moved from their initial position by a random distance, lower than a
    certain threshold.

    Examples
    --------
    >>> from landlab.graph import FramedVoronoiGraph

    >>> graph = FramedVoronoiGraph((3, 3), seed=200)
    >>> graph.number_of_nodes
    9

    >>> graph.x_of_node[2:4]
    array([2., 0.])
    >>> graph.y_of_node[2:4]
    array([0.   , 0.749])
    >>> graph.y_of_node[5]
    1.251

    >>> graph.number_of_links
    16
    >>> graph.number_of_patches
    8
    """

    def __init__(
        self,
        shape,
        xy_spacing=(1.0, 1.0),
        xy_of_lower_left=(0.0, 0.0),
        sort=False,
        xy_min_spacing=(0.5, 0.5),
        seed=200,
    ):
        """Create the graph.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of nodes.
        xy_spacing : float or tuple of float, optional
            Node spacing along *x* and *y* coordinates. If ``float``, same spacing *x* and *y*
            spacing.
        xy_of_lower_left : tuple, optional
            Minimum *x*-of-node and *y*-of-node values. Depending on the grid,
            a node may not be present at this location.
        sort: bool
            If ``True``, nodes, links and patches are re-numbered according
            certain their positions.  Currently not used.
        xy_min_spacing: float or tuple of float, optional
            Final minimal spacing between nodes. Random moves of the core nodes
            around their position cannot be above this threshold:
            ``(xy_spacing - xy_min_spacing) / 2``
            If ``float``, same minimal spacing for *x* and *y*.
        seed: int, optional
            Seed used to generate the random *x* and *y* moves.
            When set, controls a pseudo-randomness of moves to ensure
            reproducibility. When ``None``, seed is random and the moves of coordinates are
            completely random.

        Returns
        -------
        FramedVoronoiGraph
            A newly-created graph.

        Examples
        --------
        Create a grid with 3 rows and 2 columns of nodes.

        >>> from landlab.graph import FramedVoronoiGraph
        >>> graph = FramedVoronoiGraph((3, 2))
        >>> graph.number_of_nodes
        6
        """
        # 1. Check and format input arguments
        #####################################
        self._shape = shape
        self._seed = seed

        try:
            xy_spacing = np.asarray(np.broadcast_to(xy_spacing, 2), dtype=float)
        except TypeError as exc:
            raise TypeError("spacing must be a float or a tuple of floats") from exc
        else:
            self._xy_spacing = xy_spacing[0], xy_spacing[1]

        try:
            xy_of_lower_left = np.asarray(
                np.broadcast_to(xy_of_lower_left, 2), dtype=float
            )
        except TypeError as exc:
            raise TypeError(
                "xy of lower left must be a float or a tuple of floats"
            ) from exc
        else:
            self._xy_of_lower_left = xy_of_lower_left[0], xy_of_lower_left[1]

        node_layout = self._node_layout = "rect"
        orientation = self._orientation = "horizontal"

        layouts = {
            "horizontal_rect": HorizontalRectVoronoiGraph,
        }
        layout = layouts["_".join([orientation, node_layout])]

        try:
            xy_min_spacing = np.asarray(np.broadcast_to(xy_min_spacing, 2), dtype=float)
        except TypeError as exc:
            raise TypeError(
                "minimal spacing must be a float or a tuple of floats"
            ) from exc
        else:
            self._xy_min_spacing = xy_min_spacing[0], xy_min_spacing[1]

        # 2. Construction of the layout and the x-y coordinates of nodes
        ################################################################
        x_of_node, y_of_node = layout.xy_of_node(
            self._shape,
            xy_spacing=self._xy_spacing,
            xy_of_lower_left=self._xy_of_lower_left,
            xy_min_spacing=self._xy_min_spacing,
            seed=self._seed,
        )

        # 3. Determination of the perimeter and edge nodes
        #########################################
        self._perimeter_nodes = layout.perimeter_nodes(self._shape)

        (right, top, left, bottom) = layout.nodes_at_edge(self._shape)
        self._nodes_at_right_edge = np.sort(np.append(right, top[0]))
        self._nodes_at_top_edge = np.sort(np.append(top, left[0]))
        self._nodes_at_left_edge = np.sort(np.append(left, bottom[0]))
        self._nodes_at_bottom_edge = np.sort(np.append(bottom, right[0]))

        perimeter_links = np.empty((len(self._perimeter_nodes), 2), dtype=int)
        perimeter_links[:, 0] = self._perimeter_nodes
        perimeter_links[:-1, 1] = self._perimeter_nodes[1:]
        perimeter_links[-1, 1] = self._perimeter_nodes[0]

        self._x_of_node = x_of_node
        self._y_of_node = y_of_node
        self._perimeter_links = perimeter_links

        # 3. Instantiation of the parent class
        ######################################
        if 1 in shape:
            Graph.__init__(
                self,
                (y_of_node, x_of_node),
                links=list(
                    zip(np.arange(len(y_of_node) - 1), np.arange(1, len(y_of_node)))
                ),
                sort=False,
            )
        else:
            DelaunayGraph.__init__(
                self,
                (y_of_node, x_of_node),
                perimeter_links=perimeter_links,
                sort=False,
            )

    @property
    def shape(self):
        return self._shape

    @property
    def xy_spacing(self):
        return self._xy_spacing

    @property
    def orientation(self):
        return self._orientation

    @property
    def node_layout(self):
        return self._node_layout

    @cached_property
    @make_return_array_immutable
    def perimeter_nodes(self):
        return self._perimeter_nodes

    @property
    @make_return_array_immutable
    def nodes_at_right_edge(self):
        return self._nodes_at_right_edge

    @property
    @make_return_array_immutable
    def nodes_at_top_edge(self):
        return self._nodes_at_top_edge

    @property
    @make_return_array_immutable
    def nodes_at_left_edge(self):
        return self._nodes_at_left_edge

    @property
    @make_return_array_immutable
    def nodes_at_bottom_edge(self):
        return self._nodes_at_bottom_edge



================================================
File: src/landlab/graph/hex/__init__.py
================================================
from .dual_hex import DualHexGraph
from .hex import TriGraph

__all__ = ["TriGraph", "DualHexGraph"]



================================================
File: src/landlab/graph/hex/dual_hex.py
================================================
import numpy as np

from ..dual import DualGraph
from ..voronoi.dual_voronoi import DualVoronoiGraph
from .hex import HorizontalHexTriGraph
from .hex import HorizontalRectTriGraph
from .hex import TriGraph
from .hex import VerticalHexTriGraph
from .hex import VerticalRectTriGraph


class DualHexGraph(DualGraph, TriGraph):
    """Graph of a structured grid of triangles.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import DualHexGraph

    >>> graph = DualHexGraph((3, 2), node_layout="hex")
    >>> graph.number_of_nodes
    7
    >>> graph.number_of_corners
    6

    >>> np.round(graph.y_of_node * 2.0 / np.sqrt(3))
    array([0., 0., 1., 1., 1., 2., 2.])
    >>> graph.x_of_node
    array([0.5, 1.5, 0. , 1. , 2. , 0.5, 1.5])
    """

    def __init__(
        self,
        shape,
        spacing=1.0,
        xy_of_lower_left=(0.0, 0.0),
        orientation="horizontal",
        node_layout="rect",
        sort=False,
    ):
        """Create a structured grid of triangles.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of the hex grid. The first value
            is the number of nodes in the first column and the second the
            number of nodes in the first column.
        spacing : float, optional
            Length of links.
        xy_of_lower_left : tuple of float, optional
            Coordinates of lower-left corner of the grid.
        orientation: {'horizontal', 'vertical'}
            Specify if triangles should be laid out in rows or columns.
        node_layout: {'rect', 'hex'}
            Specify the overall layout of the nodes. Use *rect* for
            the layout to approximate a rectangle and *hex* for
            a hexagon.
        """
        if node_layout not in ("rect", "hex"):
            raise ValueError("node_layout not understood")

        if orientation not in ("horizontal", "vertical"):
            raise ValueError("orientation not understood")

        layouts = {
            "horizontal_hex": HorizontalHexTriGraph,
            "vertical_hex": VerticalHexTriGraph,
            "horizontal_rect": HorizontalRectTriGraph,
            "vertical_rect": VerticalRectTriGraph,
        }
        layout = layouts["_".join([orientation, node_layout])]

        try:
            spacing = float(spacing)
        except TypeError as exc:
            raise TypeError("spacing must be a float") from exc

        self._shape = tuple(shape)
        self._spacing = spacing
        self._orientation = orientation
        self._node_layout = node_layout

        x_of_node, y_of_node = layout.xy_of_node(
            shape, spacing=spacing, xy_of_lower_left=xy_of_lower_left
        )
        self._perimeter_nodes = layout.perimeter_nodes(shape)

        perimeter_links = np.empty((len(self._perimeter_nodes), 2), dtype=int)
        perimeter_links[:, 0] = self._perimeter_nodes
        perimeter_links[:-1, 1] = self._perimeter_nodes[1:]
        perimeter_links[-1, 1] = self._perimeter_nodes[0]

        DualVoronoiGraph.__init__(
            self, (y_of_node, x_of_node), perimeter_links=perimeter_links, sort=False
        )

        if sort:
            self.sort()



================================================
File: src/landlab/graph/hex/hex.py
================================================
r"""
Examples
--------

::

        * - *
       / \ / \
      * - * - *
     / \ / \ / \
    * - * - * - *
     \ / \ / \ /
      * - * - *
       \ / \ /
        * - *

>>> from landlab.graph import TriGraph
>>> graph = TriGraph((5, 2), node_layout="hex", sort=True)
>>> graph.number_of_nodes
14
>>> graph.x_of_node
array([1. , 2. ,
       0.5, 1.5, 2.5,
       0. , 1. , 2. , 3. ,
       0.5, 1.5, 2.5,
       1. , 2. ])
>>> graph.number_of_links
29
>>> graph.number_of_patches
16

::

    * - * - * - *
     \ / \ / \ / \
      * - * - * - *
     / \ / \ / \ /
    * - * - * - *

>>> from landlab.graph import TriGraph
>>> graph = TriGraph((3, 4), orientation="horizontal", node_layout="rect", sort=True)
>>> graph.number_of_nodes
12
>>> graph.x_of_node.reshape((3, 4))
array([[0. , 1. , 2. , 3. ],
       [0.5, 1.5, 2.5, 3.5],
       [0. , 1. , 2. , 3. ]])
>>> graph.number_of_links
23
>>> graph.number_of_patches
12
"""

from functools import cached_property

import numpy as np

from ...core.utils import as_id_array
from ...grid.linkorientation import LinkOrientation
from ...utils.decorators import cache_result_in_object
from ...utils.decorators import make_return_array_immutable
from ..graph import Graph
from ..voronoi.voronoi import DelaunayGraph


class HorizontalRectTriGraphCython:
    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        from .ext.hex import fill_xy_of_node_rect_horizontal

        x_of_node = np.empty(shape[0] * shape[1], dtype=float)
        y_of_node = np.empty(shape[0] * shape[1], dtype=float)
        fill_xy_of_node_rect_horizontal(shape, x_of_node, y_of_node)

        x_of_node[:] *= spacing
        y_of_node[:] *= spacing * np.sin(np.pi / 3.0)
        x_of_node[:] += xy_of_lower_left[0]
        y_of_node[:] += xy_of_lower_left[1]

        return x_of_node, y_of_node


class VerticalRectTriGraphCython:
    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        from .ext.hex import fill_xy_of_node_rect_vertical

        n_rows, n_cols = shape
        x_spacing = np.sin(np.pi / 3.0) * spacing
        y_spacing = spacing

        x_of_node = np.empty(n_rows * n_cols, dtype=float)
        y_of_node = np.empty(n_rows * n_cols, dtype=float)

        fill_xy_of_node_rect_vertical(shape, x_of_node, y_of_node)

        x_of_node *= x_spacing
        y_of_node *= y_spacing
        x_of_node += xy_of_lower_left[0]
        y_of_node += xy_of_lower_left[1]

        return x_of_node, y_of_node

        x_of_node[:, (n_cols + 1) // 2 :] = (
            np.arange(n_cols // 2) * x_spacing * 2.0 + x_spacing + xy_of_lower_left[0]
        )
        x_of_node[:, : (n_cols + 1) // 2] = (
            np.arange((n_cols + 1) // 2) * x_spacing * 2.0 + xy_of_lower_left[0]
        )

        y_of_node[:, : (n_cols + 1) // 2] = (
            np.arange(n_rows) * y_spacing + xy_of_lower_left[1]
        ).reshape((n_rows, 1))
        y_of_node[:, (n_cols + 1) // 2 :] = (
            np.arange(n_rows) * y_spacing + xy_of_lower_left[1] + y_spacing * 0.5
        ).reshape((n_rows, 1))

        return x_of_node.reshape(-1), y_of_node.reshape(-1)


class HorizontalHexTriGraphCython:
    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        from .ext.hex import fill_xy_of_node_hex_horizontal

        n_rows, n_cols = shape
        n_nodes = n_rows * n_cols + (n_rows // 2) ** 2

        x_of_node = np.empty(n_nodes, dtype=float)
        y_of_node = np.empty(n_nodes, dtype=float)

        fill_xy_of_node_hex_horizontal(shape, x_of_node, y_of_node)

        x_of_node[:] *= spacing
        y_of_node[:] *= spacing * np.sin(np.pi / 3.0)
        x_of_node[:] += xy_of_lower_left[0]
        y_of_node[:] += xy_of_lower_left[1]

        return x_of_node, y_of_node


class VerticalHexTriGraphCython:
    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        from .ext.hex import fill_xy_of_node_hex_vertical

        n_rows, n_cols = shape
        n_nodes = n_cols * n_rows + (n_cols // 2) ** 2

        x_of_node = np.empty(n_nodes, dtype=float)
        y_of_node = np.empty(n_nodes, dtype=float)

        fill_xy_of_node_hex_vertical(shape, x_of_node, y_of_node)

        x_of_node[:] *= spacing * np.sin(np.pi / 3.0)
        y_of_node[:] *= spacing
        x_of_node[:] += xy_of_lower_left[0]
        y_of_node[:] += xy_of_lower_left[1]

        return x_of_node, y_of_node


class HorizontalRectTriGraph:
    @staticmethod
    def number_of_nodes(shape):
        n_rows, n_cols = shape
        return n_rows * n_cols

    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        n_rows, n_cols = shape
        x_spacing, y_spacing = spacing, spacing * np.sin(np.pi / 3.0)

        x_of_node, y_of_node = np.meshgrid(
            np.arange(n_cols) * x_spacing + xy_of_lower_left[0],
            np.arange(n_rows) * y_spacing + xy_of_lower_left[1],
        )
        x_of_node[1::2] += spacing * 0.5

        return x_of_node.reshape(-1), y_of_node.reshape(-1)

    @staticmethod
    def corner_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import HorizontalRectTriGraph
        >>> HorizontalRectTriGraph.corner_nodes((3, 4))
        (11, 8, 0, 3)
        >>> HorizontalRectTriGraph.corner_nodes((3, 2))
        (5, 4, 0, 1)
        >>> HorizontalRectTriGraph.corner_nodes((7, 1))
        (6, 6, 0, 0)
        >>> HorizontalRectTriGraph.corner_nodes((1, 3))
        (2, 0, 0, 2)
        """
        n_rows, n_cols = shape
        return (n_rows * n_cols - 1, n_cols * (n_rows - 1), 0, n_cols - 1)

    @staticmethod
    def number_of_perimeter_nodes(shape):
        if 1 in shape:
            return np.prod(shape)
        return 2 * shape[0] + 2 * (shape[1] - 2)

    @staticmethod
    def perimeter_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import HorizontalRectTriGraph
        >>> HorizontalRectTriGraph.perimeter_nodes((3, 2))
        array([1, 3, 5, 4, 2, 0])
        """
        return np.concatenate(HorizontalRectTriGraph.nodes_at_edge(shape))

    @staticmethod
    def nodes_at_edge(shape):
        n_rows, n_cols = shape
        if n_rows == n_cols == 1:
            return (np.array([0]),) + (np.array([], dtype=int),) * 3
        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = HorizontalRectTriGraph.corner_nodes(shape)

        if n_rows > 1:
            south = np.arange(southwest, southeast)
        else:
            south = np.array([southwest], dtype=int)

        if n_cols > 1:
            west = np.arange(northwest, southwest, -n_cols)
        else:
            west = np.array([northwest], dtype=int)

        return (
            np.arange(southeast, northeast, n_cols),
            np.arange(northeast, northwest, -1),
            west,
            south,
        )


class VerticalRectTriGraph:
    @staticmethod
    def number_of_nodes(shape):
        n_rows, n_cols = shape
        return n_rows * n_cols

    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        n_rows, n_cols = shape
        x_spacing, y_spacing = spacing * np.sin(np.pi / 3.0), spacing

        x_of_node = np.empty((n_rows, n_cols), dtype=float)
        y_of_node = np.empty((n_rows, n_cols), dtype=float)

        x_of_node[:, (n_cols + 1) // 2 :] = (
            np.arange(n_cols // 2) * x_spacing * 2.0 + x_spacing + xy_of_lower_left[0]
        )
        x_of_node[:, : (n_cols + 1) // 2] = (
            np.arange((n_cols + 1) // 2) * x_spacing * 2.0 + xy_of_lower_left[0]
        )

        y_of_node[:, : (n_cols + 1) // 2] = (
            np.arange(n_rows) * y_spacing + xy_of_lower_left[1]
        ).reshape((n_rows, 1))
        y_of_node[:, (n_cols + 1) // 2 :] = (
            np.arange(n_rows) * y_spacing + xy_of_lower_left[1] + y_spacing * 0.5
        ).reshape((n_rows, 1))

        return x_of_node.reshape(-1), y_of_node.reshape(-1)

    @staticmethod
    def corner_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalRectTriGraph
        >>> VerticalRectTriGraph.corner_nodes((4, 3))
        (10, 9, 0, 1)
        >>> VerticalRectTriGraph.corner_nodes((4, 4))
        (15, 12, 0, 3)
        >>> VerticalRectTriGraph.corner_nodes((3, 2))
        (5, 4, 0, 1)
        >>> VerticalRectTriGraph.corner_nodes((7, 1))
        (6, 6, 0, 0)
        >>> VerticalRectTriGraph.corner_nodes((1, 3))
        (1, 0, 0, 1)
        >>> VerticalRectTriGraph.corner_nodes((2, 3))
        (4, 3, 0, 1)
        """
        n_rows, n_cols = shape
        if n_cols % 2 == 0:
            return (n_rows * n_cols - 1, n_cols * (n_rows - 1), 0, n_cols - 1)
        else:
            return (
                n_rows * n_cols - 1 - n_cols // 2,
                n_cols * (n_rows - 1),
                0,
                n_cols // 2,
            )

    @staticmethod
    def number_of_perimeter_nodes(shape):
        if 1 in shape:
            return np.prod(shape)
        return 2 * shape[1] + 2 * (shape[0] - 2)

    @staticmethod
    def perimeter_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalRectTriGraph
        >>> VerticalRectTriGraph.perimeter_nodes((3, 2))
        array([1, 3, 5, 4, 2, 0])
        >>> VerticalRectTriGraph.perimeter_nodes((2, 3))
        array([1, 4, 5, 3, 0, 2])
        >>> VerticalRectTriGraph.perimeter_nodes((2, 4))
        array([3, 7, 5, 6, 4, 0, 2, 1])
        """
        return np.concatenate(VerticalRectTriGraph.nodes_at_edge(shape))

    @staticmethod
    def nodes_at_edge(shape):
        n_rows, n_cols = shape
        if n_rows == n_cols == 1:
            return (np.array([0]),) + (np.array([], dtype=int),) * 3
        n_nodes = n_rows * n_cols
        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = VerticalRectTriGraph.corner_nodes(shape)

        if n_cols == 1:
            southwest = northwest - n_cols

        north = np.empty(n_cols - 1, dtype=int)
        north[::2] = n_nodes - n_cols // 2 + np.arange(n_cols // 2)
        north[1::2] = northwest + np.arange(1, n_cols - n_cols // 2)

        if n_rows > 1:
            south = np.empty(n_cols - 1, dtype=int)
            south[::2] = np.arange(0, n_cols // 2)
            south[1::2] = (n_cols + 1) // 2 + np.arange(n_cols - n_cols // 2 - 1)
        else:
            south = np.array([southwest], dtype=int)

        return (
            np.arange(southeast, northeast, n_cols),
            north[::-1],
            np.arange(northwest, southwest, -n_cols),
            south,
        )


class HorizontalHexTriGraph:
    @staticmethod
    def number_of_nodes(shape):
        n_rows, n_cols = shape
        return n_rows * n_cols + (n_rows // 2) ** 2

    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        n_rows, n_cols = shape
        x_spacing, y_spacing = spacing, spacing * np.sin(np.pi / 3.0)

        length_of_row = np.concatenate(
            (
                np.arange((n_rows + 2) // 2) + n_cols,
                (n_rows + 2) // 2
                + n_cols
                - 1
                - np.arange(1, n_rows - (n_rows + 2) // 2 + 1),
            )
        )
        offset_to_row = np.concatenate((np.array([0]), length_of_row)).cumsum()
        rows = [
            slice(start, end)
            for start, end in zip(offset_to_row[:-1], offset_to_row[1:])
        ]

        y_of_node = np.empty(HorizontalHexTriGraph.number_of_nodes(shape), dtype=float)
        for row, inds in enumerate(rows):
            y_of_node[inds] = row * y_spacing + xy_of_lower_left[1]

        x_of_node = np.empty(HorizontalHexTriGraph.number_of_nodes(shape), dtype=float)

        x_of_row = (
            np.abs((n_rows + 2) // 2 - 1 - np.arange(n_rows)) * x_spacing * 0.5
            + xy_of_lower_left[0]
        )
        for row, inds in enumerate(rows):
            x_of_node[inds] = x_of_row[row] + np.arange(length_of_row[row]) * x_spacing

        return x_of_node.reshape(-1), y_of_node.reshape(-1)

    @staticmethod
    def corner_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import HorizontalHexTriGraph
        >>> HorizontalHexTriGraph.corner_nodes((3, 2))
        (4, 6, 5, 2, 0, 1)
        >>> HorizontalHexTriGraph.corner_nodes((7, 1))
        (9, 15, 15, 6, 0, 0)
        >>> HorizontalHexTriGraph.corner_nodes((6, 1))
        (9, 14, 13, 6, 0, 0)
        >>> HorizontalHexTriGraph.corner_nodes((4, 2))
        (8, 11, 9, 5, 0, 1)
        """
        n_rows, n_cols = shape

        n_nodes_in_middle_row = n_rows // 2 + n_cols
        n_nodes = n_rows * n_cols + (n_rows // 2) ** 2

        east = (n_nodes_in_middle_row + n_cols) * ((n_rows // 2 + 1) // 2) - 1
        if (n_rows // 2) % 2 == 0:
            east += (n_nodes_in_middle_row + n_cols) // 2

        return (
            east,
            n_nodes - 1,
            n_nodes - (n_cols + (n_rows + 1) % 2),
            east - (n_nodes_in_middle_row - 1),
            0,
            n_cols - 1,
        )

    @staticmethod
    def number_of_perimeter_nodes(shape):
        if shape[0] == 1:
            return shape[1]
        return 2 * shape[0] + 2 * (shape[1] - 2) + (shape[0] + 1) % 2

    @staticmethod
    def perimeter_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import HorizontalHexTriGraph
        >>> HorizontalHexTriGraph.perimeter_nodes((3, 2))
        array([4, 6, 5, 2, 0, 1])
        >>> HorizontalHexTriGraph.perimeter_nodes((1, 3))
        array([2, 1, 0])
        """
        return np.concatenate(HorizontalHexTriGraph.nodes_at_edge(shape))

    @staticmethod
    def nodes_at_edge(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import HorizontalHexTriGraph
        >>> HorizontalHexTriGraph.nodes_at_edge((5, 3))
        (array([11, 15]), array([18, 17]), array([16, 12]), array([7, 3]),
         array([0, 1]), array([2, 6]))
        >>> HorizontalHexTriGraph.nodes_at_edge((4, 3))
        (array([11]), array([15, 14, 13]), array([12]), array([7, 3]), array([0, 1]),
         array([2, 6]))
        """
        n_rows, n_cols = shape
        (
            east,
            northeast,
            northwest,
            west,
            southwest,
            southeast,
        ) = HorizontalHexTriGraph.corner_nodes(shape)

        if n_rows == 1:
            nodes_at_south_edge = np.asarray([southwest], dtype=int)
        else:
            nodes_at_south_edge = np.arange(southwest, southeast)

        return (
            as_id_array(
                northeast
                - np.arange(northeast - northwest + 1, east - west + 1).cumsum()[::-1]
            ),
            np.arange(northeast, northwest, -1),
            as_id_array(
                west
                + np.arange(east - west + 1, northeast - northwest + 1, -1).cumsum()[
                    ::-1
                ]
            ),
            as_id_array(
                southwest + np.arange(n_cols, n_rows // 2 + n_cols).cumsum()[::-1]
            ),
            nodes_at_south_edge,
            as_id_array(
                east - np.arange(n_cols + n_rows // 2, n_cols, -1).cumsum()[::-1]
            ),
        )


class VerticalHexTriGraph:
    @staticmethod
    def number_of_nodes(shape):
        n_rows, n_cols = shape
        return n_rows * n_cols + (n_cols // 2) ** 2

    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_lower_left=(0.0, 0.0)):
        n_rows, n_cols = shape
        x_spacing, y_spacing = spacing * np.sin(np.pi / 3.0), spacing

        length_of_middle_rows = np.full(2 * n_rows - 1, n_cols // 2)
        if n_cols % 2 == 1:
            length_of_middle_rows[::2] += 1

        length_of_row = np.concatenate(
            (
                np.arange(1, n_cols // 2 + 1),
                length_of_middle_rows,
                np.arange(n_cols // 2, 0, -1),
            )
        )
        offset_to_row = np.concatenate((np.array([0]), length_of_row)).cumsum()
        rows = [
            slice(start, end)
            for start, end in zip(offset_to_row[:-1], offset_to_row[1:])
        ]

        y_of_node = np.empty(VerticalHexTriGraph.number_of_nodes(shape), dtype=float)
        for row, inds in enumerate(rows):
            y_of_node[inds] = row * y_spacing * 0.5

        x_of_node = np.empty(VerticalHexTriGraph.number_of_nodes(shape), dtype=float)

        x_of_middle_rows = np.zeros(2 * n_rows - 1)
        x_of_middle_rows[1::2] += 1.0
        x_of_row = (
            np.concatenate(
                (
                    np.arange(n_cols // 2, 0, -1),
                    x_of_middle_rows,
                    np.arange(1, n_cols // 2 + 1),
                )
            )
            * x_spacing
        )
        for row, inds in enumerate(rows):
            x_of_node[inds] = (
                x_of_row[row] + np.arange(length_of_row[row]) * 2.0 * x_spacing
            )

        x_of_node += xy_of_lower_left[0]
        y_of_node += xy_of_lower_left[1]

        return x_of_node.reshape(-1), y_of_node.reshape(-1)

    @staticmethod
    def corner_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalHexTriGraph
        >>> VerticalHexTriGraph.corner_nodes((2, 5))
        (10, 13, 8, 3, 0, 5)
        >>> VerticalHexTriGraph.corner_nodes((2, 3))
        (5, 6, 4, 1, 0, 2)
        >>> VerticalHexTriGraph.corner_nodes((2, 4))
        (10, 11, 7, 3, 0, 2)
        >>> VerticalHexTriGraph.corner_nodes((2, 2))
        (4, 4, 3, 1, 0, 0)
        >>> VerticalHexTriGraph.corner_nodes((3, 1))
        (2, 2, 2, 0, 0, 0)
        >>> VerticalHexTriGraph.corner_nodes((1, 3))
        (2, 3, 1, 1, 0, 2)
        """
        n_rows, n_cols = shape
        n_nodes = n_rows * n_cols + (n_cols // 2) ** 2

        n = n_cols // 2
        tri_nodes = (n + 1) * (n // 2)
        if n % 2 == 1:
            tri_nodes += (n + 1) // 2

        if n_cols % 2 == 0:
            southeast = tri_nodes - 1
            southwest = tri_nodes
            northwest = n_nodes - 1 - (tri_nodes - 1 + n_cols // 2)
            northeast = n_nodes - 1 - (tri_nodes - n)

        else:
            southwest = tri_nodes
            southeast = tri_nodes + n_cols // 2
            northwest = n_nodes - (tri_nodes + (n_cols + 1) // 2)
            northeast = n_nodes - 1 - tri_nodes

        south = 0
        north = n_nodes - 1

        return (northeast, north, northwest, southwest, south, southeast)

    @staticmethod
    def number_of_perimeter_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalHexTriGraph
        >>> VerticalHexTriGraph.number_of_perimeter_nodes((2, 3))
        6
        >>> VerticalHexTriGraph.number_of_perimeter_nodes((2, 2))
        5
        """
        if shape[1] == 1:
            return shape[0]
        return 2 * shape[1] + 2 * (shape[0] - 2) + (shape[1] + 1) % 2

    @staticmethod
    def perimeter_nodes(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalHexTriGraph
        >>> VerticalHexTriGraph.perimeter_nodes((3, 7))
        array([ 9, 16, 23, 26, 28, 29, 27, 24, 20, 13,  6,  3,  1,  0,  2,  5])
        >>> VerticalHexTriGraph.perimeter_nodes((2, 3))
        array([2, 5, 6, 4, 1, 0])
        >>> VerticalHexTriGraph.perimeter_nodes((2, 4))
        array([ 2, 6, 10, 11, 9, 7, 3, 1, 0])
        >>> VerticalHexTriGraph.perimeter_nodes((2, 2))
        array([0, 2, 4, 3, 1])
        >>> VerticalHexTriGraph.perimeter_nodes((3, 1))
        array([0, 1, 2])
        """
        return np.concatenate(VerticalHexTriGraph.nodes_at_edge(shape))

    @staticmethod
    def nodes_at_edge(shape):
        """
        Examples
        --------
        >>> from landlab.graph.hex.hex import VerticalHexTriGraph
        >>> VerticalHexTriGraph.nodes_at_edge((3, 7))
        (array([ 9, 16]), array([23, 26, 28]), array([29, 27, 24]), array([20, 13]),
         array([6, 3, 1]), array([0, 2, 5]))
        >>> VerticalHexTriGraph.nodes_at_edge((2, 3))
        (array([2]), array([5]), array([6]), array([4]), array([1]), array([0]))
        >>> VerticalHexTriGraph.nodes_at_edge((2, 4))
        (array([2, 6]), array([10]), array([11, 9]), array([7]), array([3, 1]), array([0]))
        """
        n_rows, n_cols = shape
        (
            northeast,
            north,
            northwest,
            southwest,
            south,
            southeast,
        ) = VerticalHexTriGraph.corner_nodes(shape)

        if shape[1] == 1:
            southwest = northwest - n_cols

        return (
            np.arange(southeast, northeast, n_cols),
            as_id_array(north - np.arange(1, (n_cols + 1) // 2).cumsum())[::-1],
            as_id_array(north - np.arange(1, (n_cols + 2) // 2).cumsum() + 1),
            np.arange(northwest, southwest, -n_cols),
            as_id_array(south + np.arange(1, (n_cols + 2) // 2).cumsum())[::-1],
            as_id_array(south + np.arange(1, (n_cols + 1) // 2).cumsum() - 1),
        )


class HexGraphExtras:
    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_right_edge(self):
        """Get nodes along the right edge.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 4), node_layout="rect")
        >>> graph.nodes_at_right_edge
        array([ 3,  7, 11])
        """
        return np.arange(
            self.shape[1] - 1, self.shape[0] * self.shape[1], self.shape[1], dtype=int
        )

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_top_edge(self):
        """Get nodes along the top edge.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 4), node_layout="rect")
        >>> graph.nodes_at_top_edge
        array([ 8,  9, 10, 11])
        """
        return np.arange(
            self.number_of_nodes - self.shape[1], self.number_of_nodes, dtype=int
        )

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_left_edge(self):
        """Get nodes along the left edge.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 4), node_layout="rect")
        >>> graph.nodes_at_left_edge
        array([0, 4, 8])
        """
        return np.arange(0, self.shape[0] * self.shape[1], self.shape[1], dtype=int)

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_bottom_edge(self):
        """Get nodes along the bottom edge.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import TriGraph
        >>> graph = TriGraph((3, 4), node_layout="rect")
        >>> graph.nodes_at_bottom_edge
        array([0, 1, 2, 3])
        """
        return np.arange(self.shape[1], dtype=int)

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def length_of_link(self):
        return np.full(self.number_of_links, self.spacing, dtype=float)

    @cached_property
    def orientation_of_link(self):
        """Return array of link orientation codes (one value per link).

        Orientation codes are defined by :class:`~.LinkOrientation`;
        1 = E, 2 = ENE, 4 = NNE, 8 = N, 16 = NNW, 32 = ESE (using powers
        of 2 allows for future applications that might want additive
        combinations).

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> import numpy as np
        >>> grid = HexModelGrid((3, 2))
        >>> grid.orientation_of_link
        array([ 1, 16,  4, 16,  4,  1,  1,  4, 16,  4, 16,  1], dtype=uint8)
        >>> grid = HexModelGrid((2, 3), orientation="vertical")
        >>> grid.orientation_of_link
        array([32,  2,  8,  2, 32,  8,  8, 32,  2,  8,  2, 32], dtype=uint8)
        """
        code = np.round(self.angle_of_link * 6.0 / np.pi).astype(np.uint8)
        code[code == 11] = 5
        code[:] = 2**code

        return code

    @cached_property
    def parallel_links_at_link(self):
        """Return similarly oriented links connected to each link.

        Return IDs of links of the same orientation that are connected to
        each given link's tail or head node.

        The data structure is a *numpy* array of shape ``(n_links, 2)`` containing the
        IDs of the "tail-wise" (connected to tail node) and "head-wise" (connected
        to head node) links, or -1 if the link is inactive (e.g., on the perimeter)
        or it has no attached parallel neighbor in the given direction.

        For instance, consider a 3x3 hex, in which link IDs are as shown::

               o---17--o---18--o
              / .     / .     / .
             11 12   13  14  15  16
            /     . /     . /     .
           o---8---o---9---o---10--o
            .     / .     / .     /
             2   3   4   5   6   7
              . /     . /     . /
               o---0---o---1---o

        Here's a mapping of the tail-wise and head-wise links, where
        there are valid parallel links::

               o-------o-------o
              / .     / .     / .
             /   .   /   .   /   .
            /     4 3     6 5     .
           o-----9-o-8--10-o-9-----o
            .    13 12   15 14    /
             .   /   .   /   .   /
              . /     . /     . /
               o-------o-------o

        The corresponding data structure would be mostly filled with -1, but
        for the 11 active links, it would look like::

            3: [[-1, 13],
            4:  [-1, 12],
            5:  [-1, 15],
            6:  [-1, 14],
            8:  [-1,  9],
            9:  [ 8, 10],
            10: [ 9, -1],
            12: [ 4, -1],
            13: [ 3, -1],
            14: [ 6, -1],
            15: [ 5, -1]]

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((3, 3))
        >>> pll = grid.parallel_links_at_link
        >>> pll[3:16]
        array([[-1, 13],
               [-1, 12],
               [-1, 15],
               [-1, 14],
               [-1, -1],
               [-1,  9],
               [ 8, 10],
               [ 9, -1],
               [-1, -1],
               [ 4, -1],
               [ 3, -1],
               [ 6, -1],
               [ 5, -1]])
        """
        if self.orientation == "horizontal":
            orientations = (LinkOrientation.E, LinkOrientation.NNE, LinkOrientation.NNW)
        else:
            orientations = (LinkOrientation.ENE, LinkOrientation.N, LinkOrientation.ESE)

        links_at_node = self._oriented_links_at_node()

        pll = np.full((self.number_of_links, 2), -1, dtype=int)

        for col, orientation in enumerate(orientations):
            links = self.orientation_of_link == orientation

            if orientation == LinkOrientation.ESE:
                pll[links, 0] = links_at_node[self.node_at_link_tail[links]][:, col]
                pll[links, 1] = links_at_node[self.node_at_link_head[links]][:, col + 3]
            else:
                pll[links, 0] = links_at_node[self.node_at_link_tail[links]][:, col + 3]
                pll[links, 1] = links_at_node[self.node_at_link_head[links]][:, col]

        return pll

    def _oriented_links_at_node(self):
        if self.orientation == "horizontal":
            orientations = (LinkOrientation.E, LinkOrientation.NNE, LinkOrientation.NNW)
        else:
            orientations = (LinkOrientation.ENE, LinkOrientation.N, LinkOrientation.ESE)

        links_at_node = np.full((self.number_of_nodes, 6), -1, dtype=int)

        for col, orientation in enumerate(orientations):
            links = np.where(self.orientation_of_link == orientation)[0]

            if orientation == LinkOrientation.ESE:
                links_at_node[self.node_at_link_tail[links], col + 3] = links
                links_at_node[self.node_at_link_head[links], col] = links
            else:
                links_at_node[self.node_at_link_tail[links], col] = links
                links_at_node[self.node_at_link_head[links], col + 3] = links

        return links_at_node


class TriGraph(HexGraphExtras, DelaunayGraph):
    """Graph of a structured grid of triangles.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import TriGraph

    >>> graph = TriGraph((3, 2))
    >>> graph.number_of_nodes == 6
    True
    >>> np.round(graph.y_of_node * 2.0 / np.sqrt(3))
    array([0., 0., 1., 1., 2., 2.])
    >>> graph.x_of_node
    array([0. , 1. , 0.5, 1.5, 0. , 1. ])
    """

    def __init__(
        self,
        shape,
        spacing=1.0,
        xy_of_lower_left=(0.0, 0.0),
        orientation="horizontal",
        node_layout="rect",
        sort=False,
    ):
        """Create a structured grid of triangles.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of the hex grid. The first value
            is the number of nodes in the first column and the second the
            number of nodes in the first column.
        spacing : float, optional
            Length of links.
        xy_of_lower_left : tuple of float, optional
            Coordinates of lower-left corner of the grid.
        orientation: {'horizontal', 'vertical'}
            Specify if triangles should be laid out in rows or columns.
        node_layout: {'rect', 'hex'}
            Specify the overall layout of the nodes. Use *rect* for
            the layout to approximate a rectangle and *hex* for
            a hexagon.
        """
        if node_layout not in ("rect", "hex"):
            raise ValueError("node_layout not understood")

        if orientation not in ("horizontal", "vertical"):
            raise ValueError("orientation not understood")

        layouts = {
            "horizontal_hex": HorizontalHexTriGraph,
            "vertical_hex": VerticalHexTriGraph,
            "horizontal_rect": HorizontalRectTriGraph,
            "vertical_rect": VerticalRectTriGraph,
        }
        layout = layouts["_".join([orientation, node_layout])]

        try:
            spacing = float(spacing)
        except TypeError as exc:
            raise TypeError("spacing must be a float") from exc

        self._shape = tuple(shape)
        self._spacing = spacing
        self._orientation = orientation
        self._node_layout = node_layout

        x_of_node, y_of_node = layout.xy_of_node(
            shape, spacing=spacing, xy_of_lower_left=xy_of_lower_left
        )
        self._perimeter_nodes = layout.perimeter_nodes(shape)

        perimeter_links = np.empty((len(self._perimeter_nodes), 2), dtype=int)
        perimeter_links[:, 0] = self._perimeter_nodes
        perimeter_links[:-1, 1] = self._perimeter_nodes[1:]
        perimeter_links[-1, 1] = self._perimeter_nodes[0]

        if 1 in shape:
            Graph.__init__(
                self,
                (y_of_node, x_of_node),
                links=list(
                    zip(np.arange(len(y_of_node) - 1), np.arange(1, len(y_of_node)))
                ),
                sort=False,
            )
        else:
            DelaunayGraph.__init__(
                self,
                (y_of_node, x_of_node),
                perimeter_links=perimeter_links,
                sort=False,
            )

        if sort:
            self.sort()

    @property
    def shape(self):
        return self._shape

    @property
    def spacing(self):
        return self._spacing

    @property
    def orientation(self):
        return self._orientation

    @property
    def node_layout(self):
        return self._node_layout

    @cached_property
    @make_return_array_immutable
    def perimeter_nodes(self):
        return self._perimeter_nodes



================================================
File: src/landlab/graph/hex/ext/__init__.py
================================================



================================================
File: src/landlab/graph/hex/ext/hex.pyx
================================================
cimport cython

from cython.parallel import prange

from libc.stdlib cimport free
from libc.stdlib cimport malloc

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_xy_of_node_hex_horizontal(
    shape,
    cython.floating [:] x_of_node,
    cython.floating [:] y_of_node,
):
    """Get x and y coordinates for each node."""
    cdef long n_rows = shape[0]
    cdef long longest_row = n_rows // 2
    cdef long row
    cdef long offset
    cdef long *size_of_row
    cdef long *offset_to_row
    cdef double x0

    try:
        size_of_row = <long*>malloc(sizeof(long) * n_rows)
        offset_to_row = <long*>malloc(sizeof(long) * (n_rows + 1))

        size_of_row[0] = shape[1]
        for row in prange(1, longest_row + 1, nogil=True, schedule="static"):
            size_of_row[row] = size_of_row[row - 1] + 1
        for row in prange(longest_row + 1, n_rows, nogil=True, schedule="static"):
            size_of_row[row] = size_of_row[row - 1] - 1

        offset_to_row[0] = 0
        for row in range(1, n_rows + 1):
            offset_to_row[row] = offset_to_row[row - 1] + size_of_row[row - 1]

        for row in prange(longest_row + 1, nogil=True, schedule="static"):
            x0 = longest_row * 0.5 - row * 0.5

            for offset in range(offset_to_row[row], offset_to_row[row + 1]):
                x_of_node[offset] = x0 + offset - offset_to_row[row]
                y_of_node[offset] = row
            # x0 -= .5

        for row in prange(longest_row + 1, n_rows, nogil=True, schedule="static"):
            x0 = (row - longest_row) * 0.5

            for offset in range(offset_to_row[row], offset_to_row[row + 1]):
                x_of_node[offset] = x0 + offset - offset_to_row[row]
                y_of_node[offset] = row
    finally:
        free(offset_to_row)
        free(size_of_row)


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_xy_of_node_hex_vertical(
    shape,
    cython.floating [:] x_of_node,
    cython.floating [:] y_of_node,
):
    cdef long n_nodes = len(x_of_node)
    cdef int n_cols = shape[1]
    cdef int longest_column = n_cols // 2
    cdef int size_of_longest_column = longest_column + shape[0]
    cdef int n_rows = 2 * size_of_longest_column - 1
    cdef long size_of_odd_row = n_cols // 2
    cdef long size_of_even_row = n_cols - size_of_odd_row
    cdef long n_middle_rows = 2 * shape[0] - 1
    cdef long n_top_rows = n_cols // 2
    cdef long row
    cdef long n
    cdef long *size_of_row
    cdef long *offset_to_row
    cdef float x0
    cdef long offset

    try:
        size_of_row = <long*>malloc(sizeof(long) * n_rows)
        offset_to_row = <long*>malloc(sizeof(long) * (n_rows + 1))

        # Bottom and top rows
        for row in prange(n_top_rows, nogil=True, schedule="static"):
            size_of_row[row] = row + 1
            size_of_row[n_rows - row - 1] = row + 1

        # Middle rows
        for row in prange(0, n_middle_rows, 2, nogil=True, schedule="static"):
            size_of_row[row + n_top_rows] = size_of_even_row
            size_of_row[row + 1 + n_top_rows] = size_of_odd_row

        offset_to_row[0] = 0
        for row in range(1, n_rows + 1):
            offset_to_row[row] = offset_to_row[row - 1] + size_of_row[row - 1]

        for row in prange(0, n_rows, 2, nogil=True, schedule="static"):
            x0 = - (size_of_row[row] - 1) // 2
            for offset in range(offset_to_row[row], offset_to_row[row + 1]):
                x_of_node[offset] = x0 + offset - offset_to_row[row]
                y_of_node[offset] = row

        for row in prange(1, n_rows, 2, nogil=True, schedule="static"):
            x0 = - size_of_row[row] // 2 + .5
            for offset in range(offset_to_row[row], offset_to_row[row + 1]):
                x_of_node[offset] = x0 + offset - offset_to_row[row]
                y_of_node[offset] = row

        x0 = x_of_node[offset_to_row[n_top_rows]]
        for n in range(n_nodes):
            x_of_node[n] -= x0
    finally:
        free(offset_to_row)
        free(size_of_row)


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_xy_of_node_rect_vertical(
    shape,
    cython.floating [:] x_of_node,
    cython.floating [:] y_of_node,
):
    """Get x and y coordinates for each node."""
    cdef long n_cols = shape[1]
    cdef long size_of_odd_row = n_cols // 2
    cdef long size_of_even_row = n_cols - size_of_odd_row
    cdef long n_rows = 2 * shape[0]
    cdef long row
    cdef long offset
    cdef long n

    # even rows
    for row in prange(0, n_rows, 2, nogil=True, schedule="static"):
        offset = row // 2 * n_cols
        for n in range(size_of_even_row):
            x_of_node[offset + n] = n * 2
            y_of_node[offset + n] = row / 2.

    # odd rows
    offset = size_of_even_row
    for row in prange(1, n_rows, 2, nogil=True, schedule="static"):
        offset = size_of_even_row + (row - 1) // 2 * n_cols

        for n in range(size_of_odd_row):
            x_of_node[offset + n] = 2 * n + 1
            y_of_node[offset + n] = row / 2.


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_xy_of_node_rect_horizontal(
    shape,
    cython.floating [:] x_of_node,
    cython.floating [:] y_of_node,
):
    """Get x and y coordinates for each node."""
    cdef int stride = 2 * shape[1]
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int row
    cdef int col
    cdef int node

    for row in range(0, n_rows, 2):
        node = stride * row // 2
        for col in range(n_cols):
            x_of_node[node] = col
            y_of_node[node] = row

            node = node + 1

    for row in range(1, n_rows, 2):
        node = stride * (row - 1) // 2 + n_cols
        for col in range(n_cols):
            x_of_node[node] = col + .5
            y_of_node[node] = row

            node = node + 1



================================================
File: src/landlab/graph/hex/ext/perimeternodes.pyx
================================================
cimport cython
from libc.stdlib cimport free
from libc.stdlib cimport malloc

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_perimeter_nodes_rect_horizontal(
    shape,
    id_t [:] perimeter_nodes,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int n_nodes = n_rows * n_cols
    cdef int i
    cdef int node

    # Right edge
    i = 0
    for node in range(n_cols - 1, n_nodes - 1, n_cols):
        perimeter_nodes[i] = node
        i += 1

    # Top edge
    for node in range(n_nodes - 1, n_nodes - n_cols, - 1):
        perimeter_nodes[i] = node
        i += 1

    # Left edge
    for node in range((n_rows - 1) * n_cols, 0, - n_cols):
        perimeter_nodes[i] = node
        i += 1

    # Bottom edge
    for node in range(0, n_cols - 1):
        perimeter_nodes[i] = node
        i += 1


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_perimeter_nodes_rect_vertical(
    shape,
    id_t [:] perimeter_nodes,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int i
    cdef int offset_to_right_edge
    cdef int offset_to_top_edge
    cdef int offset_to_left_edge
    cdef int offset_to_bottom_edge

    offset_to_top_edge = n_rows - 1
    offset_to_left_edge = offset_to_top_edge + n_cols - 1
    offset_to_bottom_edge = offset_to_left_edge + n_rows - 1
    offset_to_right_edge = offset_to_bottom_edge + n_cols - 1

    if n_cols % 2 == 0:
        perimeter_nodes[0] = n_cols - 1
    else:
        perimeter_nodes[0] = n_cols // 2

    # Right edge
    for i in range(1, offset_to_top_edge + 1):
        perimeter_nodes[i] = perimeter_nodes[i - 1] + n_cols

    # Top edge
    perimeter_nodes[offset_to_top_edge + 1] = perimeter_nodes[offset_to_top_edge]
    if n_cols % 2 == 0:
        perimeter_nodes[offset_to_top_edge + 1] -= n_cols // 2
    else:
        perimeter_nodes[offset_to_top_edge + 1] += n_cols // 2
    for i in range(offset_to_top_edge + 2, offset_to_left_edge + 1, 2):
        perimeter_nodes[i] = perimeter_nodes[i - 2] - 1
        perimeter_nodes[i + 1] = perimeter_nodes[i - 1] - 1

    # Left edge
    for i in range(offset_to_left_edge + 1, offset_to_bottom_edge + 1):
        perimeter_nodes[i] = perimeter_nodes[i - 1] - n_cols

    # Bottom edge
    perimeter_nodes[offset_to_bottom_edge] = 0
    for i in range(offset_to_bottom_edge + 2, offset_to_right_edge, 2):
        perimeter_nodes[i] = perimeter_nodes[i - 2] + 1

    perimeter_nodes[offset_to_bottom_edge + 1] = (n_cols + 1) // 2
    for i in range(offset_to_bottom_edge + 3, offset_to_right_edge, 2):
        perimeter_nodes[i] = perimeter_nodes[i - 2] + 1


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_perimeter_nodes_hex_horizontal(
    shape,
    id_t [:] perimeter_nodes,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int longest_row = n_rows // 2
    cdef int offset_to_right_edge
    cdef int offset_to_top_edge
    cdef int offset_to_left_edge
    cdef int offset_to_bottom_edge
    cdef int i
    cdef int row
    cdef int * nodes_per_row

    try:
        nodes_per_row = <int *>malloc(n_rows * sizeof(int))

        nodes_per_row[0] = n_cols
        for row in range(1, longest_row + 1):
            nodes_per_row[row] = nodes_per_row[row - 1] + 1
        for row in range(longest_row + 1, n_rows):
            nodes_per_row[row] = nodes_per_row[row - 1] - 1

        offset_to_top_edge = n_rows - 1
        offset_to_left_edge = offset_to_top_edge + nodes_per_row[n_rows - 1] - 1
        offset_to_bottom_edge = offset_to_left_edge + n_rows - 1
        offset_to_right_edge = offset_to_bottom_edge + n_cols - 1

        perimeter_nodes[0] = n_cols - 1

        # Right edge
        row = 1
        for i in range(1, offset_to_top_edge + 1):
            perimeter_nodes[i] = perimeter_nodes[i - 1] + nodes_per_row[row]
            row += 1

        # Top edge
        for i in range(offset_to_top_edge + 1, offset_to_left_edge + 1):
            perimeter_nodes[i] = perimeter_nodes[i - 1] - 1

        # Left edge
        row = n_rows - 2
        for i in range(offset_to_left_edge + 1, offset_to_bottom_edge + 1):
            perimeter_nodes[i] = perimeter_nodes[i - 1] - nodes_per_row[row]
            row -= 1

        # Bottom edge
        for i in range(offset_to_bottom_edge + 1, offset_to_right_edge):
            perimeter_nodes[i] = perimeter_nodes[i - 1] + 1
    finally:
        free(nodes_per_row)


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_perimeter_nodes_hex_vertical(
    shape,
    id_t [:] perimeter_nodes,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int longest_col = n_cols // 2
    cdef int max_nodes_per_row = n_cols - n_cols // 2
    cdef int offset_to_right_edge
    cdef int offset_to_top_edge
    cdef int offset_to_left_edge
    cdef int offset_to_bottom_edge
    cdef int i

    if n_cols % 2 == 1:
        offset_to_top_edge = n_rows - 1
    else:
        offset_to_top_edge = n_rows
    offset_to_left_edge = offset_to_top_edge + n_cols - 1
    offset_to_bottom_edge = offset_to_left_edge + n_rows - 1
    offset_to_right_edge = offset_to_bottom_edge + n_cols - 1

    # Bottom edge
    nodes_per_row = 1
    perimeter_nodes[offset_to_bottom_edge + longest_col] = 0
    for i in range(offset_to_bottom_edge + longest_col + 1, offset_to_right_edge):
        nodes_per_row += 1
        perimeter_nodes[i] = perimeter_nodes[i - 1] + nodes_per_row

    perimeter_nodes[0] = perimeter_nodes[offset_to_right_edge - 1] + max_nodes_per_row

    # Right edge
    for i in range(1, offset_to_top_edge + 1):
        perimeter_nodes[i] = perimeter_nodes[i - 1] + n_cols

    # Top edge
    nodes_per_row = max_nodes_per_row
    for i in range(offset_to_top_edge + 1, offset_to_left_edge - longest_col + 1):
        nodes_per_row -= 1
        perimeter_nodes[i] = perimeter_nodes[i - 1] + nodes_per_row
    nodes_per_row = 1
    for i in range(offset_to_left_edge - longest_col + 1, offset_to_left_edge):
        nodes_per_row += 1
        perimeter_nodes[i] = perimeter_nodes[i - 1] - nodes_per_row
    perimeter_nodes[offset_to_left_edge] = (
        perimeter_nodes[offset_to_left_edge - 1] - max_nodes_per_row
    )

    # Left edge
    for i in range(offset_to_left_edge + 1, offset_to_bottom_edge + 1):
        perimeter_nodes[i] = perimeter_nodes[i - 1] - n_cols

    # Bottom edge
    perimeter_nodes[offset_to_bottom_edge + 1] = (
        perimeter_nodes[offset_to_bottom_edge] - nodes_per_row
    )
    nodes_per_row = max_nodes_per_row
    for i in range(offset_to_bottom_edge + 2, offset_to_bottom_edge + longest_col):
        nodes_per_row -= 1
        perimeter_nodes[i] = perimeter_nodes[i - 1] - nodes_per_row



================================================
File: src/landlab/graph/matrix/__init__.py
================================================



================================================
File: src/landlab/graph/matrix/at_node.py
================================================
import numpy as np

from ...core.utils import as_id_array


def get_links(nodes_at_link, sort=True):
    """Get links and their directions at each node.

    Parameters
    ----------
    nodes_at_link : ndarray of int, shape `(n_links, 2)`
        Node identifier for each link tail and head.

    Returns
    -------
    tuple of ndarray of int
        Tuple of link identifiers for each node, link directions for each
        node and offsets into these arrays for each node.

    Examples
    --------
    ::
        0 -- 1
        |    | \
        2 -- 3 - 4

    >>> import numpy as np
    >>> nodes_at_link = np.array([[2, 3], [3, 4], [2, 0], [3, 1], [4, 1], [0, 1]])
    >>> (links_at_node, link_dirs_at_node, offset_to_node) = get_links(nodes_at_link)
    >>> links_at_node
    array([2, 5, 3, 4, 5, 0, 2, 0, 1, 3, 1, 4])
    >>> link_dirs_at_node
    array([ 1, -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1], dtype=int8)
    >>> offset_to_node
    array([ 0,  2,  5,  7, 10, 12])
    """
    sorted = np.argsort(nodes_at_link.reshape((-1,)), kind="stable")

    links_at_node = sorted // 2
    link_dirs_at_node = sorted % 2
    link_dirs_at_node[link_dirs_at_node == 0] = -1

    (_, links_per_node) = np.unique(nodes_at_link, return_counts=True)

    offset_to_node = np.empty(len(links_per_node) + 1, dtype=int)
    offset_to_node[0] = 0
    links_per_node.cumsum(out=offset_to_node[1:])

    return (
        as_id_array(links_at_node),
        np.asarray(link_dirs_at_node, dtype=np.int8),
        offset_to_node,
    )



================================================
File: src/landlab/graph/matrix/at_patch.py
================================================
import numpy as np

from ...utils.jaggedarray import unravel
from ..sort import sort_patches


def links_at_patch(patches, sort=True, nodes_at_link=None, xy_of_node=None):
    """Construct as links_at_patch array for a graph.

    Parameters
    ----------
    patches : tuple of ndarray of int
        Links that define patches as `(links, offset_to_patch)`.
    sort : bool, optional
        Sort the links.
    nodes_at_link : ndarray of int, shape `(n_links, 2)`
        Nodes at link tail and head.
    xy_of_node : ndarray of float, shape `(n_nodes, 2)`
        Coordinates of nodes.

    Examples
    --------
    """
    from ..quantity.ext.of_link import calc_midpoint_of_link
    from ..sort.ext.remap_element import reorder_links_at_patch

    links_at_patch, offset_to_patch = patches

    sort = False
    # print 'SORTING TURNED OFF'
    if sort:
        xy_of_link = np.empty((len(nodes_at_link), 2), dtype=float)
        calc_midpoint_of_link(
            nodes_at_link, xy_of_node[:, 0], xy_of_node[:, 1], xy_of_link
        )
        reorder_links_at_patch(links_at_patch, offset_to_patch, xy_of_link)

        sort_patches(links_at_patch, offset_to_patch, xy_of_link)

    return unravel(links_at_patch, offset_to_patch, pad=-1)



================================================
File: src/landlab/graph/matrix/ext/__init__.py
================================================



================================================
File: src/landlab/graph/matrix/ext/at_patch.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_links_at_patch(
    const id_t [:] links_at_patch,
    const id_t [:] offset_to_patch,
    id_t [:, :] out,
):
    cdef int i
    cdef int link
    cdef int patch
    cdef int offset
    cdef int n_links
    cdef int n_patches = len(offset_to_patch) - 1

    for patch in prange(n_patches, nogil=True, schedule="static"):
        offset = offset_to_patch[patch]
        n_links = offset_to_patch[patch + 1] - offset

        link = 0
        for i in range(offset, offset + n_links):
            out[patch, link] = links_at_patch[i]
            link = link + 1



================================================
File: src/landlab/graph/matrix/ext/matrix.pyx
================================================
cimport cython
from cython.parallel cimport prange
from libc.stdlib cimport free
from libc.stdlib cimport malloc
from libc.string cimport memcpy
from libc.string cimport memmove

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


cdef void roll(
    void * values,
    size_t n_values,
    size_t size,
    long shift,
) noexcept nogil:
    cdef size_t offset
    cdef void * src = values
    cdef void * dst
    cdef void * end
    cdef void * buff

    if shift == 0:
        return
    elif shift < 0:
        offset = (n_values + shift) % n_values
    else:
        offset = shift % n_values

    dst = <char *>values + offset * size
    end = <char *>src + (n_values - offset) * size
    buff = malloc(offset * size)

    memcpy(buff, end, offset * size)
    memmove(dst, src, (n_values - offset) * size)
    memcpy(src, buff, offset * size)

    free(buff)


@cython.boundscheck(False)
@cython.wraparound(False)
def roll_id_matrix_rows(
    id_t [:, :] matrix,
    id_t [:] shift,
):
    cdef int n_rows = matrix.shape[0]
    cdef int n_cols = matrix.shape[1]
    cdef int itemsize = matrix.itemsize
    cdef int row
    cdef int n

    for row in prange(n_rows, nogil=True, schedule="static"):
        n = 0
        while n < n_cols and matrix[row, n] != -1:
            n = n + 1

        roll(&matrix[row, 0], n, itemsize, shift[row])



================================================
File: src/landlab/graph/object/__init__.py
================================================
"""Get the connectivity of graphs objects."""



================================================
File: src/landlab/graph/object/at_node.py
================================================
import numpy as np

from landlab.core.utils import as_id_array


def get_links_at_node(graph, sort=False):
    """Set up data structures for node-to-link connectivity.

    Parameters
    ----------
    graph : Graph
        A `Graph`.

    nodes_at_link: ndarray of int
        Nodes at either end of a link (tail node, then head node).
    number_of_nodes: int, optional
        The total number of nodes. If not given, use the largest node in
        *nodes_at_link*.

    Returns
    -------
    tuple of ndarray
        Tuple of *links_at_node* and *link_dirs_at_node*.
    """
    from landlab.graph.object.ext.at_node import get_links_at_node

    node_count = np.bincount(graph.nodes_at_link.flat)
    number_of_nodes = graph.number_of_nodes

    max_node_count = np.max(node_count)

    link_dirs_at_node = np.full((number_of_nodes, max_node_count), 0, dtype=np.int8)
    links_at_node = np.full((number_of_nodes, max_node_count), -1, dtype=int)

    get_links_at_node(graph.nodes_at_link, links_at_node, link_dirs_at_node)

    if sort:
        sort_links_at_node_by_angle(
            links_at_node, link_dirs_at_node, graph.angle_of_link, inplace=True
        )

    return links_at_node, link_dirs_at_node


def sort_links_at_node_by_angle(
    links_at_node, link_dirs_at_node, angle_of_link, inplace=False
):
    """Sort links as spokes about a hub.

    Parameters
    ----------
    links_at_node : ndarray of int, shape `(n_nodes, max_links_per_node)`
        Links entering or leaving each node.
    link_dirs_at_node : ndarray of int, shape `(n_nodes, max_links_per_node)`
        Direction of links entering or leaving each node.
    angle_of_link : ndarray of float, shape `(n_links, )`
        Angle (in radians) of each link as measured from its head to tail.

    Returns
    -------
    tuple of (links_at_node, link_dirs_at_node)
        The sorted arrays. If `inplace` is `True`, these are the input
        arrays.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph.object.at_node import sort_links_at_node_by_angle

    ::

        (1) - 1 -> (3)
         |          ^
         2          3
         V          |
        (0) - 0 -> (2)


    >>> links_at_node = [[2, 0], [1, 2], [3, 0], [3, 1]]
    >>> link_dirs_at_node = [[1, -1], [-1, -1], [-1, 1], [1, 1]]
    >>> angle_of_link = np.array([0.0, 0.0, -90.0, 90.0]) * np.pi / 180.0

    >>> out = sort_links_at_node_by_angle(
    ...     links_at_node, link_dirs_at_node, angle_of_link
    ... )

    The first item of the returned tuple is links at each node sorted
    counterclockwise by angle.

    >>> out[0]
    array([[0, 2], [2, 1], [3, 0],  [1, 3]])

    The second item is the direction of the link (entering or leaving).

    >>> out[1]
    array([[-1,  1], [-1, -1], [-1,  1], [ 1,  1]], dtype=int8)

    Because the input arrays are lists, not numpy arrays, the sort is not
    in-place.

    >>> out[0] is not links_at_node
    True

    >>> links_at_node = np.asarray([[2, 0], [1, 2], [3, 0], [3, 1]], dtype=int)
    >>> link_dirs_at_node = np.asarray(
    ...     [[1, -1], [-1, -1], [-1, 1], [1, 1]], dtype=np.int8
    ... )
    >>> angle_of_link = np.array([0.0, 0.0, -90.0, 90.0]) * np.pi / 180.0

    >>> _ = sort_links_at_node_by_angle(
    ...     links_at_node, link_dirs_at_node, angle_of_link, inplace=True
    ... )
    >>> links_at_node
    array([[0, 2], [2, 1], [3, 0],  [1, 3]])
    >>> link_dirs_at_node
    array([[-1,  1], [-1, -1], [-1,  1], [ 1,  1]], dtype=int8)
    """
    from landlab.graph.object.ext.at_node import reorder_rows_inplace

    out = (
        np.asarray(links_at_node, dtype=int),
        np.asarray(link_dirs_at_node, dtype=np.int8),
    )

    if inplace and (out[0] is not links_at_node or out[1] is not link_dirs_at_node):
        raise ValueError(
            "links_at_node and link_dirs_at_node arrays must be ndarray for in-place sort"
        )

    if not inplace:
        if out[0] is links_at_node:
            out[0] = links_at_node.copy()
        if out[1] is link_dirs_at_node:
            out[1] = link_dirs_at_node.copy()

    links_at_node, link_dirs_at_node = out

    outward_angle = angle_of_link[links_at_node]

    links_entering = np.where(link_dirs_at_node == 1)
    outward_angle[links_entering] += np.pi
    outward_angle[outward_angle >= 2 * np.pi] -= 2 * np.pi

    outward_angle[np.where(link_dirs_at_node == 0)] = 4 * np.pi

    sorted_links = as_id_array(np.argsort(outward_angle))

    reorder_rows_inplace(links_at_node, sorted_links)
    reorder_rows_inplace(link_dirs_at_node, sorted_links)

    return links_at_node, link_dirs_at_node



================================================
File: src/landlab/graph/object/at_patch.py
================================================
import numpy as np

from .ext.at_patch import get_nodes_at_patch as _get_nodes_at_patch


def get_nodes_at_patch(graph):
    """Set up data structure that describes node-patch connectivity.

    Parameters
    ----------
    links_at_patch: ndarray
        Links that define each patch.
    nodes_at_link: ndarray
        Nodes that define each link.

    Returns
    -------
    ndarray
        Nodes that define each patch.
    """
    nodes_at_patch = np.full(graph.links_at_patch.shape, -1, dtype=int)

    _get_nodes_at_patch(graph.links_at_patch, graph.nodes_at_link, nodes_at_patch)

    return nodes_at_patch



================================================
File: src/landlab/graph/object/ext/__init__.py
================================================



================================================
File: src/landlab/graph/object/ext/at_node.pyx
================================================
cimport cython
cimport numpy as np
from cython.parallel cimport parallel
from cython.parallel cimport prange
from libc.stdint cimport int8_t
from libc.stdlib cimport free
from libc.stdlib cimport malloc
import numpy as np

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused float_or_int:
    cython.floating
    cython.integral
    long long
    int8_t

ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
cdef long _find_links_at_node(
    const int node,
    const id_t[:, :] nodes_at_link,
    id_t[:] links_at_node,
    int8_t[:] link_dirs_at_node,
) noexcept nogil:
    """Find links touching a node and their directions.

    Parameters
    ----------
    node : int
        A node ID.
    nodes_at_link : ndarray of int, shape `(n_links, 2)`
        Nodes at link tail and head.
    links_at_node : ndarray of int, shape `(max_links_per_node, )`
        Buffer to hold link identifiers for links around node.
    link_dirs_at_node : ndarray of int, shape `(max_links_per_node, )`
        Buffer to hold link directions for links around node.

    Returns
    -------
    int
        The number of links found.
    """
    cdef long link = 0
    cdef long n_links_found = 0
    cdef long max_links_at_node = links_at_node.shape[0]
    cdef long n_links = nodes_at_link.shape[0]

    while n_links_found < max_links_at_node and link < n_links:
        if nodes_at_link[link, 0] == node:
            links_at_node[n_links_found] = link
            link_dirs_at_node[n_links_found] = -1
            n_links_found += 1
        elif nodes_at_link[link, 1] == node:
            links_at_node[n_links_found] = link
            link_dirs_at_node[n_links_found] = 1
            n_links_found += 1

        link += 1

    return n_links_found


@cython.boundscheck(False)
@cython.wraparound(False)
def get_links_at_node(
    const id_t[:, :] nodes_at_link,
    id_t[:, :] links_at_node,
    int8_t[:, :] link_dirs_at_node,
):
    """Get links touching each node and their directions.

    Parameters
    ----------
    nodes_at_link : ndarray of int, shape `(n_links, 2)`
        Node identifiers for each link tail and head.
    links_at_node : ndarray of int, shape `(n_nodes, max_nodes_per_link)`
        Buffer to hold link identifiers for each node.
    link_dirs_at_node : ndarray of int, shape `(n_nodes, max_nodes_per_link)`
        Buffer to hold link directions for each node.
    """
    cdef int node
    cdef int n_nodes = links_at_node.shape[0]

    for node in prange(n_nodes, nogil=True, schedule="static"):
        _find_links_at_node(
            node, nodes_at_link, links_at_node[node], link_dirs_at_node[node]
        )


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_rows(
    float_or_int[:, :] value_at_row,
    const id_t[:, :] sorted_cols,
):
    cdef long n_rows = value_at_row.shape[0]
    cdef long n_cols = value_at_row.shape[1]
    cdef long row
    cdef long col
    cdef np.ndarray[float_or_int, ndim=2] out = np.empty_like(value_at_row)

    for row in prange(n_rows, nogil=True, schedule="static"):
        for col in range(n_cols):
            out[row, col] = value_at_row[row, sorted_cols[row, col]]

    return out


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_rows_inplace(
    float_or_int[:, :] value_at_row,
    const id_t[:, :] sorted_cols,
):
    cdef int n_rows = value_at_row.shape[0]
    cdef int n_cols = value_at_row.shape[1]
    cdef int row
    cdef int col
    cdef float_or_int *scratch

    with nogil, parallel():
        scratch = <float_or_int *>malloc(n_cols * sizeof(float_or_int))

        for row in prange(n_rows, schedule="static"):
            for col in range(n_cols):
                scratch[col] = value_at_row[row, sorted_cols[row, col]]
            for col in range(n_cols):
                value_at_row[row, col] = scratch[col]

        free(scratch)


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_links_at_node(
    id_t[:, :] links_at_node,
    const id_t[:, :] sorted_links,
):
    cdef int n_nodes = links_at_node.shape[0]
    cdef int n_links_per_node = links_at_node.shape[1]
    cdef int i
    cdef int node
    cdef int *buffer = <int *>malloc(n_links_per_node * sizeof(int))

    try:
        for node in range(n_nodes):
            for i in range(n_links_per_node):
                buffer[i] = links_at_node[node, sorted_links[node, i]]
            for i in range(n_links_per_node):
                links_at_node[node, i] = buffer[i]
    finally:
        free(buffer)


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_link_dirs_at_node(
    int8_t[:, :] link_dirs_at_node,
    const id_t[:, :] sorted_links,
):
    cdef int n_nodes = link_dirs_at_node.shape[0]
    cdef int n_links_per_node = link_dirs_at_node.shape[1]
    cdef int i
    cdef int node
    cdef int *buffer = <int *>malloc(n_links_per_node * sizeof(int))

    try:
        for node in range(n_nodes):
            for i in range(n_links_per_node):
                buffer[i] = link_dirs_at_node[node, sorted_links[node, i]]
            for i in range(n_links_per_node):
                link_dirs_at_node[node, i] = buffer[i]
    finally:
        free(buffer)



================================================
File: src/landlab/graph/object/ext/at_patch.pyx
================================================
cimport cython
from cython.parallel cimport prange
from libc.stdint cimport int8_t

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused float_or_int:
    cython.floating
    cython.integral
    long long
    int8_t

ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def get_rightmost_edge_at_patch(
    const id_t [:, :] links_at_patch,
    const cython.floating [:, :] xy_of_link,
    id_t [:] edge,
):
    cdef int n_patches = links_at_patch.shape[0]
    cdef int n_cols = links_at_patch.shape[1]
    cdef int patch
    cdef int link
    cdef int n
    cdef int max_n
    cdef double max_x

    for patch in prange(n_patches, nogil=True, schedule="static"):
        link = links_at_patch[patch, 0]
        max_x, max_n = xy_of_link[link][0], 0

        for n in range(1, n_cols):
            link = links_at_patch[patch, n]
            if link == -1:
                break
            if xy_of_link[link][0] > max_x:
                max_x, max_n = xy_of_link[link][0], n
        edge[patch] = max_n


cdef id_t find_common_node(
    const id_t * link_a,
    const id_t * link_b,
) noexcept nogil:
    if link_a[0] == link_b[0] or link_a[0] == link_b[1]:
        return link_a[0]
    elif link_a[1] == link_b[0] or link_a[1] == link_b[1]:
        return link_a[1]
    else:
        raise ValueError("links are not connected")


cdef long all_nodes_at_patch(
    const id_t * links_at_patch,
    long max_links,
    const id_t * nodes_at_link,
    long * out,
) noexcept nogil:
    cdef long n_links = max_links
    cdef long link
    cdef long i
    cdef long n_nodes = 0

    while links_at_patch[n_links - 1] == -1:
        n_links -= 1

    for i in range(n_links):
        link = links_at_patch[i]

        out[n_nodes] = nodes_at_link[link * 2]
        out[n_nodes + 1] = nodes_at_link[link * 2 + 1]

        n_nodes += 2

    return n_links


cdef void order_nodes_at_patch(
    const id_t * all_nodes_at_patch,
    id_t * out,
    const long n_vertices,
):
    cdef long i
    cdef long vertex

    out[0] = all_nodes_at_patch[1]
    for vertex in range(n_vertices - 1):
        i = vertex * 2
        while all_nodes_at_patch[i] != out[vertex]:
            i += 1
        if i % 2 == 0:
            out[vertex + 1] = all_nodes_at_patch[i + 1]
        else:
            out[vertex + 1] = all_nodes_at_patch[i - 1]


@cython.boundscheck(False)
@cython.wraparound(False)
def get_nodes_at_patch(
    const id_t [:, :] links_at_patch,
    const id_t [:, :] nodes_at_link,
    id_t [:, :] nodes_at_patch,
):
    cdef int n_patches = links_at_patch.shape[0]
    cdef int max_links_at_patch = links_at_patch.shape[1]
    cdef int patch

    for patch in prange(n_patches, nogil=True, schedule="static"):
        _nodes_at_patch(
            &links_at_patch[patch, 0],
            max_links_at_patch,
            &nodes_at_link[0, 0],
            &nodes_at_patch[patch, 0],
        )


cdef long _nodes_at_patch(
    const id_t * links_at_patch,
    const long max_links,
    const id_t * nodes_at_link,
    id_t * out,
) noexcept nogil:
    cdef long n_links = max_links
    cdef long link, next_link
    cdef long i

    while links_at_patch[n_links - 1] == -1:
        n_links -= 1

    next_link = links_at_patch[0]
    for i in range(0, n_links - 1):
        link, next_link = next_link, links_at_patch[i + 1]

        out[i] = find_common_node(
            &nodes_at_link[link * 2], &nodes_at_link[next_link * 2]
        )

    link, next_link = links_at_patch[n_links - 1], links_at_patch[0]
    out[n_links - 1] = find_common_node(
        &nodes_at_link[link * 2], &nodes_at_link[next_link * 2]
    )

    return n_links



================================================
File: src/landlab/graph/quantity/__init__.py
================================================
"""Get quatities associated with graph objects."""



================================================
File: src/landlab/graph/quantity/of_link.py
================================================
import numpy as np


def get_angle_of_link(graph, out=None):
    """Get angles of links in a graph.

    Parameters
    ----------
    graph : `Graph`
        A `Graph`.

    Returns
    -------
    ndarray of float
        Angle of each link as measured in radians from link tail to head.
    out : ndarray of float, optional
        Buffer to place output.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import UniformRectilinearGraph
    >>> from landlab.graph.quantity.of_link import get_angle_of_link

    >>> graph = UniformRectilinearGraph((2, 2))
    >>> get_angle_of_link(graph) * 180.0 / np.pi
    array([  0.,  90.,  90.,   0.])

    >>> angles = np.empty(graph.number_of_links, dtype=float)
    >>> rtn = get_angle_of_link(graph, out=angles)
    >>> angles is rtn
    True
    """
    if out is None:
        out = np.empty(graph.number_of_links, dtype=float)

    y = graph.y_of_node[graph.nodes_at_link]
    x = graph.x_of_node[graph.nodes_at_link]

    np.arctan2(np.diff(y).flat, np.diff(x).flat, out=out)

    return np.mod(out, 2.0 * np.pi, out=out)


def get_midpoint_of_link(graph, out=None):
    """Get xy position of the midpoint of links.

    Parameters
    ----------
    graph : `Graph`
        A `Graph`.
    out : ndarray of float, optional
        Buffer to place output.

    Returns
    -------
    ndarray of float, shape `(n_links, 2)`
        Coordinates of link midpoints.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import UniformRectilinearGraph
    >>> from landlab.graph.quantity.of_link import get_midpoint_of_link

    >>> graph = UniformRectilinearGraph((2, 2))
    >>> get_midpoint_of_link(graph)
    array([[0.5, 0. ],
           [0. , 0.5],
           [1. , 0.5],
           [0.5, 1. ]])

    >>> points = np.empty((graph.number_of_links, 2), dtype=float)
    >>> rtn = get_midpoint_of_link(graph, out=points)
    >>> points is rtn
    True
    """
    from .ext.of_link import calc_midpoint_of_link

    if out is None:
        out = np.empty((graph.number_of_links, 2), dtype=float)

    calc_midpoint_of_link(graph.nodes_at_link, graph.x_of_node, graph.y_of_node, out)

    return out


def get_length_of_link(graph):
    nodes_at_link = graph.nodes_at_link
    dx = graph.x_of_node[nodes_at_link[:, 0]] - graph.x_of_node[nodes_at_link[:, 1]]
    dy = graph.y_of_node[nodes_at_link[:, 0]] - graph.y_of_node[nodes_at_link[:, 1]]
    return np.sqrt(dx**2 + dy**2)



================================================
File: src/landlab/graph/quantity/of_patch.py
================================================
import numpy as np


def get_area_of_patch(graph, out=None):
    from .ext.of_patch import calc_area_at_patch

    if out is None:
        out = np.empty(graph.number_of_patches, dtype=float)

    calc_area_at_patch(
        graph.nodes_at_patch,
        np.ascontiguousarray(graph.x_of_node),
        np.ascontiguousarray(graph.y_of_node),
        out,
    )

    return out


def get_centroid_of_patch(graph, out=None):
    from .ext.of_patch import calc_centroid_at_patch

    if out is None:
        out = np.empty((graph.number_of_patches, 2), dtype=float)

    # calc_centroid_at_patch(
    #     graph.nodes_at_patch,
    #     np.ascontiguousarray(graph.x_of_node),
    #     np.ascontiguousarray(graph.y_of_node),
    #     out,
    # )

    links_at_patch = graph.ds["links_at_patch"].values
    calc_centroid_at_patch(
        links_at_patch,
        # graph.links_at_patch,
        np.ascontiguousarray(graph.xy_of_link[:, 0]),
        np.ascontiguousarray(graph.xy_of_link[:, 1]),
        # graph.ds["nodes_at_patch"].values,
        # graph.nodes_at_patch,
        # np.ascontiguousarray(graph.x_of_node),
        # np.ascontiguousarray(graph.y_of_node),
        out,
    )

    return out



================================================
File: src/landlab/graph/quantity/ext/__init__.py
================================================



================================================
File: src/landlab/graph/quantity/ext/of_element.pyx
================================================
cimport cython
from cython.parallel import prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long

ctypedef fused integral_out_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef diff_of_children_at_parent(
    const id_t [:, :] children_at_parent,
    const cython.floating [:] value_at_parent,
    const cython.floating [:] value_at_child,
    cython.floating [:, :] out,
):
    """Calculate differences between parents and children.

    Parameters
    ----------
    children_at_parent : array of shape (n_parents, max_children)
        Array that specifies the children of each parent as indices
        into the *value_at_child* array. Values of -1 indicate
        non-existant children.
    value_at_parent : array
        Value for each parent.
    value_at_child : array
        Value for each child.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int parent, child
    cdef int col

    for parent in prange(n_parents, nogil=True, schedule="static"):
        for col in range(n_cols):
            child = children_at_parent[parent, col]
            if child >= 0:
                out[parent, col] = value_at_child[child] - value_at_parent[parent]


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef mean_of_children_at_parent(
    id_t [:, :] children_at_parent,
    cython.floating [:] value_at_child,
    cython.floating [:] out,
):
    """Calculate means of parents' children.

    Parameters
    ----------
    children_at_parent : array of shape (n_parents, max_children)
        Array that specifies the children of each parent as indices
        into the *value_at_child* array. Values of -1 indicate
        non-existant children.
    value_at_child : array
        Value for each child.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int parent, col
    cdef int child
    cdef int count
    cdef cython.floating total

    for parent in prange(n_parents, nogil=True, schedule="static"):
        count = 0
        total = 0
        for col in range(n_cols):
            child = children_at_parent[parent, col]
            if child >= 0:
                total = total + value_at_child[child]
                count = count + 1
        if count > 0:
            out[parent] = total / count


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef min_of_children_at_parent(
    id_t [:, :] children_at_parent,
    cython.floating [:] value_at_child,
    cython.floating [:] out,
):
    """Calculate minimums of parents' children.

    Parameters
    ----------
    children_at_parent : array of shape (n_parents, max_children)
        Array that specifies the children of each parent as indices
        into the *value_at_child* array. Values of -1 indicate
        non-existant children.
    value_at_child : array
        Value for each child.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int parent, col
    cdef int child
    cdef cython.floating value, min_value
    cdef int first

    for parent in prange(n_parents, nogil=True, schedule="static"):
        first = n_cols
        for col in range(n_cols):
            child = children_at_parent[parent, col]
            if child != -1:
                first = col
                min_value = value_at_child[child]
                break
        for col in range(first + 1, n_cols):
            child = children_at_parent[parent, col]
            if child != -1:
                value = value_at_child[child]
                if value < min_value:
                    min_value = value
        if first < n_cols:
            out[parent] = min_value


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef max_of_children_at_parent(
    id_t [:, :] children_at_parent,
    cython.floating [:] value_at_child,
    cython.floating [:] out,
):
    """Calculate maximums of parents' children.

    Parameters
    ----------
    children_at_parent : array of shape (n_parents, max_children)
        Array that specifies the children of each parent as indices
        into the *value_at_child* array. Values of -1 indicate
        non-existant children.
    value_at_child : array
        Value for each child.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int parent, col
    cdef int child
    cdef cython.floating value, max_value
    cdef int first

    for parent in prange(n_parents, nogil=True, schedule="static"):
        first = n_cols
        for col in range(n_cols):
            child = children_at_parent[parent, col]
            if child != -1:
                first = col
                max_value = value_at_child[child]
                break
        for col in range(first + 1, n_cols):
            child = children_at_parent[parent, col]
            if child != -1:
                value = value_at_child[child]
                if value > max_value:
                    max_value = value
        if first < n_cols:
            out[parent] = max_value


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef count_of_children_at_parent(
    const id_t [:, :] children_at_parent,
    integral_out_t [:] out,
):
    """Count the number of children for each parent.

    Parameters
    ----------
    children_at_parent : array of shape (n_parents, max_children)
        Array that specifies the children of each parent as indices
        into the *value_at_child* array. Values of -1 indicate
        non-existant children.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int parent, col
    cdef int count

    for parent in prange(n_parents, nogil=True, schedule="static"):
        count = 0
        for col in range(n_cols):
            if children_at_parent[parent, col] != -1:
                count = count + 1
        out[parent] = count



================================================
File: src/landlab/graph/quantity/ext/of_link.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_midpoint_of_link(
    const id_t [:, :] nodes_at_link,
    const cython.floating [:] x_of_node,
    const cython.floating [:] y_of_node,
    cython.floating [:, :] xy_of_link,
):
    cdef int link
    cdef int n_links = nodes_at_link.shape[0]
    cdef int link_tail
    cdef int link_head

    for link in prange(n_links, nogil=True, schedule="static"):
        link_tail = nodes_at_link[link, 0]
        link_head = nodes_at_link[link, 1]

        xy_of_link[link][0] = (x_of_node[link_tail] + x_of_node[link_head]) * .5
        xy_of_link[link][1] = (y_of_node[link_tail] + y_of_node[link_head]) * .5



================================================
File: src/landlab/graph/quantity/ext/of_patch.pyx
================================================
cimport cython
from cython.parallel cimport prange
from libc.stdlib cimport free
from libc.stdlib cimport malloc

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_area_at_patch(
    const id_t [:, :] nodes_at_patch,
    const cython.floating [:] x_of_node,
    const cython.floating [:] y_of_node,
    cython.floating [:] out,
):
    cdef long n_patches = nodes_at_patch.shape[0]
    cdef long n_vertices = nodes_at_patch.shape[1]
    cdef long n

    for n in prange(n_patches, nogil=True, schedule="static"):
        out[n] = calc_area_of_patch(
            &nodes_at_patch[n, 0], n_vertices, &x_of_node[0], &y_of_node[0]
        )


cdef cython.floating calc_area_of_patch(
    const id_t * nodes_at_patch,
    const long n_vertices,
    const cython.floating * x_of_node,
    const cython.floating * y_of_node,
) noexcept nogil:
    cdef int n
    cdef int node
    cdef cython.floating * x_of_vertex = <cython.floating *>malloc(
        n_vertices * sizeof(cython.floating)
    )
    cdef cython.floating * y_of_vertex = <cython.floating *>malloc(
        n_vertices * sizeof(cython.floating)
    )

    try:
        for n in range(n_vertices):
            node = nodes_at_patch[n]
            if node == -1:
                n -= 1
                break
            x_of_vertex[n] = x_of_node[node]
            y_of_vertex[n] = y_of_node[node]

        return calc_area_of_polygon(x_of_vertex, y_of_vertex, n + 1)
    finally:
        free(y_of_vertex)
        free(x_of_vertex)


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_centroid_at_patch(
    const id_t [:, :] nodes_at_patch,
    const cython.floating [:] x_of_node,
    const cython.floating [:] y_of_node,
    cython.floating [:, :] out,
):
    cdef long n_patches = nodes_at_patch.shape[0]
    cdef long n_vertices = nodes_at_patch.shape[1]
    cdef long n

    for n in prange(n_patches, nogil=True, schedule="static"):
        calc_centroid_of_patch(
            &nodes_at_patch[n, 0], n_vertices, &x_of_node[0], &y_of_node[0], &out[n, 0]
        )


cdef void calc_centroid_of_patch(
    const id_t * nodes_at_patch,
    const long n_vertices,
    const cython.floating * x_of_node,
    const cython.floating * y_of_node,
    cython.floating * out,
) noexcept nogil:
    cdef int n
    cdef int node
    cdef cython.floating * x = <cython.floating *>malloc(
        n_vertices * sizeof(cython.floating)
    )
    cdef cython.floating * y = <cython.floating *>malloc(
        n_vertices * sizeof(cython.floating)
    )

    try:
        for n in range(n_vertices):
            node = nodes_at_patch[n]
            if node == -1:
                n -= 1
                break
            x[n] = x_of_node[node]
            y[n] = y_of_node[node]
        calc_centroid_of_polygon(x, y, n + 1, out)
    finally:
        free(y)
        free(x)


cdef void calc_centroid_of_polygon(
    const cython.floating * x,
    const cython.floating * y,
    const long n_vertices,
    cython.floating * out,
) noexcept nogil:
    cdef double x_of_centroid = 0.
    cdef double y_of_centroid = 0.
    cdef double area = calc_area_of_polygon(x, y, n_vertices)
    cdef double c
    cdef int n

    c = x[n_vertices - 1] * y[0] - x[0] * y[n_vertices - 1]
    x_of_centroid = (x[n_vertices - 1] + x[0]) * c
    y_of_centroid = (y[n_vertices - 1] + y[0]) * c

    for n in range(n_vertices - 1):
        c = x[n] * y[n + 1] - x[n + 1] * y[n]
        x_of_centroid += (x[n] + x[n + 1]) * c
        y_of_centroid += (y[n] + y[n + 1]) * c

    # c = x[n_vertices - 1] * y[0] - x[0] - y[n_vertices - 1]
    # x_of_centroid += (x[n_vertices - 1] + x[0]) * c
    # y_of_centroid += (y[n_vertices - 1] + y[0]) * c

    x_of_centroid /= 6. * area
    y_of_centroid /= 6. * area

    out[0] = x_of_centroid
    out[1] = y_of_centroid


cdef cython.floating calc_area_of_polygon(
    const cython.floating * x,
    const cython.floating * y,
    const long n_vertices,
) noexcept nogil:
    cdef double area = 0.
    cdef int n

    for n in range(n_vertices - 1):
        area += x[n] * y[n + 1]
        area -= x[n + 1] * y[n]
    area += x[n_vertices - 1] * y[0]
    area -= x[0] * y[n_vertices - 1]
    area *= 0.5

    return area



================================================
File: src/landlab/graph/quasi_spherical/__init__.py
================================================



================================================
File: src/landlab/graph/quasi_spherical/dual_icosphere.py
================================================
#!/usr/bin/python
"""
icosphere_global_grid: Create a Landlab global (i.e., quasi-spherical)
grid based on an IcoSphere, which is formed by iteratively densifying
an icosahedron.

Greg Tucker, University of Colorado Boulder, September 2023
"""

import numpy as np

from landlab.graph.quasi_spherical.refinable_icosahedron import RefinableIcosahedron
from landlab.utils.geometry.spherical import arc_length
from landlab.utils.geometry.spherical import area_of_sphertri
from landlab.utils.geometry.spherical import cartesian_to_spherical
from landlab.utils.geometry.spherical import rotate_zy


class DualIcosphereGraph:
    """
    A Landlab global (quasi-spherical) graph type based on an IcoSphere.

    Parameters
    ----------
    radius : float, optional
        Radius for the icosphere, m (default 1)
    mesh_densification_level : int, optional
        Number of iterative subdivisions of initial triangles (default 0)
    """

    def __init__(self, radius=1.0, mesh_densification_level=0):
        """
        Initialize DualIcosphereGraph

        Parameters
        ----------
        radius : float, optional
            Radius of the sphere (default 1.0)
        mesh_densification_level : int, optional
            Number of times to subdivide the mesh (default 0)

        Notes
        -----
        Data structures set up include the following (note that
        n_cells = n_nodes and n_faces = n_links):
        - coords_of_node : ndarray of float (n_nodes, 3)
        - x_of_node, y_of_node, z_of_node : ((n_nodes, ) views of coords_of_node)
        - coords_of_corner : ndarray of float (n_corners, 3)
        - x_of_corner, y_of_corner, z_of_corner : ndarray of float (n_corners, )
        - length_of_link : ndarray of float (n_links, )
        - nodes_at_link : ndarray of int (n_links, 2)
        - node_at_link_tail, node_at_link_head : (n_links, ) views of nodes_at_link
        - links_at_node : ndarray of int (n_nodes, 6)
        - cell_at_node, node_at_cell : ndarray of int (n_nodes, )
        - corners_at_face : ndarray of int (n_links, 2)
        - corners_at_node, corners_at_cell : ndarray of int (n_nodes, 6)
        - area_of_cell : ndarray of float (n_nodes, )
        - length_of_face : ndarray of float (n_links, )
        - link_at_face, face_at_link : ndarray of int (n_links, )
        - faces_at_cell : ndarray of int (n_nodes, 6)
        - adjacent_nodes_at_node : ndarray of int (n_nodes, 6)

        Examples
        --------
        >>> import numpy as np

        Basic example: dodecahedron

        >>> ico = DualIcosphereGraph()
        >>> np.round(ico.coords_of_node[0], 3)
        array([-0.526,  0.851,  0.   ])
        >>> ico.r_of_node[0]
        1.0
        >>> int(ico.phi_of_node[0] * 100), int(ico.theta_of_node[0] * 100)
        (212, 157)
        >>> np.round(ico.coords_of_corner[1], 3)
        array([-0.   ,  0.934,  0.357])
        >>> round(ico.length_of_link[0], 3)
        1.107
        >>> ico.nodes_at_link[0]
        array([ 0, 11])
        >>> ico.links_at_node[0]
        array([ 0,  2,  4,  6,  8, -1])
        >>> ico.cell_at_node[0]
        0
        >>> ico.node_at_cell[1]
        1
        >>> ico.corners_at_face[0]
        array([0, 4])
        >>> int(10000 * ico.length_of_face[0])
        7297
        >>> ico.corners_at_node[0]
        array([ 3,  4,  0,  1,  2, -1])
        >>> ico.corners_at_cell[0]
        array([ 3,  4,  0,  1,  2, -1])
        >>> int(1e6 * ico.area_of_cell[0])
        1047197
        >>> ico.link_at_face[2]
        2
        >>> ico.face_at_link[3]
        3
        >>> ico.faces_at_cell[0]
        array([ 0,  2,  4,  6,  8, -1])
        >>> ico.adjacent_nodes_at_node[0]
        array([11,  5,  1,  7, 10, -1])

        Icosphere with 1 level of subdivision

        >>> ico = DualIcosphereGraph(mesh_densification_level=1)
        >>> ico.number_of_patches
        80
        """
        ico = RefinableIcosahedron(radius)
        if mesh_densification_level > 0:
            ico.refine_triangles(mesh_densification_level)

        self._radius = radius
        self._setup_nodes(ico.vertices)
        self._setup_links(ico.faces)
        self._setup_patches_and_corners(ico.faces)
        self._setup_faces()
        self._setup_cells()

    def _setup_faces(self):
        """
        Create corners_at_face and length_of_face.
        """
        # Set up a temporary dict to look up patches by pairs of shared nodes.
        patches_at_node_pair = {}
        for i in range(self.number_of_patches):
            for j in range(3):
                n1 = self.nodes_at_patch[i, j - 1]
                n2 = self.nodes_at_patch[i, j]
                key = (min(n1, n2), max(n1, n2))
                try:
                    patch1 = patches_at_node_pair[key]
                    patches_at_node_pair[key] = (min(i, patch1), max(i, patch1))
                except KeyError:
                    patches_at_node_pair[key] = i

        self.number_of_faces = self.number_of_links
        self.corners_at_face = np.zeros((self.number_of_faces, 2), dtype=int)
        self.length_of_face = np.zeros(self.number_of_faces)
        for face in range(self.number_of_faces):
            ln1 = min(self.nodes_at_link[face])
            ln2 = max(self.nodes_at_link[face])
            cnr0, cnr1 = patches_at_node_pair[(ln1, ln2)]
            # the corners are the same as patches, and faces same as links, so we
            # can assign the two corners (patches) to the face (link)
            self.corners_at_face[face, 0] = cnr0
            self.corners_at_face[face, 1] = cnr1
            self.length_of_face[face] = self._radius * arc_length(
                self.coords_of_corner[cnr0], self.coords_of_corner[cnr1], self._radius
            )

    def _setup_nodes(self, ico_vertices):
        """
        Set up the arrays coords_of_node, x_of_node, y_of_node, z_of_node
        (the latter 3 being views of the coords_of_node).

        Parameters
        ----------
        ico_vertices : list of 3-element tuples
            List of vertices from RefinableIcosahedron

        Examples
        --------
        >>> grid = DualIcosphereGraph()
        >>> grid.number_of_nodes
        12
        """
        nverts = len(ico_vertices)
        self.coords_of_node = np.zeros((nverts, 3))
        self.x_of_node = self.coords_of_node[:, 0]
        self.y_of_node = self.coords_of_node[:, 1]
        self.z_of_node = self.coords_of_node[:, 2]
        self.number_of_nodes = nverts
        for i in range(nverts):
            vtx = ico_vertices[i]
            self.x_of_node[i] = vtx[0]
            self.y_of_node[i] = vtx[1]
            self.z_of_node[i] = vtx[2]

    def _add_link(self, p1, p2):
        """
        Add a link between p1 and p2 to a temporary list of links,
        if it doesn't already exist.

        Parameters
        ----------
        p1, p2 : int
            IDs of the two points.
        """
        key = (min(p1, p2) << 32) + max(p1, p2)
        if not (key in self.links):
            self.links[key] = (p1, p2)

    def _setup_links(self, ico_faces):
        """
        Set up link-related data structures.

        Parameters
        ----------
        ico_faces : list of 3-int tuples
            List of triangular faces

        Examples
        --------
        >>> ico = DualIcosphereGraph()
        >>> ico.number_of_links
        30
        """
        self.links = {}
        self.nodes_at_link = np.zeros((int(1.5 * len(ico_faces)), 2), dtype=int)
        self.links_at_node = np.zeros((self.number_of_nodes, 6), dtype=int) - 1
        self.link_dirs_at_node = np.zeros((self.number_of_nodes, 6), dtype=int)
        self.adjacent_nodes_at_node = np.zeros((self.number_of_nodes, 6), dtype=int) - 1
        link_at_node_index = np.zeros(self.number_of_nodes, dtype=int)
        for icoface in ico_faces:
            self._add_link(icoface[0], icoface[1])
            self._add_link(icoface[1], icoface[2])
            self._add_link(icoface[2], icoface[0])
        i = 0
        self.number_of_links = len(self.links)
        self.length_of_link = np.zeros(self.number_of_links)
        for link in self.links.values():
            tail = link[0]
            head = link[1]
            self.nodes_at_link[i, 0] = tail
            self.links_at_node[tail, link_at_node_index[tail]] = i
            self.link_dirs_at_node[tail, link_at_node_index[tail]] = -1
            self.adjacent_nodes_at_node[tail, link_at_node_index[tail]] = head
            link_at_node_index[tail] += 1
            self.nodes_at_link[i, 1] = head
            self.links_at_node[head, link_at_node_index[head]] = i
            self.link_dirs_at_node[head, link_at_node_index[head]] = 1
            self.adjacent_nodes_at_node[head, link_at_node_index[head]] = tail
            link_at_node_index[head] += 1
            self.length_of_link[i] = self._radius * arc_length(
                self.coords_of_node[tail], self.coords_of_node[head], self._radius
            )
            i += 1
        self.node_at_link_tail = self.nodes_at_link[:, 0]
        self.node_at_link_head = self.nodes_at_link[:, 1]

    @property
    def cell_at_node(self):
        try:
            return self._cell_at_node
        except AttributeError:
            self._cell_at_node = np.arange(self.number_of_nodes, dtype=int)
            return self._cell_at_node

    @property
    def node_at_cell(self):
        return self.cell_at_node

    @property
    def face_at_link(self):
        try:
            return self._face_at_link
        except AttributeError:
            self._face_at_link = np.arange(self.number_of_links, dtype=int)
            return self._face_at_link

    @property
    def link_at_face(self):
        return self.face_at_link

    @property
    def patches_at_node(self):
        return self.corners_at_node

    @property
    def corners_at_cell(self):
        return self.corners_at_node

    @property
    def faces_at_cell(self):
        """Face-cell and node-link numbering are the same!"""
        return self.links_at_node

    @property
    def area_of_patch(self):
        try:
            return self._area_of_patch
        except AttributeError:
            self._calc_area_of_patch()
            return self._area_of_patch

    @property
    def r_of_node(self):
        try:
            return self._r_of_node
        except AttributeError:
            self._setup_node_spherical_coords()
            return self._r_of_node

    @property
    def phi_of_node(self):
        try:
            return self._phi_of_node
        except AttributeError:
            self._setup_node_spherical_coords()
            return self._phi_of_node

    @property
    def theta_of_node(self):
        try:
            return self._theta_of_node
        except AttributeError:
            self._setup_node_spherical_coords()
            return self._theta_of_node

    def _set_coords_of_corner(self):
        """
        Set up (x,y,z) coordinates for each corner.

        Examples
        --------
        >>> import numpy as np
        >>> ico = DualIcosphereGraph()
        >>> ico.x_of_corner**2 + ico.y_of_corner**2 + ico.z_of_corner**2
        array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
               1., 1., 1.])
        """

        p0 = self.coords_of_node[self.nodes_at_patch[:, 0]]
        p1 = self.coords_of_node[self.nodes_at_patch[:, 1]]
        p2 = self.coords_of_node[self.nodes_at_patch[:, 2]]

        U = p1 - p0  # one side of each tri
        V = p2 - p0  # another side of each tri

        self.coords_of_corner = np.cross(U, V)  # cross-product gives normal vector
        self.x_of_corner = self.coords_of_corner[:, 0]
        self.y_of_corner = self.coords_of_corner[:, 1]
        self.z_of_corner = self.coords_of_corner[:, 2]
        veclen = np.sqrt(
            self.x_of_corner**2 + self.y_of_corner**2 + self.z_of_corner**2
        )  # this is the vector length...
        for i in range(3):
            self.coords_of_corner[:, i] *= (
                self._radius / veclen
            )  # ... which we use to normalize

    def _setup_patches_and_corners(self, ico_faces):
        """
        Set up nodes_at_patch and corners_at_node.

        Parameters
        ----------
        ico_faces : list of 3-int tuples
            List of triangular faces

        Notes
        -----
        Landlab *patches* are the same as what the original algorithm/code
        calls "faces": the triangles that have *nodes* as vertices and
        *links* as edges.

        We assume that the corners are the unit normals of the triangular
        patches (which the original algorithm calls faces), rescaled for
        the given radius.

        Examples
        --------
        >>> import numpy as np
        >>> ico = DualIcosphereGraph()
        >>> ico.number_of_corners
        20
        >>> ico.number_of_patches
        20
        >>> ico.nodes_at_patch[0]
        array([ 0, 11,  5])
        >>> ico.corners_at_node[1]
        array([ 2,  1,  5, 19,  9, -1])
        >>> ico.patches_at_node[1]
        array([ 2,  1,  5, 19,  9, -1])
        """
        self.number_of_corners = len(ico_faces)
        self.number_of_patches = self.number_of_corners

        # Nodes at patch and corners at node
        self.nodes_at_patch = np.zeros((self.number_of_patches, 3), dtype=int)
        self.corners_at_node = -np.ones((self.number_of_nodes, 6), dtype=int)
        corners_at_node_index = np.zeros(self.number_of_nodes, dtype=int)
        for p in range(self.number_of_patches):
            self.nodes_at_patch[p, :] = np.array(ico_faces[p])
            for node in self.nodes_at_patch[p, :]:
                self.corners_at_node[node, corners_at_node_index[node]] = p
                corners_at_node_index[node] += 1
        self._set_coords_of_corner()
        self._sort_corners_ccw()

    def _calc_area_of_patch(self):
        """
        Calculate the surface area of the spherical triangular patches.
        Store result in self._area_of_patch. Called by self.area_of_patch
        (a @property) when self._area_of_patch does not already exist.

        Examples
        --------

        For an icosahedron of unit radius, the area of each triangular
        patch should be 1/20th of sphere area 4 pi.

        >>> import numpy as np
        >>> from numpy.testing import assert_array_almost_equal
        >>> ico = DualIcosphereGraph()
        >>> assert_array_almost_equal(ico.area_of_patch, 4 * np.pi / 20)
        """
        self._area_of_patch = np.zeros(self.number_of_patches)
        for i in range(self.number_of_patches):
            self._area_of_patch[i] = area_of_sphertri(
                self.coords_of_node[self.nodes_at_patch[i, 0]],
                self.coords_of_node[self.nodes_at_patch[i, 1]],
                self.coords_of_node[self.nodes_at_patch[i, 2]],
                self._radius,
            )

    def _setup_node_spherical_coords(self):
        """Calculate and store spherical coordinates of nodes."""
        (
            self._r_of_node,
            self._phi_of_node,
            self._theta_of_node,
        ) = cartesian_to_spherical(self.x_of_node, self.y_of_node, self.z_of_node)

    def _sort_corners_ccw(self):
        """
        Sort the arrays of corners at node counter-clockwise with respect
        to the node.

        Notes
        -----

        The algorithm is:

        FOR EACH NODE
            GET SPHERICAL COORDS R, PHI, THETA
            MAKE A COPY OF CORNER COORDS ROTATED BY -PHI AND -THETA
            FIND ANGLE OF (ROTATED) CORNERS RELATIVE TO NODE IN XY PLANE
            SORT CORNERS AT NODE ACCORDING TO ANGLE

        Examples
        --------
        >>> ico = DualIcosphereGraph()
        >>> ico.corners_at_node[0]
        array([ 3,  4,  0,  1,  2, -1])
        """
        for node in range(self.number_of_nodes):  # can this be vectorized?
            # rotate corners such that node (x,y) = 0
            nc = np.count_nonzero(
                self.corners_at_node[node] + 1
            )  # number of corners at this node (5 or 6)
            cx = self.x_of_corner[self.corners_at_node[node, :nc]]
            cy = self.y_of_corner[self.corners_at_node[node, :nc]]
            cz = self.z_of_corner[self.corners_at_node[node, :nc]]
            rcx, rcy, _ = rotate_zy(
                cx, cy, cz, -self.phi_of_node[node], -self.theta_of_node[node]
            )

            # find angles of vectors node -> each corner
            ang = np.arctan2(rcy, rcx)
            ang[ang < 0.0] += 2 * np.pi

            # sort by angle
            idx = np.argsort(ang)
            self.corners_at_node[node, :nc] = self.corners_at_node[node, idx]

    def _setup_cells(self):
        """
        Calculate areas of cells.

        Area calculation uses the fact that cells are either pentagonal or hexagonal.
        Therefore the area can be calculated by first finding the area of a triangle
        formed by the cell's node and the first two of its corners, and then
        multiplying by either 5 or 6. We take advantage of the fact that node and
        cell numbering are the same. We detect shape by looking at the number of
        non-negative (= valid) entries in the corners_at_cell array.

        We could probably just calculate the first hex and first pent, and then
        assign the same area to all others accordingly (TODO).
        """
        self.number_of_cells = self.number_of_nodes
        self.area_of_cell = np.zeros(self.number_of_cells)

        for cell in range(self.number_of_cells):
            p0 = self.coords_of_node[cell]
            p1 = self.coords_of_corner[self.corners_at_node[cell][0]]
            p2 = self.coords_of_corner[self.corners_at_node[cell][1]]
            area_of_tri = area_of_sphertri(p0, p1, p2, self._radius)
            ntri = 5 + int(np.amin(self.corners_at_node[cell]) > -1)
            self.area_of_cell[cell] = ntri * area_of_tri



================================================
File: src/landlab/graph/quasi_spherical/refinable_icosahedron.py
================================================
#!/usr/bin/python
"""
RefinableIcosahedron: class that creates the vertices and triangular
faces of an icosahedron (20-sided polygonal solid) that can be
iteratively refined by replacing each triangle with four smaller
triangles. Designed to provide the starting point for a Landlab
icosphere grid.

Greg Tucker, University of Colorado Boulder, 2023
Adapted from a blog post and code snippet by Andreas Kahler, and
translated into Python (plus function to output in vtk format)
"""

import os
import pathlib

from landlab.io.legacy_vtk import _format_vtk_cells
from landlab.io.legacy_vtk import _format_vtk_header
from landlab.io.legacy_vtk import _format_vtk_points


class RefinableIcosahedron:
    """
    An icosahedron with faces that can be iteratively subdivided.

    Class includes Cartesian coordinates of vertices (12 if not
    subdivided) and IDs of vertices composing each face (20 faces if
    not subdivided). Adapted from a blog post by Andreas Kahler.

    Parameters
    ----------
    radius : float
        Radius for the RefinableIcosahedron, length units (default 1)

    Examples
    --------

    Basic icosahedron

    >>> ico = RefinableIcosahedron()
    >>> len(ico.faces)
    20
    >>> len(ico.vertices)
    12

    Icosphere with two iterations of refinement

    >>> ico.refine_triangles(recursion_level=2)
    >>> len(ico.faces)
    320
    >>> len(ico.vertices)
    162

    Icosahedron with radius != 1

    >>> ico = RefinableIcosahedron(radius=2.0)
    >>> round(ico.vertices[1][0], 2)
    1.05
    >>> round(ico.vertices[0][1], 2)
    1.7
    """

    def __init__(self, radius=1.0):
        """
        Initialize RefinableIcosahedron
        """
        self.radius = radius
        self.vertices = []
        self.faces = []
        self.middle_point_index_cache = {}
        self.vertex_index = -1
        self.create_vertices()
        self.create_faces()

    def add_vertex(self, vtx):
        """
        Add a vertex, scaling its coordinates to fit the given radius,
        and return its index in the vertices list.

        Parameters
        ----------
        vtx : 3-element tuple of float
            x, y, and z coordinates of vertex

        Returns
        -------
        int : index number of the new vertex
        """
        length = (vtx[0] ** 2 + vtx[1] ** 2 + vtx[2] ** 2) ** 0.5
        scale_fac = self.radius / length
        self.vertices.append(
            (vtx[0] * scale_fac, vtx[1] * scale_fac, vtx[2] * scale_fac)
        )
        self.vertex_index += 1
        return self.vertex_index

    def create_vertices(self):
        """
        Create the 12 vertices of an icosahedron.

        Note that the vertex coordinates will be scaled to match
        the given radius.
        """
        t = (1.0 + 5.0**0.5) / 2.0  # this is the famous Golden Mean

        self.add_vertex((-1.0, t, 0.0))
        self.add_vertex((1.0, t, 0.0))
        self.add_vertex((-1.0, -t, 0.0))
        self.add_vertex((1.0, -t, 0.0))

        self.add_vertex((0.0, -1.0, t))
        self.add_vertex((0.0, 1.0, t))
        self.add_vertex((0.0, -1.0, -t))
        self.add_vertex((0.0, 1.0, -t))

        self.add_vertex((t, 0.0, -1.0))
        self.add_vertex((t, 0.0, 1.0))
        self.add_vertex((-t, 0.0, -1.0))
        self.add_vertex((-t, 0.0, 1.0))

    def create_faces(self):
        """
        Create the 20 triangular faces of the icosahedron.

        Faces are stored in a list of 3-element tuples with the vertex IDs.

        Note that "face" here means a triangle on the surface of the object,
        and is different from the Landlab definition of face as the edge
        shared by two neighboring cells.
        """
        # 5 faces around point 0
        self.faces.append((0, 11, 5))
        self.faces.append((0, 5, 1))
        self.faces.append((0, 1, 7))
        self.faces.append((0, 7, 10))
        self.faces.append((0, 10, 11))

        # 5 adjacent faces
        self.faces.append((1, 5, 9))
        self.faces.append((5, 11, 4))
        self.faces.append((11, 10, 2))
        self.faces.append((10, 7, 6))
        self.faces.append((7, 1, 8))

        # 5 faces around point 3
        self.faces.append((3, 9, 4))
        self.faces.append((3, 4, 2))
        self.faces.append((3, 2, 6))
        self.faces.append((3, 6, 8))
        self.faces.append((3, 8, 9))

        # 5 adjacent faces
        self.faces.append((4, 9, 5))
        self.faces.append((2, 4, 11))
        self.faces.append((6, 2, 10))
        self.faces.append((8, 6, 7))
        self.faces.append((9, 8, 1))

    def write_to_vtk(self, path, clobber=False):
        """Save the geometry in a vtk-format text file.

        Note: this function is intended to test the RefinableIcosahedron.
        To write vtk for a Landlab IcosphereGlobalGrid, use
        `landlab.io.legacy_vtk.dump` to capture the full set of geometric
        primitives.

        Parameters
        ----------
        path : str, path-like , or file-like
            Target for output.
        clobber : bool, optional
            Whether to allow overwriting of existing file.

        Returns
        -------
        path : same as input above
            The given output path

        Examples
        --------
        >>> import io
        >>> import os

        >>> ico = RefinableIcosahedron()
        >>> output = ico.write_to_vtk(io.StringIO())
        >>> lines = output.getvalue().splitlines()

        >>> print(lines[0])
        # vtk DataFile Version 2.0

        >>> print(os.linesep.join(lines[5:18]))
        POINTS 12 float
        -0.5257311121191336 0.85065080835204 0.0
        0.5257311121191336 0.85065080835204 0.0
        -0.5257311121191336 -0.85065080835204 0.0
        0.5257311121191336 -0.85065080835204 0.0
        0.0 -0.5257311121191336 0.85065080835204
        0.0 0.5257311121191336 0.85065080835204
        0.0 -0.5257311121191336 -0.85065080835204
        0.0 0.5257311121191336 -0.85065080835204
        0.85065080835204 0.0 -0.5257311121191336
        0.85065080835204 0.0 0.5257311121191336
        -0.85065080835204 0.0 -0.5257311121191336
        -0.85065080835204 0.0 0.5257311121191336

        >>> print(os.linesep.join(lines[18:40]))
        CELLS 20 80
        3 0 11 5
        3 0 5 1
        3 0 1 7
        3 0 7 10
        3 0 10 11
        3 1 5 9
        3 5 11 4
        3 11 10 2
        3 10 7 6
        3 7 1 8
        3 3 9 4
        3 3 4 2
        3 3 2 6
        3 3 6 8
        3 3 8 9
        3 4 9 5
        3 2 4 11
        3 6 2 10
        3 8 6 7
        3 9 8 1

        >>> print(os.linesep.join(lines[41:45]))
        CELL_TYPES 20
        5
        5
        5
        """
        if isinstance(path, (str, pathlib.Path)):
            if os.path.exists(path) and not clobber:
                raise ValueError(f"file exists ({path})")

            with open(path, "w") as fp:
                self._write_vtk_to_filelike(fp)
        else:
            self._write_vtk_to_filelike(path)

        return path

    def _write_vtk_to_filelike(self, file_like):
        """
        Write legacy vtk format to a given file-like object.

        Parameters
        ----------
        file_like : a file-like object (e.g., file pointer, StringIO object)
            The file-like object to write to.

        Returns
        -------
        None
        """
        file_like.write(
            (2 * "\n").join(
                [
                    _format_vtk_header(),
                    _format_vtk_points(self.vertices),
                    _format_vtk_cells(self.faces),
                ]
            )
        )

    def get_middle_point(self, p1, p2):
        """
        Identify and add a new point between two existing points.

        Parameters
        ----------
        p1, p2 : int
            IDs of two points (vertices)

        Returns
        -------
        int : index of the point (vertex) added

        Notes
        -----
        This function is used to refine the icosphere, and is called
        to place new vertices in the middle of the edges of triangles.
        Because each edge is shared by two triangles, we have to avoid
        adding the same point twice. To do this, we use a dictionary
        (middle_point_index_cache) to keep track of points already
        added. Each point has a key made of the two vertex IDs (one
        is bit-shifted, then they are added together). We only add
        a point if it isn't already in the dict.
        """

        # do we already have it?
        key = (min(p1, p2) << 32) + max(p1, p2)
        if key in self.middle_point_index_cache:
            return self.middle_point_index_cache[key]

        # not in cache, so calculate
        point1 = self.vertices[p1]
        point2 = self.vertices[p2]
        middle = (
            (point1[0] + point2[0]) / 2.0,
            (point1[1] + point2[1]) / 2.0,
            (point1[2] + point2[2]) / 2.0,
        )

        i = self.add_vertex(middle)

        # store it and return index
        self.middle_point_index_cache[key] = i
        return i

    def refine_triangles(self, recursion_level=1):
        """
        Subdivide each triangle into four, and add corresponding vertices.

        Parameters
        ----------
        recursion_level : int, optional
            Number of subdivisions to apply (default 1)
        """
        for _ in range(recursion_level):
            faces2 = []
            for tri in self.faces:
                # replace triangle by 4 triangles
                a = self.get_middle_point(tri[0], tri[1])
                b = self.get_middle_point(tri[1], tri[2])
                c = self.get_middle_point(tri[2], tri[0])

                faces2.append((tri[0], a, c))
                faces2.append((tri[1], b, a))
                faces2.append((tri[2], c, b))
                faces2.append((a, b, c))

            self.faces = faces2



================================================
File: src/landlab/graph/radial/__init__.py
================================================
from .dual_radial import DualRadialGraph
from .radial import RadialGraph

__all__ = ["RadialGraph", "DualRadialGraph"]



================================================
File: src/landlab/graph/radial/dual_radial.py
================================================
import numpy as np

from ..dual import DualGraph
from ..voronoi.dual_voronoi import DualVoronoiGraph
from .radial import RadialGraph
from .radial import RadialGraphLayout


class DualRadialGraph(DualGraph, RadialGraph):
    """Graph of a series of points on concentric circles.

    Examples
    --------
    >>> from landlab.graph import DualRadialGraph
    >>> graph = DualRadialGraph((1, 4), sort=True)
    >>> graph.number_of_corners
    4
    >>> graph.y_of_corner
    array([-0.5, -0.5,  0.5,  0.5])
    >>> graph.x_of_corner
    array([-0.5,  0.5, -0.5,  0.5])
    """

    def __init__(self, shape, spacing=1.0, xy_of_center=(0.0, 0.0), sort=False):
        """Create a structured grid of triangles arranged radially.

        Parameters
        ----------
        shape : tuple of int
            Shape of the graph as number of rings and number of points
            in the first ring.
        spacing : float, optional
            Spacing between rings.
        xy_of_center : tuple of float, optional
            Coordinates of the center of the grid.
        """
        try:
            spacing = float(spacing)
        except TypeError as exc:
            raise TypeError("spacing must be a float") from exc

        xy_of_center = tuple(np.broadcast_to(xy_of_center, 2))

        x_of_node, y_of_node = RadialGraphLayout.xy_of_node(
            shape, spacing=spacing, xy_of_center=xy_of_center
        )

        self._ring_spacing = spacing
        self._shape = tuple(shape)
        self._xy_of_center = xy_of_center

        DualVoronoiGraph.__init__(self, (y_of_node, x_of_node), sort=False)

        if sort:
            self.sort()

    @property
    def shape(self):
        return self._shape

    @property
    def spacing(self):
        return self._spacing

    @property
    def origin(self):
        return self._xy_of_center

    @property
    def xy_of_center(self):
        return self._xy_of_center



================================================
File: src/landlab/graph/radial/radial.py
================================================
from functools import cached_property

import numpy as np

from ...core.utils import as_id_array
from ...utils.decorators import read_only_array
from ..voronoi.voronoi import DelaunayGraph


class RadialGraphLayout:
    @staticmethod
    def number_of_nodes(shape):
        return np.sum(np.arange(1, shape[0] + 1)) * shape[1] + 1

    @staticmethod
    def xy_of_node(shape, spacing=1.0, xy_of_center=(0.0, 0.0)):
        """Create the node layout for a radial grid.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph.radial.radial import RadialGraphLayout
        >>> x, y = RadialGraphLayout.xy_of_node((1, 6))
        >>> x
        array([ 0. ,  1. ,  0.5, -0.5, -1. , -0.5,  0.5])
        >>> np.round(y / np.sin(np.pi / 3.0))
        array([ 0.,  0.,  1.,  1.,  0., -1., -1.])
        """
        n_rings, n_points = shape
        n_nodes = RadialGraphLayout.number_of_nodes(shape)

        x = np.empty((n_nodes,), dtype=float)
        y = np.empty((n_nodes,), dtype=float)

        x[0] = y[0] = 0.0
        offset = 1
        for ring in range(1, n_rings + 1):
            rho = spacing * ring
            d_theta = np.pi * 2 / (ring * shape[1])
            theta = np.arange(ring * shape[1]) * d_theta

            y[offset : offset + len(theta)] = rho * np.sin(theta)
            x[offset : offset + len(theta)] = rho * np.cos(theta)

            offset += len(theta)

        x = np.round(x, decimals=6)
        y = np.round(y, decimals=6)

        x += xy_of_center[0]
        y += xy_of_center[1]

        return (x, y)


class RadialGraphExtras:
    @property
    def shape(self):
        return self._shape

    @property
    def spacing(self):
        return self._spacing

    @property
    def origin(self):
        return self._origin

    @property
    def number_of_rings(self):
        return self.shape[0]

    @property
    def spacing_of_rings(self):
        return self.spacing

    @cached_property
    @read_only_array
    def radius_of_ring(self):
        return np.arange(0, self.number_of_rings, dtype=float) * self.spacing_of_rings

    @cached_property
    @read_only_array
    def angle_spacing_of_ring(self):
        return 2.0 * np.pi / self.nodes_per_ring

    @cached_property
    @read_only_array
    def nodes_per_ring(self):
        nodes_per_ring = np.empty(self.number_of_rings, dtype=int)
        nodes_per_ring[0] = 1
        nodes_per_ring[1:] = np.round(2.0 * np.pi * np.arange(1, self.number_of_rings))
        return nodes_per_ring

    @cached_property
    @read_only_array
    def ring_at_node(self):
        return np.repeat(np.arange(self.number_of_rings), self.nodes_per_ring)

    @cached_property
    @read_only_array
    def radius_at_node(self):
        return self.radius_of_ring[self.ring_at_node]

    @cached_property
    @read_only_array
    def angle_at_node(self):
        angle_at_node = np.empty(self.nodes_per_ring.sum(), dtype=float)
        angle_at_node[0] = 0.0
        offset = 1
        for n_nodes in self.nodes_per_ring[1:]:
            angles, step = np.linspace(
                0.0, 2 * np.pi, n_nodes, endpoint=False, retstep=True, dtype=float
            )
            angle_at_node[offset : offset + n_nodes] = np.add(
                angles, 0.5 * step, out=angles
            )
            offset += n_nodes
        return angle_at_node


class RadialGraph(RadialGraphExtras, DelaunayGraph):
    """Graph of a series of points on concentric circles.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import RadialGraph
    >>> graph = RadialGraph((1, 4), sort=True)
    >>> graph.number_of_nodes
    5
    >>> graph.y_of_node
    array([-1.,  0.,  0.,  0.,  1.])
    >>> graph.x_of_node
    array([ 0., -1.,  0.,  1.,  0.])
    """

    def __init__(self, shape, spacing=1.0, xy_of_center=(0.0, 0.0), sort=False):
        """Create a structured grid of triangles arranged radially.

        Parameters
        ----------
        shape : tuple of int
            Shape of the graph as number of rings and number of points
            in the first ring.
        spacing : float, optional
            Spacing between rings.
        xy_of_center : tuple of float, optional
            Coordinates of the node at the center of the grid.
        """
        try:
            spacing = float(spacing)
        except TypeError as exc:
            raise TypeError("spacing must be a float") from exc

        xy_of_center = tuple(np.broadcast_to(xy_of_center, 2))

        x_of_node, y_of_node = RadialGraphLayout.xy_of_node(
            shape, spacing=spacing, xy_of_center=xy_of_center
        )

        self._ring_spacing = spacing
        self._shape = tuple(shape)
        self._xy_of_center = xy_of_center

        DelaunayGraph.__init__(self, (y_of_node, x_of_node))

        if sort:
            self.sort()

    @property
    def xy_of_center(self):
        return self._xy_of_center

    @property
    def number_of_rings(self):
        """Number of node rings in grid.

        Returns
        -------
        int
            The number of node rings in the radial grid (not counting the
            center node).

        Examples
        --------
        >>> import numpy as np
        >>> from landlab.graph import RadialGraph
        >>> graph = RadialGraph((1, 4))
        >>> graph.number_of_rings
        1

        :meta landlab: info-grid
        """
        return self._shape[0]

    @property
    def spacing_of_rings(self):
        """Fixed distance between rings.

        Returns
        -------
        ndarray of float
            The distance from the center node of each node.

        >>> from landlab.graph import RadialGraph
        >>> graph = RadialGraph((2, 6), spacing=2.0)
        >>> graph.spacing_of_rings
        2.0

        :meta landlab: info-grid, quantity
        """
        return self._ring_spacing

    @cached_property
    def radius_at_node(self):
        """Distance for center node to each node.

        Returns
        -------
        ndarray of float
            The distance from the center node of each node.

        >>> from landlab.graph import RadialGraph
        >>> graph = RadialGraph((2, 6), sort=True)
        >>> np.round(graph.radius_at_node, 3)
        array([2., 2., 2., 2., 2., 1., 1., 2., 1., 0., 1., 2., 1.,
               1., 2., 2., 2., 2., 2.])

        :meta landlab: info-node, quantity
        """
        return np.sqrt(
            np.square(self.x_of_node - self._xy_of_center[0])
            + np.square(self.y_of_node - self._xy_of_center[1])
        )

    @cached_property
    def number_of_nodes_in_ring(self):
        """Number of nodes in each ring.

        Returns
        -------
        ndarray of int
            Number of nodes in each ring, excluding the center node.

        >>> from landlab.graph import RadialGraph
        >>> graph = RadialGraph((4, 6))
        >>> graph.number_of_nodes_in_ring
        array([ 6, 12, 24, 48])

        :meta landlab: info-node, quantity
        """
        return as_id_array(self._shape[1] * 2 ** np.arange(self.number_of_rings))



================================================
File: src/landlab/graph/sort/__init__.py
================================================
from .sort import reindex_by_xy
from .sort import reorder_links_at_patch
from .sort import sort_graph
from .sort import sort_links_at_patch
from .sort import sort_nodes
from .sort import sort_patches

__all__ = [
    "sort_graph",
    "sort_links_at_patch",
    "sort_patches",
    "sort_nodes",
    "reindex_by_xy",
    "reorder_links_at_patch",
]



================================================
File: src/landlab/graph/sort/intpair.py
================================================
from collections.abc import Collection
from collections.abc import Iterable
from collections.abc import Mapping
from pprint import pformat

import numpy as np
from numpy.typing import ArrayLike

from landlab.graph.sort.ext.intpair import fill_offsets_to_sorted_blocks
from landlab.graph.sort.ext.intpair import find_pair
from landlab.graph.sort.ext.intpair import find_pairs
from landlab.graph.sort.ext.intpair import find_rolling_pairs_2d

from .ext._deprecated_sparse import map_pairs_to_values as _map_pairs_to_values
from .ext._deprecated_sparse import (
    map_rolling_pairs_to_values as _map_rolling_pairs_to_values,
)
from .ext._deprecated_sparse import pair_isin as _pair_isin


class IntPairCollection(Collection):
    """Collection of pairs of int, that ignores ordering of pairs.


    Examples
    --------
    >>> from landlab.graph.sort.intpair import IntPairCollection
    >>> pairs = IntPairCollection([(0, 1), (2, 3), (1, 2), (4, 5)])
    >>> (0, 1) in pairs
    True
    >>> (1, 0) in pairs
    True
    >>> (2, 4) in pairs
    False

    >>> pairs.contains_pairs([(1, 0), (5, 4), (4, 5), (3, 200)])
    array([ True, True, True, False])

    >>> pairs.contains_pairs([(1, 0, 2), (5, 4, -1), (-1, 4, 5), (3, 2, 1)])
    array([[ True, False],
           [ True, False],
           [False, False],
           [ True,  True]])

    >>> pairs.contains_pairs(
    ...     [(1, 0, 2), (5, 4, -1), (-1, 4, 5), (3, 2, 1)], wraparound=True
    ... )
    array([[ True, False,  True],
           [ True,  True, False],
           [False, False, False],
           [ True,  True, False]])
    """

    def __init__(
        self,
        pairs: ArrayLike,
        sorter: ArrayLike | None = None,
        sorted: bool = False,
    ):
        pairs = np.atleast_2d(pairs)

        if sorter is None and not sorted:
            sorter = np.argsort(pairs[:, 0])

        if sorter is not None:
            pairs = pairs[sorter]

        self._data = pairs
        self._offsets = np.empty(pairs.max() + 2, dtype=int)

        fill_offsets_to_sorted_blocks(self._data[:, 0], self._offsets)

        self._assert_is_sorted(self._data)

    @staticmethod
    def _assert_is_sorted(data):
        if np.any(np.diff(data[:, 0]) < 0):
            raise ValueError("array is not sorted")

    def __contains__(self, pair) -> bool:
        pairs = np.atleast_2d(pair)
        result = np.asarray([-1], dtype=int)

        find_pairs(self._data, self._offsets, pairs, result)

        return result[0] >= 0

    def __len__(self) -> int:
        return len(self._data)

    def __iter__(self) -> tuple[int, int]:
        for pair in self._data:
            yield tuple(pair)

    def _find_pairs(self, pairs, out=None, wraparound=False):
        pairs = np.atleast_2d(pairs)

        if wraparound:
            shape = (pairs.shape[0], pairs.shape[1])
        else:
            shape = (pairs.shape[0], pairs.shape[1] - 1)
        result = np.full(shape, -2, dtype=int)

        find_rolling_pairs_2d(self._data, self._offsets, pairs, result, int(wraparound))

        return result

    def contains_pairs(self, pairs, wraparound=False):
        return np.squeeze(self._find_pairs(pairs, wraparound=wraparound) >= 0)

    def __repr__(self) -> str:
        if len(self._data) > 6:
            s = (
                f"[{' '.join([repr(tuple(p)) + ',' for p in self._data[:3]])}"
                " ... "
                f"{', '.join([repr(tuple(p)) for p in self._data[-3:]])}]"
            )
        else:
            s = f"{pformat([tuple(pair) for pair in self._data], compact=True)}"
        return f"IntPairCollection({s})"


class IntPairMapping(Mapping, IntPairCollection):
    """Mapping of pairs of int, that ignores ordering of pairs.


    Examples
    --------
    >>> from landlab.graph.sort.intpair import IntPairMapping
    >>> pairs = IntPairMapping([(0, 1), (2, 3), (1, 2), (4, 5)], values=[1, 2, 3, 4])
    >>> pairs[(1, 0)]
    1
    >>> pairs[(0, 1)]
    1
    >>> pairs[(2, 4)]
    Traceback (most recent call last):
    KeyError: (2, 4)

    >>> pairs.get_items([(1, 0), (5, 4), (4, 5), (3, 200)])
    array([ 1, 4, 4, -1])

    >>> pairs.get_items([(1, 0, 2), (5, 4, -1), (-1, 4, 5), (3, 2, 1)])
    array([[ 1, -1],
           [ 4, -1],
           [-1, -1],
           [ 2,  3]])

    >>> pairs.get_items([(1, 0, 2), (5, 4, -1), (-1, 4, 5), (3, 2, 1)], wraparound=True)
    array([[ 1, -1,  3],
           [ 4,  4, -1],
           [-1, -1, -1],
           [ 2,  3, -1]])
    """

    def __init__(
        self,
        pairs: ArrayLike,
        values: ArrayLike,
        sorter: ArrayLike | None = None,
        sorted: bool = False,
    ) -> None:
        pairs = np.atleast_2d(pairs)
        values = np.asarray(values)

        if sorter is None and not sorted:
            sorter = np.argsort(pairs[:, 0])

        if sorter is not None:
            pairs = pairs[sorter]
            values = values[sorter]

        self._values = values
        self._data = pairs
        self._offsets = np.empty(pairs.max() + 2, dtype=int)

        fill_offsets_to_sorted_blocks(self._data[:, 0], self._offsets)

    def __getitem__(self, key: Iterable[int]):
        ind = find_pair(self._data, self._offsets, key[0], key[1])
        if ind == -1:
            ind = find_pair(self._data, self._offsets, key[1], key[0])
        if ind == -1:
            raise KeyError(key)
        else:
            return self._values[ind]

    def get_items(self, keys, out=None, wraparound=False):
        keys = np.atleast_2d(keys)

        if wraparound:
            shape = (keys.shape[0], keys.shape[1])
        else:
            shape = (keys.shape[0], keys.shape[1] - 1)

        if out is None:
            _out = np.empty(shape, dtype=self._values.dtype)
        else:
            _out = out.reshape(shape)

        result = np.full(shape, -1, dtype=int)

        find_rolling_pairs_2d(
            self._data,
            self._offsets,
            keys,
            result,
            int(wraparound),
        )

        _out[:] = self._values[result]
        _out[result == -1] = -1

        if out is None:
            return np.squeeze(_out)
        else:
            return out

    def __repr__(self) -> str:
        if len(self._data) > 6:
            s = (
                f"[{' '.join([repr(tuple(p)) + ',' for p in self._data[:3]])}"
                " ... "
                f"{', '.join([repr(tuple(p)) for p in self._data[-3:]])}]"
            )
            v = (
                f"[{' '.join([repr(v) + ',' for v in self._values[:3]])}"
                " ... "
                f"{', '.join([repr(v) for v in self._values[-3:]])}]"
            )
        else:
            s = f"{pformat([tuple(pair) for pair in self._data], compact=True)}"
            v = f"{pformat(list(self._values), compact=True)}"
        return f"IntPairCollection({s}, values={v})"


def pair_isin(src, pairs, out=None, sorter=None, sorted=False):
    if not sorted and sorter is None:
        sorter = np.argsort(src[:, 0])
    if sorter is not None:
        src = src[sorter]

    offsets = np.empty(pairs.max() + 2, dtype=int)
    fill_offsets_to_sorted_blocks(src[:, 0], offsets)

    result = np.empty(len(pairs), dtype=int)

    find_pairs(src, offsets, pairs, result)

    if out is None:
        out = result >= 0
    else:
        out[:] = result >= 0

    return out


def __pair_isin(src, pairs, out=None, sorter=None, sorted=False):
    """Check if integer-pairs are contained in source set.

    Parameters
    ----------
    src : ndarray of int, size *(N, 2)*
        Integer pairs that form the source set.
    pairs : ndarray of int, size *(M, 2)*
        Integer pairs to check if they are contained in the source set.
    out : ndarray of bool, size *(M,)*, optional
        Buffer to place the result. If not provided, a new array will be allocated.
    sorter : ndarray of int, size *(N,)*, optional
        Array of indices that sorts the *src*, as would be returned by *argsort*.
        If not provided, *src* is assumed to already be sorted.
    sorted : bool, optional
        Indicate if the source pairs are already sorted.

    Returns
    -------
    ndarray of bool
        Array that indicates if the pair is contained in the source set.
    """
    if not sorted and sorter is None:
        sorter = np.argsort(src[:, 0])
    if sorter is not None:
        src = src[sorter]

    result = np.empty(len(pairs), dtype=np.uint8)
    _pair_isin(np.ascontiguousarray(src), np.ascontiguousarray(pairs), result)

    if out is None:
        out = result.astype(dtype=bool, copy=False)
    else:
        out[:] = result.astype(dtype=bool, copy=False)
    return out


def map_pairs_to_values(mapping, pairs, out=None, sorter=None, sorted=False):
    """Return the values for integer pairs from a mapping.

    Parameters
    ----------
    mapping : tuple of ndarray of int
        Integer pair to value mapping as *(pairs, values)* where *pairs* is
        *ndarray* of shape *(M, 2)* and *values* an array of length *M*.
    pairs : ndarray of int of shape *(N, 2)*
        Integer pairs to get the values of.
    out : ndarray of bool, size *(N,)*, optional
        Buffer to place the result. If not provided, a new array will be allocated.
    sorter : ndarray of int, size *(M,)*, optional
        Array of indices that sorts the *src*, as would be returned by *argsort*.
        If not provided, *src* is assumed to already be sorted.
    sorted : bool, optional
        Indicate if the mapping key pairs are already sorted.

    Returns
    -------
    ndarray of int
        Array of values of the given integer pairs.

    Examples
    --------
    >>> from landlab.graph.sort.intpair import map_pairs_to_values

    >>> keys = [[0, 1], [1, 1], [2, 1], [3, 1], [4, 1]]
    >>> values = [0, 10, 20, 30, 40]
    >>> pairs = [[1, 1], [3, 1]]
    >>> map_pairs_to_values((keys, values), pairs)
    array([10, 30])
    """
    keys, values = mapping

    if sorted and sorter is not None:
        sorter = None

    if not sorted and sorter is None:
        keys = np.atleast_2d(keys)
        sorter = np.argsort(keys[:, 0])

    mapping = IntPairMapping(keys, values=values, sorter=sorter)
    return mapping.get_items(pairs, out=out)


def __map_pairs_to_values(mapping, pairs, out=None, sorter=None, sorted=False):
    """Return the values for integer pairs from a mapping.

    Parameters
    ----------
    mapping : tuple of ndarray of int
        Integer pair to value mapping as *(pairs, values)* where *pairs* is
        *ndarray* of shape *(M, 2)* and *values* an array of length *M*.
    pairs : ndarray of int of shape *(N, 2)*
        Integer pairs to get the values of.
    out : ndarray of bool, size *(N,)*, optional
        Buffer to place the result. If not provided, a new array will be allocated.
    sorter : ndarray of int, size *(M,)*, optional
        Array of indices that sorts the *src*, as would be returned by *argsort*.
        If not provided, *src* is assumed to already be sorted.
    sorted : bool, optional
        Indicate if the mapping key pairs are already sorted.

    Returns
    -------
    ndarray of int
        Array of values of the given integer pairs.

    Examples
    --------
    >>> from landlab.graph.sort.intpair import map_pairs_to_values

    >>> keys = [[0, 1], [1, 1], [2, 1], [3, 1], [4, 1]]
    >>> values = [0, 10, 20, 30, 40]
    >>> pairs = [[1, 1], [3, 1]]
    >>> map_pairs_to_values((keys, values), pairs)
    array([10, 30])
    """
    keys, values = np.asarray(mapping[0]), np.asarray(mapping[1])
    pairs = np.asarray(pairs)

    if out is None:
        out = np.empty(len(pairs), dtype=values.dtype)

    if not sorted and sorter is None:
        sorter = np.argsort(keys[:, 0])
    if sorter is not None:
        keys = keys[sorter]
        values = values[sorter]

    _map_pairs_to_values(
        np.ascontiguousarray(keys), np.ascontiguousarray(values), pairs, out
    )

    return out


def map_rolling_pairs_to_values(
    mapping,
    pairs,
    out=None,
    sorter=None,
    sorted=False,
    size_of_row=None,
    wraparound=True,
):
    keys, values = np.asarray(mapping[0]), np.asarray(mapping[1])
    pairs = np.asarray(pairs)

    if out is None:
        out = np.empty_like(pairs, dtype=int)

    if size_of_row is None:
        size_of_row = np.full(len(pairs), pairs.shape[1], dtype=int)
    else:
        size_of_row = np.asarray(size_of_row)
        out[:] = -1

    if not sorted and sorter is None:
        sorter = np.argsort(keys[:, 0])
    if sorter is not None:
        keys = keys[sorter]
        values = values[sorter]

    offsets = np.empty(pairs.max() + 2, dtype=int)
    fill_offsets_to_sorted_blocks(keys[:, 0], offsets)

    result = np.full(pairs.shape, -1, dtype=int)

    find_rolling_pairs_2d(
        keys,
        offsets,
        pairs,
        result,
        bool(wraparound),
    )

    out[:] = values[result]
    out[result == -1] = -1

    # _map_rolling_pairs_to_values(
    #     np.ascontiguousarray(keys),
    #     np.ascontiguousarray(values),
    #     np.ascontiguousarray(pairs),
    #     np.ascontiguousarray(size_of_row),
    #     out,
    # )

    return out


def __map_rolling_pairs_to_values(
    mapping, pairs, out=None, sorter=None, sorted=False, size_of_row=None
):
    """Return the values for integer pairs given as a 2D matrix of rolling
    pairs.

    Parameters
    ----------
    mapping : tuple of ndarray of int
        Integer pair to value mapping as *(pairs, values)* where *pairs* is
        *ndarray* of shape *(N, 2)* and *values* an array of length *N*.
    pairs : ndarray of int of shape *(M, L)*
        Integer pairs to get the values of.
    out : ndarray of bool, size *(M, L)*, optional
        Buffer to place the result. If not provided, a new array will be allocated.
    sorter : ndarray of int, size *(N,)*, optional
        Array of indices that sorts the *src*, as would be returned by *argsort*.
        If not provided, *src* is assumed to already be sorted.
    sorted : bool, optional
        Indicate if the mapping key pairs are already sorted.

    Returns
    -------
    ndarray of int
        Array of values of the given integer pairs.

    Examples
    --------
    >>> from landlab.graph.sort.intpair import map_rolling_pairs_to_values

    >>> keys = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 0]]
    >>> values = [0, 10, 20, 30, 40]
    >>> pairs = [[0, 1, 2, 3], [0, 2, 3, 4]]
    >>> map_rolling_pairs_to_values((keys, values), pairs)
    array([[ 0, 10, 20, -1],
           [-1, 20, 30, 40]])
    """
    keys, values = np.asarray(mapping[0]), np.asarray(mapping[1])
    pairs = np.asarray(pairs)

    if out is None:
        out = np.empty_like(pairs, dtype=int)

    if size_of_row is None:
        size_of_row = np.full(len(pairs), pairs.shape[1], dtype=int)
    else:
        size_of_row = np.asarray(size_of_row)
        out[:] = -1

    if not sorted and sorter is None:
        sorter = np.argsort(keys[:, 0])
    if sorter is not None:
        keys = keys[sorter]
        values = values[sorter]

    _map_rolling_pairs_to_values(
        np.ascontiguousarray(keys),
        np.ascontiguousarray(values),
        np.ascontiguousarray(pairs),
        np.ascontiguousarray(size_of_row),
        out,
    )

    return out



================================================
File: src/landlab/graph/sort/sort.py
================================================
"""Sort the elements of a graph.

This module provides functions that sort the elements of a graph
structure.
"""

import numpy as np

from ...core.utils import argsort_points_by_x_then_y
from ...core.utils import as_id_array
from ...utils.jaggedarray import flatten_jagged_array
from ..quantity.ext.of_element import mean_of_children_at_parent
from .ext.argsort import sort_id_array


def remap(src, mapping, out=None, inplace=False):
    """Remap elements in an id array.

    Parameters
    ----------
    src : ndarray of int
        Initial array of ids.
    mapping : ndarray of int
        Mapping of ids.
    out : ndarray of int, optional
        Buffer into which to place output.
    inplace : bool, optional
        Mapping of values will include inplace.

    Returns
    -------
    ndarray of int
        Array of remapped values.

    Examples
    --------
    >>> from landlab.graph.sort.sort import remap
    >>> import numpy as np

    >>> src = np.array([1, 2, 3, 4])
    >>> mapping = np.array([-1, 10, 20, 30, 40])
    >>> remap(src, mapping)
    array([10, 20, 30, 40])
    """
    from .ext.remap_element import remap_graph_element

    if inplace:
        out = src
    else:
        if out is None:
            out = src.copy()
        else:
            out[:] = src[:]

    remap_graph_element(out.reshape((-1,)), mapping)

    return out


def reverse_one_to_one(ids, minlength=None):
    """Reverse a one-to-one mapping.

    Parameters
    ----------
    ids : ndarray of int, shape `(N, )`
        Array of identifier mapping.
    minlength : int, optional
        A minimum number of identifiers for the output array.
    Returns
    -------
    ndarray of int, shape `(n, )`
        Array of the reverse mapping.

    Examples
    --------
    >>> from landlab.graph.sort.sort import reverse_one_to_one
    >>> ids = np.array([-1, -1, 6, 3, -1, 2, 4, 1, -1, 5, 0], dtype=int)
    >>> reverse_one_to_one(ids)
    array([10,  7,  5,  3,  6,  9,  2])
    """
    from .ext.remap_element import reverse_one_to_one

    if minlength is None:
        minlength = ids.max() + 1
    out = np.full((minlength,), -1, dtype=int)

    reverse_one_to_one(ids, out)

    return out


def reverse_one_to_many(ids, min_counts=0):
    """Reverse a one-to-many mapping.

    Parameters
    ----------
    ids : ndarray of int, shape `(M, N)`
        Array of identifier mapping.

    Returns
    -------
    ndarray of int, shape `(m, n)`
        Array of the reverse mapping.

    Examples
    --------
    >>> from landlab.graph.sort.sort import reverse_one_to_many
    >>> ids = np.array([[1, 2, 3], [-1, -1, -1], [2, 3, -1]], dtype=int)
    >>> reverse_one_to_many(ids)
    array([[-1, -1],
           [ 0, -1],
           [ 0,  2],
           [ 0,  2]])
    """
    from .ext.remap_element import reverse_one_to_many

    counts = np.bincount(ids.reshape((-1,)) + 1)
    max_counts = np.max((np.max(counts[1:]), min_counts))

    out = np.full((ids.max() + 1, max_counts), -1, dtype=int)

    reverse_one_to_many(ids, out)

    return out


def reorder_links_at_patch(graph):
    from ..matrix.ext.matrix import roll_id_matrix_rows
    from ..object.ext.at_patch import get_rightmost_edge_at_patch
    from ..quantity.of_link import get_midpoint_of_link
    from ..quantity.of_patch import get_area_of_patch
    from .ext.remap_element import reverse_element_order

    if graph.number_of_patches == 0:
        return

    xy_of_link = get_midpoint_of_link(graph)

    shift = np.empty(graph.number_of_patches, dtype=int)

    get_rightmost_edge_at_patch(graph.links_at_patch, xy_of_link, shift)
    roll_id_matrix_rows(graph.links_at_patch, -shift)

    before = graph.links_at_patch.copy()
    area_before = get_area_of_patch(graph)

    negative_areas = as_id_array(np.where(get_area_of_patch(graph) < 0.0)[0])
    reverse_element_order(graph.links_at_patch, negative_areas)
    # reverse_element_order(graph._links_at_patch, negative_areas)

    # graph._nodes_at_patch = get_nodes_at_patch(graph)
    if "nodes_at_patch" in graph._ds:
        graph._ds = graph._ds.drop("nodes_at_patch")

    if np.any(get_area_of_patch(graph) < 0.0):
        raise ValueError(
            (graph.links_at_patch, before, get_area_of_patch(graph), area_before)
        )


def reorient_link_dirs(graph):
    from ..quantity.of_link import get_angle_of_link

    if graph.number_of_links == 0:
        return

    angles = get_angle_of_link(graph)
    links_to_swap = (angles < 7.0 * np.pi / 4.0) & (angles >= np.pi * 0.75)
    graph.nodes_at_link[links_to_swap, :] = graph.nodes_at_link[links_to_swap, ::-1]


def sort_links_at_patch(links_at_patch, nodes_at_link, xy_of_node):
    """Reorder links around a patch to be counterclockwise.

    Examples
    --------
    >>> from landlab.graph.sort.sort import sort_links_at_patch
    >>> import numpy as np
    >>> xy_of_node = np.array(
    ...     [
    ...         [0.0, 0.0],
    ...         [0.0, 1.0],
    ...         [1.0, 1.0],
    ...         [1.0, 0.0],
    ...     ]
    ... )
    >>> nodes_at_link = np.array([[0, 1], [1, 2], [2, 3], [3, 0]])
    >>> links_at_patch = np.array([[0, 1, 3, 2]])
    >>> sort_links_at_patch(links_at_patch, nodes_at_link, xy_of_node)
    >>> links_at_patch
    array([[2, 1, 0, 3]])

    >>> xy_of_node = np.array(
    ...     [
    ...         [0.0, 0.0],
    ...         [0.0, 1.0],
    ...         [1.0, 1.0],
    ...         [1.0, 0.0],
    ...         [2.0, 0.0],
    ...     ]
    ... )
    >>> nodes_at_link = np.array([[0, 1], [1, 2], [2, 3], [3, 0], [2, 4], [3, 4]])
    >>> links_at_patch = np.array([[0, 1, 3, 2], [2, 4, 5, -1]])
    >>> sort_links_at_patch(links_at_patch, nodes_at_link, xy_of_node)
    >>> links_at_patch
    array([[ 2,  1,  0,  3],
           [ 4,  2,  5, -1]])

    >>> xy_of_node = np.array(
    ...     [
    ...         [0.0, 0.0],
    ...         [0.0, 1.0],
    ...         [1.0, 1.0],
    ...         [1.0, 0.0],
    ...         [2.0, 1.0],
    ...     ]
    ... )
    >>> nodes_at_link = np.array([[0, 1], [1, 2], [2, 3], [3, 0], [2, 4], [3, 4]])
    >>> links_at_patch = np.array([[0, 1, 3, 2], [2, -1, 4, 5]])
    >>> sort_links_at_patch(links_at_patch, nodes_at_link, xy_of_node)
    >>> links_at_patch
    array([[ 2,  1,  0,  3],
           [ 4,  2,  5, -1]])
    """
    xy_of_link = np.mean(xy_of_node[nodes_at_link], axis=1)

    xy_of_patch = np.empty((len(links_at_patch), 2), dtype=float)

    mean_of_children_at_parent(links_at_patch, xy_of_link[:, 0], xy_of_patch[:, 0])
    mean_of_children_at_parent(links_at_patch, xy_of_link[:, 1], xy_of_patch[:, 1])

    sort_spokes_at_hub(links_at_patch, xy_of_patch, xy_of_link, inplace=True)


def reindex_by_xy(graph):
    sorted_nodes = reindex_nodes_by_xy(graph)

    if "nodes_at_link" in graph.ds:
        sorted_links = reindex_links_by_xy(graph)
    else:
        sorted_links = None

    if "links_at_patch" in graph.ds:
        sorted_patches = reindex_patches_by_xy(graph)
    else:
        sorted_patches = None

    return sorted_nodes, sorted_links, sorted_patches


def reindex_patches_by_xy(graph):
    from ..quantity.of_patch import get_centroid_of_patch

    if graph.number_of_patches == 1:
        return np.array([0], dtype=int)

    xy_at_patch = get_centroid_of_patch(graph)

    y = xy_at_patch[:, 1]
    y_min, y_max = y.min(), y.max()
    if np.isclose(y_min, y_max):
        y_max = y_min + 1.0

    sorted_patches = argsort_points_by_x_then_y(
        (xy_at_patch[:, 0], np.round((y - y_min) / (y_max - y_min), decimals=5))
    )

    graph.links_at_patch[:] = graph.links_at_patch[sorted_patches, :]

    if "nodes_at_patch" in graph._ds:
        graph._ds = graph.ds.drop("nodes_at_patch")

    return sorted_patches


def reindex_links_by_xy(graph):
    from ..quantity.of_link import get_midpoint_of_link
    from .ext.remap_element import remap_graph_element_ignore

    xy_of_link = get_midpoint_of_link(graph)

    sorted_links = argsort_points_by_x_then_y(xy_of_link)

    # graph._nodes_at_link[:] = graph._nodes_at_link[sorted_links, :]
    graph.nodes_at_link[:] = graph.nodes_at_link[sorted_links, :]

    # if hasattr(graph, '_links_at_patch'):
    if "links_at_patch" in graph.ds:
        remap_graph_element_ignore(
            graph.links_at_patch.reshape((-1,)),
            as_id_array(np.argsort(sorted_links, kind="stable")),
            -1,
        )

    return sorted_links


def reindex_nodes_by_xy(graph):
    from .ext.remap_element import remap_graph_element

    graph.y_of_node[:] = np.round(graph.y_of_node, decimals=6)

    sorted_nodes = argsort_points_by_x_then_y((graph.x_of_node, graph.y_of_node))

    graph.y_of_node[:] = graph.y_of_node[sorted_nodes]
    graph.x_of_node[:] = graph.x_of_node[sorted_nodes]

    if "nodes_at_link" in graph.ds:
        remap_graph_element(
            graph.nodes_at_link.reshape((-1,)),
            as_id_array(np.argsort(sorted_nodes, kind="stable")),
        )

    if "nodes_at_patch" in graph.ds:
        remap_graph_element(
            graph.nodes_at_patch.reshape((-1,)),
            as_id_array(np.argsort(sorted_nodes, kind="stable")),
        )

    return sorted_nodes


def sort_graph(nodes, links=None, patches=None):
    """Sort elements of a graph by x, then y.

    Parameters
    ----------
    nodes : tuple of ndarray
        Coordinate of nodes as (y, x).
    links : ndarray of int, shape `(n_links, 2)`, optional
        Indices into *nodes* array of link tail then head.
    patches : array_like of array_like, optional
        Indices into *links* array of the links that define each patch.

    Returns
    -------
    (nodes, links, patches)
        Sorted nodes, links, and patches.

    Examples
    --------
    o---o---o
    |   | / |
    o---o---o

    >>> from landlab.graph.sort import sort_graph
    >>> import numpy as np
    >>> x = np.array([1.0, 2.0, 2.0, 0.0, 1.0, 0.0])
    >>> y = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0])

    Sort a graph with just points - no links or patches.

    >>> _ = sort_graph((y, x))
    >>> y
    array([0., 0., 0., 1., 1., 1.])
    >>> x
    array([0., 1., 2., 0., 1., 2.])

    Sort the points and links of a graph.

    >>> x = np.array([1.0, 2.0, 2.0, 0.0, 1.0, 0.0])
    >>> y = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0])
    >>> links = np.array(
    ...     [[3, 0], [0, 4], [4, 5], [5, 3], [0, 1], [1, 2], [2, 0], [2, 4]]
    ... )
    >>> _ = sort_graph((y, x), links)
    >>> links
    array([[0, 1], [1, 2], [3, 0], [1, 4], [5, 1], [2, 5], [4, 3], [5, 4]])

    Sort the points, links, and patches of a graph.

    >>> x = np.array([1.0, 2.0, 2.0, 0.0, 1.0, 0.0])
    >>> y = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0])
    >>> links = np.array(
    ...     [[3, 0], [0, 4], [4, 5], [5, 3], [0, 1], [1, 2], [2, 0], [2, 4]]
    ... )
    >>> patches = (np.array([1, 6, 7, 4, 5, 6, 0, 1, 2, 3]), np.array([0, 3, 6, 10]))
    >>> _ = sort_graph((y, x), links, patches)
    >>> patches[0]
    array([1, 5, 4, 0, 3, 6, 2, 3, 4, 7])
    >>> patches[1]
    array([ 0,  3,  7, 10])
    """
    from .ext.remap_element import remap_graph_element

    if patches is not None and links is None:
        raise ValueError("graph that has patches must also have links")

    if links is not None:
        links = as_id_array(links)

    if patches is not None:
        if len(patches) == 2 and isinstance(patches[0], np.ndarray):
            links_at_patch, offset_to_patch = patches
        else:
            links_at_patch, offset_to_patch = flatten_jagged_array(patches, dtype=int)
        links_at_patch, offset_to_patch = (
            as_id_array(links_at_patch),
            as_id_array(offset_to_patch),
        )
    else:
        links_at_patch, offset_to_patch = (None, None)

    sorted_nodes = sort_nodes(nodes)

    if links is not None:
        remap_graph_element(
            links.reshape((-1,)),
            as_id_array(np.argsort(sorted_nodes, kind="mergesort")),
        )
        midpoint_of_link = np.empty((len(links), 2), dtype=float)
        sorted_links = sort_links(links, nodes, midpoint_of_link=midpoint_of_link)

    if patches is not None:
        remap_graph_element(
            links_at_patch, as_id_array(np.argsort(sorted_links, kind="mergesort"))
        )
        sort_patches(links_at_patch, offset_to_patch, midpoint_of_link)

    if links_at_patch is None:
        return nodes, links, None
    else:
        return nodes, links, (links_at_patch, offset_to_patch)


def sort_nodes(nodes):
    """Sort nodes based on their position.

    Parameters
    ----------
    nodes : tuple of ndarray of float
        Coordinates of nodes as (*y*, *x*).

    Returns
    -------
    ndarray of int
        Array of indices that sort the nodes.

    Examples
    --------
    >>> from landlab.graph.sort import sort_nodes
    >>> import numpy as np
    >>> x = np.array([0.0, 1.0, 2.0])
    >>> y = np.array([0.5, 0.0, 1.0])
    >>> sort_nodes((y, x))
    array([1, 0, 2])
    >>> x
    array([1., 0., 2.])
    >>> y
    array([0. , 0.5, 1. ])
    """
    sorted_nodes = argsort_points_by_x_then_y((nodes[1], nodes[0]))
    nodes[0][:] = nodes[0][sorted_nodes]
    nodes[1][:] = nodes[1][sorted_nodes]

    return sorted_nodes


def sort_links(nodes_at_link, nodes, midpoint_of_link=None):
    """Sort links by their midpoint.

    Parameters
    ----------
    nodes_at_link : ndarray of int, shape `(n_links, 2)`
        Node for each link tail and head.
    nodes : tuple of ndarray of float
        Node coordinates.
    midpoint_of_link : ndarray of float, shape `(n_links, 2)`, optional
        Buffer to store the link midpoints that were used for sorting.

    Returns
    -------
    ndarray of int
        Array of indices that sort the links.

    Examples
    --------
    >>> from landlab.graph.sort import sort_nodes
    >>> import numpy as np
    >>> nodes = np.array([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]])
    >>> links = np.array([[0, 1], [0, 3], [1, 2], [1, 4], [2, 5], [3, 4], [4, 5]])
    >>> sort_links(links, nodes)
    array([0, 2, 1, 3, 4, 5, 6])
    >>> links
    array([[0, 1],
           [1, 2],
           [0, 3],
           [1, 4],
           [2, 5],
           [3, 4],
           [4, 5]])
    """
    from ..quantity.ext.of_link import calc_midpoint_of_link

    y_of_node = np.asarray(nodes[0], dtype=float)
    x_of_node = np.asarray(nodes[1], dtype=float)

    if midpoint_of_link is None:
        midpoint_of_link = np.empty((len(nodes_at_link), 2), dtype=float)

    calc_midpoint_of_link(nodes_at_link, x_of_node, y_of_node, midpoint_of_link)

    sorted_links = argsort_points_by_x_then_y(midpoint_of_link)
    nodes_at_link[:] = nodes_at_link[sorted_links]
    midpoint_of_link[:] = midpoint_of_link[sorted_links]

    return sorted_links


def sort_patches(links_at_patch, offset_to_patch, xy_of_link):
    """Sort patches by their centroid.

    Parameters
    ----------
    links_at_patch : ndarray of int
        Links that define patches.
    offset_to_patch : ndarray of int
        Offsets into *links_at_patch* for each patch.
    xy_of_link : ndarray of float, shape `(n_links, 2)`
        Midpoint coordinates for each link.

    Examples
    --------
    >>> from landlab.graph.sort import sort_patches
    >>> import numpy as np
    >>> links_at_patch = np.array([0, 1, 2, 3, 2, 4])
    >>> offset_to_patch = np.array([0, 3, 6])
    >>> xy_of_link = np.array(
    ...     [[0.0, 0.5], [0.5, 1.0], [0.5, 0.5], [0.5, 0.0], [1.0, 0.5]]
    ... )
    >>> sort_patches(links_at_patch, offset_to_patch, xy_of_link)
    array([1, 0])
    >>> links_at_patch
    array([3, 2, 4, 0, 1, 2])
    >>> offset_to_patch
    array([0, 3, 6])
    """
    from .ext.remap_element import calc_center_of_patch
    from .ext.remap_element import reorder_patches

    n_patches = len(offset_to_patch) - 1
    xy_at_patch = np.empty((n_patches, 2), dtype=float)

    calc_center_of_patch(links_at_patch, offset_to_patch, xy_of_link, xy_at_patch)

    sorted_patches = argsort_points_by_x_then_y(xy_at_patch)
    reorder_patches(links_at_patch, offset_to_patch, sorted_patches)

    return sorted_patches


def sort_spokes_at_hub_on_graph(graph, spoke=None, at="node", inplace=False):
    """Order spokes of a graph clockwise around spokes.

    Parameters
    ----------
    graph : Graph-like
        A landlab graph.
    spoke : str
        Name of graph elements that make the spokes.
    at : {'node', 'corner', 'link', 'face', 'patch', 'cell'}
        Namve of graph elements that make the hubs.

    Returns
    -------
    ndarray of int, shape `(n_spokes, n_hubs)`
        Spokes ordered around each hub.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import UniformRectilinearGraph, TriGraph
    >>> from landlab.graph.sort.sort import sort_spokes_at_hub_on_graph

    >>> graph = UniformRectilinearGraph((3, 3))
    >>> sort_spokes_at_hub_on_graph(graph, "link", at="node")
    array([[ 0,  2, -1, -1],
           [ 1,  3,  0, -1],
           [ 4,  1, -1, -1],
           [ 5,  7,  2, -1],
           [ 6,  8,  5,  3],
           [ 9,  6,  4, -1],
           [10,  7, -1, -1],
           [11, 10,  8, -1],
           [11,  9, -1, -1]])

    >>> graph = TriGraph((3, 3), node_layout="hex", sort=True)
    >>> sort_spokes_at_hub_on_graph(graph, "patch", at="node")
    array([[ 0,  2, -1, -1, -1, -1],
           [ 1,  3,  0, -1, -1, -1],
           [ 4,  1, -1, -1, -1, -1],
           [ 5,  2, -1, -1, -1, -1],
           [ 6,  8,  5,  2,  0,  3],
           [ 7,  9,  6,  3,  1,  4],
           [ 7,  4, -1, -1, -1, -1],
           [ 5,  8, -1, -1, -1, -1],
           [ 8,  6,  9, -1, -1, -1],
           [ 9,  7, -1, -1, -1, -1]])
    """
    sorted_spokes = argsort_spokes_at_hub_on_graph(graph, spoke=spoke, at=at)
    if spoke == "patch":
        plural = "patches"
    else:
        plural = spoke + "s"
    spokes_at_hub = getattr(graph, f"{plural}_at_{at}")

    if inplace:
        out = spokes_at_hub
    else:
        out = np.empty_like(spokes_at_hub)

    return np.take(spokes_at_hub, sorted_spokes, out=out)


def argsort_spokes_at_hub_on_graph(graph, spoke=None, at="node"):
    """Order spokes clockwise around spokes.

    Parameters
    ----------
    graph : Graph-like
        A landlab graph.
    spoke : str
        Name of graph elements that make the spokes.
    at : str
        Namve of graph elements that make the hubs.

    Returns
    -------
    ndarray of int, shape `(n_spokes, n_hubs)`
        Spokes ordered around each hub.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import UniformRectilinearGraph
    >>> from landlab.graph.sort.sort import argsort_spokes_at_hub_on_graph

    >>> graph = UniformRectilinearGraph((3, 3))
    >>> argsort_spokes_at_hub_on_graph(graph, "link", at="node")
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 9, 10,  8, 11],
           [12, 13, 15, 14],
           [16, 17, 18, 19],
           [21, 22, 23, 20],
           [24, 27, 25, 26],
           [28, 30, 31, 29],
           [34, 35, 32, 33]])
    """
    angles = calc_angle_of_spoke_on_graph(graph, spoke=spoke, at=at, badval=np.inf)
    angles[angles < 0] += np.pi

    n_hubs, n_spokes = angles.shape
    ordered_angles = np.argsort(angles, kind="stable")
    ordered_angles += np.arange(n_hubs).reshape((-1, 1)) * n_spokes

    return as_id_array(ordered_angles)


def calc_angle_of_spoke_on_graph(graph, spoke=None, at="node", badval=None):
    """Calculate angles spokes make with a hub.

    Parameters
    ----------
    graph : Graph-like
        A landlab graph.
    spoke : str
        Name of graph elements that make the spokes.
    at : str
        Namve of graph elements that make the hubs.
    badval : float or iterable of float, optional
        Value to insert for missing spokes. If an iterable, use items as
        bad values to use for different spokes.

    Returns
    -------
    ndarray of float, shape `(n_spokes, n_hubs)`
        Angle that spoke elements make with each hub element.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.graph import UniformRectilinearGraph
    >>> from landlab.graph.sort.sort import calc_angle_of_spoke_on_graph

    >>> graph = UniformRectilinearGraph((3, 3))
    >>> np.rad2deg(
    ...     calc_angle_of_spoke_on_graph(graph, "link", at="node", badval=np.nan)
    ... )
    array([[   0.,   90.,   nan,   nan],
           [   0.,   90.,  180.,   nan],
           [  nan,   90.,  180.,   nan],
           [   0.,   90.,   nan,  270.],
           [   0.,   90.,  180.,  270.],
           [  nan,   90.,  180.,  270.],
           [   0.,   nan,   nan,  270.],
           [   0.,   nan,  180.,  270.],
           [  nan,   nan,  180.,  270.]])
    """
    xy_of_hub = getattr(graph, f"xy_of_{at}")
    xy_of_spoke = getattr(graph, f"xy_of_{spoke}")
    if spoke == "patch":
        plural = "patches"
    else:
        plural = spoke + "s"
    spokes_at_hub = getattr(graph, f"{plural}_at_{at}")

    angle_of_spoke = calc_angle_of_spoke(
        spokes_at_hub, xy_of_hub, xy_of_spoke, badval=badval
    )

    return angle_of_spoke


def sort_spokes_at_hub(spokes_at_hub, xy_of_hub, xy_of_spokes, inplace=False):
    if inplace:
        out = spokes_at_hub
    else:
        out = np.empty_like(spokes_at_hub)

    dx = np.subtract(xy_of_spokes[:, 0][spokes_at_hub], xy_of_hub[:, 0, None])
    dy = np.subtract(xy_of_spokes[:, 1][spokes_at_hub], xy_of_hub[:, 1, None])

    angle_of_spoke_at_hub = np.arctan2(dy, dx, where=spokes_at_hub != -1)
    angle_of_spoke_at_hub[angle_of_spoke_at_hub < 0.0] += np.pi * 2.0

    sort_id_array(spokes_at_hub, angle_of_spoke_at_hub, out)

    return out


def argsort_spokes_at_hub(spokes_at_hub, xy_of_hub, xy_of_spokes):
    angles = calc_angle_of_spoke(spokes_at_hub, xy_of_hub, xy_of_spokes, badval=np.inf)
    angles[angles < 0] += np.pi

    n_hubs, n_spokes = angles.shape
    ordered_angles = np.argsort(angles, kind="stable")
    ordered_angles += np.arange(n_hubs).reshape((-1, 1)) * n_spokes

    return as_id_array(ordered_angles)


def calc_angle_of_spoke(spokes_at_hub, xy_of_hub, xy_of_spoke, badval=None):
    xy_of_spoke = xy_of_spoke[spokes_at_hub.flat]
    x_of_spoke = xy_of_spoke[:, 0].reshape(spokes_at_hub.shape)
    y_of_spoke = xy_of_spoke[:, 1].reshape(spokes_at_hub.shape)

    x_of_hub, y_of_hub = xy_of_hub[:, 0], xy_of_hub[:, 1]

    dx = (x_of_spoke.T - x_of_hub).T
    dy = (y_of_spoke.T - y_of_hub).T

    angle_of_spoke = np.arctan2(dy, dx)
    angle_of_spoke[angle_of_spoke < 0.0] += np.pi * 2.0

    if badval is not None:
        try:
            badval_for_column = enumerate(badval)
        except TypeError:
            angle_of_spoke[spokes_at_hub == -1] = badval
        else:
            for col, val in badval_for_column:
                angle_of_spoke[spokes_at_hub[:, col] == -1, col] = val

    return angle_of_spoke



================================================
File: src/landlab/graph/sort/ext/__init__.py
================================================



================================================
File: src/landlab/graph/sort/ext/_deprecated_sparse.pyx
================================================
cimport cython
from libc.stdint cimport uint8_t
from libc.stdlib cimport free
from libc.stdlib cimport malloc

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long

ctypedef fused integral_out_t:
    cython.integral
    long long


cdef struct SparseMatrixInt:
    long *values
    long n_values
    long *offset_to_row
    long *col
    long col_start
    long col_stride
    long n_rows
    long n_cols
    long no_val


cdef SparseMatrixInt sparse_matrix_alloc_with_tuple(
    const id_t [:] rows_and_cols,
    const integral_out_t [:] values,
    long n_values,
    long no_val,
):
    cdef long n_rows
    cdef long n_cols
    cdef long max_row = 0
    cdef long max_col = 0
    cdef long i
    cdef SparseMatrixInt mat
    cdef long * col_ptr
    cdef long * values_ptr
    cdef long * offset_ptr
    cdef long [:] offset_array

    for i in range(0, n_values * 2, 2):
        if rows_and_cols[i] > max_row:
            max_row = rows_and_cols[i]
        if rows_and_cols[i + 1] > max_col:
            max_col = rows_and_cols[i + 1]
    n_rows = max_row + 1
    n_cols = max_col + 1

    offset_ptr = <long *>malloc((n_rows + 1) * sizeof(long))
    offset_array = <long [:n_rows + 1]>offset_ptr

    col_ptr = <long *>malloc((2 * n_values) * sizeof(long))
    values_ptr = <long *>malloc(n_values * sizeof(long))
    for i in range(2 * n_values):
        col_ptr[i] = rows_and_cols[i]
    for i in range(n_values):
        values_ptr[i] = values[i]

    _offset_to_sorted_blocks(rows_and_cols, n_values, 2, offset_array, n_rows + 1)

    mat.values = values_ptr
    mat.n_values = n_values
    mat.offset_to_row = offset_ptr
    mat.col = col_ptr
    mat.col_start = 1
    mat.col_stride = 2
    mat.n_rows = n_rows
    mat.n_cols = n_cols
    mat.no_val = no_val

    return mat


cdef sparse_matrix_free(SparseMatrixInt mat):
    free(mat.offset_to_row)
    free(mat.col)
    free(mat.values)


cdef long sparse_matrix_get_or_transpose(SparseMatrixInt mat, long row, long col):
    cdef long val
    val = sparse_matrix_get(mat, row, col)
    if val == mat.no_val:
        val = sparse_matrix_get(mat, col, row)
    return val


cdef long sparse_matrix_get(SparseMatrixInt mat, long row, long col):
    cdef long start
    cdef long stop
    cdef long n
    cdef long i

    if row < 0:
        return mat.no_val
    elif row >= mat.n_rows:
        return mat.no_val
    elif col < 0:
        return mat.no_val
    elif col >= mat.n_cols:
        return mat.no_val

    start = mat.offset_to_row[row]
    stop = mat.offset_to_row[row + 1]

    i = mat.col_start + start * mat.col_stride
    for n in range(start, stop):
        if mat.col[i] == col:
            return mat.values[n]
        i += mat.col_stride

    return mat.no_val


cdef void _offset_to_sorted_blocks(
    const id_t [:] array,
    long len,
    long stride,
    integral_out_t [:] offset,
    long n_values,
) noexcept:
    cdef long i
    cdef long value
    cdef long first_non_negative

    first_non_negative = len * stride
    for i in range(0, len * stride, stride):
        if array[i] >= 0:
            first_non_negative = i
            break

    offset[0] = first_non_negative
    for value in range(1, n_values):
        offset[value] = offset[value - 1]
        for i in range(offset[value], len * stride, stride):
            if array[i] >= value:
                offset[value] = i
                break
        else:
            offset[value] = len * stride

    for value in range(n_values):
        offset[value] = offset[value] // stride


@cython.boundscheck(False)
@cython.wraparound(False)
def offset_to_sorted_block(
    id_t [:, :] sorted_ids,
    integral_out_t [:] offset_to_block,
):
    cdef long n_ids = sorted_ids.shape[0]
    cdef long n_blocks = offset_to_block.shape[0]
    cdef id_t *ptr = &sorted_ids[0, 0]
    cdef id_t [:] sorted_ids_flat = <id_t[:sorted_ids.size]>ptr

    _offset_to_sorted_blocks(
        sorted_ids_flat,
        n_ids,
        sorted_ids.shape[1],
        offset_to_block,
        n_blocks,
    )


@cython.boundscheck(False)
@cython.wraparound(False)
def pair_isin(
    const id_t [:, :] src_pairs,
    const id_t [:, :] pairs,
    uint8_t [:] out,
):
    cdef long pair
    cdef long n_pairs = pairs.shape[0]
    cdef long n_values = src_pairs.shape[0]
    cdef long * data_ptr = <long *>malloc(n_values * sizeof(long))
    cdef long [:] data_array = <long [:n_values]>data_ptr
    cdef const id_t *ptr = &src_pairs[0, 0]
    cdef const id_t [:] src_pairs_flat = <const id_t[:src_pairs.size]>ptr
    cdef SparseMatrixInt mat

    for n in range(n_values):
        data_array[n] = 1

    try:
        mat = sparse_matrix_alloc_with_tuple(src_pairs_flat, data_array, n_values, 0)
        for pair in range(n_pairs):
            out[pair] = sparse_matrix_get_or_transpose(
                mat, pairs[pair, 0], pairs[pair, 1]
            )
    finally:
        free(data_ptr)


@cython.boundscheck(False)
@cython.wraparound(False)
def map_pairs_to_values(
    const id_t [:, :] src_pairs,
    const integral_out_t [:] data,
    const id_t [:, :] pairs,
    integral_out_t [:] out,
):
    cdef long pair
    cdef long n_pairs = out.shape[0]
    cdef long n_values = data.shape[0]
    cdef const id_t *ptr = &src_pairs[0, 0]
    cdef const id_t [:] src_pairs_flat = <const id_t[:src_pairs.size]>ptr
    cdef SparseMatrixInt mat

    mat = sparse_matrix_alloc_with_tuple(src_pairs_flat, data, n_values, -1)

    for pair in range(n_pairs):
        out[pair] = sparse_matrix_get_or_transpose(mat, pairs[pair, 0], pairs[pair, 1])


@cython.boundscheck(False)
@cython.wraparound(False)
def map_rolling_pairs_to_values(
    const id_t [:, :] src_pairs,
    const integral_out_t [:] data,
    const id_t [:, :] pairs,
    const id_t [:] size_of_row,
    integral_out_t [:, :] out,
):
    cdef long n_values = data.shape[0]
    cdef long n_pairs = pairs.shape[0]
    cdef long pair
    cdef const id_t *ptr = &src_pairs[0, 0]
    cdef const id_t [:] src_pairs_flat = <const id_t[:2 * len(src_pairs)]>ptr
    cdef SparseMatrixInt mat

    mat = sparse_matrix_alloc_with_tuple(src_pairs_flat, data, n_values, -1)

    for pair in range(n_pairs):
        _map_rolling_pairs(mat, pairs[pair, :], out[pair, :], size_of_row[pair])


cdef _map_rolling_pairs(
    SparseMatrixInt mat,
    const id_t [:] pairs,
    integral_out_t [:] out,
    long size,
):
    cdef long n

    if size > 0:
        for n in range(size - 1):
            out[n] = sparse_matrix_get_or_transpose(mat, pairs[n], pairs[n + 1])

        n = size - 1
        out[n] = sparse_matrix_get_or_transpose(mat, pairs[n], pairs[0])



================================================
File: src/landlab/graph/sort/ext/argsort.pxd
================================================
cimport cython

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


cdef void argsort_flt(cython.floating * base, int n_elements, id_t * out) nogil
cdef void argsort_int(long * base, int n_elements, int * out) nogil
cdef int unique_int(long * data, int n_elements, int * out)



================================================
File: src/landlab/graph/sort/ext/argsort.pyx
================================================
cimport cython
from cython cimport view
from libc.stdlib cimport free
from libc.stdlib cimport malloc

from cython.parallel import prange


cdef struct Sorter:
    long index
    double value


cdef struct IntSorter:
    long index
    long value


cdef extern from "stdlib.h":
    ctypedef void const_void "const void"
    int qsort(void *, size_t, size_t, int(*)(const_void *, const_void *)) nogil
    int	mergesort(void *, size_t, size_t, int (*)(const_void *, const_void *)) nogil


cdef int _compare(const_void *a, const_void *b) noexcept:
    cdef double v = ((<Sorter*>a)).value - ((<Sorter*>b)).value
    if v < 0:
        return -1
    elif v > 0:
        return 1
    else:
        return 0


cdef int _compare_int(const_void *a, const_void *b) noexcept:
    cdef int v = ((<IntSorter*>a)).value - ((<IntSorter*>b)).value
    if v < 0:
        return -1
    elif v > 0:
        return 1
    else:
        return 0


cdef void argsort_flt(
    cython.floating * data, int n_elements, id_t * out
) noexcept nogil:
    cdef Sorter *sorted_struct = <Sorter*>malloc(n_elements * sizeof(Sorter))
    cdef int i

    try:
        # _argsort(data, n_elements, sorted_struct)
        for i in range(n_elements):
            sorted_struct[i].index = i
            sorted_struct[i].value = data[i]

        qsort(<void*> sorted_struct, n_elements, sizeof(Sorter), _compare_int)

        for i in range(n_elements):
            out[i] = sorted_struct[i].index
    finally:
        free(sorted_struct)


cdef void argsort_int(long * data, int n_elements, int * out) noexcept nogil:
    cdef IntSorter *sorted_struct = <IntSorter*>malloc(n_elements * sizeof(IntSorter))
    cdef int i

    try:
        for i in range(n_elements):
            sorted_struct[i].index = i
            sorted_struct[i].value = data[i]

        qsort(<void*> sorted_struct, n_elements, sizeof(IntSorter), _compare_int)

        for i in range(n_elements):
            out[i] = sorted_struct[i].index
    finally:
        free(sorted_struct)


cdef int unique_int(long * data, int n_elements, int * out):
    cdef int * index = <int *>malloc(n_elements * sizeof(int))
    cdef int n_unique

    try:
        argsort_int(data, n_elements, index)

        if data[index[0]] != data[index[1]]:
            out[0] = data[index[0]]
        else:
            out[0] = data[index[1]]

        n_unique = 1
        for i in range(1, n_elements):
            if data[index[i]] != data[index[i - 1]]:
                out[n_unique] = data[index[i]]
                n_unique += 1
    finally:
        free(index)

    return n_unique


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef sort_children_at_parent(
    id_t [:, :] children_at_parent,
    cython.floating [:] value_at_child,
    id_t [:, :] out,
):
    """Sort the children of parents based on child values.

    Parameters
    ----------
    children_at_parent : ndarray of shape (n_parents, max_family_size)
        Matrix where each row is the IDs of the children (i.e. an index
        into the value_at_child array) belonging to a parent. A value
        of -1 indicates the lack of a child. Note that children can
        belong to multiple parents.
    value_at_child : ndarray of shape (n_children,)
        A value for each child to sort on.
    out : ndarray of shape (n_parents, max_family_size)
        Output array that contains the sorted children for each parent.
        Missing children (i.e. -1 values) are pushed to the each of
        each row.
    """
    cdef int n_parents = children_at_parent.shape[0]
    cdef int n_cols = children_at_parent.shape[1]
    cdef int n_children
    cdef int col
    cdef int parent, child
    cdef double [:, :] values = view.array(
        shape=(n_parents, n_cols),
        itemsize=sizeof(double),
        format="d",
        allocate_buffer=True,
    )
    cdef int [:, :] sorted_indices = view.array(
        shape=(n_parents, n_cols),
        itemsize=sizeof(int),
        format="i",
        allocate_buffer=True,
    )
    cdef int [:, :] indices = view.array(
        shape=(n_parents, n_cols),
        itemsize=sizeof(int),
        format="i",
        allocate_buffer=True,
    )

    for parent in prange(n_parents, nogil=True, schedule="static"):
        n_children = 0
        for col in range(n_cols):
            child = children_at_parent[parent, col]
            if child != -1:
                indices[parent, n_children] = child
                values[parent, n_children] = value_at_child[child]
                n_children = n_children + 1

        if n_children > 0:
            argsort_flt(&values[parent, 0], n_children, &sorted_indices[parent, 0])
            for col in range(n_children):
                out[parent, col] = indices[parent, sorted_indices[parent, col]]
            for col in range(n_children, n_cols):
                out[parent, col] = -1


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef sort_id_array(
    const id_t [:, :] id_array,
    const cython.floating [:, :] data,
    id_t [:, :] out,
):
    """Sort rows of an id-array matrix.

    Parameters
    ----------
    children_at_parent : ndarray of shape (n_parents, max_family_size)
        Matrix where each row is the IDs of the children (i.e. an index
        into the value_at_child array) belonging to a parent. A value
        of -1 indicates the lack of a child.
    value_at_child : ndarray of shape (n_children,)
        A value for each child to sort on.
    out : ndarray of shape (n_parents, max_family_size)
        Output array that contains the sorted children for each parent.
        Missing children (i.e. -1 values) are pushed to the each of
        each row.
    """
    cdef int n_rows = data.shape[0]
    cdef int n_cols = data.shape[1]
    cdef int row, col
    cdef int [:, :] sorted_indices = view.array(
        shape=(n_rows, n_cols),
        itemsize=sizeof(int),
        format="i",
        allocate_buffer=True,
    )
    cdef id_t * temp

    for row in prange(n_rows, nogil=True, schedule="static"):
        temp = <id_t*>malloc(sizeof(id_t) * n_cols)
        try:
            for col in range(n_cols):
                temp[col] = id_array[row, col]

            argsort_id_array(data[row, :], id_array[row, :], sorted_indices[row, :])
            for col in range(n_cols):
                if sorted_indices[row, col] != -1:
                    out[row, col] = temp[sorted_indices[row, col]]
                else:
                    out[row, col] = -1
        finally:
            free(temp)


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void argsort_id_array(
    const cython.floating [:] data,
    const id_t [:] id_array,
    cython.integral [:] out,
) noexcept nogil:
    cdef int n_elements = len(data)
    cdef int i
    cdef int count = 0
    cdef Sorter *order = <Sorter*>malloc(n_elements * sizeof(Sorter))

    try:
        for i in range(n_elements):
            if id_array[i] != -1:
                order[count].index = i
                order[count].value = data[i]
                count = count + 1

        qsort(<void*> order, count, sizeof(Sorter), _compare)

        for i in range(count):
            out[i] = order[i].index
        for i in range(count, n_elements):
            out[i] = -1
    finally:
        free(order)



================================================
File: src/landlab/graph/sort/ext/intpair.pyx
================================================
cimport cython

from cython.parallel import prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


ctypedef fused integral_out_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void fill_offsets_to_sorted_blocks(
    const id_t [:] array,
    integral_out_t [:] offsets,
) noexcept nogil:
    cdef long n_values = len(array)
    cdef long n_offsets = len(offsets)
    cdef long first_non_negative
    cdef long i
    cdef long j

    for i in range(0, n_values):
        if array[i] >= 0:
            first_non_negative = i
            break
    else:
        first_non_negative = n_values

    offsets[0] = first_non_negative
    for i in range(1, n_offsets):
        offsets[i] = offsets[i - 1]
        for j in range(offsets[i], n_values):
            if array[j] >= i:
                offsets[i] = j
                break
        else:
            offsets[i] = n_values


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void find_pairs(
    const id_t [:, :] array,
    const integral_out_t [:] offsets,
    const id_t [:, :] pairs,
    id_t [:] where,
) noexcept nogil:
    cdef long n_pairs = len(pairs)
    cdef long pair
    cdef long first
    cdef long second
    cdef long ind

    for pair in prange(n_pairs, nogil=True, schedule="static"):
        first = pairs[pair, 0]
        second = pairs[pair, 1]

        ind = find_pair(array, offsets, first, second)
        if ind == -1:
            ind = find_pair(array, offsets, second, first)

        where[pair] = ind


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void find_rolling_pairs(
    const id_t [:, :] array,
    const integral_out_t [:] offsets,
    const id_t [:] pairs,
    integral_out_t [:] where,
    const int wraparound,
) noexcept nogil:
    cdef long n_pairs = len(pairs)
    cdef long first
    cdef long second
    cdef long i
    cdef long ind

    for i in range(n_pairs - 1):
        first = pairs[i]
        second = pairs[i + 1]

        ind = find_pair(array, offsets, first, second)
        if ind == -1:
            ind = find_pair(array, offsets, second, first)

        where[i] = ind

    if wraparound:
        first = pairs[n_pairs - 1]
        second = pairs[0]

        ind = find_pair(array, offsets, first, second)
        if ind == -1:
            ind = find_pair(array, offsets, second, first)

        where[n_pairs - 1] = ind


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef void find_rolling_pairs_2d(
    const id_t [:, :] array,
    const integral_out_t [:] offsets,
    const id_t [:, :] pairs,
    integral_out_t [:, :] where,
    const int wraparound,
) noexcept nogil:
    cdef long n_rows = len(pairs)
    cdef long n_cols = pairs.shape[1]
    cdef long length_of_row
    cdef long row

    for row in prange(n_rows, nogil=True, schedule="static"):
        length_of_row = find_first(pairs[row, :], -1)
        if length_of_row == -1:
            length_of_row = n_cols

        if length_of_row > 1:
            find_rolling_pairs(
                array,
                offsets,
                pairs[row, :length_of_row],
                where[row, :length_of_row],
                wraparound,
            )


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef long find_pair(
    const id_t [:, :] pairs,
    const integral_out_t [:] offsets,
    const long a,
    const long b,
) noexcept nogil:
    cdef long n_offsets = len(offsets)
    cdef long start
    cdef long stop
    cdef long ind

    if a + 1 >= n_offsets:
        return -1

    start = offsets[a]
    stop = offsets[a + 1]

    ind = find_first(pairs[start:stop, 1], b)
    if ind >= 0:
        ind += start

    return ind


@cython.boundscheck(False)
@cython.wraparound(False)
cpdef long find_first(
    const id_t [:] array,
    const id_t value,
) noexcept nogil:
    cdef long n_values = len(array)
    cdef long i

    for i in range(n_values):
        if array[i] == value:
            return i
    else:
        return -1



================================================
File: src/landlab/graph/sort/ext/remap_element.pyx
================================================
cimport cython

import numpy as np
from cython.parallel import prange

cimport numpy as np
from libc.stdlib cimport free
from libc.stdlib cimport malloc


cdef extern from "math.h":
    double atan2(double y, double x) nogil


from .spoke_sort import sort_spokes_at_wheel

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long

ctypedef fused integral_out_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def reverse_one_to_one(
    const id_t [:] mapping,
    id_t [:] out,
):
    cdef int n_elements = mapping.shape[0]
    cdef int index
    cdef int id_

    for index in prange(n_elements, nogil=True, schedule="static"):
        id_ = mapping[index]
        if id_ >= 0:
            out[id_] = index


@cython.boundscheck(False)
@cython.wraparound(False)
def reverse_one_to_many(
    const id_t [:, :] mapping,
    id_t [:, :] out,
):
    cdef int n_elements = mapping.shape[0]
    cdef int n_cols = mapping.shape[1]
    cdef int out_rows = out.shape[0]
    cdef int index
    cdef int id_
    cdef int *count = <int *>malloc(out_rows * sizeof(int))

    try:
        for index in range(out_rows):
            count[index] = 0

        for index in range(n_elements):
            for col in range(n_cols):
                id_ = mapping[index, col]
                if id_ >= 0:
                    out[id_, count[id_]] = index
                    count[id_] += 1
    finally:
        free(count)


@cython.boundscheck(False)
@cython.wraparound(False)
def remap_graph_element(
    id_t [:] elements,
    const id_t [:] old_to_new,
):
    """Remap elements in an array in place.

    Parameters
    ----------
    elements : ndarray of int
        Identifiers of elements.
    old_to_new : ndarray of int
        Mapping from the old identifier to the new identifier.
    """
    cdef int n_elements = elements.shape[0]
    cdef int i

    for i in prange(n_elements, nogil=True, schedule="static"):
        elements[i] = old_to_new[elements[i]]


@cython.boundscheck(False)
@cython.wraparound(False)
def remap_graph_element_ignore(
    id_t [:] elements,
    const id_t [:] old_to_new,
    long bad_val,
):
    """Remap elements in an array in place, ignoring bad values.

    Parameters
    ----------
    elements : ndarray of int
        Identifiers of elements.
    old_to_new : ndarray of int
        Mapping from the old identifier to the new identifier.
    bad_val : int
        Ignore values in the input array when remapping.
    """
    cdef long n_elements = elements.shape[0]
    cdef long i

    for i in prange(n_elements, nogil=True, schedule="static"):
        if elements[i] != bad_val:
            elements[i] = old_to_new[elements[i]]


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_patches(
    id_t [:] links_at_patch,
    id_t [:] offset_to_patch,
    const id_t [:] sorted_patches,
):
    cdef int i
    cdef int patch
    cdef int offset
    cdef int n_links
    cdef int n_patches = len(sorted_patches)
    cdef int *new_offset = <int *>malloc(len(offset_to_patch) * sizeof(int))
    cdef int *new_patches = <int *>malloc(len(links_at_patch) * sizeof(int))

    try:
        new_offset[0] = 0
        for patch in range(n_patches):
            offset = offset_to_patch[sorted_patches[patch]]
            n_links = offset_to_patch[sorted_patches[patch] + 1] - offset

            new_offset[patch + 1] = new_offset[patch] + n_links
            for i in range(n_links):
                new_patches[new_offset[patch] + i] = links_at_patch[offset + i]

        for i in range(len(links_at_patch)):
            links_at_patch[i] = new_patches[i]
        for i in range(len(offset_to_patch)):
            offset_to_patch[i] = new_offset[i]
    finally:
        free(new_offset)
        free(new_patches)


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_center_of_patch(
    const id_t [:] links_at_patch,
    const id_t [:] offset_to_patch,
    const cython.floating [:, :] xy_at_link,
    cython.floating [:, :] xy_at_patch,
):
    cdef int patch
    cdef int link
    cdef int i
    cdef int offset
    cdef int n_links
    cdef int n_patches = len(xy_at_patch)
    cdef double x
    cdef double y

    for patch in range(n_patches):
        offset = offset_to_patch[patch]
        n_links = offset_to_patch[patch + 1] - offset
        x = 0.
        y = 0.
        for i in range(offset, offset + n_links):
            link = links_at_patch[i]
            x += xy_at_link[link, 0]
            y += xy_at_link[link, 1]
        xy_at_patch[patch, 0] = x / n_links
        xy_at_patch[patch, 1] = y / n_links


@cython.boundscheck(False)
@cython.wraparound(False)
def reorder_links_at_patch(
    id_t [:] links_at_patch,
    id_t [:] offset_to_patch,
    cython.floating [:, :] xy_of_link,
):
    cdef int n_patches = len(offset_to_patch) - 1

    xy_of_patch = np.empty((n_patches, 2), dtype=float)
    calc_center_of_patch(
        links_at_patch, offset_to_patch, xy_of_link, xy_of_patch
    )
    sort_spokes_at_wheel(
        links_at_patch, offset_to_patch, xy_of_patch, xy_of_link
    )


cdef void reverse_order(id_t * array, long size) noexcept nogil:
    cdef long i
    cdef long temp

    for i in range(size // 2):
        temp = array[i]
        array[i] = array[(size - 1) - i]
        array[(size - 1) - i] = temp


@cython.boundscheck(False)
@cython.wraparound(False)
def reverse_element_order(
    id_t [:, :] links_at_patch,
    const id_t [:] patches,
):
    cdef long n_patches = patches.shape[0]
    cdef long max_links = links_at_patch.shape[1]
    cdef long patch
    cdef long n
    cdef long i

    for i in prange(n_patches, nogil=True, schedule="static"):
        patch = patches[i]
        n = 1
        while n < max_links:
            if links_at_patch[patch, n] == -1:
                break
            n = n + 1
        reverse_order(&links_at_patch[patch, 1], n - 1)



================================================
File: src/landlab/graph/sort/ext/spoke_sort.pyx
================================================
cimport cython

from cython.parallel import prange

from libc.math cimport M_PI
from libc.math cimport atan2
from libc.stdlib cimport free
from libc.stdlib cimport malloc

from .argsort cimport argsort_flt

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


cdef void _calc_spoke_angles(
    cython.floating * hub,
    cython.floating * spokes,
    int n_spokes,
    cython.floating * angles,
) noexcept nogil:
    cdef int i
    cdef double x0 = hub[0]
    cdef double y0 = hub[1]
    cdef cython.floating * spoke = spokes
    cdef double two_pi = 2. * M_PI
    cdef double x
    cdef double y

    for i in range(n_spokes):
        x = spoke[0]
        y = spoke[1]

        angles[i] = atan2(y - y0, x - x0)
        if angles[i] < 0.:
            angles[i] += two_pi
        spoke += 2


cdef void _argsort_spokes_around_hub(
    id_t * spokes,
    int n_spokes,
    cython.floating * xy_of_spoke,
    cython.floating * xy_of_hub,
    id_t * ordered,
) noexcept nogil:
    cdef int point
    cdef int spoke
    cdef cython.floating * points = <cython.floating *>malloc(
        2 * n_spokes * sizeof(cython.floating)
    )
    cdef cython.floating * angles = <cython.floating *>malloc(
        n_spokes * sizeof(cython.floating)
    )

    try:
        point = 0
        for spoke in range(n_spokes):
            points[point] = xy_of_spoke[2 * spokes[spoke]]
            points[point + 1] = xy_of_spoke[2 * spokes[spoke] + 1]
            point += 2

        _calc_spoke_angles(xy_of_hub, points, n_spokes, angles)
        argsort_flt(angles, n_spokes, ordered)
    finally:
        free(angles)
        free(points)


cdef void _sort_spokes_around_hub(
    id_t * spokes,
    int n_spokes,
    cython.floating * xy_of_spoke,
    cython.floating * xy_of_hub,
) noexcept nogil:
    cdef int spoke
    cdef id_t * ordered = <id_t *>malloc(n_spokes * sizeof(id_t))
    cdef id_t * temp = <id_t *>malloc(n_spokes * sizeof(id_t))

    try:
        _argsort_spokes_around_hub(spokes, n_spokes, xy_of_spoke, xy_of_hub, ordered)

        for spoke in range(n_spokes):
            temp[spoke] = spokes[ordered[spoke]]

        for spoke in range(n_spokes):
            spokes[spoke] = temp[spoke]
    finally:
        free(temp)
        free(ordered)


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_spoke_angles(
    cython.floating [:] hub,
    cython.floating [:] spokes,
    cython.floating [:] angles,
):
    cdef int n_spokes = spokes.shape[0] // 2
    _calc_spoke_angles(&hub[0], &spokes[0], n_spokes, &angles[0])


@cython.boundscheck(False)
@cython.wraparound(False)
def sort_spokes_around_hub(
    id_t [:] spokes,
    cython.floating [:, :] xy_of_spoke,
    cython.floating [:] xy_of_hub,
):
    cdef int n_spokes = spokes.shape[0]

    _sort_spokes_around_hub(&spokes[0], n_spokes, &xy_of_spoke[0, 0], &xy_of_hub[0])


@cython.boundscheck(False)
@cython.wraparound(False)
def argsort_points_around_hub(
    cython.floating [:, :] points,
    cython.floating [:] hub,
    id_t [:] out,
):
    """Sort spokes by angle around a hub.

    Parameters
    ----------
    points : ndarray of float, shape `(n_points, 2)`
        Coordinates of points as (*x*, *y*).
    out : ndarray of int, shape `(n_points, )`
        Indices of sorted points.

    Returns
    -------
    ndarray of int, shape `(n_points, )`
        Indices of sorted points.
    """
    cdef int n_points = points.shape[0]
    cdef cython.floating *angles = <cython.floating *>malloc(
        n_points * sizeof(cython.floating)
    )

    try:
        _calc_spoke_angles(&hub[0], &points[0, 0], n_points, angles)
        argsort_flt(angles, n_points, &out[0])
    finally:
        free(angles)

    return out


@cython.boundscheck(False)
@cython.wraparound(False)
def argsort_spokes_at_wheel(
    id_t [:] spokes_at_wheel,
    id_t [:] offset_to_wheel,
    cython.floating [:, :] xy_of_hub,
    cython.floating [:, :] xy_of_spoke,
    id_t [:] ordered,
):
    cdef long n_wheels = len(offset_to_wheel) - 1
    cdef long i
    cdef id_t n_spokes
    cdef id_t * wheel
    cdef id_t * order

    for i in prange(n_wheels, nogil=True, schedule="static"):
        n_spokes = offset_to_wheel[i + 1] - offset_to_wheel[i]
        wheel = &spokes_at_wheel[offset_to_wheel[i]]
        order = &ordered[offset_to_wheel[i]]

        _argsort_spokes_around_hub(
            wheel, n_spokes, &xy_of_spoke[0, 0], &xy_of_hub[i, 0], order
        )


@cython.boundscheck(False)
@cython.wraparound(False)
def sort_spokes_at_wheel(
    id_t [:] spokes_at_wheel,
    id_t [:] offset_to_wheel,
    cython.floating [:, :] xy_of_hub,
    cython.floating [:, :] xy_of_spoke,
):
    """Sort spokes about multiple hubs.

    Parameters
    ----------
    spokes_at_wheel : ndarray of int
        Spokes for each wheel.
    offset_to_wheel : ndarray of int
        Offset into *spokes_at_wheel* for each wheel.
    xy_of_hub : ndarray of float, shape `(n_hubs, 2)`
        Coordinates of each hub as `(x, y)`.
    xy_of_spoke : ndarray of float, shape `(n_spokes, 2)`
        Coordinates of the end of each spoke as `(x, y)`.
    """
    cdef int n_wheels = len(offset_to_wheel) - 1
    cdef int i
    cdef int n_spokes
    cdef int spoke
    cdef id_t * wheel

    for i in prange(n_wheels, nogil=True, schedule="static"):
        wheel = &spokes_at_wheel[offset_to_wheel[i]]
        n_spokes = offset_to_wheel[i + 1] - offset_to_wheel[i]
        for spoke in range(n_spokes):
            if wheel[spoke] == -1:
                n_spokes = spoke
                break

        _sort_spokes_around_hub(wheel, n_spokes, &xy_of_spoke[0, 0], &xy_of_hub[i, 0])



================================================
File: src/landlab/graph/structured_quad/__init__.py
================================================
from .dual_structured_quad import DualRectilinearGraph
from .dual_structured_quad import DualStructuredQuadGraph
from .dual_structured_quad import DualUniformRectilinearGraph
from .structured_quad import RectilinearGraph
from .structured_quad import StructuredQuadGraph
from .structured_quad import UniformRectilinearGraph

__all__ = [
    "StructuredQuadGraph",
    "RectilinearGraph",
    "UniformRectilinearGraph",
    "DualUniformRectilinearGraph",
    "DualRectilinearGraph",
    "DualStructuredQuadGraph",
]



================================================
File: src/landlab/graph/structured_quad/dual_structured_quad.py
================================================
import numpy as np

from ..dual import DualGraph
from .structured_quad import RectilinearGraph
from .structured_quad import StructuredQuadGraph
from .structured_quad import UniformRectilinearGraph


class DualStructuredQuadGraph(DualGraph, StructuredQuadGraph):
    """Dual graph of a structured grid of quadrilaterals.

    Examples
    --------
    >>> from landlab.graph import DualStructuredQuadGraph
    >>> node_y = [-1, -2, -3, 0, 0, 0, 1, 2, 3]
    >>> node_x = [0, 1, 2, 0, 2, 3, 0, 1, 2]
    >>> graph = DualStructuredQuadGraph((node_y, node_x), shape=(3, 3), sort=True)
    >>> graph.number_of_corners == 4
    True
    >>> graph.y_of_corner
    array([-1.25, -0.75,  0.75,  1.25])
    >>> graph.x_of_corner
    array([2.  , 0.75, 0.75, 2.  ])
    >>> graph.node_at_cell
    array([4])
    """

    def __init__(self, node_y_and_x, shape=None, sort=True):
        StructuredQuadGraph.__init__(self, node_y_and_x, shape=shape)

        dual_graph = StructuredQuadGraph(
            DualStructuredQuadGraph.get_corners(node_y_and_x, self.shape)
        )

        self.merge(
            dual_graph,
            node_at_cell=DualStructuredQuadGraph.get_node_at_cell(self.shape),
            nodes_at_face=DualStructuredQuadGraph.get_nodes_at_face(self.shape),
        )

        if sort:
            self.sort()

    @staticmethod
    def get_corners(node_y_and_x, shape):
        y_of_node, x_of_node = (
            np.asarray(node_y_and_x[0], dtype=float),
            np.asarray(node_y_and_x[1], dtype=float),
        )
        y_of_node.shape = x_of_node.shape = shape

        x_of_corner = (
            x_of_node[:-1, :-1]
            + x_of_node[:-1, 1:]
            + x_of_node[1:, :-1]
            + x_of_node[1:, 1:]
        ) * 0.25
        y_of_corner = (
            y_of_node[:-1, :-1]
            + y_of_node[:-1, 1:]
            + y_of_node[1:, :-1]
            + y_of_node[1:, 1:]
        ) * 0.25

        return y_of_corner, x_of_corner

    @staticmethod
    def get_node_at_cell(shape):
        """Set up an array that gives the node at each cell.

        Examples
        --------
        >>> from landlab.graph.structured_quad import DualStructuredQuadGraph
        >>> DualStructuredQuadGraph.get_node_at_cell((5, 6))
        array([ 7,  8,  9, 10,
               13, 14, 15, 16,
               19, 20, 21, 22])
        """
        from .ext.at_cell import fill_node_at_cell

        node_at_cell = np.empty((shape[0] - 2) * (shape[1] - 2), dtype=int)

        fill_node_at_cell(shape, node_at_cell)

        return node_at_cell

    @staticmethod
    def get_nodes_at_face(shape):
        """Set up an array that gives the nodes on either side of each face.

        Examples
        --------
        >>> from landlab.graph.structured_quad import DualStructuredQuadGraph
        >>> DualStructuredQuadGraph.get_nodes_at_face((3, 4))
        array([[ 1,  5], [ 2,  6],
               [ 4,  5], [ 5,  6], [ 6,  7],
               [ 5,  9], [ 6, 10]])
        """
        from .ext.at_face import fill_nodes_at_face

        n_faces = (shape[1] - 2) * (shape[0] - 1) + (shape[0] - 2) * (shape[1] - 1)
        nodes_at_face = np.empty((n_faces, 2), dtype=int)
        fill_nodes_at_face(shape, nodes_at_face)

        return nodes_at_face


class DualRectilinearGraph(DualGraph, RectilinearGraph):
    """Create a dual graph for a rectilinear grid.

    Examples
    --------
    >>> from landlab.graph import DualRectilinearGraph
    >>> graph = DualRectilinearGraph(([0, 1, 3], [0, 5, 15, 30]))
    >>> graph.x_of_corner.reshape((2, 3))
    array([[  2.5,  10. ,  22.5],
           [  2.5,  10. ,  22.5]])
    >>> graph.y_of_corner.reshape((2, 3))
    array([[0.5, 0.5, 0.5],
           [2. , 2. , 2. ]])
    >>> graph.number_of_cells == 2
    True
    >>> graph.faces_at_cell
    array([[3, 5, 2, 0],
           [4, 6, 3, 1]])
    """

    def __init__(self, node_y_and_x):
        RectilinearGraph.__init__(self, node_y_and_x)

        dual_graph = RectilinearGraph(DualRectilinearGraph.get_corners(node_y_and_x))

        self.merge(
            dual_graph,
            node_at_cell=DualStructuredQuadGraph.get_node_at_cell(self.shape),
            nodes_at_face=DualStructuredQuadGraph.get_nodes_at_face(self.shape),
        )

    @staticmethod
    def get_corners(node_y_and_x):
        y_of_node, x_of_node = (
            np.asarray(node_y_and_x[0]),
            np.asarray(node_y_and_x[1]),
        )

        return (
            (y_of_node[1:] + y_of_node[:-1]) * 0.5,
            (x_of_node[1:] + x_of_node[:-1]) * 0.5,
        )


class DualUniformRectilinearGraph(DualGraph, UniformRectilinearGraph):
    """Create a dual graph for a uniform rectilinear grid.

    Examples
    --------
    >>> from landlab.graph import DualUniformRectilinearGraph
    >>> graph = DualUniformRectilinearGraph((4, 3))
    >>> graph.x_of_corner.reshape((3, 2))
    array([[0.5, 1.5],
           [0.5, 1.5],
           [0.5, 1.5]])
    >>> graph.y_of_corner.reshape((3, 2))
    array([[0.5, 0.5],
           [1.5, 1.5],
           [2.5, 2.5]])
    >>> graph.number_of_cells == 2
    True
    >>> graph.faces_at_cell
    array([[2, 3, 1, 0],
           [5, 6, 4, 3]])
    """

    def __init__(self, shape, spacing=1.0, origin=(0.0, 0.0)):
        spacing = np.broadcast_to(spacing, 2)
        origin = np.broadcast_to(origin, 2)

        UniformRectilinearGraph.__init__(self, shape, spacing=spacing, origin=origin)

        dual_graph = UniformRectilinearGraph(
            (shape[0] - 1, shape[1] - 1), spacing=spacing, origin=origin + spacing * 0.5
        )

        self.merge(
            dual_graph,
            node_at_cell=DualStructuredQuadGraph.get_node_at_cell(self.shape),
            nodes_at_face=DualStructuredQuadGraph.get_nodes_at_face(self.shape),
        )



================================================
File: src/landlab/graph/structured_quad/structured_quad.py
================================================
from abc import ABC
from abc import abstractmethod
from functools import cached_property

import numpy as np

from ...grid.linkorientation import LinkOrientation
from ...utils.decorators import read_only_array
from ..graph import Graph


class StructuredQuadLayout(ABC):
    @staticmethod
    def corner_nodes(shape):
        n_rows, n_cols = shape
        return (n_rows * n_cols - 1, (n_rows - 1) * n_cols, 0, n_cols - 1)

    @staticmethod
    @abstractmethod
    def links_at_patch(shape): ...

    @staticmethod
    @abstractmethod
    def nodes_at_link(shape): ...

    @staticmethod
    @abstractmethod
    def horizontal_links(shape): ...

    @staticmethod
    @abstractmethod
    def vertical_links(shape): ...

    @staticmethod
    @abstractmethod
    def perimeter_nodes(shape): ...

    @staticmethod
    @abstractmethod
    def links_at_node(shape): ...

    @staticmethod
    @abstractmethod
    def patches_at_link(shape): ...

    @staticmethod
    @abstractmethod
    def link_dirs_at_node(shape): ...

    @staticmethod
    @abstractmethod
    def patches_at_node(shape): ...


class StructuredQuadLayoutCython(StructuredQuadLayout):
    @staticmethod
    def links_at_patch(shape):
        """Get links that define patches for a raster grid.

        Examples
        --------
        >>> from landlab.graph.structured_quad.structured_quad import (
        ...     StructuredQuadLayoutCython,
        ... )
        >>> StructuredQuadLayoutCython.links_at_patch((3, 4))
        array([[ 4,  7,  3,  0], [ 5,  8,  4,  1], [ 6,  9,  5,  2],
               [11, 14, 10,  7], [12, 15, 11,  8], [13, 16, 12,  9]])
        """
        from .ext.at_patch import fill_links_at_patch

        n_patches = (shape[0] - 1) * (shape[1] - 1)
        links_at_patch = np.empty((n_patches, 4), dtype=int)
        fill_links_at_patch(shape, links_at_patch)
        return links_at_patch

    @staticmethod
    def nodes_at_link(shape):
        """
        Examples
        --------
        >>> from landlab.graph.structured_quad.structured_quad import (
        ...     StructuredQuadLayoutCython,
        ... )
        >>> StructuredQuadLayoutCython.nodes_at_link((3, 4))
        array([[ 0,  1], [ 1,  2], [ 2,  3],
               [ 0,  4], [ 1,  5], [ 2,  6], [ 3,  7],
               [ 4,  5], [ 5,  6], [ 6,  7],
               [ 4,  8], [ 5,  9], [ 6, 10], [ 7, 11],
               [ 8,  9], [ 9, 10], [10, 11]])
        """
        from .ext.at_link import fill_nodes_at_link

        n_links = shape[0] * (shape[1] - 1) + (shape[0] - 1) * shape[1]
        nodes_at_link = np.empty((n_links, 2), dtype=int)
        fill_nodes_at_link(shape, nodes_at_link)

        return nodes_at_link

    @staticmethod
    def horizontal_links(shape):
        from .ext.at_link import fill_horizontal_links

        n_horizontal_links = shape[0] * (shape[1] - 1)
        horizontal_links = np.empty(n_horizontal_links, dtype=int)
        fill_horizontal_links(shape, horizontal_links)

        return horizontal_links

    @staticmethod
    def vertical_links(shape):
        from .ext.at_link import fill_vertical_links

        n_vertical_links = (shape[0] - 1) * shape[1]
        vertical_links = np.empty(n_vertical_links, dtype=int)
        fill_vertical_links(shape, vertical_links)

        return vertical_links

    @staticmethod
    def perimeter_nodes(shape):
        from .ext.at_node import fill_perimeter_nodes

        n_perimeter_nodes = 2 * shape[0] + 2 * (shape[1] - 2)
        perimeter_nodes = np.empty(n_perimeter_nodes, dtype=int)
        fill_perimeter_nodes(shape, perimeter_nodes)

        return perimeter_nodes

    @staticmethod
    def links_at_node(shape):
        from .ext.at_node import fill_links_at_node

        n_nodes = shape[0] * shape[1]
        links_at_node = np.empty((n_nodes, 4), dtype=int)
        fill_links_at_node(shape, links_at_node)

        return links_at_node

    @staticmethod
    def patches_at_link(shape):
        from .ext.at_link import fill_patches_at_link

        n_links = shape[0] * (shape[1] - 1) + (shape[0] - 1) * shape[1]
        patches_at_link = np.empty((n_links, 2), dtype=int)
        fill_patches_at_link(shape, patches_at_link)

        return patches_at_link

    @staticmethod
    def link_dirs_at_node(shape):
        from .ext.at_node import fill_link_dirs_at_node

        n_nodes = shape[0] * shape[1]
        link_dirs_at_node = np.empty((n_nodes, 4), dtype=np.int8)
        fill_link_dirs_at_node(shape, link_dirs_at_node)
        return link_dirs_at_node

    @staticmethod
    def patches_at_node(shape):
        from .ext.at_node import fill_patches_at_node

        n_nodes = shape[0] * shape[1]
        patches_at_node = np.empty((n_nodes, 4), dtype=int)
        fill_patches_at_node(shape, patches_at_node)

        return patches_at_node


class StructuredQuadLayoutPython(StructuredQuadLayout):
    @staticmethod
    def links_at_patch(shape):
        n_rows, n_cols = shape
        n_patches = (shape[0] - 1) * (shape[1] - 1)
        links_at_patch = np.empty((4, n_patches), dtype=int)

        patches = np.arange(n_patches, dtype=int).reshape((n_rows - 1, n_cols - 1))
        south_links = patches + np.arange(n_rows - 1).reshape((n_rows - 1, 1)) * n_cols
        links_at_patch[3, :] = south_links.flat
        links_at_patch[2, :] = links_at_patch[3, :] + n_cols - 1
        links_at_patch[1, :] = links_at_patch[3, :] + 2 * n_cols - 1
        links_at_patch[0, :] = links_at_patch[2, :] + 1

        return links_at_patch.T

    @staticmethod
    def nodes_at_link(shape):
        n_rows, n_cols = shape

        nodes_at_link = np.empty(
            (2, n_rows * (n_cols - 1) + (n_rows - 1) * n_cols), dtype=int
        )
        nodes = np.arange(n_rows * n_cols, dtype=int).reshape((n_rows, n_cols))

        nodes_at_link[0, -(n_cols - 1) :] = nodes[-1, :-1]
        nodes_at_link[1, -(n_cols - 1) :] = nodes[-1, 1:]

        head_nodes = nodes_at_link[0, : -(n_cols - 1)].reshape(
            (n_rows - 1, 2 * n_cols - 1)
        )
        head_nodes[:, : n_cols - 1] = nodes[:-1, :-1]
        head_nodes[:, n_cols - 1 :] = nodes[:-1, :]

        tail_nodes = nodes_at_link[1, : -(n_cols - 1)].reshape(
            (n_rows - 1, 2 * n_cols - 1)
        )
        tail_nodes[:, : n_cols - 1] = nodes[:-1, 1:]
        tail_nodes[:, n_cols - 1 :] = nodes[1:, :]

        return nodes_at_link.T

    @staticmethod
    def horizontal_links(shape):
        n_rows, n_cols = shape
        horizontal_links = np.empty((n_rows, n_cols - 1), dtype=int)
        horizontal_links[:, :] = np.arange(n_cols - 1)
        horizontal_links[:, :] += np.arange(n_rows).reshape((n_rows, 1)) * (
            2 * n_cols - 1
        )

        return horizontal_links.reshape(-1)

    @staticmethod
    def vertical_links(shape):
        n_rows, n_cols = shape

        vertical_links = np.empty((n_rows - 1, n_cols), dtype=int)
        vertical_links[:, :] = np.arange(n_cols) + n_cols - 1
        vertical_links[:, :] += np.arange(n_rows - 1).reshape((n_rows - 1, 1)) * (
            2 * n_cols - 1
        )

        return vertical_links.reshape(-1)

    @staticmethod
    def perimeter_nodes(shape):
        n_rows, n_cols = shape
        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = StructuredQuadLayout.corner_nodes(shape)

        return np.concatenate(
            (
                np.arange(southeast, northeast, n_cols),
                np.arange(northeast, northwest, -1),
                np.arange(northwest, southwest, -n_cols),
                np.arange(southwest, southeast, 1),
            )
        )

    @staticmethod
    def links_at_node(shape):
        n_rows, n_cols = shape

        links_at_node = np.empty((n_rows * n_cols, 4), dtype=int)

        east_links_at_node = links_at_node[:, 0].reshape((n_rows, n_cols))[:, :-1]
        east_links_at_node[:] = StructuredQuadLayoutPython.horizontal_links(
            shape
        ).reshape((n_rows, n_cols - 1))
        west_links_at_node = links_at_node[:, 2].reshape((n_rows, n_cols))[:, 1:]
        west_links_at_node[:] = StructuredQuadLayoutPython.horizontal_links(
            shape
        ).reshape((n_rows, n_cols - 1))

        north_links_at_node = links_at_node[:, 1].reshape((n_rows, n_cols))[:-1, :]
        north_links_at_node[:] = StructuredQuadLayoutPython.vertical_links(
            shape
        ).reshape((n_rows - 1, n_cols))
        south_links_at_node = links_at_node[:, 3].reshape((n_rows, n_cols))[1:, :]
        south_links_at_node[:] = StructuredQuadLayoutPython.vertical_links(
            shape
        ).reshape((n_rows - 1, n_cols))

        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = StructuredQuadLayout.corner_nodes(shape)
        bottom = slice(southwest, southeast + 1)
        top = slice(northwest, northeast + 1)
        left = slice(southwest, northwest + n_cols, n_cols)
        right = slice(southeast, northeast + n_cols, n_cols)

        for col, edge in enumerate((right, top, left, bottom)):
            links_at_node[edge, col] = -1

        return links_at_node

    @staticmethod
    def patches_at_link(shape):
        n_rows, n_cols = shape
        n_links = shape[0] * (shape[1] - 1) + (shape[0] - 1) * shape[1]
        n_patches = (n_rows - 1) * (n_cols - 1)
        patches = np.arange(n_patches, dtype=int).reshape((n_rows - 1, n_cols - 1))

        patches_at_link = np.empty((2, n_links), dtype=int)
        patches_at_link[0, : n_cols - 1] = -1
        patches_at_link[1, -(n_cols - 1) :] = -1

        right = (0, slice(n_cols - 1, n_links))
        left = (1, slice(0, -(n_cols - 1)))
        for edge in (right, left):
            edge_patches = patches_at_link[edge].reshape((n_rows - 1, 2 * n_cols - 1))
            edge_patches[:, : n_cols - 1] = patches
            edge_patches[:, n_cols - 1] = -1
            edge_patches[:, -(n_cols - 1) :] = patches

        return patches_at_link.T

    @staticmethod
    def link_dirs_at_node(shape):
        n_rows, n_cols = shape
        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = StructuredQuadLayout.corner_nodes(shape)

        link_dirs_at_node = np.empty((n_rows * n_cols, 4), dtype=np.int8)
        link_dirs_at_node[:, 0] = -1
        link_dirs_at_node[:, 1] = -1
        link_dirs_at_node[:, 2] = 1
        link_dirs_at_node[:, 3] = 1

        bottom = slice(southwest, southeast + 1)
        top = slice(northwest, northeast + 1)
        left = slice(southwest, northwest + n_cols, n_cols)
        right = slice(southeast, northeast + n_cols, n_cols)

        for col, edge in enumerate((right, top, left, bottom)):
            link_dirs_at_node[edge, col] = 0

        return link_dirs_at_node

    @staticmethod
    def patches_at_node(shape):
        n_rows, n_cols = shape

        patches_at_node = np.empty((4, n_rows * n_cols), dtype=int)

        ne = (slice(n_rows - 1), slice(n_cols - 1))
        nw = (slice(n_rows - 1), slice(1, n_cols))
        sw = (slice(1, n_rows), slice(1, n_cols))
        se = (slice(1, n_rows), slice(n_cols - 1))

        patches = np.arange((n_rows - 1) * (n_cols - 1), dtype=int).reshape(
            (n_rows - 1, n_cols - 1)
        )
        for col, nodes in enumerate((ne, nw, sw, se)):
            patches_at_node[col].reshape((n_rows, n_cols))[nodes] = patches

        (
            northeast,
            northwest,
            southwest,
            southeast,
        ) = StructuredQuadLayout.corner_nodes(shape)
        bottom = slice(southwest, southeast + 1)
        top = slice(northwest, northeast + 1)
        left = slice(southwest, northwest + n_cols, n_cols)
        right = slice(southeast, northeast + n_cols, n_cols)

        patches_at_node[0, right] = -1
        patches_at_node[0, top] = -1
        patches_at_node[1, left] = -1
        patches_at_node[1, top] = -1
        patches_at_node[2, left] = -1
        patches_at_node[2, bottom] = -1
        patches_at_node[3, right] = -1
        patches_at_node[3, bottom] = -1

        return patches_at_node.T


class StructuredQuadGraphTopology:
    _layout = StructuredQuadLayoutCython

    def __init__(self, shape):
        self._shape = tuple(shape)

    @property
    def shape(self):
        return self._shape

    @property
    def number_of_node_rows(self):
        return self._shape[0]

    @property
    def number_of_node_columns(self):
        return self._shape[1]

    @cached_property
    @read_only_array
    def nodes(self):
        """A shaped array of node ids.

        Returns
        -------
        ndarray
            Node IDs in an array shaped as *number_of_node_rows* by
            *number_of_node_columns*.
        """
        return np.arange(self.shape[0] * self.shape[1]).reshape(self.shape)

    @cached_property
    @read_only_array
    def nodes_at_right_edge(self):
        return np.arange(self.shape[1] - 1, np.prod(self.shape), self.shape[1])

    @cached_property
    @read_only_array
    def nodes_at_top_edge(self):
        return np.arange(self.number_of_nodes - self.shape[1], np.prod(self.shape))

    @cached_property
    @read_only_array
    def nodes_at_left_edge(self):
        return np.arange(0, np.prod(self.shape), self.shape[1])

    @cached_property
    @read_only_array
    def nodes_at_bottom_edge(self):
        return np.arange(self.shape[1])

    def nodes_at_edge(self, edge):
        if edge not in ("right", "top", "left", "bottom"):
            raise ValueError("value for edge not understood")
        return getattr(self, f"nodes_at_{edge}_edge")

    @property
    def nodes_at_corners_of_grid(self):
        """Nodes at corners of grid.

        The nodes at at the corners of the grid. The nodes are returned
        counterclockwise starting with the upper-right.

        Return
        ------
        tuple of int
            Nodes at the four corners.

        Examples
        --------
        >>> from landlab.graph import UniformRectilinearGraph
        >>> graph = UniformRectilinearGraph((4, 5))
        >>> graph.nodes_at_corners_of_grid
        (19, 15, 0, 4)
        """
        return (
            self.number_of_nodes - 1,
            self.number_of_nodes - self.number_of_node_columns,
            0,
            self.number_of_node_columns - 1,
        )

    @cached_property
    @read_only_array
    def nodes_at_link(self):
        return self._layout.nodes_at_link(self.shape)

    @cached_property
    def horizontal_links(self):
        return self._layout.horizontal_links(self.shape)

    @cached_property
    def vertical_links(self):
        return self._layout.vertical_links(self.shape)

    @property
    def corner_nodes(self):
        n_rows, n_cols = self.shape
        return np.asarray(
            (n_rows * n_cols - 1, (n_rows - 1) * n_cols, 0, n_cols - 1), dtype=int
        )

    @cached_property
    def perimeter_nodes(self):
        return self._layout.perimeter_nodes(self.shape)

    @cached_property
    def links_at_node(self):
        return self._layout.links_at_node(self.shape)

    @cached_property
    def link_dirs_at_node(self):
        return self._layout.link_dirs_at_node(self.shape)

    @cached_property
    @read_only_array
    def patches_at_link(self):
        return self._layout.patches_at_link(self.shape)

    @cached_property
    @read_only_array
    def patches_at_node(self):
        return self._layout.patches_at_node(self.shape)


class StructuredQuadGraphExtras(StructuredQuadGraphTopology, Graph):
    def __init__(self, node_y_and_x, sort=False):
        StructuredQuadGraphTopology.__init__(self, node_y_and_x[0].shape)
        Graph.__init__(
            self,
            node_y_and_x,
            links=StructuredQuadLayoutCython.nodes_at_link(self.shape),
            patches=StructuredQuadLayoutCython.links_at_patch(self.shape),
            sort=sort,
        )

    @property
    def nodes_at_link(self):
        return self.ds["nodes_at_link"].values

    @cached_property
    def orientation_of_link(self):
        """Return array of link orientation codes (one value per link).

        Orientation codes are defined by :class:`~.LinkOrientation`;
        1 = E, 2 = ENE, 4 = NNE, 8 = N, 16 = NNW, 32 = ESE (using powers
        of 2 allows for future applications that might want additive
        combinations).
        """
        orientation_of_link = np.full(
            self.number_of_links, LinkOrientation.E, dtype=np.uint8
        )
        orientation_of_link[self.vertical_links] = LinkOrientation.N
        return orientation_of_link

    @cached_property
    def parallel_links_at_link(self):
        """Return similarly oriented links connected to each link.

        Return IDs of links of the same orientation that are connected to
        each given link's tail or head node.

        The data structure is a *numpy* array of shape ``(n_links, 2)`` containing the
        IDs of the "tail-wise" (connected to tail node) and "head-wise" (connected to
        head node) links, or -1 if the link is inactive (e.g., on the perimeter) or
        it has no attached parallel neighbor in the given direction.

        For instance, consider a 3x4 raster, in which link IDs are as shown::

            .-14-.-15-.-16-.
            |    |    |    |
            10  11   12   13
            |    |    |    |
            .--7-.--8-.--9-.
            |    |    |    |
            3    4    5    6
            |    |    |    |
            .--0-.--1-.--2-.

        Here's a mapping of the tail-wise (shown at left or bottom of links) and
        head-wise (shown at right or top of links) links::

            .----.----.----.
            |    |    |    |
            |    |    |    |
            |    4    5    |
            .---8.7--9.8---.
            |   11   12    |
            |    |    |    |
            |    |    |    |
            .----.----.----.

        So the corresponding data structure would be mostly filled with -1, but
        for the 7 active links, it would look like::

            4: [[-1, 11],
            5:  [-1, 12],
            7:  [-1,  8],
            8:  [ 7,  9],
            9:  [ 8, -1],
            11: [ 4, -1],
            12: [ 5, -1]]

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> pll = grid.parallel_links_at_link
        >>> pll[4:13, :]
        array([[-1, 11],
               [-1, 12],
               [-1, 13],
               [-1,  8],
               [ 7,  9],
               [ 8, -1],
               [ 3, -1],
               [ 4, -1],
               [ 5, -1]])
        """
        plinks_at_link = np.full((self.number_of_links, 2), -1, dtype=int)

        plinks_at_link[self.vertical_links, 0] = self.links_at_node[
            self.node_at_link_tail[self.vertical_links], 3
        ]
        plinks_at_link[self.vertical_links, 1] = self.links_at_node[
            self.node_at_link_head[self.vertical_links], 1
        ]
        plinks_at_link[self.horizontal_links, 0] = self.links_at_node[
            self.node_at_link_tail[self.horizontal_links], 2
        ]
        plinks_at_link[self.horizontal_links, 1] = self.links_at_node[
            self.node_at_link_head[self.horizontal_links], 0
        ]

        return plinks_at_link


class StructuredQuadGraph(StructuredQuadGraphExtras):
    def __init__(self, coords, shape=None, sort=False):
        node_y, node_x = (
            np.asarray(coords[0], dtype=float),
            np.asarray(coords[1], dtype=float),
        )

        if shape:
            node_y.shape = shape
            node_x.shape = shape
        else:
            node_x.shape = node_y.shape

        if node_y.shape != node_x.shape:
            raise ValueError("shape mismatch in node x and y coordinates")

        StructuredQuadGraphExtras.__init__(self, (node_y, node_x), sort=sort)

    @staticmethod
    def setup_node_y_and_x(yx_at_node, shape=None):
        node_y = np.asarray(yx_at_node[0], dtype=float)
        node_x = np.asarray(yx_at_node[1], dtype=float)

        if shape:
            node_y.shape = shape
            node_x.shape = shape
        else:
            node_x.shape = node_y.shape

        if node_y.shape != node_x.shape:
            raise ValueError("shape mismatch in node x and y coordinates")

        return (node_y, node_x)


class RectilinearGraph(StructuredQuadGraphExtras):
    """Graph of a rectlinear grid of nodes.

    Examples
    --------
    >>> from landlab.graph import RectilinearGraph
    >>> graph = RectilinearGraph(([0, 1, 2, 3], [1, 4, 8]))
    >>> graph.number_of_nodes
    12
    >>> graph.y_of_node.reshape(graph.shape)
    array([[0., 0., 0.],
           [1., 1., 1.],
           [2., 2., 2.],
           [3., 3., 3.]])
    >>> graph.x_of_node.reshape(graph.shape)
    array([[1., 4., 8.],
           [1., 4., 8.],
           [1., 4., 8.],
           [1., 4., 8.]])
    """

    def __init__(self, nodes, sort=False):
        rows = np.asarray(nodes[0], dtype=float)
        cols = np.asarray(nodes[1], dtype=float)
        node_y_and_x = np.meshgrid(rows, cols, indexing="ij")

        StructuredQuadGraphExtras.__init__(self, node_y_and_x, sort=sort)

    @staticmethod
    def setup_node_y_and_x(coords):
        rows = np.asarray(coords[0], dtype=float)
        cols = np.asarray(coords[1], dtype=float)

        return np.meshgrid(rows, cols, indexing="ij")


class UniformRectilinearGraph(StructuredQuadGraphExtras):
    """Graph of a structured grid of quadrilaterals.

    Examples
    --------
    >>> from landlab.graph import UniformRectilinearGraph
    >>> graph = UniformRectilinearGraph((4, 3), spacing=(1, 2), origin=(-1, 0))
    >>> graph.number_of_nodes
    12
    >>> graph.y_of_node.reshape(graph.shape)
    array([[-1., -1., -1.],
           [ 0.,  0.,  0.],
           [ 1.,  1.,  1.],
           [ 2.,  2.,  2.]])
    >>> graph.x_of_node.reshape(graph.shape)
    array([[0.,  2.,  4.],
           [0.,  2.,  4.],
           [0.,  2.,  4.],
           [0.,  2.,  4.]])
    >>> graph.links_at_node
    array([[ 0,  2, -1, -1], [ 1,  3,  0, -1], [-1,  4,  1, -1],
           [ 5,  7, -1,  2], [ 6,  8,  5,  3], [-1,  9,  6,  4],
           [10, 12, -1,  7], [11, 13, 10,  8], [-1, 14, 11,  9],
           [15, -1, -1, 12], [16, -1, 15, 13], [-1, -1, 16, 14]])
    >>> graph.link_dirs_at_node
    array([[-1, -1,  0,  0], [-1, -1,  1,  0], [ 0, -1,  1,  0],
           [-1, -1,  0,  1], [-1, -1,  1,  1], [ 0, -1,  1,  1],
           [-1, -1,  0,  1], [-1, -1,  1,  1], [ 0, -1,  1,  1],
           [-1,  0,  0,  1], [-1,  0,  1,  1], [ 0,  0,  1,  1]], dtype=int8)
    >>> graph.nodes_at_link
    array([[ 0,  1], [ 1,  2], [ 0,  3], [ 1,  4], [ 2,  5],
           [ 3,  4], [ 4,  5], [ 3,  6], [ 4,  7], [ 5,  8],
           [ 6,  7], [ 7,  8], [ 6,  9], [ 7, 10], [ 8, 11],
           [ 9, 10], [10, 11]])
    >>> graph.links_at_patch
    array([[ 3,  5,  2,  0], [ 4,  6,  3,  1],
           [ 8, 10,  7,  5], [ 9, 11,  8,  6],
           [13, 15, 12, 10], [14, 16, 13, 11]])
    >>> graph.nodes_at_patch
    array([[ 4,  3,  0,  1], [ 5,  4,  1,  2],
           [ 7,  6,  3,  4], [ 8,  7,  4,  5],
           [10,  9,  6,  7], [11, 10,  7,  8]])
    """

    def __init__(self, shape, spacing=1.0, origin=0.0, sort=False):
        spacing = np.broadcast_to(spacing, 2)
        origin = np.broadcast_to(origin, 2)

        rows = np.arange(shape[0], dtype=float) * spacing[0] + origin[0]
        cols = np.arange(shape[1], dtype=float) * spacing[1] + origin[1]

        node_y_and_x = np.meshgrid(rows, cols, indexing="ij")

        StructuredQuadGraphExtras.__init__(self, node_y_and_x, sort=sort)

        self._spacing = tuple(spacing)
        self._origin = tuple(origin)

    @property
    def spacing(self):
        return self._spacing

    @property
    def origin(self):
        return self._origin

    @property
    def dx(self):
        return self._spacing[1]

    @property
    def dy(self):
        return self._spacing[0]



================================================
File: src/landlab/graph/structured_quad/ext/__init__.py
================================================



================================================
File: src/landlab/graph/structured_quad/ext/at_cell.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_node_at_cell(
    shape,
    id_t[:] node_at_cell,
):
    """Get node contained in a cell.

    Parameters
    ----------
    shape : tuple of int
        Shape of the grid as `(n_rows, n_cols)`.
    node_at_cell : ndarray of int
        Buffer into which to place node identifiers.
    """
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long cells_per_row = shape[1] - 2
    cdef long first_node
    cdef long cell
    cdef int row
    cdef int col

    for row in prange(1, n_rows - 1, nogil=True, schedule="static"):
        cell = (row - 1) * cells_per_row
        first_node = row * n_cols + 1
        for col in range(cells_per_row):
            node_at_cell[cell] = first_node + col
            cell = cell + 1

    return node_at_cell



================================================
File: src/landlab/graph/structured_quad/ext/at_face.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_nodes_at_face(
    shape,
    id_t [:, :] nodes_at_face,
):
    """Get nodes on either side of a face.

    Parameters
    ----------
    shape : tuple of int
        Shape of the grid as `(n_rows, n_cols)`.
    nodes_at_face : ndarray of int, shape `(n_faces, 2)`
        Buffer into which to place node identifiers.
    """
    cdef int face
    cdef int node
    cdef int row
    cdef int col
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef long vertical_faces_per_row = n_cols - 1
    cdef long horizontal_faces_per_row = n_cols - 2
    cdef long faces_per_row = vertical_faces_per_row + horizontal_faces_per_row

    for row in prange(n_rows - 2, nogil=True, schedule="static"):
        face = row * faces_per_row
        node = row * n_cols + 1

        for col in range(horizontal_faces_per_row):
            nodes_at_face[face, 0] = node
            nodes_at_face[face, 1] = node + n_cols

            node = node + 1
            face = face + 1

        node = (row + 1) * n_cols
        for col in range(vertical_faces_per_row):
            nodes_at_face[face, 0] = node
            nodes_at_face[face, 1] = node + 1

            node = node + 1
            face = face + 1

    face = (n_rows - 2) * faces_per_row
    node = (n_rows - 2) * n_cols + 1
    for col in prange(horizontal_faces_per_row, nogil=True, schedule="static"):
        nodes_at_face[face + col, 0] = node + col
        nodes_at_face[face + col, 1] = node + col + n_cols



================================================
File: src/landlab/graph/structured_quad/ext/at_link.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_horizontal_links(
    shape,
    id_t [:] horizontal_links,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long horizontal_links_per_row = n_cols - 1
    cdef long vertical_links_per_row = n_cols
    cdef long links_per_row = horizontal_links_per_row + vertical_links_per_row
    cdef long horizontal_link
    cdef long link
    cdef long row
    cdef long col

    for row in prange(n_rows, nogil=True, schedule="static"):
        link = row * links_per_row
        horizontal_link = row * horizontal_links_per_row

        for col in range(horizontal_links_per_row):
            horizontal_links[horizontal_link + col] = link + col


@cython.wraparound(False)
@cython.boundscheck(False)
def fill_vertical_links(
    shape,
    id_t [:] vertical_links,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long horizontal_links_per_row = n_cols - 1
    cdef long vertical_links_per_row = n_cols
    cdef long links_per_row = horizontal_links_per_row + vertical_links_per_row
    cdef long link
    cdef long vertical_link
    cdef long row
    cdef long col

    for row in prange(n_rows - 1, nogil=True, schedule="static"):
        link = row * links_per_row + horizontal_links_per_row
        vertical_link = row * vertical_links_per_row

        for col in range(n_cols):
            vertical_links[vertical_link + col] = link + col


@cython.wraparound(False)
@cython.boundscheck(False)
def fill_patches_at_link(
    shape,
    id_t [:, :] patches_at_link,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long patches_per_row = n_cols - 1
    cdef long horizontal_links_per_row = n_cols - 1
    cdef long vertical_links_per_row = n_cols
    cdef long links_per_row = horizontal_links_per_row + vertical_links_per_row
    cdef long link
    cdef long patch
    cdef long row
    cdef long col
    cdef long first_link

    for row in prange(n_rows - 1, nogil=True, schedule="static"):
        first_link = row * links_per_row
        patch = row * patches_per_row
        for link in range(first_link, first_link + horizontal_links_per_row):
            patches_at_link[link, 0] = patch - patches_per_row
            patches_at_link[link, 1] = patch
            patch = patch + 1

        first_link = row * links_per_row + horizontal_links_per_row
        patch = row * patches_per_row
        for link in range(first_link, first_link + vertical_links_per_row):
            patches_at_link[link, 0] = patch
            patches_at_link[link, 1] = patch - 1
            patch = patch + 1
        patches_at_link[first_link, 1] = - 1
        patches_at_link[first_link + vertical_links_per_row - 1, 0] = - 1

    # Bottom row
    for link in prange(horizontal_links_per_row, nogil=True, schedule="static"):
        patches_at_link[link, 0] = -1

    # Top row
    first_link = (n_rows - 1) * links_per_row
    patch = (n_rows - 2) * patches_per_row
    for col in prange(horizontal_links_per_row, nogil=True, schedule="static"):
        patches_at_link[first_link + col, 0] = patch + col
        patches_at_link[first_link + col, 1] = -1


@cython.wraparound(False)
@cython.boundscheck(False)
def fill_nodes_at_link(
    shape,
    id_t [:, :] nodes_at_link,
):
    cdef long row
    cdef long col
    cdef long link
    cdef long node
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long horizontal_links_per_row = n_cols - 1
    cdef long vertical_links_per_row = n_cols
    cdef long links_per_row = horizontal_links_per_row + vertical_links_per_row

    for row in prange(n_rows - 1, nogil=True, schedule="static"):
        node = row * n_cols
        link = row * links_per_row

        for col in range(horizontal_links_per_row):
            nodes_at_link[link, 0] = node
            nodes_at_link[link, 1] = node + 1
            node = node + 1
            link = link + 1

        node = row * n_cols
        for col in range(vertical_links_per_row):
            nodes_at_link[link, 0] = node
            nodes_at_link[link, 1] = node + n_cols
            node = node + 1
            link = link + 1

    node = (n_rows - 1) * n_cols
    link = (n_rows - 1) * links_per_row
    for col in prange(horizontal_links_per_row, nogil=True, schedule="static"):
        nodes_at_link[link + col, 0] = node + col
        nodes_at_link[link + col, 1] = node + col + 1



================================================
File: src/landlab/graph/structured_quad/ext/at_node.pyx
================================================
cimport cython
from cython.parallel cimport prange
from libc.stdint cimport int8_t

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_perimeter_nodes(
    shape,
    id_t [:] perimeter_nodes,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long n_nodes = n_rows * n_cols
    cdef long offset_to_top = n_rows - 1
    cdef long offset_to_left = offset_to_top + n_cols - 1
    cdef long offset_to_bottom = offset_to_left + n_rows - 1
    cdef long row
    cdef long col

    for row in prange(n_rows - 1, nogil=True, schedule="static"):
        perimeter_nodes[row] = (row + 1) * n_cols - 1
        perimeter_nodes[offset_to_left + row] = n_nodes - (row + 1) * n_cols

    for col in prange(n_cols - 1, nogil=True, schedule="static"):
        perimeter_nodes[offset_to_top + col] = n_nodes - 1 - col
        perimeter_nodes[offset_to_bottom + col] = col


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_patches_at_node(
    shape,
    id_t [:, :] patches_at_node,
):
    cdef long patch
    cdef long node
    cdef long row
    cdef long col
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long patches_per_row = n_cols - 1
    cdef long first_node
    cdef long first_patch

    # Bottom row
    for node in prange(n_cols, nogil=True, schedule="static"):
        patch = node

        patches_at_node[node, 0] = patch
        patches_at_node[node, 1] = patch - 1
        patches_at_node[node, 2] = - 1
        patches_at_node[node, 3] = - 1
    patches_at_node[0, 1] = -1
    patches_at_node[n_cols - 1, 0] = -1

    # Interior nodes
    for row in prange(1, n_rows - 1, nogil=True, schedule="static"):
        first_node = row * n_cols
        patch = row * patches_per_row
        for node in range(first_node, first_node + n_cols):
            patches_at_node[node, 0] = patch
            patches_at_node[node, 1] = patch - 1
            patches_at_node[node, 2] = patch - patches_per_row - 1
            patches_at_node[node, 3] = patch - patches_per_row

            patch = patch + 1
        patches_at_node[first_node, 1] = -1
        patches_at_node[first_node, 2] = -1
        patches_at_node[first_node + n_cols - 1, 0] = -1
        patches_at_node[first_node + n_cols - 1, 3] = -1

    # Top row
    first_node = (n_rows - 1) * n_cols
    first_patch = (n_rows - 2) * patches_per_row
    for col in prange(n_cols, nogil=True, schedule="static"):
        node = first_node + col

        patches_at_node[node, 0] = - 1
        patches_at_node[node, 1] = - 1
        patches_at_node[node, 2] = first_patch - 1 + col
        patches_at_node[node, 3] = first_patch + col
    patches_at_node[first_node, 2] = - 1
    patches_at_node[first_node + n_cols - 1, 3] = - 1


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_links_at_node(
    shape,
    id_t [:, :] links_at_node,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long vertical_links_per_row = n_cols
    cdef long horizontal_links_per_row = n_cols - 1
    cdef long links_per_row = horizontal_links_per_row + vertical_links_per_row
    cdef long link
    cdef long node
    cdef long row
    cdef long col
    cdef long first_node
    cdef long first_link

    # Bottom row
    for node in prange(n_cols, nogil=True, schedule="static"):
        link = node
        links_at_node[node, 0] = link
        links_at_node[node, 1] = link + horizontal_links_per_row
        links_at_node[node, 2] = link - 1
        links_at_node[node, 3] = - 1
    links_at_node[0, 2] = - 1
    links_at_node[n_cols - 1, 0] = - 1

    # Middle rows
    for row in prange(1, n_rows - 1, nogil=True, schedule="static"):
        first_node = row * n_cols
        link = row * links_per_row
        for node in range(first_node, first_node + n_cols):
            links_at_node[node, 0] = link
            links_at_node[node, 1] = link + horizontal_links_per_row
            links_at_node[node, 2] = link - 1
            links_at_node[node, 3] = link - vertical_links_per_row

            link = link + 1
        links_at_node[first_node, 2] = -1
        links_at_node[first_node + n_cols - 1, 0] = -1

    # Top row
    first_node = (n_rows - 1) * n_cols
    first_link = (n_rows - 1) * links_per_row
    for col in prange(n_cols, nogil=True, schedule="static"):
        node = first_node + col
        link = first_link + col
        links_at_node[node, 0] = link
        links_at_node[node, 1] = - 1
        links_at_node[node, 2] = link - 1
        links_at_node[node, 3] = link - vertical_links_per_row
    links_at_node[first_node, 2] = -1
    links_at_node[first_node + n_cols - 1, 0] = -1


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_link_dirs_at_node(
    shape,
    int8_t [:, :] link_dirs_at_node,
):
    cdef long n_rows = shape[0]
    cdef long n_cols = shape[1]
    cdef long first_node
    cdef long node
    cdef long row

    # Bottom row
    for node in prange(n_cols, nogil=True, schedule="static"):
        link_dirs_at_node[node, 0] = - 1
        link_dirs_at_node[node, 1] = - 1
        link_dirs_at_node[node, 2] = 1
        link_dirs_at_node[node, 3] = 0
    link_dirs_at_node[0, 2] = 0
    link_dirs_at_node[n_cols - 1, 0] = 0

    # Middle rows
    for row in prange(1, n_rows - 1, nogil=True, schedule="static"):
        first_node = row * n_cols

        for node in range(first_node, first_node + n_cols):
            link_dirs_at_node[node, 0] = - 1
            link_dirs_at_node[node, 1] = - 1
            link_dirs_at_node[node, 2] = 1
            link_dirs_at_node[node, 3] = 1
        link_dirs_at_node[first_node, 2] = 0
        link_dirs_at_node[first_node + n_cols - 1, 0] = 0

    # Top row
    first_node = (n_rows - 1) * n_cols
    for node in prange(first_node, first_node + n_cols, nogil=True, schedule="static"):
        link_dirs_at_node[node, 0] = -1
        link_dirs_at_node[node, 1] = 0
        link_dirs_at_node[node, 2] = 1
        link_dirs_at_node[node, 3] = 1
    link_dirs_at_node[first_node, 2] = 0
    link_dirs_at_node[first_node + n_cols - 1, 0] = 0



================================================
File: src/landlab/graph/structured_quad/ext/at_patch.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_links_at_patch(
    shape,
    id_t [:, :] links_at_patch,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int links_per_row = 2 * n_cols - 1
    cdef int patches_per_row = n_cols - 1
    cdef int row
    cdef int link
    cdef int patch
    cdef int col

    for row in prange(n_rows - 1, nogil=True, schedule="static"):
        link = row * links_per_row + n_cols
        patch = row * patches_per_row
        for col in range(n_cols - 1):
            links_at_patch[patch, 0] = link
            links_at_patch[patch, 1] = link + n_cols - 1
            links_at_patch[patch, 2] = link - 1
            links_at_patch[patch, 3] = link - n_cols

            patch = patch + 1
            link = link + 1



================================================
File: src/landlab/graph/voronoi/__init__.py
================================================
from .dual_voronoi import DualVoronoiGraph
from .voronoi import DelaunayGraph

__all__ = ["DelaunayGraph", "DualVoronoiGraph"]



================================================
File: src/landlab/graph/voronoi/dual_voronoi.py
================================================
import numpy as np

from ..dual import DualGraph
from ..graph import Graph
from .voronoi import DelaunayGraph
from .voronoi_to_graph import VoronoiDelaunayToGraph


class DualVoronoiGraph(DualGraph, DelaunayGraph):
    def __init__(
        self, node_y_and_x, max_node_spacing=None, sort=False, perimeter_links=None
    ):
        """Create a voronoi grid.

        Parameters
        ----------
        nodes : tuple of array_like
            Coordinates of every node. First *y*, then *x*.

        Examples
        --------
        >>> from landlab.graph import DualVoronoiGraph
        >>> node_x = [0, 1, 2, 3, 0.2, 1.2, 2.2, 3.2, 0.4, 1.4, 2.4, 3.4]
        >>> node_y = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]
        >>> graph = DualVoronoiGraph((node_y, node_x), sort=True)
        >>> graph.x_of_corner
        array([0.5,  1.5,  2.5,  0.7,  1.7,  2.7,  0.7,  1.7,  2.7,  0.9,  1.9,
               2.9])
        >>> graph.y_of_corner
        array([0.42,  0.42,  0.42,  0.58,  0.58,  0.58,  1.42,  1.42,  1.42,
               1.58,  1.58,  1.58])
        >>> graph.corners_at_face
        array([[ 0,  3], [ 3,  1], [ 1,  4], [ 4,  2], [ 2,  5],
               [ 3,  6], [ 4,  7], [ 5,  8],
               [ 6,  9], [ 9,  7], [ 7, 10], [10,  8], [ 8, 11]])
        >>> graph.faces_at_corner
        array([[ 0, -1, -1], [ 2,  1, -1], [ 4,  3, -1],
               [ 5,  0,  1], [ 6,  2,  3], [ 7,  4, -1],
               [ 8,  5, -1], [10,  9,  6], [12, 11,  7],
               [ 8,  9, -1], [10, 11, -1], [12, -1, -1]])
        >>> graph.node_at_cell
        array([5, 6])
        """
        mesh = VoronoiDelaunayToGraph(
            np.vstack((node_y_and_x[1], node_y_and_x[0])).T,
            perimeter_links=perimeter_links,
        )

        Graph.__init__(
            self,
            node_y_and_x,
            links=mesh.nodes_at_link,
            patches=mesh.links_at_patch,
            sort=False,
        )
        dual_graph = Graph(
            (mesh.y_of_corner, mesh.x_of_corner),
            links=mesh.corners_at_face,
            patches=mesh.faces_at_cell,
            sort=False,
        )

        self.merge(
            dual_graph, node_at_cell=mesh.node_at_cell, nodes_at_face=mesh.nodes_at_face
        )

        if sort:
            self.sort()



================================================
File: src/landlab/graph/voronoi/voronoi.py
================================================
import numpy as np

from ..graph import Graph
from .voronoi_to_graph import VoronoiDelaunayToGraph


class DelaunayGraph(Graph):
    """Graph of a voronoi grid.

    Examples
    --------
    >>> from landlab.graph import DelaunayGraph
    """

    def __init__(
        self, node_y_and_x, max_node_spacing=None, sort=False, perimeter_links=None
    ):
        """Create a voronoi grid.

        Parameters
        ----------
        nodes : tuple of array_like
            Coordinates of every node. First *y*, then *x*.

        Examples
        --------
        >>> from landlab.graph import DelaunayGraph
        >>> node_x = [0.0, 1.0, 2.0, 0.9, 1.9, 2.9]
        >>> node_y = [0, 0, 0, 2, 2, 2]
        >>> graph = DelaunayGraph((node_y, node_x), sort=True)
        >>> graph.x_of_node
        array([0. ,  1. ,  2. ,  0.9,  1.9,  2.9])
        >>> graph.y_of_node
        array([0.,  0.,  0.,  2.,  2.,  2.])
        >>> graph.nodes_at_link
        array([[0, 1], [1, 2],
               [0, 3], [1, 3], [1, 4], [2, 4], [2, 5],
               [3, 4], [4, 5]])
        >>> graph.links_at_node
        array([[ 0,  2, -1, -1], [ 1,  4,  3,  0], [ 6,  5,  1, -1],
               [ 7,  2,  3, -1], [ 8,  7,  4,  5], [ 8,  6, -1, -1]])
        >>> graph.links_at_patch
        array([[3, 2, 0], [5, 4, 1], [7, 3, 4], [8, 5, 6]])

        >>> graph.nodes_at_patch
        array([[3, 0, 1], [4, 1, 2], [4, 3, 1], [5, 4, 2]])
        """
        mesh = VoronoiDelaunayToGraph(
            np.vstack((node_y_and_x[1], node_y_and_x[0])).T,
            perimeter_links=perimeter_links,
        )

        Graph.__init__(
            self,
            node_y_and_x,
            links=mesh.nodes_at_link,
            patches=mesh.links_at_patch,
            sort=sort,
        )



================================================
File: src/landlab/graph/voronoi/voronoi_to_graph.py
================================================
import re

import numpy as np
import xarray as xr
from scipy.spatial import Delaunay
from scipy.spatial import Voronoi

from landlab.core.utils import as_id_array
from landlab.graph.sort.intpair import IntPairCollection
from landlab.graph.sort.intpair import IntPairMapping
from landlab.graph.sort.sort import reverse_one_to_one
from landlab.utils import jaggedarray


class VoronoiDelaunay:
    def __init__(self, xy_of_node):
        # What we need:
        # * [x] xy_of_node
        # * [x] nodes_at_link
        # * [x] links_at_patch
        # And then for the dual graph:
        # * [x] xy_of_corner
        # * [x] corners_at_face
        # * [x] faces_at_cell
        # And the to link the graphs:
        # * [x] node_at_cell
        # * [x] nodes_at_face
        # points == xy_of_node
        # vertices == xy_of_corner
        # regions == corners_at_cell
        # ridge_vertices == corners_at_face
        # ridge_points == nodes_at_face
        # point_region == node_at_cell

        delaunay = Delaunay(xy_of_node)
        voronoi = Voronoi(xy_of_node)

        voronoi.regions, voronoi.point_region = VoronoiDelaunay._remove_empty_regions(
            voronoi.regions, voronoi.point_region
        )

        mesh = xr.Dataset(
            {
                "node": xr.DataArray(
                    data=np.arange(len(voronoi.points)),
                    coords={
                        "x_of_node": xr.DataArray(voronoi.points[:, 0], dims=("node",)),
                        "y_of_node": xr.DataArray(voronoi.points[:, 1], dims=("node",)),
                    },
                    dims=("node",),
                ),
                "corner": xr.DataArray(
                    data=np.arange(len(voronoi.vertices)),
                    coords={
                        "x_of_corner": xr.DataArray(
                            voronoi.vertices[:, 0], dims=("corner",)
                        ),
                        "y_of_corner": xr.DataArray(
                            voronoi.vertices[:, 1], dims=("corner",)
                        ),
                    },
                    dims=("corner",),
                ),
            }
        )
        mesh.update(
            {
                "nodes_at_link": xr.DataArray(
                    as_id_array(voronoi.ridge_points), dims=("link", "Two")
                ),
                "nodes_at_patch": xr.DataArray(
                    np.asarray(delaunay.simplices, dtype=int), dims=("patch", "Three")
                ),
                "corners_at_face": xr.DataArray(
                    voronoi.ridge_vertices, dims=("face", "Two")
                ),
                "corners_at_cell": xr.DataArray(
                    self._corners_at_cell(voronoi.regions),
                    dims=("cell", "max_corners_per_cell"),
                ),
                "n_corners_at_cell": xr.DataArray(
                    [len(cell) for cell in voronoi.regions], dims=("cell",)
                ),
                "nodes_at_face": xr.DataArray(
                    np.asarray(voronoi.ridge_points, dtype=int), dims=("face", "Two")
                ),
                "cell_at_node": xr.DataArray(
                    np.asarray(voronoi.point_region, dtype=int), dims=("node",)
                ),
            }
        )
        self._mesh = mesh

    @staticmethod
    def _corners_at_cell(regions):
        jagged = jaggedarray.JaggedArray(regions)
        return np.asarray(
            jaggedarray.unravel(jagged.array, jagged.offset, pad=-1), dtype=int
        )

    @staticmethod
    def _remove_empty_regions(regions, point_region):
        """Remove regions that have no points.

        Parameters
        ----------
        regions : list of list of int
            Lists of each region's vertices.
        point_regions : list in int
            The region associated with each point.

        Returns
        -------
        regions, point_regions
            Copies of the input arrays with empty regions removed.
        """
        size_of_region = np.array([len(region) for region in regions], dtype=int)
        empty_regions = np.where(size_of_region == 0)[0]

        if len(empty_regions):
            point_region = np.asarray(point_region, dtype=int)

            regions = list(regions)
            for region in empty_regions[::-1]:
                regions.pop(region)
                point_region[point_region >= region] -= 1
        return regions, point_region

    @property
    def number_of_nodes(self):
        return self._mesh.sizes["node"]

    @property
    def number_of_links(self):
        return self._mesh.sizes["link"]

    @property
    def number_of_patches(self):
        return self._mesh.sizes["patch"]

    @property
    def number_of_corners(self):
        return self._mesh.sizes["corner"]

    @property
    def number_of_faces(self):
        return self._mesh.sizes["face"]

    @property
    def number_of_cells(self):
        return self._mesh.sizes["cell"]

    @property
    def x_of_node(self):
        return self._mesh["x_of_node"].values

    @property
    def y_of_node(self):
        return self._mesh["y_of_node"].values

    @property
    def x_of_corner(self):
        return self._mesh["x_of_corner"].values

    @property
    def y_of_corner(self):
        return self._mesh["y_of_corner"].values

    @property
    def nodes_at_patch(self):
        return self._mesh["nodes_at_patch"].values

    @property
    def nodes_at_link(self):
        return self._mesh["nodes_at_link"].values

    @property
    def nodes_at_face(self):
        return self._mesh["nodes_at_face"].values

    @property
    def corners_at_face(self):
        return self._mesh["corners_at_face"].values

    @property
    def corners_at_cell(self):
        return self._mesh["corners_at_cell"].values

    @property
    def n_corners_at_cell(self):
        return self._mesh["n_corners_at_cell"].values

    @property
    def cell_at_node(self):
        return self._mesh["cell_at_node"].values


class VoronoiDelaunayToGraph(VoronoiDelaunay):
    def __init__(self, xy_of_node, perimeter_links=None):
        super().__init__(xy_of_node)

        if perimeter_links is not None:
            perimeter_links = np.asarray(perimeter_links, dtype=int)
        self._perimeter_links = perimeter_links

        mesh = self._mesh
        mesh.update(
            {
                "links_at_patch": xr.DataArray(
                    self._links_at_patch(
                        mesh["nodes_at_link"].data, mesh["nodes_at_patch"].data
                    ),
                    dims=("patch", "Three"),
                ),
                "node_at_cell": xr.DataArray(
                    reverse_one_to_one(mesh["cell_at_node"].data), dims=("cell",)
                ),
            }
        )
        mesh.update(
            {
                "faces_at_cell": xr.DataArray(
                    self._links_at_patch(
                        mesh["corners_at_face"].data,
                        mesh["corners_at_cell"].data,
                        n_links_at_patch=self.n_corners_at_cell,
                    ),
                    dims=("cell", "max_faces_per_cell"),
                )
            }
        )

        self.drop_corners(self.unbound_corners())
        self.drop_perimeter_faces()
        self.drop_perimeter_cells()

    @staticmethod
    def _links_at_patch(nodes_at_link, nodes_at_patch, n_links_at_patch=None):
        """Construct links_at_path from nodes_at_link/nodes_at_path."""
        pairs = IntPairMapping(nodes_at_link, values=np.arange(len(nodes_at_link)))

        return pairs.get_items(nodes_at_patch, wraparound=True)

    def is_perimeter_face(self):
        return np.any(self.corners_at_face == -1, axis=1)

    def is_perimeter_cell(self):
        from .ext.voronoi import id_array_contains

        is_perimeter_cell = np.empty(len(self.n_corners_at_cell), dtype=bool)
        id_array_contains(
            self.corners_at_cell,
            self.n_corners_at_cell,
            -1,
            is_perimeter_cell.view(dtype=np.uint8),
        )
        is_perimeter_cell |= self.n_corners_at_cell < 3

        return is_perimeter_cell

    def is_perimeter_link(self):
        if self._perimeter_links is not None:
            pairs = IntPairCollection(self._perimeter_links)
            is_perimeter_link = pairs.contains_pairs(self.nodes_at_link)
        else:
            is_perimeter_link = self.is_perimeter_face()
        return is_perimeter_link

    def unbound_corners(self):
        faces_to_drop = np.where(self.is_perimeter_face() & ~self.is_perimeter_link())

        unbound_corners = self.corners_at_face[faces_to_drop].reshape((-1,))

        return np.unique(unbound_corners[unbound_corners >= 0])

    def is_bound_corner(self):
        corners = np.full(self._mesh.sizes["corner"], True)
        corners[self.unbound_corners()] = False

        return corners

    def drop_corners(self, corners):
        if len(corners) == 0:
            return

        # Remove the corners
        corners_to_drop = np.asarray(corners, dtype=int)
        self.drop_element(corners_to_drop, at="corner")

        # Remove bad links
        is_a_link = np.any(self._mesh["corners_at_face"].data != -1, axis=1)
        self.drop_element(np.where(~is_a_link)[0], at="link")

        # Remove the bad patches
        is_a_patch = np.all(self._mesh["links_at_patch"] >= 0, axis=1)
        self.drop_element(np.where(~is_a_patch)[0], at="patch")

    def drop_perimeter_faces(self):
        self.drop_element(np.where(self.is_perimeter_face())[0], at="face")

    def drop_perimeter_cells(self):
        self.drop_element(np.where(self.is_perimeter_cell())[0], at="cell")

    def ids_with_prefix(self, at):
        matches = set()
        if at == "patch":
            prefix = re.compile(f"^{at}(es)?_at_")
        else:
            prefix = re.compile(f"^{at}(s)?_at_")
        for name in self._mesh.variables:
            if prefix.search(name):
                matches.add(name)
        return matches

    def ids_with_suffix(self, at):
        matches = set()
        suffix = re.compile(f"at_{at}$")
        for name in self._mesh.variables:
            if suffix.search(name):
                matches.add(name)
        return matches

    def drop_element(self, ids, at="node"):
        dropped_ids = np.asarray(ids, dtype=int)
        dropped_ids.sort()
        is_a_keeper = np.full(self._mesh.sizes[at], True)
        is_a_keeper[dropped_ids] = False

        at_ = {}
        if at in self._mesh.coords:
            x = self._mesh[f"x_of_{at}"].values[is_a_keeper]
            y = self._mesh[f"y_of_{at}"].values[is_a_keeper]
            data = np.arange(len(x))

            at_[at] = xr.DataArray(
                data=data,
                coords={
                    f"x_of_{at}": xr.DataArray(x, dims=(at,)),
                    f"y_of_{at}": xr.DataArray(y, dims=(at,)),
                },
                dims=(at,),
            )
            self._mesh = self._mesh.drop_vars([f"x_of_{at}", f"y_of_{at}"])

        for name in self.ids_with_suffix(at):
            var = self._mesh[name]
            at_[name] = xr.DataArray(var.values[is_a_keeper], dims=var.sizes)

        self._mesh = self._mesh.drop_vars(list(at_))
        self._mesh.update(at_)

        for name in self.ids_with_prefix(at):
            var = self._mesh[name]
            array = var.values.reshape((-1,))
            array[np.isin(array, dropped_ids)] = -1
            for id_ in dropped_ids[::-1]:
                array[array > id_] -= 1

    @property
    def links_at_patch(self):
        return self._mesh["links_at_patch"].values

    @property
    def node_at_cell(self):
        return self._mesh["node_at_cell"].values

    @property
    def faces_at_cell(self):
        return self._mesh["faces_at_cell"].values



================================================
File: src/landlab/graph/voronoi/ext/__init__.py
================================================



================================================
File: src/landlab/graph/voronoi/ext/delaunay.pyx
================================================
cimport cython
from libc.stdlib cimport free
from libc.stdlib cimport malloc

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def remove_patches(
    id_t [:, :] links_at_patch,
    id_t [:] patches_to_remove,
):
    cdef int n_patches = links_at_patch.shape[0]
    cdef int max_links = links_at_patch.shape[1]
    cdef int patch
    cdef int n

    new_patch = 0
    for patch in range(n_patches):
        if patch in patches_to_remove:
            pass
        else:
            for n in range(max_links):
                links_at_patch[new_patch, n] = links_at_patch[patch, n]
            patch += 1


@cython.boundscheck(False)
@cython.wraparound(False)
def remove_tris(
    id_t [:, :] nodes_at_tri,
    id_t [:, :] neighbors_at_tri,
    const id_t [:] bad_tris,
):
    cdef int n_tris = nodes_at_tri.shape[0]
    cdef int tri
    cdef int patch
    cdef int *patch_at_tri = <int *>malloc(n_tris * sizeof(int))
    cdef int n
    cdef int old

    try:
        patch = 0
        for tri in range(n_tris):
            if tri in bad_tris:
                patch_at_tri[tri] = -1
            else:
                for n in range(3):
                    nodes_at_tri[patch, n] = nodes_at_tri[tri, n]
                    neighbors_at_tri[patch, n] = neighbors_at_tri[tri, n]
                patch_at_tri[tri] = patch
                patch += 1

        for tri in range(n_tris):
            for n in range(3):
                old = neighbors_at_tri[tri, n]
                if old >= 0:
                    neighbors_at_tri[tri, n] = patch_at_tri[old]
                else:
                    neighbors_at_tri[tri, n] = -1
    finally:
        free(patch_at_tri)


@cython.boundscheck(False)
@cython.wraparound(False)
def _setup_links_at_patch(
    id_t [:, :] nodes_at_patch,
    id_t [:, :] tri_neighbors,
    id_t [:, :] nodes_at_link,
    id_t [:, :] links_at_patch,
):
    cdef int i
    cdef int link
    cdef int neighbor
    cdef int n_patches = len(nodes_at_patch)
    cdef int *tri_done = <int *>malloc(n_patches * sizeof(int))
    cdef int *links_per_patch = <int *>malloc(n_patches * sizeof(int))

    if not tri_done or not links_per_patch:
        raise MemoryError(
            "unable to allocate {bytes} bytes".format(bytes=n_patches * sizeof(int))
        )

    try:
        for tri in range(n_patches):
            tri_done[tri] = 0
            links_per_patch[tri] = 0

        link = 0
        for tri in range(n_patches):
            for i in (0, 1, 2):
                neighbor = tri_neighbors[tri, i]

                if neighbor == -1 or not tri_done[neighbor]:
                    nodes_at_link[link, 0] = nodes_at_patch[tri, (i + 1) % 3]
                    nodes_at_link[link, 1] = nodes_at_patch[tri, (i + 2) % 3]

                    links_at_patch[tri, links_per_patch[tri]] = link
                    links_per_patch[tri] += 1

                    if neighbor >= 0:
                        links_at_patch[neighbor, links_per_patch[neighbor]] = link
                        links_per_patch[neighbor] += 1
                        tri_done[tri] = True

                    link += 1
    finally:
        free(links_per_patch)
        free(tri_done)



================================================
File: src/landlab/graph/voronoi/ext/voronoi.pyx
================================================
cimport cython

from cython.parallel import prange

from libc.stdint cimport uint8_t

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


cdef int _id_array_contains(const id_t *array, long size, long bad_id) noexcept nogil:
    cdef long n
    for n in range(size):
        if array[n] == bad_id:
            return 1
    return 0


@cython.boundscheck(False)
@cython.wraparound(False)
def id_array_contains(
    const id_t [:, :] corners_at_cell,
    const id_t [:] n_corners_at_cell,
    long bad_val,
    uint8_t [:] out,
):
    cdef long n_cells = corners_at_cell.shape[0]
    cdef long cell

    for cell in prange(n_cells, nogil=True, schedule="static"):
        out[cell] = _id_array_contains(
            &corners_at_cell[cell, 0],
            n_corners_at_cell[cell],
            bad_val,
        )



================================================
File: src/landlab/grid/__init__.py
================================================
from landlab.grid.base import ModelGrid
from landlab.grid.create import create_grid
from landlab.grid.framed_voronoi import FramedVoronoiGrid
from landlab.grid.hex import HexModelGrid
from landlab.grid.network import NetworkModelGrid
from landlab.grid.radial import RadialModelGrid
from landlab.grid.raster import RasterModelGrid
from landlab.grid.voronoi import VoronoiDelaunayGrid

__all__ = [
    "ModelGrid",
    "HexModelGrid",
    "RadialModelGrid",
    "RasterModelGrid",
    "FramedVoronoiGrid",
    "VoronoiDelaunayGrid",
    "NetworkModelGrid",
    "create_grid",
]



================================================
File: src/landlab/grid/base.py
================================================
#! /usr/env/python
"""Python implementation of ModelGrid, a base class used to create and manage
grids for 2D numerical models.
"""
import contextlib
import fnmatch
from functools import cached_property

import numpy as np
import xarray as xr

from landlab.utils.decorators import make_return_array_immutable

from ..core import load_params
from ..core.utils import add_module_functions_to_class
from ..field.graph_field import GraphFields
from ..layers.eventlayers import EventLayersMixIn
from ..layers.materiallayers import MaterialLayersMixIn
from ..plot.imshow import ModelGridPlotterMixIn
from ..utils.decorators import cache_result_in_object
from . import grid_funcs as gfuncs
from .decorators import override_array_setitem_and_reset
from .decorators import return_id_array
from .decorators import return_readonly_id_array
from .linkstatus import LinkStatus
from .linkstatus import set_status_at_link
from .nodestatus import NodeStatus

#: Indicates an index is, in some way, *bad*.
BAD_INDEX_VALUE = -1
# DEJH thinks the user should be able to override this value if they want

# Map names grid elements to the ModelGrid attribute that contains the count
# of that element in the grid.
_ARRAY_LENGTH_ATTRIBUTES = {
    "node": "number_of_nodes",
    "patch": "number_of_patches",
    "link": "number_of_links",
    "corner": "number_of_corners",
    "face": "number_of_faces",
    "cell": "number_of_cells",
    "active_link": "number_of_active_links",
    "active_face": "number_of_active_faces",
    "core_node": "number_of_core_nodes",
    "core_cell": "number_of_core_cells",
}

# Fields whose sizes can not change.
_SIZED_FIELDS = {"node", "link", "patch", "corner", "face", "cell"}


def _sort_points_into_quadrants(x, y, nodes):
    """Divide x, y points into quadrants.

    Divide points with locations given in the *x*, and *y* arrays into north,
    south, east, and west quadrants. Returns nodes contained in quadrants
    (west, east, north, south).

    Parameters
    ----------
    x : array_like
        X-coordinates of points.
    y : array_like
        Y-coordinates of points.
    nodes : array_like
        Nodes associated with points.

    Returns
    -------
    tuple of array_like
        Tuple of nodes in each coordinate. Nodes are grouped as
        (*east*, *north*, *west*, *south*).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.base import _sort_points_into_quadrants
    >>> x = np.array([0, 1, 0, -1])
    >>> y = np.array([1, 0, -1, 0])
    >>> nodes = np.array([1, 2, 3, 4])
    >>> _sort_points_into_quadrants(x, y, nodes)
    (array([2]), array([1]), array([4]), array([3]))
    """
    above_x_axis = y > 0
    right_of_y_axis = x > 0
    closer_to_y_axis = np.abs(y) >= np.abs(x)

    north_nodes = nodes[above_x_axis & closer_to_y_axis]
    south_nodes = nodes[(~above_x_axis) & closer_to_y_axis]
    east_nodes = nodes[right_of_y_axis & (~closer_to_y_axis)]
    west_nodes = nodes[(~right_of_y_axis) & (~closer_to_y_axis)]

    return (east_nodes, north_nodes, west_nodes, south_nodes)


def _default_axis_names(n_dims):
    """Name of each axis.

    Parameters
    ----------
    n_dims : int
        Number of spatial dimensions.

    Returns
    -------
    tuple of str
        Name of each axis.

    Examples
    --------
    >>> from landlab.grid.base import _default_axis_names
    >>> _default_axis_names(1)
    ('x',)
    >>> _default_axis_names(2)
    ('x', 'y')
    >>> _default_axis_names(3)
    ('x', 'y', 'z')
    """
    _DEFAULT_NAMES = ("x", "y", "z")
    return _DEFAULT_NAMES[:n_dims]


def _default_axis_units(n_dims):
    """Unit names for each axis.

    Parameters
    ----------
    n_dims : int
        Number of spatial dimensions.

    Returns
    -------
    tuple of str
        Units of each axis.

    Examples
    --------
    >>> from landlab.grid.base import _default_axis_units
    >>> _default_axis_units(1)
    ('-',)
    >>> _default_axis_units(2)
    ('-', '-')
    >>> _default_axis_units(3)
    ('-', '-', '-')
    """
    return ("-",) * n_dims


def find_true_vector_from_link_vector_pair(L1, L2, b1x, b1y, b2x, b2y):
    r"""Separate a pair of links with vector values into x and y components.

    The concept here is that a pair of adjacent links attached to a node are
    projections of a 'true' but unknown vector. This function finds and returns
    the x and y components of this true vector. The trivial case is the
    situation in which the two links are orthogonal and aligned with the grid
    axes, in which case the vectors of these two links *are* the x and y
    components.

    Parameters
    ----------
    L1, L2 : float
        Values (magnitudes) associated with the two links
    b1x, b1y, b2x, b2y : float
        Unit vectors of the two links

    Returns
    -------
    ax, ay : float
        x and y components of the 'true' vector

    Notes
    -----
    The function does an inverse vector projection. Suppose we have a given
    'true' vector :math:`a`, and we want to project it onto two other lines
    with unit vectors (b1x,b1y) and (b2x,b2y). In the context of Landlab,
    the 'true' vector is some unknown vector quantity, which might for
    example represent the local water flow velocity. The lines represent two
    adjacent links in the grid.

    Let :math:`\mathbf{a}` be the true vector, :math:`\mathbf{B}` be a
    different vector with unit vector :math:`\mathbf{b}`, and :math:`L`
    be the scalar projection of *a* onto *B*. Then,

    ..math::

        L = \mathbf{a} \dot \mathbf{b} = a_x b_x + a_y b_y,

    where :math:`(a_x,a_y)` are the components of **a** and :math:`(b_x,b_y)`
    are the components of the unit vector **b**.

    In this case, we know *b* (the link unit vector), and we want to know the
    *x* and *y* components of **a**. The problem is that we have one equation
    and two unknowns (:math:`a_x` and :math:`a_y`). But we can solve this if
    we have *two* vectors, both of which are projections of **a**. Using the
    subscripts 1 and 2 to denote the two vectors, we can obtain equations for
    both :math:`a_x` and :math:`a_y`:

    ..math::

        a_x = L_1 / b_{1x} - a_y b_{1y} / b_{1x}

        a_y = L_2 / b_{2y} - a_x b_{2x} / b_{2y}

    Substituting the second into the first,

    ..math::

        a_x = [L_1/b_{1x}-L_2 b_{1y}/(b_{1x} b_{2y})] / [1-b_{1y} b_{2x}/(b_{1x} b_{2y})]

    Hence, we find the original vector :math:`(a_x,a_y)` from two links with
    unit vectors :math:`(b_{1x},b_{1y})` and :math:`(b_{2x},b_{2y})` and
    associated values :math:`L_1` and :math:`L_2`.

    Note that the above equations require that :math:`b_{1x}>0` and
    :math:`b_{2y}>0`. If this isn't the case, we invert the order of the two
    links, which requires :math:`b_{2x}>0` and :math:`b_{1y}>0`. If none of
    these conditions is met, then we have a degenerate case.

    Examples
    --------
    The following example represents the active links in a 7-node hexagonal
    grid, with just one core node. The 'true' vector has a magnitude of 5 units
    and an orientation of 30 degrees, pointing up and to the right (i.e., the
    postive-x and postive-y quadrant), so that its vector components are 4 (x)
    and 3 (y) (in other words, it is a 3-4-5 triangle). The values assigned to
    L below are the projection of that true vector onto the six link
    vectors. The algorithm should recover the correct vector component
    values of 4 and 3. The FOR loop examines each pair of links in turn.

    >>> import numpy as np
    >>> from landlab.grid.base import find_true_vector_from_link_vector_pair
    >>> bx = np.array([0.5, -0.5, -1.0, -0.5, 1.0, 0.5])
    >>> by = np.array([0.866, 0.866, 0.0, -0.866, 0.0, -0.866])
    >>> L = np.array([4.6, 0.6, -4.0, -4.6, 4.0, -0.6])
    >>> for i in range(5):
    ...     ax, ay = find_true_vector_from_link_vector_pair(
    ...         L[i], L[i + 1], bx[i], by[i], bx[i + 1], by[i + 1]
    ...     )
    ...     round(ax, 1), round(ay, 1)
    ...
    (4.0, 3.0)
    (4.0, 3.0)
    (4.0, 3.0)
    (4.0, 3.0)
    (4.0, 3.0)
    """
    assert (b1x != 0 and b2y != 0) or (b2x != 0 and b1y != 0), "Improper unit vectors"

    if b1x != 0.0 and b2y != 0.0:
        ax = (L1 / b1x - L2 * (b1y / (b1x * b2y))) / (1.0 - (b1y * b2x) / (b1x * b2y))
        ay = L2 / b2y - ax * (b2x / b2y)
    elif b2x != 0.0 and b1y != 0.0:
        ax = (L2 / b2x - L1 * (b2y / (b2x * b1y))) / (1.0 - (b2y * b1x) / (b2x * b1y))
        ay = L1 / b1y - ax * (b1x / b1y)

    return ax, ay


class ModelGrid(
    GraphFields, EventLayersMixIn, MaterialLayersMixIn, ModelGridPlotterMixIn
):
    """Base class for 2D structured or unstructured grids for numerical models.

    The idea is to have at least two inherited
    classes, RasterModelGrid and DelaunayModelGrid, that can create and
    manage grids. To this might be added a GenericModelGrid, which would
    be an unstructured polygonal grid that doesn't necessarily obey or
    understand the Delaunay triangulation, but rather simply accepts
    an input grid from the user. Also a :class:`~.HexModelGrid` for hexagonal.


    Other Parameters
    ----------------
    axis_name : tuple, optional
        Name of axes
    axis_units : tuple, optional
        Units of coordinates
    """

    #: Indicates a node is *bad index*.
    BAD_INDEX = BAD_INDEX_VALUE

    #: Indicates a node is *core*.
    BC_NODE_IS_CORE = NodeStatus.CORE
    #: Indicates a boundary node has a fixed value.
    BC_NODE_IS_FIXED_VALUE = NodeStatus.FIXED_VALUE
    #: Indicates a boundary node has a fixed gradient.
    BC_NODE_IS_FIXED_GRADIENT = NodeStatus.FIXED_GRADIENT
    #: Indicates a boundary node is wrap-around.
    BC_NODE_IS_LOOPED = NodeStatus.LOOPED
    #: Indicates a boundary node is closed
    BC_NODE_IS_CLOSED = NodeStatus.CLOSED

    #: Indicates a link is *active*, and can carry flux
    BC_LINK_IS_ACTIVE = LinkStatus.ACTIVE
    #: Indicates a link has a fixed gradient value, and behaves as a boundary
    BC_LINK_IS_FIXED = LinkStatus.FIXED
    #: Indicates a link is *inactive*, and cannot carry flux
    BC_LINK_IS_INACTIVE = LinkStatus.INACTIVE

    #: Grid elements on which fields can be placed.
    VALID_LOCATIONS = ("node", "link", "patch", "corner", "face", "cell", "grid")

    at_node = {}  # : Values defined at nodes
    at_link = {}  # : Values defined at links
    at_patch = {}  # : Values defined at patches
    at_corner = {}  # : Values defined at corners
    at_face = {}  # : Values defined at faces
    at_cell = {}  # : Values defined at cells
    at_grid = {}  # : Values defined at grid

    @classmethod
    def from_file(cls, file_like):
        """Create grid from a file-like object.

        File to load either as a file-like object, path to an existing file, or
        the contents of a file as a string.

        Parameters
        ----------
        file_like :
            File-like object, filepath, or string.

        Examples
        --------
        >>> from io import StringIO
        >>> from landlab import RasterModelGrid
        >>> filelike = StringIO(
        ...     '''
        ... shape:
        ...     - 3
        ...     - 4
        ... xy_spacing: 2
        ... '''
        ... )
        >>> grid = RasterModelGrid.from_file(filelike)
        >>> grid.x_of_node
        array([0.,  2.,  4.,  6.,  0.,  2.,  4.,  6.,  0.,  2.,  4.,  6.])
        >>> grid.y_of_node
        array([0.,  0.,  0.,  0.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.])
        """
        params = load_params(file_like)
        return cls.from_dict(params)

    @classmethod
    def from_dict(cls, params):
        """Create grid from dictionary.

        Parameters
        ----------
        params : dictionary
            Dictionary of required parameters to create a model grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> params = {"shape": (3, 4), "xy_spacing": 2}
        >>> grid = RasterModelGrid.from_dict(params)
        >>> grid.x_of_node
        array([0.,  2.,  4.,  6.,  0.,  2.,  4.,  6.,  0.,  2.,  4.,  6.])
        >>> grid.y_of_node
        array([0.,  0.,  0.,  0.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.])
        """
        return cls(**params)

    def __init__(self, **kwds):
        axis_units = kwds.pop("xy_axis_units", "-")
        axis_name = kwds.pop("xy_axis_name", ("x", "y"))

        super().__init__()

        self.new_field_location("node", self.number_of_nodes)
        self.new_field_location("link", self.number_of_links)
        self.new_field_location("patch", self.number_of_patches)
        self.new_field_location("corner", self.number_of_corners)
        self.new_field_location("face", self.number_of_faces)
        self.new_field_location("cell", self.number_of_cells)
        self.new_field_location("grid", None)
        self.default_group = "node"

        # self.axis_name = kwds.get("axis_name", _default_axis_names(self.ndim))
        # self.axis_units = kwds.get("axis_units", _default_axis_units(self.ndim))

        self._ref_coord = tuple(kwds.get("xy_of_reference", (0.0, 0.0)))
        self._link_length = None
        self._all_node_distances_map = None
        self._all_node_azimuths_map = None
        self.bc_set_code = 0

        self._axis_units = tuple(np.broadcast_to(axis_units, self.ndim))
        self._axis_name = tuple(np.broadcast_to(axis_name, self.ndim))

    def fields(self, include="*", exclude=None):
        """List of fields held by the grid.

        The returned field names are returned as their canonical names. That is,
        as a string of the for ``"at_<location>:<name>"``. This allows for fields with
        the same name to be defined at different grid locations. You could have,
        for example, a variable "elevation" defined at both *nodes* and
        *links*.

        Both the *include* and *exclude* patterns are glob-style expressions,
        not regular expressions. If either *include* or *exclude* are lists,
        then the patterns are matched using an "or".

        The *include* filters are applied before the *exclude* filters.

        Parameters
        ----------
        include : str, or iterable of str, optional
            Glob-style pattern for field names to include.
        exclude : str, or iterable of str, optional
            Glob-style pattern for field names to exclude.

        Returns
        -------
        set
            Filtered set of canonical field names held by the grid

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))

        Add some fields to the grid. Notice that we have defined a field
        named "elevation" at both *nodes* and *links*.

        >>> _ = grid.add_full("elevation", 3.0, at="node")
        >>> _ = grid.add_full("elevation", 4.0, at="link")
        >>> _ = grid.add_full("temperature", 5.0, at="node")

        >>> sorted(grid.fields())
        ['at_link:elevation', 'at_node:elevation', 'at_node:temperature']
        >>> sorted(grid.fields(include="at_node*"))
        ['at_node:elevation', 'at_node:temperature']
        >>> sorted(grid.fields(include="at_node*", exclude="*temp*"))
        ['at_node:elevation']

        Fields can also be defined at *layers*. In the following example
        we've filtered the results to just return the layer fields.

        >>> grid.event_layers.add(1.0, rho=0.5)
        >>> sorted(grid.fields(include="at_layer*"))
        ['at_layer:rho']

        If a list, the fields are matched with an "or".

        >>> sorted(grid.fields(include=["at_node*", "*elevation*"]))
        ['at_link:elevation', 'at_node:elevation', 'at_node:temperature']
        """
        if isinstance(include, str):
            include = [include]
        if isinstance(exclude, str):
            exclude = [exclude]

        layer_groups = {"_".join(["layer", at]) for at in self.groups}
        layer_groups.add("layer")

        canonical_names = set()
        for at in self.groups | layer_groups:
            with contextlib.suppress(KeyError):
                canonical_names.update([f"at_{at}:{name}" for name in self[at]])

        names = set()
        for pattern in include:
            names.update(fnmatch.filter(canonical_names, pattern))
        for pattern in exclude or []:
            names.difference_update(fnmatch.filter(canonical_names, pattern))

        return names

    def as_dataarray(self, name, at=None, time=None):
        """Create an xarray DataArray representation of a grid field.

        Parameters
        ----------
        name : str
            Name of a field. This can either be a canonical field name (of the
            form "at_<element>:<field_name>", or just the field name. In the
            latter case, use the *at* keyword to specify where the field is
            defined.
        at : str, optional
            The grid elements on which the field is defined. Use this only if
            *name* is not a canonical field name that already contains the grid
            element.

        Returns
        -------
        DataArray
            The field represented as a newly-created *xarray* *DataArray*.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> _ = grid.add_full("elevation", 3.0, at="node")

        >>> grid.as_dataarray("at_node:elevation")
        <xarray.DataArray 'at_node:elevation' (node: 12)> Size: 96B
        array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])
        Dimensions without coordinates: node

        >>> all(
        ...     grid.as_dataarray("at_node:elevation")
        ...     == grid.as_dataarray("elevation", at="node")
        ... )
        True
        """
        if at is None:
            at, field_name = name[len("at_") :].split(":")
        else:
            field_name = name
        values = getattr(self, f"at_{at}")[field_name]

        if at == "layer":  # For backward compatibility
            at = "layer_cell"

        dims = at.split("_")

        if at == "grid":
            dims = [f"{field_name}_per_grid"] if values.shape else []

        if time is not None and "layer" not in dims:
            dims = ["time"] + dims
            values = values[None]

        return xr.DataArray(values, dims=dims, name=f"at_{at}:{field_name}")

    def as_dataset(self, include="*", exclude=None, time=None):
        """Create an xarray Dataset representation of a grid.

        This method creates a new xarray Dataset object that contains the grid's
        data fields. A particular grid type (e.g. a *RasterModelGrid*) should
        define its own *as_dataset* method to represent that particular
        grid type as a *Dataset* and then call this method to add the
        data fields.

        Parameters
        ----------
        include : str or iterable or str
            Glob-style patterns of fields to include in the dataset.
        exclude : str or iterable or str
            Glob-style patterns of fields to exclude from the dataset.

        Returns
        -------
        Dataset
            An xarray Dataset representation of a *ModelGrid*.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))

        Add some fields to the grid. Notice that we have defined a field
        named "elevation" at both *nodes* and *links*.

        >>> _ = grid.add_full("elevation", 3.0, at="node")
        >>> _ = grid.add_full("elevation", 4.0, at="link")
        >>> _ = grid.add_full("temperature", 5.0, at="node")

        >>> ds = grid.as_dataset()
        >>> sorted(ds.sizes.items())
        [('dim', 2), ('link', 17), ('node', 12)]
        >>> sorted([var for var in ds.data_vars if var.startswith("at_")])
        ['at_link:elevation', 'at_node:elevation', 'at_node:temperature']

        >>> grid.event_layers.add(1.0, rho=0.5)

        >>> ds = grid.as_dataset()
        >>> sorted(ds.sizes.items())
        [('cell', 2), ('dim', 2), ('layer', 1), ('link', 17), ('node', 12)]
        >>> sorted([var for var in ds.data_vars if var.startswith("at_")])
        ['at_layer_cell:rho', 'at_layer_cell:thickness', 'at_link:elevation',
         'at_node:elevation', 'at_node:temperature']
        """
        names = self.fields(include=include, exclude=exclude)

        data = {}
        for name in names:
            array = self.as_dataarray(name, time=time)
            data[array.name] = array

        if self.event_layers.number_of_layers > 0:
            data["at_layer_cell:thickness"] = (("layer", "cell"), self.event_layers.dz)
        data["status_at_node"] = (("node",), self.status_at_node)

        if time is not None:
            data["time"] = (("time",), [time])

        return xr.Dataset(data)

    @property
    def xy_of_reference(self):
        """Return the coordinates (x, y) of the reference point.

        For RasterModelGrid and HexModelGrid the reference point is the
        minimum of x_of_node and of y_of_node. By default it is (0, 0). For
        VoronoiDelaunayGrid the reference point is (0, 0). For RadialModelGrid
        it is the (x, y) of the center point.

        The intention of these coordinates is to provide a method to store
        the large float values of projected coordinates.

        Example
        -------

        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5), xy_of_reference=(12345, 678910))
        >>> rmg.xy_of_reference
        (12345, 678910)
        >>> rmg.xy_of_reference = (98765, 43210)
        >>> rmg.xy_of_reference
        (98765, 43210)
        """
        return self._ref_coord

    @xy_of_reference.setter
    def xy_of_reference(self, new_xy_of_reference):
        """Set a new value for the model grid xy_of_reference."""
        self._ref_coord = (new_xy_of_reference[0], new_xy_of_reference[1])

    @property
    def ndim(self):
        """Number of spatial dimensions of the grid.

        :meta landlab: info-grid
        """
        return 2

    @property
    @override_array_setitem_and_reset("reset_status_at_node")
    def status_at_node(self):
        """Get array of the boundary status for each node.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import LinkStatus, NodeStatus, RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.status_at_node.reshape((4, 5))
        array([[1, 1, 1, 1, 1],
               [1, 0, 0, 0, 1],
               [1, 0, 0, 0, 1],
               [1, 1, 1, 1, 1]], dtype=uint8)
        >>> np.any(mg.status_at_link == LinkStatus.FIXED)
        False

        >>> mg.status_at_node[mg.nodes_at_left_edge] = NodeStatus.FIXED_GRADIENT
        >>> mg.status_at_node.reshape((4, 5))
        array([[2, 1, 1, 1, 1],
               [2, 0, 0, 0, 1],
               [2, 0, 0, 0, 1],
               [2, 1, 1, 1, 1]], dtype=uint8)
        >>> np.any(mg.status_at_link == LinkStatus.FIXED)  # links auto-update
        True

        :meta landlab: info-node, boundary-condition
        """
        return self._node_status

    @status_at_node.setter
    def status_at_node(self, new_status):
        """Set the array of node boundary statuses."""
        self._node_status[:] = new_status[:]
        self.reset_status_at_node()

    @property
    @cache_result_in_object()
    @return_readonly_id_array
    def active_adjacent_nodes_at_node(self):
        """Adjacent nodes for each grid node.

        For each grid node, get the adjacent nodes ordered
        counterclockwise starting from the positive x axis.

        Examples
        --------
        >>> from landlab import RasterModelGrid, HexModelGrid
        >>> grid = RasterModelGrid((4, 5))

        >>> grid.active_adjacent_nodes_at_node[(-1, 6, 2),]
        array([[-1, -1, -1, -1],
               [ 7, 11,  5,  1],
               [-1,  7, -1, -1]])

        Setting a node to closed causes all links touching it to
        be inactive.

        >>> grid.status_at_node[6] = grid.BC_NODE_IS_CLOSED
        >>> grid.active_adjacent_nodes_at_node[(-1, 6, 2),]
        array([[-1, -1, -1, -1],
               [-1, -1, -1, -1],
               [-1,  7, -1, -1]])

        >>> grid.active_adjacent_nodes_at_node[7]
        array([ 8, 12, -1,  2])
        >>> grid.active_adjacent_nodes_at_node[2]
        array([-1,  7, -1, -1])

        >>> grid = HexModelGrid((3, 2))
        >>> grid.status_at_node[0] = grid.BC_NODE_IS_CLOSED
        >>> grid.active_adjacent_nodes_at_node
        array([[-1, -1, -1, -1, -1, -1],
               [-1,  3, -1, -1, -1, -1],
               [ 3, -1, -1, -1, -1, -1],
               [ 4,  6,  5,  2, -1,  1],
               [-1,  3, -1, -1, -1, -1],
               [-1, -1,  3, -1, -1, -1],
               [-1,  3, -1, -1, -1, -1]])

        :meta landlab: info-node, connectivity, boundary-condition
        """
        return np.choose(
            self.status_at_link[self.links_at_node] == LinkStatus.ACTIVE,
            (-1, self.adjacent_nodes_at_node),
        )

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def active_link_dirs_at_node(self):
        """Return link directions into each node.

        A value of 1 indicates a link points toward a given node, while a value
        of -1 indicates a link points away from a node. Note that inactive links
        have a value of 0, but active and fixed links are both reported normally.

        Returns
        -------
        (n_nodes, max_links_per_node) ndarray of int
            Link directions relative to the nodes of a grid. The shape of the
            matrix will be number of nodes by the maximum number of links per
            node. A zero indicates no link at this position.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))

        ::

            .--->.--->.--->.
            ^    ^    ^    ^
            |    |    |    |
            .--->5--->.--->.
            ^    ^    ^    ^
            |    |    |    |
            .--->.--->.--->.

        >>> grid.active_link_dirs_at_node[5]
        array([-1, -1,  1,  1], dtype=int8)

        If we set the nodes along the left edge to be closed, the links attached
        to those nodes become inactive and so their directions are reported as 0.

        >>> grid.status_at_node[grid.nodes_at_left_edge] = grid.BC_NODE_IS_CLOSED
        >>> grid.active_link_dirs_at_node
        array([[ 0,  0,  0,  0], [ 0, -1,  0,  0], [ 0, -1,  0,  0], [ 0,  0,  0,  0],
               [ 0,  0,  0,  0], [-1, -1,  0,  1], [-1, -1,  1,  1], [ 0,  0,  1,  0],
               [ 0,  0,  0,  0], [ 0,  0,  0,  1], [ 0,  0,  0,  1], [ 0,  0,  0,  0]],
               dtype=int8)

        :meta landlab: info-node, info-link, connectivity
        """
        return np.choose(
            self.link_status_at_node == LinkStatus.ACTIVE, (0, self.link_dirs_at_node)
        )

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def link_status_at_node(self):
        return self.status_at_link[self.links_at_node]

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def core_nodes(self):
        """Get array of core nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.core_nodes
        array([ 6,  7,  8, 11, 12, 13])

        :meta landlab: info-node, boundary-condition
        """
        return np.where(self.status_at_node == NodeStatus.CORE)[0]

    @property
    @return_readonly_id_array
    def boundary_nodes(self):
        """Get array of boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.boundary_nodes
        array([ 0,  1,  2,  3,  4,  5,  9, 10, 14, 15, 16, 17, 18, 19])

        :meta landlab: info-node, boundary-condition
        """
        try:
            return self._boundary_nodes
        except AttributeError:
            (boundary_node_ids,) = np.where(self._node_status != NodeStatus.CORE)
            return boundary_node_ids

    @property
    @return_readonly_id_array
    def open_boundary_nodes(self):
        """Get array of open boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> for edge in (
        ...     mg.nodes_at_left_edge,
        ...     mg.nodes_at_right_edge,
        ...     mg.nodes_at_bottom_edge,
        ... ):
        ...     mg.status_at_node[edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.open_boundary_nodes
        array([16, 17, 18])

        :meta landlab: info-node, boundary-condition
        """
        (open_boundary_node_ids,) = np.where(
            (self._node_status != self.BC_NODE_IS_CLOSED)
            & (self._node_status != self.BC_NODE_IS_CORE)
        )
        return open_boundary_node_ids

    @property
    @return_readonly_id_array
    def closed_boundary_nodes(self):
        """Get array of closed boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.closed_boundary_nodes
        array([15, 16, 17, 18, 19])

        :meta landlab: info-node, boundary-condition
        """
        (closed_boundary_node_ids,) = np.where(
            self._node_status == self.BC_NODE_IS_CLOSED
        )
        return closed_boundary_node_ids

    @property
    @return_readonly_id_array
    def fixed_gradient_boundary_nodes(self):
        """Get array of fixed gradient boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_FIXED_GRADIENT
        >>> mg.fixed_gradient_boundary_nodes
        array([15, 16, 17, 18, 19])

        :meta landlab: info-node, boundary-condition
        """
        (fixed_gradient_boundary_node_ids,) = np.where(
            self._node_status == self.BC_NODE_IS_FIXED_GRADIENT
        )
        return fixed_gradient_boundary_node_ids

    @property
    @return_readonly_id_array
    def fixed_gradient_boundary_node_fixed_link(self):
        """An array of the fixed_links connected to fixed gradient boundary
        nodes.

        Note that on a raster, some nodes (notably the corners) can be
        `NodeStatus.FIXED_GRADIENT`, but not have a true `LinkStatus.FIXED` neighboring
        link. In such cases, the link returned will be a closed link joining
        the corner node to a neighboring `NodeStatus.FIXED_GRADIENT` node (see
        example).

        An AssertionError will be raised if for some reason a
        `NodeStatus.FIXED_GRADIENT` node exists which has neither a
        `NodeStatus.FIXED_GRADIENT` neighbor, or a `LinkStatus.FIXED`.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> leftedge = grid.nodes_at_left_edge
        >>> grid.status_at_node[leftedge] = grid.BC_NODE_IS_FIXED_GRADIENT
        >>> grid.fixed_gradient_boundary_nodes
        array([0, 4, 8])
        >>> grid.fixed_gradient_boundary_node_fixed_link
        array([ 3,  7, 10])
        """
        try:
            return self._fixed_gradient_boundary_node_links
        except AttributeError:
            self._create_fixed_gradient_boundary_node_links()
            return self._fixed_gradient_boundary_node_links

    @property
    @return_readonly_id_array
    def fixed_gradient_boundary_node_anchor_node(self):
        """Returns the node at the other end of the fixed link for a fixed
        gradient boundary node.

        Degenerate `NodeStatus.FIXED_GRADIENT` nodes (e.g., corners) are handled as
        in :func:`fixed_gradient_boundary_node_fixed_link`, by pointing to a
        neighboring `NodeStatus.FIXED_GRADIENT` node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> leftedge = grid.nodes_at_left_edge
        >>> grid.status_at_node[leftedge] = grid.BC_NODE_IS_FIXED_GRADIENT
        >>> grid.fixed_gradient_boundary_nodes
        array([0, 4, 8])
        >>> grid.fixed_gradient_boundary_node_fixed_link
        array([ 3,  7, 10])
        >>> grid.fixed_gradient_boundary_node_anchor_node
        array([4, 5, 4])
        """
        try:
            return self._fixed_gradient_boundary_node_anchor_node
        except AttributeError:
            self._create_fixed_gradient_boundary_node_anchor_node()
            return self._fixed_gradient_boundary_node_anchor_node

    def _create_fixed_gradient_boundary_node_links(self):
        """Builds a data structure to hold the fixed_links which control the
        values of any `NodeStatus.FIXED_GRADIENT` nodes in the grid.

        An AssertionError will be raised if for some reason a
        `NodeStatus.FIXED_GRADIENT` node exists which has neither a
        `NodeStatus.FIXED_GRADIENT` neighbor, or a `LinksStatus.FIXED`.
        """
        self._fixed_grad_links_created = True
        self._fixed_gradient_boundary_node_links = np.empty_like(
            self.fixed_gradient_boundary_nodes, dtype=int
        )
        fix_nodes = self.fixed_gradient_boundary_nodes
        neighbor_links = self.links_at_node[fix_nodes]  # -1s
        boundary_exists = self.link_dirs_at_node[fix_nodes]
        # next line retains -1 indexes
        link_stat_badind = self.status_at_link[neighbor_links] == LinkStatus.FIXED
        true_connection = np.logical_and(link_stat_badind, boundary_exists)
        true_fix_nodes = true_connection.sum(axis=1).astype(bool)
        self._fixed_gradient_boundary_node_links[true_fix_nodes] = neighbor_links[
            true_connection
        ]
        # resolve any corner nodes
        neighbor_nodes = self.adjacent_nodes_at_node[fix_nodes]  # BAD_INDEX_VALUEs
        neighbor_nodes[neighbor_nodes == self.BAD_INDEX] = -1
        fixed_grad_neighbor = np.logical_and(
            (self.status_at_node[neighbor_nodes] == NodeStatus.FIXED_GRADIENT),
            boundary_exists,
        )
        # ^True when NodeStatus.FIXED_GRADIENT for real
        # winnow it down to only one possibility for fixed_grad neighbor:
        which_neighbor = np.argmax(fixed_grad_neighbor, axis=1)
        indexing_range = np.arange(fixed_grad_neighbor.shape[0])
        a_link_to_fixed_grad = neighbor_links[indexing_range, which_neighbor]
        corners = np.logical_not(true_fix_nodes)
        assert np.all(fixed_grad_neighbor[indexing_range, which_neighbor][corners])
        self._fixed_gradient_boundary_node_links[corners] = a_link_to_fixed_grad[
            corners
        ]

    def _create_fixed_gradient_boundary_node_anchor_node(self):
        """Builds a data structure to hold the nodes which anchor the values of
        any `NodeStatus.FIXED_GRADIENT` nodes in the grid, i.e., those at the other
        ends of the `LinkStatus.FIXED`.

        An AssertionError will be raised if for some reason a
        `NodeStatus.FIXED_GRADIENT` node exists which has neither a
        `NodeStatus.FIXED_GRADIENT` neighbor, or a `LinkStatus.FIXED`.
        """
        self._fixed_grad_links_created = True
        fix_grad_nodes = self.fixed_gradient_boundary_nodes
        self._fixed_gradient_boundary_node_anchor_node = np.empty_like(fix_grad_nodes)
        heads_and_tails = np.empty((fix_grad_nodes.size, 2))
        which_one = np.empty_like(heads_and_tails, dtype=bool)
        heads_and_tails[:, 0] = self.node_at_link_head[
            self.fixed_gradient_boundary_node_fixed_link
        ]
        heads_and_tails[:, 1] = self.node_at_link_tail[
            self.fixed_gradient_boundary_node_fixed_link
        ]
        which_one[:, 0] = heads_and_tails[:, 0] == fix_grad_nodes
        which_one[:, 1] = heads_and_tails[:, 1] == fix_grad_nodes
        assert np.all(which_one.sum(axis=1) == 1)
        self._fixed_gradient_boundary_node_anchor_node = heads_and_tails[
            np.logical_not(which_one)
        ]

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def fixed_value_boundary_nodes(self):
        """Get array of fixed value boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))

        Initially all the perimeter nodes are fixed value boundary.

        >>> grid.fixed_value_boundary_nodes
        array([ 0,  1,  2,  3,  4, 5,  9, 10, 14, 15, 16, 17, 18, 19])

        Set left, right, and bottom edges to closed.

        >>> for edge in (
        ...     grid.nodes_at_left_edge,
        ...     grid.nodes_at_right_edge,
        ...     grid.nodes_at_bottom_edge,
        ... ):
        ...     grid.status_at_node[edge] = grid.BC_NODE_IS_CLOSED

        Now nodes on just the top edge are fixed.

        >>> grid.fixed_value_boundary_nodes
        array([16, 17, 18])

        :meta landlab: info-node, boundary-condition
        """
        return np.where(self._node_status == NodeStatus.FIXED_VALUE)[0]

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def active_faces(self):
        """Get array of active faces.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.active_faces
        array([0, 1, 2, 3, 4, 5, 6])

        >>> grid.status_at_node[6] = grid.BC_NODE_IS_CLOSED
        >>> grid.active_faces
        array([0, 2, 5])

        :meta landlab: info-face, boundary-condition
        """
        return self.face_at_link[self.active_links]

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def active_links(self):
        """Get array of active links.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.active_links
        array([ 4,  5,  7,  8,  9, 11, 12])

        :meta landlab: info-link, boundary-condition
        """
        return np.where(self.status_at_link == LinkStatus.ACTIVE)[0]

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def fixed_links(self):
        """Get array of fixed links.

        Examples
        --------
        >>> from landlab import NodeStatus, RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.status_at_node.reshape(grid.shape)
        array([[1, 1, 1, 1],
               [1, 0, 0, 1],
               [1, 1, 1, 1]], dtype=uint8)
        >>> grid.fixed_links.size
        0

        >>> grid.status_at_node[:4] = NodeStatus.FIXED_GRADIENT
        >>> grid.status_at_node.reshape(grid.shape)
        array([[2, 2, 2, 2],
               [1, 0, 0, 1],
               [1, 1, 1, 1]], dtype=uint8)
        >>> grid.fixed_links
        array([4, 5])

        :meta landlab: info-link, boundary-condition
        """
        return np.where(self.status_at_link == LinkStatus.FIXED)[0]

    @return_id_array
    def link_with_node_status(self, status_at_tail=None, status_at_head=None):
        """Links with a given node status.

        Parameters
        ----------
        status_at_tail : NodeStatus, optional
            Status of the link tail node.
        status_at_head : NodeStatus, optional
            Status of the link head node.

        Returns
        -------
        array of int
            Links with the given tail and head node statuses.

        Examples
        --------
        >>> from landlab import RasterModelGrid, NodeStatus
        >>> grid = RasterModelGrid((4, 5))

        >>> grid.status_at_node[13] = NodeStatus.FIXED_VALUE
        >>> grid.status_at_node[2] = NodeStatus.CLOSED
        >>> grid.link_with_node_status(
        ...     status_at_tail=NodeStatus.CORE, status_at_head=NodeStatus.CORE
        ... )
        array([10, 11, 14, 15, 19])
        >>> grid.link_with_node_status(
        ...     status_at_tail=NodeStatus.CORE, status_at_head=NodeStatus.FIXED_VALUE
        ... )
        array([12, 16, 20, 23, 24])
        >>> grid.link_with_node_status(
        ...     status_at_tail=NodeStatus.FIXED_VALUE, status_at_head=NodeStatus.CORE
        ... )
        array([ 5,  7,  9, 18])

        >>> grid.link_with_node_status(status_at_head=NodeStatus.CORE)
        array([ 5,  6,  7,  9, 10, 11, 14, 15, 18, 19])
        >>> grid.link_with_node_status(status_at_tail=NodeStatus.CORE)
        array([10, 11, 12, 14, 15, 16, 19, 20, 23, 24])
        >>> grid.link_with_node_status()
        array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
               17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])
        """
        masks = []
        if status_at_tail is not None:
            masks.append(self.status_at_node[self.node_at_link_tail] == status_at_tail)
        if status_at_head is not None:
            masks.append(self.status_at_node[self.node_at_link_head] == status_at_head)

        if len(masks) == 0:
            return np.arange(self.number_of_links, dtype=int)
        if len(masks) == 1:
            return np.where(masks[0])[0]
        else:
            return np.where(masks[0] & masks[1])[0]

    @return_id_array
    def link_with_angle(self, angle, in_degrees=False):
        """Return array of IDs of links with given angle.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((3, 3))
        >>> grid.link_with_angle(0.0)
        array([  0,  1,  8,  9, 10, 17, 18])
        >>> grid.link_with_angle(60.0, in_degrees=True)
        array([  3,  5,  7, 11, 13, 15])
        >>> grid.link_with_angle(2.0944)  # 120 degrees
        array([  2,  4,  6, 12, 14, 16])
        >>> len(grid.link_with_angle(0.5236))  # no links at 30 deg
        0
        >>> grid = HexModelGrid((3, 3), orientation="vertical")
        >>> grid.link_with_angle(30.0, in_degrees=True)
        array([  1,  3,  8, 10, 15, 17])
        >>> grid.link_with_angle(1.5708)  # 90 degrees
        array([ 2,  5,  6,  9, 12, 13, 16])
        >>> grid.link_with_angle(330.0, in_degrees=True)
        array([ 0,  4,  7, 11, 14, 18])
        >>> len(grid.link_with_angle(60.0, in_degrees=True))  # none at 60 deg
        0
        """
        if in_degrees:
            angle = np.deg2rad(angle % 360.0)
        return np.where(np.isclose(self.angle_of_link, angle))[0]

    @property
    @cache_result_in_object()
    @return_readonly_id_array
    def node_at_core_cell(self):
        """Get array of nodes associated with core cells.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))

        Initially each cell's node is core.

        >>> grid.node_at_core_cell
        array([ 6,  7,  8,
               11, 12, 13])

        Setting a node to closed causes means its cell is also
        "closed".

        >>> grid.status_at_node[8] = grid.BC_NODE_IS_CLOSED
        >>> grid.node_at_core_cell
        array([ 6,  7, 11, 12, 13])

        :meta landlab: info-node, info-cell, boundary-condition, connectivity
        """
        return np.where(self.status_at_node == NodeStatus.CORE)[0]

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def core_cells(self):
        """Get array of core cells.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))

        Initially all of the cells are "core".

        >>> grid.core_cells
        array([0, 1, 2,
               3, 4, 5])

        Setting a node to closed causes its cell to no longer be core.

        >>> grid.status_at_node[8] = grid.BC_NODE_IS_CLOSED
        >>> grid.core_cells
        array([0, 1, 3, 4, 5])

        :meta landlab: info-cell, boundary-condition
        """
        return self.cell_at_node[self.core_nodes]

    @property
    def number_of_active_faces(self):
        """Total number of active faces.

        Returns
        -------
        int
            Total number of active faces in the grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.number_of_active_faces
        7

        The number of active faces is updated when a node status changes.

        >>> grid.status_at_node[6] = grid.BC_NODE_IS_CLOSED
        >>> grid.number_of_active_faces
        3

        :meta landlab: info-face, boundary-condition
        """
        return self.active_faces.size

    @property
    def number_of_core_nodes(self):
        """Number of core nodes.

        The number of core nodes on the grid (i.e., excluding all boundary
        nodes).

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.number_of_core_nodes
        6

        >>> grid.status_at_node[7] = grid.BC_NODE_IS_CLOSED
        >>> grid.number_of_core_nodes
        5

        :meta landlab: info-node, boundary-condition
        """
        return self.core_nodes.size

    @property
    def number_of_core_cells(self):
        """Number of core cells.

        A core cell excludes all boundary cells.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.number_of_core_cells
        6

        >>> grid.status_at_node[7] = grid.BC_NODE_IS_CLOSED
        >>> grid.number_of_core_cells
        5

        :meta landlab: info-cell, boundary-condition
        """
        return self.core_cells.size

    @property
    def number_of_active_links(self):
        """Number of active links.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.number_of_active_links
        17
        >>> for edge in (
        ...     mg.nodes_at_left_edge,
        ...     mg.nodes_at_right_edge,
        ...     mg.nodes_at_bottom_edge,
        ... ):
        ...     mg.status_at_node[edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.number_of_active_links
        10

        :meta landlab: info-link, boundary-condition
        """
        return self.active_links.size

    @property
    def number_of_fixed_links(self):
        """Number of fixed links.

        Examples
        --------
        >>> from landlab import NodeStatus, RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.number_of_fixed_links
        0
        >>> mg.status_at_node[mg.nodes_at_top_edge] = NodeStatus.FIXED_GRADIENT
        >>> mg.number_of_fixed_links
        3

        :meta landlab: info-link, boundary-condition
        """
        return self.fixed_links.size

    def number_of_elements(self, name):
        """Number of instances of an element.

        Get the number of instances of a grid element in a grid.

        Parameters
        ----------
        name : {'node', 'cell', 'link', 'face', 'core_node', 'core_cell',
                'active_link', 'active_face'}
            Name of the grid element.

        Returns
        -------
        int
            Number of elements in the grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.number_of_elements("node")
        20
        >>> mg.number_of_elements("core_cell")
        6
        >>> mg.number_of_elements("link")
        31
        >>> mg.number_of_elements("active_link")
        17
        >>> mg.status_at_node[8] = mg.BC_NODE_IS_CLOSED
        >>> mg.number_of_elements("link")
        31
        >>> mg.number_of_elements("active_link")
        13

        :meta landlab: info-grid
        """
        try:
            return getattr(self, _ARRAY_LENGTH_ATTRIBUTES[name])
        except KeyError as exc:
            raise TypeError(f"{name}: element name not understood") from exc

    @make_return_array_immutable
    def node_axis_coordinates(self, axis=0):
        """Get the coordinates of nodes along a particular axis.

        Return node coordinates from a given *axis* (defaulting to 0). Axis
        numbering is the same as that for numpy arrays. That is, the zeroth
        axis is along the rows, and the first along the columns.

        Parameters
        ----------
        axis : int, optional
            Coordinate axis.

        Returns
        -------
        ndarray
            Coordinates of nodes for a given axis.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.node_axis_coordinates(0).reshape(grid.shape)
        array([[0.,  0.,  0.,  0.,  0.],
               [1.,  1.,  1.,  1.,  1.],
               [2.,  2.,  2.,  2.,  2.],
               [3.,  3.,  3.,  3.,  3.]])
        >>> grid.node_axis_coordinates(1).reshape(grid.shape)
        array([[0.,  1.,  2.,  3.,  4.],
               [0.,  1.,  2.,  3.,  4.],
               [0.,  1.,  2.,  3.,  4.],
               [0.,  1.,  2.,  3.,  4.]])

        :meta landlab: info-grid, info-node, quantity
        """
        AXES = ("node_y", "node_x")
        try:
            return getattr(self, AXES[axis])
        except IndexError as exc:
            raise ValueError("'axis' entry is out of bounds") from exc

    @property
    def axis_units(self):
        """Get units for each axis.

        Returns
        -------
        tuple of str
            The units (as a string) for each of a grid's coordinates.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5), xy_spacing=(3.0, 2.0))
        >>> mg.axis_units
        ('-', '-')
        >>> mg.axis_units = ("degrees_north", "degrees_east")
        >>> mg.axis_units
        ('degrees_north', 'degrees_east')
        >>> mg.axis_units = "m"
        >>> mg.axis_units
        ('m', 'm')

        :meta landlab: info-grid
        """
        return self._axis_units

    @axis_units.setter
    def axis_units(self, new_units):
        """Set the units for each coordinate axis."""
        new_units = np.broadcast_to(new_units, self.ndim)
        if len(new_units) != self.ndim:
            raise ValueError("length of units does not match grid dimension")
        self._axis_units = tuple(new_units)

    @property
    def axis_name(self):
        """Get the name of each coordinate axis.

        Returns
        -------
        tuple of str
            The names of each axis.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.axis_name
        ('x', 'y')
        >>> grid.axis_name = ("lon", "lat")
        >>> grid.axis_name
        ('lon', 'lat')

        :meta landlab: info-grid
        """
        return self._axis_name

    @axis_name.setter
    def axis_name(self, new_names):
        """Set the names of a grid's coordinate axes.

        Raises
        ------
        ValueError
            If the number of dimension do not match.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.axis_name = ("y", "x")
        >>> grid.axis_name = ("lon", "lat")
        >>> grid.axis_name
        ('lon', 'lat')
        """
        new_names = np.broadcast_to(new_names, self.ndim)
        if len(new_names) != self.ndim:
            raise ValueError("length of names does not match grid dimension")
        self._axis_name = tuple(new_names)

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def status_at_link(self):
        """Get array of the status of all links.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.status_at_node[mg.nodes_at_left_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.status_at_node[mg.nodes_at_right_edge] = mg.BC_NODE_IS_FIXED_GRADIENT
        >>> mg.status_at_link
        array([4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 0, 0, 2, 4, 0, 0, 0, 4, 4, 0, 0,
               2, 4, 0, 0, 0, 4, 4, 4, 4, 4], dtype=uint8)

        :meta landlab: boundary-condition, info-link
        """
        return set_status_at_link(self.status_at_node[self.nodes_at_link])

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def angle_of_link_about_head(self):
        """Find and return the angle of a link about the node at the link head.

        Because links have direction, their angle can be specified as an angle
        about either the node at the link head, or the node at the link tail.
        The default behaviour of `angle_of_link` is to return the angle about
        the link tail, but this method gives the angle about the link head.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> import numpy as np

        >>> grid = HexModelGrid((3, 2), node_layout="hex")
        >>> np.round(grid.angle_of_link[:3] / np.pi * 3.0)
        array([0., 2.,  1.])
        >>> np.round(grid.angle_of_link_about_head[:3] / np.pi * 3.0)  # 60 deg segments
        array([3.,  5.,  4.])

        :meta landlab: info-link, quantity
        """
        angles = np.arctan2(-np.sin(self.angle_of_link), -np.cos(self.angle_of_link))
        return np.mod(angles, 2.0 * np.pi, out=angles)

    def resolve_values_on_links(self, link_values, out=None):
        """Resolve the xy-components of links.

        Resolves values provided defined on links into the x and y directions.
        Returns values_along_x, values_along_y

        :meta landlab: info-link
        """
        return gfuncs.resolve_values_on_links(self, link_values, out=out)

    def link_at_node_is_upwind(self, values, out=None):
        """Return a boolean the same shape as :func:`links_at_node` which flags
        links which are upwind of the node as True.

        link_at_node_is_upwind iterates across the grid and identifies the link
        values at each link connected to a node. It then uses the
        link_dirs_at_node data structure to identify links bringing flux into
        the node. It then return a boolean array the same shape as
        links_at_node flagging these links. e.g., for a raster, the returned
        array will be shape (nnodes, 4).

        Parameters
        ----------
        values : str or array
            Name of variable field defined at links, or array of values at
            links.
        out : ndarray, optional
            Buffer to place mapped values into or `None` to create a new array.
            Must be correct shape and boolean dtype.

        Returns
        -------
        ndarray
            Boolean of which links are upwind at nodes.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> rmg = RasterModelGrid((3, 4))

        >>> rmg.at_link["grad"] = [
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -5.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ... ]
        >>> rmg.link_at_node_is_upwind("grad")
        array([[False, False, False, False],
               [False, False,  True, False],
               [False, False,  True, False],
               [False, False,  True, False],
               [False, False, False,  True],
               [False, False,  True,  True],
               [False, False,  True,  True],
               [False, False,  True,  True],
               [False, False, False,  True],
               [False, False,  True,  True],
               [False, False,  True,  True],
               [False, False,  True,  True]])

        :meta landlab: info-link, info-node, connectivity
        """
        if out is None:
            out = np.empty_like(self.links_at_node, dtype=bool)
        else:
            assert out.shape is self.links_at_node.shape
            assert out.dtype is bool
        if type(values) is str:
            vals = self.at_link[values]
        else:
            assert len(values) == self.number_of_links
            vals = values
        values_at_links = vals[self.links_at_node] * self.link_dirs_at_node
        # this procedure makes incoming links NEGATIVE
        np.less(values_at_links, 0.0, out=out)

        return out

    def link_at_node_is_downwind(self, values, out=None):
        """Return a boolean the same shape as :func:`links_at_node` which flags
        links which are downwind of the node as True.

        link_at_node_is_downwind iterates across the grid and identifies the
        link values at each link connected to a node. It then uses the
        link_dirs_at_node data structure to identify links carrying flux out of
        the node. It then return a boolean array the same shape as
        links_at_node flagging these links. e.g., for a raster, the returned
        array will be shape (nnodes, 4).

        Parameters
        ----------
        values : str or array
            Name of variable field defined at links, or array of values at
            links.
        out : ndarray, optional
            Buffer to place mapped values into or `None` to create a new array.
            Must be correct shape and boolean dtype.

        Returns
        -------
        ndarray
            Boolean of which links are downwind at nodes.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> rmg = RasterModelGrid((3, 4))
        >>> rmg.at_link["grad"] = [
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -5.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ... ]
        >>> rmg.link_at_node_is_downwind("grad")
        array([[ True,  True, False, False],
               [ True,  True, False, False],
               [ True,  True, False, False],
               [False,  True, False, False],
               [ True,  True, False, False],
               [ True,  True, False, False],
               [ True,  True, False, False],
               [False,  True, False, False],
               [ True, False, False, False],
               [ True, False, False, False],
               [ True, False, False, False],
               [False, False, False, False]])

        :meta landlab: info-link, info-node, connectivity
        """
        if out is None:
            out = np.empty_like(self.links_at_node, dtype=bool)
        else:
            assert out.shape is self.links_at_node.shape
            assert out.dtype is bool
        if type(values) is str:
            vals = self.at_link[values]
        else:
            assert len(values) == self.number_of_links
            vals = values
        values_at_links = vals[self.links_at_node] * self.link_dirs_at_node
        # this procedure makes incoming links NEGATIVE
        np.greater(values_at_links, 0.0, out=out)

        return out

    def upwind_links_at_node(self, values, bad_index=-1):
        """Return an (nnodes, X) shape array of link IDs of which links are
        upwind of each node, according to *values* (field or array).

        X is the maximum upwind links at any node. Nodes with fewer upwind
        links than this have additional slots filled with *bad_index*. Links
        are ordered anticlockwise from east.

        Parameters
        ----------
        values : str or array
            Name of variable field defined at links, or array of values at
            links.
        bad_index : int
            Index to place in array indicating no link.

        Returns
        -------
        ndarray
            Array of upwind link IDs

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> rmg = RasterModelGrid((3, 4))
        >>> rmg.at_link["grad"] = [
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -5.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ... ]
        >>> rmg.upwind_links_at_node("grad", bad_index=-1)
        array([[-1, -1],
               [ 0, -1],
               [ 1, -1],
               [ 2, -1],
               [ 3, -1],
               [ 7,  4],
               [ 8,  5],
               [ 9,  6],
               [10, -1],
               [14, 11],
               [15, 12],
               [16, 13]])

        :meta landlab: info-link, info-node, connectivity
        """
        if type(values) is str:
            vals = self.at_link[values]
        else:
            assert len(values) == self.number_of_links
            vals = values
        values_at_links = vals[self.links_at_node] * self.link_dirs_at_node
        # this procedure makes incoming links NEGATIVE
        unordered_IDs = np.where(values_at_links < 0.0, self.links_at_node, bad_index)
        bad_IDs = unordered_IDs == bad_index
        nnodes = self.number_of_nodes
        flat_sorter = np.argsort(bad_IDs, axis=1) + self.links_at_node.shape[
            1
        ] * np.arange(nnodes).reshape((nnodes, 1))
        big_ordered_array = unordered_IDs.ravel()[flat_sorter].reshape(
            self.links_at_node.shape
        )
        cols_to_cut = int(bad_IDs.sum(axis=1).min())

        if cols_to_cut > 0:
            return big_ordered_array[:, :-cols_to_cut]
        else:
            return big_ordered_array

    def downwind_links_at_node(self, values, bad_index=-1):
        """Return an (nnodes, X) shape array of link IDs of which links are
        downwind of each node, according to *values* (array or field).

        X is the maximum downwind links at any node. Nodes with fewer downwind
        links than this have additional slots filled with *bad_index*. Links
        are ordered anticlockwise from east.

        Parameters
        ----------
        values : str or array
            Name of variable field defined at links, or array of values at
            links.
        bad_index : int
            Index to place in array indicating no link.

        Returns
        -------
        ndarray
            Array of upwind link IDs

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> rmg = RasterModelGrid((3, 4))
        >>> rmg.at_link["grad"] = [
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -5.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ...     -1.0,
        ...     -2.0,
        ...     -3.0,
        ...     -4.0,
        ...     -1.0,
        ...     -2.0,
        ...     -1.0,
        ... ]
        >>> rmg.downwind_links_at_node("grad", bad_index=rmg.BAD_INDEX)
        array([[ 0,  3],
               [ 1,  4],
               [ 2,  5],
               [ 6, -1],
               [ 7, 10],
               [ 8, 11],
               [ 9, 12],
               [13, -1],
               [14, -1],
               [15, -1],
               [16, -1],
               [-1, -1]])

        :meta landlab: info-link, info-node, connectivity
        """
        if type(values) is str:
            vals = self.at_link[values]
        else:
            assert len(values) == self.number_of_links
            vals = values
        values_at_links = vals[self.links_at_node] * self.link_dirs_at_node
        # this procedure makes incoming links NEGATIVE
        unordered_IDs = np.where(values_at_links > 0.0, self.links_at_node, bad_index)
        bad_IDs = unordered_IDs == bad_index
        nnodes = self.number_of_nodes
        flat_sorter = np.argsort(bad_IDs, axis=1) + self.links_at_node.shape[
            1
        ] * np.arange(nnodes).reshape((nnodes, 1))
        big_ordered_array = unordered_IDs.ravel()[flat_sorter].reshape(
            self.links_at_node.shape
        )
        cols_to_cut = int(bad_IDs.sum(axis=1).min())

        if cols_to_cut > 0:
            return big_ordered_array[:, :-cols_to_cut]
        else:
            return big_ordered_array

    @property
    @make_return_array_immutable
    def patches_present_at_node(self):
        """A boolean array, False where a patch has a closed node or is
        missing.

        The array is the same shape as :func:`patches_at_node`, and is designed
        to mask it.

        Note that in cases where patches may have more than 3 nodes (e.g.,
        rasters), a patch is considered still present as long as at least 3
        open nodes are present.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((3, 3))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.patches_at_node
        array([[ 0, -1, -1, -1],
               [ 1,  0, -1, -1],
               [-1,  1, -1, -1],
               [ 2, -1, -1,  0],
               [ 3,  2,  0,  1],
               [-1,  3,  1, -1],
               [-1, -1, -1,  2],
               [-1, -1,  2,  3],
               [-1, -1,  3, -1]])
        >>> mg.patches_present_at_node
        array([[ True, False, False, False],
               [ True,  True, False, False],
               [False,  True, False, False],
               [False, False, False,  True],
               [False, False,  True,  True],
               [False, False,  True, False],
               [False, False, False, False],
               [False, False, False, False],
               [False, False, False, False]])
        >>> 1 in mg.patches_at_node * mg.patches_present_at_node
        True
        >>> 2 in mg.patches_at_node * mg.patches_present_at_node
        False

        :meta landlab: info-patch, info-node
        """
        try:
            return self._patches_present_mask
        except AttributeError:
            self.patches_at_node
            self._reset_patch_status()
            return self._patches_present_mask

    @property
    @make_return_array_immutable
    def patches_present_at_link(self):
        """A boolean array, False where a patch has a closed node or is
        missing.

        The array is the same shape as :func:`patches_at_link`, and is designed
        to mask it.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((3, 3))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.patches_at_link
        array([[-1,  0],
               [-1,  1],
               [ 0, -1],
               [ 1,  0],
               [-1,  1],
               [ 0,  2],
               [ 1,  3],
               [ 2, -1],
               [ 3,  2],
               [-1,  3],
               [ 2, -1],
               [ 3, -1]])
        >>> mg.patches_present_at_link
        array([[False,  True],
               [False,  True],
               [ True, False],
               [ True,  True],
               [False,  True],
               [ True, False],
               [ True, False],
               [False, False],
               [False, False],
               [False, False],
               [False, False],
               [False, False]])
        >>> 1 in mg.patches_at_link * mg.patches_present_at_link
        True
        >>> 2 in mg.patches_at_link * mg.patches_present_at_link
        False

        :meta landlab: info-patch, info-link
        """
        try:
            return self._patches_present_link_mask
        except AttributeError:
            self.patches_at_node
            self._reset_patch_status()
            return self._patches_present_link_mask

    @property
    @make_return_array_immutable
    def number_of_patches_present_at_node(self):
        """Return the number of patches at a node without a closed node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((3, 3))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.patches_present_at_node
        array([[ True, False, False, False],
               [ True,  True, False, False],
               [False,  True, False, False],
               [False, False, False,  True],
               [False, False,  True,  True],
               [False, False,  True, False],
               [False, False, False, False],
               [False, False, False, False],
               [False, False, False, False]])
        >>> mg.number_of_patches_present_at_node
        array([1, 2, 1, 1, 2, 1, 0, 0, 0])

        :meta landlab: info-patch, info-node, boundary-condition
        """
        try:
            return self._number_of_patches_present_at_node
        except AttributeError:
            self.patches_at_node
            self._reset_patch_status()
            return self._number_of_patches_present_at_node

    @property
    @make_return_array_immutable
    def number_of_patches_present_at_link(self):
        """Return the number of patches at a link without a closed node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((3, 3))
        >>> mg.status_at_node[mg.nodes_at_top_edge] = mg.BC_NODE_IS_CLOSED
        >>> mg.patches_present_at_link
        array([[False,  True],
               [False,  True],
               [ True, False],
               [ True,  True],
               [False,  True],
               [ True, False],
               [ True, False],
               [False, False],
               [False, False],
               [False, False],
               [False, False],
               [False, False]])
        >>> mg.number_of_patches_present_at_link
        array([1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0])

        :meta landlab: info-patch, info-link, boundary-condition
        """
        try:
            return self._number_of_patches_present_at_link
        except AttributeError:
            self.patches_at_node
            self._reset_patch_status()
            return self._number_of_patches_present_at_link

    def _reset_patch_status(self):
        """Creates the array which stores patches_present_at_node.

        Call whenever boundary conditions are updated on the grid.
        """
        from landlab import RasterModelGrid
        from landlab import VoronoiDelaunayGrid

        node_status_at_patch = self.status_at_node[self.nodes_at_patch]
        if isinstance(self, RasterModelGrid):
            max_nodes_at_patch = 4
        elif isinstance(self, VoronoiDelaunayGrid):
            max_nodes_at_patch = 3
        else:
            max_nodes_at_patch = (self.nodes_at_patch > -1).sum(axis=1)
        any_node_at_patch_closed = (node_status_at_patch == self.BC_NODE_IS_CLOSED).sum(
            axis=1
        ) > (max_nodes_at_patch - 3)
        absent_patches = any_node_at_patch_closed[self.patches_at_node]
        bad_patches = np.logical_or(absent_patches, self.patches_at_node == -1)
        self._patches_present_mask = np.logical_not(bad_patches)
        self._number_of_patches_present_at_node = np.sum(
            self._patches_present_mask, axis=1
        )
        absent_patches = any_node_at_patch_closed[self.patches_at_link]
        bad_patches = np.logical_or(absent_patches, self.patches_at_link == -1)
        self._patches_present_link_mask = np.logical_not(bad_patches)
        self._number_of_patches_present_at_link = np.sum(
            self._patches_present_link_mask, axis=1
        )

    def calc_hillshade_at_node(
        self,
        alt=45.0,
        az=315.0,
        slp=None,
        asp=None,
        unit="degrees",
        elevs="topographic__elevation",
    ):
        """Get array of hillshade.

        .. codeauthor:: Katy Barnhart <katherine.barnhart@colorado.edu>

        Parameters
        ----------
        alt : float
            Sun altitude (from horizon) - defaults to 45 degrees
        az : float
            Sun azimuth (CW from north) - defaults to 315 degrees
        slp : float
            slope of cells at surface - optional
        asp : float
            aspect of cells at surface (from north) - optional (with slp)
        unit : string
            'degrees' (default) or 'radians' - only needed if slp and asp
                                                are not provided

        If slp and asp are both not specified, 'elevs' must be provided as
        a grid field name (defaults to 'topographic__elevation') or an
        nnodes-long array of elevation values. In this case, the method will
        calculate local slopes and aspects internally as part of the hillshade
        production.

        Returns
        -------
        ndarray of float
            Hillshade at each cell.

        Notes
        -----
        code taken from GeospatialPython.com example from December 14th, 2014
        DEJH found what looked like minor sign problems, and adjusted to follow
        the `ArcGIS algorithm
        <https://help.arcgis.com/en/arcgisdesktop/10.0/help/#How_Hillshade_works/009z000000z2000000/>`.

        Remember when plotting that bright areas have high values. cmap='Greys'
        will give an apparently inverted color scheme. *cmap='gray'* has white
        associated with the high values, so is recommended for plotting.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> mg = RasterModelGrid((5, 5), xy_spacing=1.0)
        >>> z = mg.x_of_node * np.tan(60.0 * np.pi / 180.0)
        >>> mg.calc_hillshade_at_node(elevs=z, alt=30.0, az=210.0)
        array([0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,
               0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,
               0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,  0.625,
               0.625])

        :meta landlab: info-node, surface
        """
        if slp is not None and asp is not None:
            if unit == "degrees":
                (alt, az, slp, asp) = (
                    np.radians(alt),
                    np.radians(az),
                    np.radians(slp),
                    np.radians(asp),
                )
            elif unit == "radians":
                if alt > np.pi / 2.0 or az > 2.0 * np.pi:
                    print(
                        "Assuming your solar properties are in degrees, "
                        "but your slopes and aspects are in radians..."
                    )
                    (alt, az) = (np.radians(alt), np.radians(az))
                    # ...because it would be super easy to specify radians,
                    # but leave the default params alone...
            else:
                raise TypeError("unit must be 'degrees' or 'radians'")
        elif slp is None and asp is None:
            if unit == "degrees":
                (alt, az) = (np.radians(alt), np.radians(az))
            elif unit == "radians":
                pass
            else:
                raise TypeError("unit must be 'degrees' or 'radians'")
            slp, slp_comps = self.calc_slope_at_node(elevs, return_components=True)

            asp = self.calc_aspect_at_node(
                slope_component_tuple=slp_comps, unit="radians"
            )
        else:
            raise TypeError("Either both slp and asp must be set, or neither!")

        shaded = np.sin(alt) * np.cos(slp) + np.cos(alt) * np.sin(slp) * np.cos(
            az - asp
        )

        return shaded.clip(0.0)

    @cached_property
    @make_return_array_immutable
    def cell_area_at_node(self):
        """Cell areas in a nnodes-long array.

        Zeros are entered at all perimeter nodes, which lack cells.

        Returns
        -------
        ndarray
            Cell areas as an n_nodes-long array.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5), xy_spacing=(3, 4))
        >>> grid.status_at_node[7] = grid.BC_NODE_IS_CLOSED
        >>> grid.cell_area_at_node
        array([  0.,   0.,   0.,   0.,   0.,
                 0.,  12.,  12.,  12.,   0.,
                 0.,  12.,  12.,  12.,   0.,
                 0.,   0.,   0.,   0.,   0.])

        :meta landlab: info-cell, info-node, connectivity
        """
        cell_area_at_node = np.zeros(self.number_of_nodes, dtype=float)
        cell_area_at_node[self.node_at_cell] = self.area_of_cell
        return cell_area_at_node

    def reset_status_at_node(self):
        attrs = [
            "_active_link_dirs_at_node",
            "_status_at_link",
            "_active_links",
            "_fixed_links",
            "_activelink_fromnode",
            "_activelink_tonode",
            "_active_faces",
            "_core_nodes",
            "_core_cells",
            "_fixed_links",
            "_active_adjacent_nodes_at_node",
            "_fixed_value_boundary_nodes",
            "_node_at_core_cell",
            "_link_status_at_node",
        ]

        for attr in attrs:
            with contextlib.suppress(KeyError):
                del self.__dict__[attr]
        try:
            self.bc_set_code += 1
        except AttributeError:
            self.bc_set_code = 0
        with contextlib.suppress(KeyError):
            del self.__dict__["__node_active_inlink_matrix"]
        with contextlib.suppress(KeyError):
            del self.__dict__["__node_active_outlink_matrix"]

    def set_nodata_nodes_to_closed(self, node_data, nodata_value):
        """Make no-data nodes closed boundaries.

        Sets node status to `BC_NODE_IS_CLOSED` for all nodes whose value
        of *node_data* is equal to the *nodata_value*.

        Any links connected to `BC_NODE_IS_CLOSED` nodes are automatically
        set to `LinkStatus.INACTIVE` boundary.

        Parameters
        ----------
        node_data : ndarray
            Data values.
        nodata_value : float
            Value that indicates an invalid value.

        Examples
        --------

        The following example uses the following grid::

          *--I--->o------>o------>o
          ^       ^       ^       ^
          I       I       |       |
          |       |       |       |
          *--I--->*--I--->o------>o
          ^       ^       ^       ^
          I       I       I       I
          |       |       |       |
          *--I--->*--I--->*--I--->*

        .. note::

          Links set to `LinkStatus.ACTIVE` are not shown in this diagram.

        ``*`` indicates the nodes that are set to `NodeStatus.CLOSED`

        ``o`` indicates the nodes that are set to `NodeStatus.CORE`

        ``I`` indicates the links that are set to `LinkStatus.INACTIVE`

        >>> import numpy as np
        >>> import landlab as ll
        >>> mg = ll.RasterModelGrid((3, 4))
        >>> mg.status_at_node.reshape(mg.shape)
        array([[1, 1, 1, 1],
               [1, 0, 0, 1],
               [1, 1, 1, 1]], dtype=uint8)
        >>> h = np.array(
        ...     [
        ...         [-9999, -9999, -9999, -9999],
        ...         [-9999, -9999, 12345.0, 0.0],
        ...         [-9999, 0.0, 0.0, 0.0],
        ...     ]
        ... ).flatten()
        >>> mg.set_nodata_nodes_to_closed(h, -9999)
        >>> mg.status_at_node.reshape(mg.shape)
        array([[4, 4, 4, 4],
               [4, 4, 0, 1],
               [4, 1, 1, 1]], dtype=uint8)

        :meta landlab: boundary-condition, info-node
        """
        # Find locations where value equals the NODATA code and set these nodes
        # as inactive boundaries.
        nodata_locations = np.nonzero(node_data == nodata_value)
        self.status_at_node[nodata_locations] = self.BC_NODE_IS_CLOSED

    def set_nodata_nodes_to_fixed_gradient(self, node_data, nodata_value):
        """Make no-data nodes fixed gradient boundaries.

        Set node status to `BC_NODE_IS_FIXED_VALUE` for all nodes
        whose value of *node_data* is equal to *nodata_value*.

        Any links between `BC_NODE_IS_FIXED_GRADIENT` nodes and
        `BC_NODE_IS_CORE` are automatically set to `LinkStatus.FIXED` boundary
        status.

        Parameters
        ----------
        node_data : ndarray
            Data values.
        nodata_value : float
            Value that indicates an invalid value.

        Examples
        --------

        The following examples use this grid::

          *--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*
          ^       ^       ^       ^       ^       ^       ^       ^       ^
          I       I       I       X       X       X       X       X       I
          |       |       |       |       |       |       |       |       |
          *--I--->*--I--->*--X--->o       o       o       o       o--X--->*
          ^       ^       ^       ^       ^       ^       ^       ^       ^
          I       I       I       |       |       |       |       |       I
          |       |       |       |       |       |       |       |       |
          *--I--->*--I--->*--X--->o       o       o       o       o--X--->*
          ^       ^       ^       ^       ^       ^       ^       ^       ^
          I       I       I       X       X       X       X       X       I
          |       |       |       |       |       |       |       |       |
          *--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*--I--->*

        .. note::

            Links set to `LinkStatus.ACTIVE` are not shown in this diagram.

        ``X`` indicates the links that are set to `LinkStatus.FIXED`

        ``I`` indicates the links that are set to `LinkStatus.INACTIVE`

        ``o`` indicates the nodes that are set to `NodeStatus.CORE`

        ``*`` indicates the nodes that are set to
              `BC_NODE_IS_FIXED_GRADIENT`

        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 9))
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[1, 1, 1, 1, 1, 1, 1, 1, 1],
               [1, 0, 0, 0, 0, 0, 0, 0, 1],
               [1, 0, 0, 0, 0, 0, 0, 0, 1],
               [1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=uint8)

        >>> z = np.array(
        ...     [
        ...         [-99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0],
        ...         [-99.0, -99.0, -99.0, 0.0, 0.0, 0.0, 0.0, 0.0, -99.0],
        ...         [-99.0, -99.0, -99.0, 0.0, 0.0, 0.0, 0.0, 0.0, -99.0],
        ...         [-99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0, -99.0],
        ...     ]
        ... ).flatten()

        >>> rmg.set_nodata_nodes_to_fixed_gradient(z, -99)
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[2, 2, 2, 2, 2, 2, 2, 2, 2],
               [2, 2, 2, 0, 0, 0, 0, 0, 2],
               [2, 2, 2, 0, 0, 0, 0, 0, 2],
               [2, 2, 2, 2, 2, 2, 2, 2, 2]], dtype=uint8)

        >>> rmg.status_at_link[rmg.horizontal_links].reshape((4, 8))
        array([[4, 4, 4, 4, 4, 4, 4, 4],
               [4, 4, 2, 0, 0, 0, 0, 2],
               [4, 4, 2, 0, 0, 0, 0, 2],
               [4, 4, 4, 4, 4, 4, 4, 4]], dtype=uint8)
        >>> rmg.status_at_link[rmg.vertical_links].reshape((3, 9))
        array([[4, 4, 4, 2, 2, 2, 2, 2, 4],
               [4, 4, 4, 0, 0, 0, 0, 0, 4],
               [4, 4, 4, 2, 2, 2, 2, 2, 4]], dtype=uint8)

        :meta landlab: boundary-condition, info-node
        """
        # Find locations where value equals the NODATA code and set these nodes
        # as inactive boundaries.
        nodata_locations = np.nonzero(node_data == nodata_value)
        self.status_at_node[nodata_locations] = NodeStatus.FIXED_GRADIENT

    @property
    def unit_vector_sum_xcomponent_at_node(self):
        """Get array of x-component of unit vector sums at each node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 3))
        >>> len(grid.unit_vector_sum_xcomponent_at_node) == grid.number_of_nodes
        True
        >>> grid.unit_vector_sum_xcomponent_at_node
        array([1.,  2.,  1.,  1.,  2.,  1.,  1.,  2.,  1.])

        :meta landlab: info-node, quantity
        """
        return self.unit_vector_at_node[:, 0]

    @property
    def unit_vector_sum_ycomponent_at_node(self):
        """Get array of y-component of unit vector sums at each node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 3))
        >>> len(grid.unit_vector_sum_ycomponent_at_node) == grid.number_of_nodes
        True
        >>> grid.unit_vector_sum_ycomponent_at_node
        array([1.,  1.,  1.,  2.,  2.,  2.,  1.,  1.,  1.])

        :meta landlab: info-node, quantity
        """
        return self.unit_vector_at_node[:, 1]

    def node_is_boundary(self, ids, boundary_flag=None):
        """Check if nodes are boundary nodes.

        Check if nodes at given *ids* are boundary nodes. Use the
        *boundary_flag* to specify a particular boundary type status flag.

        Parameters
        ----------
        ids : ndarray
            Node IDs to check.
        boundary_flag : int, optional
            A boundary type to check for.

        Returns
        -------
        ndarray
            Array of booleans indicating if nodes are boundary nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.node_is_boundary([0, 6])
        array([ True, False])
        >>> mg.node_is_boundary([0, 6], boundary_flag=mg.BC_NODE_IS_CLOSED)
        array([False, False])

        :meta landlab: info-node, boundary-condition
        """
        if boundary_flag is None:
            return ~(self._node_status[ids] == NodeStatus.CORE)
        else:
            return self._node_status[ids] == boundary_flag

    def calc_distances_of_nodes_to_point(
        self, coord, get_az=None, node_subset=None, out_distance=None, out_azimuth=None
    ):
        """Get distances for nodes to a given point.

        Returns an array of distances for each node to a provided point.
        If "get_az" is set to 'angles', returns both the distance array and an
        array of azimuths from up/north. If it is set to 'displacements', it
        returns the azimuths as a 2xnnodes array of x and y displacements.
        If it is not set, returns just the distance array.

        If "node_subset" is set as an ID, or list/array/etc of IDs method
        returns just the distance (and optionally azimuth) for that node.
        Point is provided as a tuple (x,y).

        If out_distance (& out_azimuth) are provided, these arrays are used to
        store the outputs. This is recommended for memory management reasons if
        you are working with node subsets.

        .. note::

            Angles are returned in radians but measured clockwise from
            north.

        Parameters
        ----------
        coord : tuple of float
            Coodinates of point as (x, y).
        get_az: {None, 'angles', 'displacements'}, optional
            Optionally calculate azimuths as either angles or displacements.
            The calculated values will be returned along with the distances
            as the second item of a tuple.
        node_subset : array_like, optional
            Calculate distances on a subset of grid nodes. The default is to
            calculate distances from the provided points to all nodes.
        out_distance : array_like, optional
            If provided, put the calculated distances here. Otherwise,
            create a new array.
        out_azimuth : array_like, optional
            If provided, put the calculated distances here. Otherwise,
            create a new array.

        Returns
        -------
        ndarray or tuple of ndarray
            If *get_az* is ``None`` return the array of distances. Otherwise,
            return a tuple of distances and azimuths.

        Notes
        -----
        Once you start working with node subsets in Landlab, which can change
        size between loops, it's quite possible for Python's internal memory
        management to crap out after large numbers of loops (~>10k). This is
        to do with the way it block allocates memory for arrays of differing
        lengths, then cannot free this memory effectively.
        The solution - as implemented here - is to pre-allocate all arrays as
        nnodes long, then only work with the first [len_subset] entries by
        slicing (in a pseudo-C-style). Care has to be taken not to
        "accidentally" allow Python to allocate a new array you don't have
        control over.
        Then, to maintain efficient memory allocation, we create some "dummy"
        nnode-long arrays to store intermediate parts of the solution in.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))

        Calculate distances from point at (2., 1.) to a subset of nodes on
        the grid.

        >>> grid.calc_distances_of_nodes_to_point((2, 1), node_subset=(2, 6, 7, 8, 12))
        array([1.,  1.,  0.,  1.,  1.])

        Calculate distances from a point to all nodes on the grid.

        >>> dist = grid.calc_distances_of_nodes_to_point((2, 1))
        >>> dist.shape == (grid.number_of_nodes,)
        True
        >>> dist.take((2, 6, 7, 8, 12))
        array([1.,  1.,  0.,  1.,  1.])

        Put the distances into a buffer.

        >>> out = np.empty(grid.number_of_nodes, dtype=float)
        >>> dist = grid.calc_distances_of_nodes_to_point((2, 1), out_distance=out)
        >>> out is dist
        True
        >>> out.take((2, 6, 7, 8, 12))
        array([1.,  1.,  0.,  1.,  1.])

        Calculate azimuths along with distances. The azimuths are calculated
        in radians but measured clockwise from north.

        >>> (_, azim) = grid.calc_distances_of_nodes_to_point((2, 1), get_az="angles")
        >>> azim.take((2, 6, 7, 8, 12)) * 180.0 / np.pi
        array([180.,  270.,    0.,   90.,    0.])
        >>> (_, azim) = grid.calc_distances_of_nodes_to_point(
        ...     (2, 1), get_az="angles", node_subset=(1, 3, 11, 13)
        ... )
        >>> azim * 180.0 / np.pi
        array([225.,  135.,  315.,   45.])

        When calculating displacements, the first row contains displacements
        in x and the second displacements in y.

        >>> (_, azim) = grid.calc_distances_of_nodes_to_point(
        ...     (2, 1), get_az="displacements", node_subset=(2, 6, 7, 8, 12)
        ... )
        >>> azim
        array([[ 0., -1.,  0.,  1.,  0.],
               [-1.,  0.,  0.,  0.,  1.]])

        :meta landlab: info-node, quantity
        """
        if len(coord) != 2:
            raise ValueError("coordinate must iterable of length 2")

        if get_az not in (None, "displacements", "angles"):
            raise ValueError("get_az not understood")

        if node_subset is not None and np.any(np.isnan(node_subset)):
            node_subset = None

        if node_subset is not None:
            if not isinstance(node_subset, np.ndarray):
                node_subset = np.array(node_subset)
            node_subset = node_subset.reshape((-1,))
            len_subset = node_subset.size
        else:
            len_subset = self.number_of_nodes

        if out_distance is None:
            out_distance = np.empty(len_subset, dtype=float)
        if out_distance.size != len_subset:
            raise ValueError("output array size mismatch for distances")

        if get_az is not None:
            if get_az == "displacements":
                az_shape = (2, len_subset)
            else:
                az_shape = (len_subset,)
            if out_azimuth is None:
                out_azimuth = np.empty(az_shape, dtype=float)
            if out_azimuth.shape != az_shape:
                raise ValueError("output array mismatch for azimuths")

        azimuths_as_displacements = np.empty((2, self.number_of_nodes))
        dummy_nodes_1 = np.empty(self.number_of_nodes)
        dummy_nodes_2 = np.empty(self.number_of_nodes)
        dummy_nodes_3 = np.empty(self.number_of_nodes)

        if node_subset is None:
            azimuths_as_displacements[0] = self.node_x - coord[0]
            azimuths_as_displacements[1] = self.node_y - coord[1]
        else:
            azimuths_as_displacements[0, :len_subset] = (
                self.node_x[node_subset] - coord[0]
            )
            azimuths_as_displacements[1, :len_subset] = (
                self.node_y[node_subset] - coord[1]
            )

        np.square(
            azimuths_as_displacements[0, :len_subset], out=dummy_nodes_1[:len_subset]
        )
        np.square(
            azimuths_as_displacements[1, :len_subset], out=dummy_nodes_2[:len_subset]
        )
        np.add(
            dummy_nodes_1[:len_subset],
            dummy_nodes_2[:len_subset],
            out=dummy_nodes_3[:len_subset],
        )
        np.sqrt(dummy_nodes_3[:len_subset], out=out_distance)

        if get_az:
            if get_az == "displacements":
                out_azimuth[:] = azimuths_as_displacements[:, :len_subset]
            elif get_az == "angles":
                np.arctan2(
                    azimuths_as_displacements[0, :len_subset],
                    azimuths_as_displacements[1, :len_subset],
                    out=out_azimuth[:len_subset],
                )

                less_than_zero = np.empty(self.number_of_nodes, dtype=bool)
                np.less(out_azimuth, 0.0, out=less_than_zero[:len_subset])
                out_azimuth[less_than_zero[:len_subset]] += 2.0 * np.pi

            return out_distance, out_azimuth
        else:
            return out_distance

    @property
    def all_node_distances_map(self):
        """Get distances from every node to every other node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> distances = grid.all_node_distances_map

        The shape of the array is ``number_of_nodes`` by ``number_of_nodes``
        and distance from a node to itself is zero.

        >>> distances.shape == (grid.number_of_nodes, grid.number_of_nodes)
        True
        >>> distances.diagonal()
        array([0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])

        The distances from the first node to all nodes in its row and all the
        nodes in its column.

        >>> distances[0, :4]
        array([0.,  1.,  2.,  3.])
        >>> distances[0, ::4]
        array([0.,  1.,  2.])

        :meta landlab: info-node, quantity
        """
        if self._all_node_distances_map is None:
            self._create_all_node_distances_azimuths_maps()
        return self._all_node_distances_map

    @property
    def all_node_azimuths_map(self):
        """Get azimuths from every node to every other node.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> angles = grid.all_node_azimuths_map

        The shape of the array is ``number_of_nodes`` by ``number_of_nodes``
        and azimuth from a node to itself is zero.

        >>> angles.shape == (grid.number_of_nodes, grid.number_of_nodes)
        True
        >>> angles.diagonal()
        array([0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])

        Angles are measured in radians and increase clockwise starting at
        north.

        >>> angles *= 180.0 / np.pi
        >>> angles[0, :4]
        array([ 0.,  90.,  90.,  90.])
        >>> angles[0, ::4]
        array([0.,  0.,  0.])
        >>> angles[0, ::5]
        array([ 0.,  45.,  45.])

        :meta landlab: info-node, quantity
        """
        if self._all_node_azimuths_map is None:
            self._create_all_node_distances_azimuths_maps()
        return self._all_node_azimuths_map

    def _create_all_node_distances_azimuths_maps(self):
        """Build distance-azimuth maps.

        This function creates and stores in the grid field two ``nnodes`` by
        ``nnodes`` arrays that map the distances and azimuths of all nodes
        in the grid to all nodes in the grid.

        This is useful if your module needs to make repeated lookups of
        distances between the same nodes, but does potentially use up a lot
        of memory so should be used with caution.

        The map is symmetrical, so it does not matter whether rows are
        "from" or "to".

        The arrays are called:
        - ``self.all_node_distances_map``
        - ``self.all_node_azimuths_map``

        Returns
        -------
        tuple of ndarrays
            Tuple of (distances, azimuths)
        """
        self._all_node_distances_map = np.empty(
            (self.number_of_nodes, self.number_of_nodes)
        )
        self._all_node_azimuths_map = np.empty(
            (self.number_of_nodes, self.number_of_nodes)
        )

        node_coords = np.empty((self.number_of_nodes, 2))
        node_coords[:, 0] = self.node_x
        node_coords[:, 1] = self.node_y

        for i in range(self.number_of_nodes):
            (
                self._all_node_distances_map[i, :],
                self._all_node_azimuths_map[i, :],
            ) = self.calc_distances_of_nodes_to_point(
                (node_coords[i, 0], node_coords[i, 1]), get_az="angles"
            )

        assert np.all(self._all_node_distances_map >= 0.0)

        return self._all_node_distances_map, self._all_node_azimuths_map

    # def node_has_boundary_neighbor(self, ids):
    def node_has_boundary_neighbor(self):
        """Check if ModelGrid nodes have neighbors that are boundary nodes.

        Checks to see if one of the eight neighbor nodes of node(s) with
        *id* has a boundary node.  Returns True if a node has a boundary node,
        False if all neighbors are interior.

        Parameters
        ----------
        ids : int, or iterable of int
            ID of node to test.

        Returns
        -------
        boolean
            ``True`` if node has a neighbor with a boundary ID,
            ``False`` otherwise.

        Examples
        --------

        ::

                0,  1,  2,  3,
              4,  5,  6,  7,  8,
            9, 10,  11, 12, 13, 14,
              15, 16, 17, 18, 19,
                20, 21, 22, 23

        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((5, 4))
        >>> grid.node_has_boundary_neighbor()
        array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
                True,  True, False, False,  True,  True,  True,  True,  True,
                True,  True,  True,  True,  True,  True])

        >>> grid.node_has_boundary_neighbor()[6]
        True
        >>> grid.node_has_boundary_neighbor()[12]
        False
        >>> grid.node_has_boundary_neighbor()[((12, 0),)]
        array([False,  True])

        :meta landlab: info-node, connectivity, boundary-condition
        """
        status_of_neighbor = self._node_status[self.adjacent_nodes_at_node]
        neighbor_not_core = status_of_neighbor != NodeStatus.CORE
        bad_neighbor = self.adjacent_nodes_at_node == self.BAD_INDEX
        neighbor_not_core[bad_neighbor] = False
        return np.any(neighbor_not_core, axis=1)

        # node_has_boundary_neighbor = np.any(neighbor_not_core, axis=1)
        # return node_has_boundary_neighbor[ids]


add_module_functions_to_class(ModelGrid, "mappers.py", pattern="map_*")
# add_module_functions_to_class(ModelGrid, 'gradients.py',
#                               pattern='calculate_*')
add_module_functions_to_class(ModelGrid, "gradients.py", pattern="calc_*")
add_module_functions_to_class(ModelGrid, "divergence.py", pattern="calc_*")



================================================
File: src/landlab/grid/create.py
================================================
#! /usr/bin/env python
"""Create landlab model grids."""

from ..core import load_params
from ..io import read_esri_ascii
from ..io.netcdf import read_netcdf
from ..values import constant
from ..values import plane
from ..values import random
from ..values import sine
from ..values import units
from .hex import HexModelGrid
from .network import NetworkModelGrid
from .radial import RadialModelGrid
from .raster import RasterModelGrid
from .voronoi import VoronoiDelaunayGrid

_MODEL_GRIDS = {
    "RasterModelGrid": RasterModelGrid,
    "HexModelGrid": HexModelGrid,
    "VoronoiDelaunayGrid": VoronoiDelaunayGrid,
    "NetworkModelGrid": NetworkModelGrid,
    "RadialModelGrid": RadialModelGrid,
}

_SYNTHETIC_FIELD_CONSTRUCTORS = {
    "plane": plane,
    "random": random,
    "sine": sine,
    "constant": constant,
    "units": units,
}


class Error(Exception):
    """Base class for exceptions from this module."""

    pass


class BadGridTypeError(Error):
    """Raise this error for a bad grid type."""

    def __init__(self, grid_type):
        self._type = str(grid_type)  # TODO: not tested.

    def __str__(self):
        return self._type  # TODO: not tested.


def grid_from_dict(grid_type, params):
    """Create a grid from a dictionary of parameters."""
    try:
        cls = _MODEL_GRIDS[grid_type]
    except KeyError as exc:
        raise ValueError(f"unknown grid type ({grid_type})") from exc
    args, kwargs = _parse_args_kwargs(params)
    return cls(*args, **kwargs)


def grids_from_file(file_like, section=None):
    """Create grids from a file."""
    params = load_params(file_like)

    if section:
        try:
            grids = params[section]
        except KeyError as exc:  # TODO: not tested.
            raise ValueError(
                f"missing required section ({section})"
            ) from exc  # TODO: not tested.
    else:  # TODO: not tested.
        grids = params  # TODO: not tested.

    new_grids = []
    for grid_type, grid_desc in as_list_of_tuples(grids):
        new_grids.append(grid_from_dict(grid_type, grid_desc))

    return new_grids


def add_fields_from_dict(grid, fields):
    """Add fields to a grid from a dictionary."""
    fields = dict(fields)

    unknown_locations = set(fields) - set(grid.VALID_LOCATIONS)
    if unknown_locations:
        raise ValueError(
            "unknown field locations ({})".format(", ".join(unknown_locations))
        )

    for location, fields_at_location in fields.items():
        for name, function in fields_at_location.items():
            add_field_from_function(grid, name, function, at=location)

    return grid


def add_field_from_function(grid, name, functions, at="node"):
    """Add a field to a grid as functions.

    Parameters
    ----------
    grid : ModelGrid
        A landlab grid to add fields to.
    name : str
        Name of the new field.
    functions : *(func_name, func_args)* or iterable of *(func_name, func_args)*
        The functions to apply to the field. Functions are applied in the order
        the appear in the list.
    at : str
        The grid element to which the field will be added.

    Returns
    -------
    ModelGrid
        The grid with the new field.
    """
    valid_functions = set(_SYNTHETIC_FIELD_CONSTRUCTORS) | {
        "read_esri_ascii",
        "read_netcdf",
    }

    for func_name, func_args in as_list_of_tuples(functions):
        if func_name not in valid_functions:
            raise ValueError(f"function not understood ({func_name})")

        args, kwargs = _parse_args_kwargs(func_args)

        if func_name in _SYNTHETIC_FIELD_CONSTRUCTORS:
            # if any args, raise an error, there shouldn't be any.
            synth_function = _SYNTHETIC_FIELD_CONSTRUCTORS[func_name]
            synth_function(grid, name, at=at, **kwargs)
        elif func_name == "read_esri_ascii":
            read_esri_ascii(*args, grid=grid, name=name, **kwargs)
        elif func_name == "read_netcdf":
            read_netcdf(*args, grid=grid, name=name, **kwargs)

    return grid


def add_boundary_conditions(grid, boundary_conditions=()):
    for bc_name, bc_args in as_list_of_tuples(boundary_conditions):
        args, kwargs = _parse_args_kwargs(bc_args)
        try:
            func = getattr(grid, bc_name)
        except AttributeError as exc:
            raise ValueError(
                f"create_grid: No function {bc_name} exists for grid types "
                f"{grid.__class__.__name__}. If you think this type of grid "
                "should have such a function. Please create a GitHub Issue to "
                "discuss contributing it to the Landlab codebase."
            ) from exc
        else:
            func(*args, **kwargs)


def as_list_of_tuples(items):
    """Convert a collection of key/values to a list of tuples.

    Examples
    --------
    >>> from collections import OrderedDict
    >>> from landlab.grid.create import as_list_of_tuples
    >>> as_list_of_tuples({"eric": "idle"})
    [('eric', 'idle')]
    >>> as_list_of_tuples([("john", "cleese"), {"eric": "idle"}])
    [('john', 'cleese'), ('eric', 'idle')]
    >>> as_list_of_tuples(
    ...     [("john", "cleese"), OrderedDict([("eric", "idle"), ("terry", "gilliam")])]
    ... )
    [('john', 'cleese'), ('eric', 'idle'), ('terry', 'gilliam')]
    """
    try:
        items = list(items.items())
    except AttributeError:
        items = list(items)

    if len(items) == 2 and isinstance(items[0], str):
        items = [items]

    tuples = []
    for item in items:
        try:
            tuples.extend(list(item.items()))
        except AttributeError:
            tuples.append(tuple(item))

    return tuples


def create_grid(file_like, section=None):
    """Create grid, initialize fields, and set boundary conditions.

    :func:`~.create_grid` expects a dictionary with three keys: "grid", "fields", and
    "boundary_conditions".

    **Dictionary Section "grid"**

    The value associated with the "grid" key should itself be a dictionary
    containing the name of a Landlab model grid type as its only key. The
    following grid types are valid:

    *  :class:`~.RasterModelGrid`
    *  :class:`~.VoronoiDelaunayGrid`
    *  :class:`~.HexModelGrid`
    *  :class:`~.RadialModelGrid`
    *  :class:`~.NetworkModelGrid`

    The value associated with the grid name key is a list containing the
    arguments. If any keyword arguments are passed, they should be passed as
    the last element of the list. For example the following code block is a
    yaml file indicating a RasterModelGrid with shape (4, 5) and xy-spacing of
    (3, 4).

    .. code-block:: yaml

        grid:
          RasterModelGrid:
            - [4, 5]
            - xy_spacing: [3, 4]

    These arguments and keyword arguments will be passed to the ``__init__``
    constructor of the specified model grid. Refer to the documentation for
    each grid to determine its requirements.

    **Dictionary Section "fields"**

    Fields can be created by reading from files or by creating synthetic
    values.

    The value associated with the "fields" key is a nested set of dictionaries
    indicating where the fields are created, what the field names are, and how
    to create the fields. As part of a grid's description, the value
    associated with the "fields" key must be a dictionary with keys indicating
    at which grid elements fields should be created (e.g. to create fields at
    node, use "node").

    The value associated with each "xxx" (i.e. "node", "link", "patch", etc.)
    value is itself a dictionary
    indicating the name of the field and how it should be created. A field can
    either be created by reading from a file or creating synthetic values. The
    :func:`~.netcdf.read.read_netcdf` and :func:`~.esri_ascii.load` functions,
    and the :mod:`synthetic fields <landlab.values.synthetic>`
    package are currently supported methods to create fields. These may be
    chained together (as is shown in the Example section below). If these
    functions do not meet your needs, we welcome contributions that extend the
    capabilities of this function.

    An additional supported method, which can be chained together with
    either synthetic fields or fields read from a file, is *units*. The
    *units* function will set the units attribute of its corresponding field.
    If this optional function is not used, the resulting field will not be
    given any units.

    The following example would use the
    :func:`~.synthetic.plane` function from the synthetic
    values package to create a *node* value for the field
    *topographic__elevation*. The plane function adds values to a Landlab model
    grid field that lie on a plane specified by a point and a normal vector. In
    the below example the plane goes through the point (1.0, 1.0, 1.0) and has
    a normal of (-2.0, -1.0, 1.0). The *units* function sets the units of
    elevation to *meters*.

    .. code-block:: yaml

        grid:
          RasterModelGrid:
            - [4, 5]
            - xy_spacing: [3, 4]
            - fields:
                node:
                  topographic__elevation:
                    plane:
                      - point: [1, 1, 1]
                        normal: [-2, -1, 1]
                    units:
                        - units: "meters"

    **Dictionary Section "boundary_conditions"**

    The final portion of the input dictionary calls bound functions of the
    model grid to set boundary conditions. Any valid bound function can be
    called. The specified functions are provided in a list, and called in
    order. If required, multiple functions may be called.

    Each entry to the list is a dictionary with a single key, the name of the
    bound function. The value associated with that key is a list of arguments
    and keyword arguments, similar in structure to those described above.
    As with the "fields" section, the "boundary_conditions" section must be
    described under its associated grid description.

    For example, the following sets closed boundaries at all sides of the grid.

    .. code-block:: yaml

        grid:
          RasterModelGrid:
            - [4, 5]
            - xy_spacing: [3, 4]
            - boundary_conditions:
              - set_closed_boundaries_at_grid_edges:
                - True
                - True
                - True
                - True

    Parameters
    ----------
    file_like or str
        Dictionary, contents of a dictionary as a string, a file-like object,
        or the path to a file containing a YAML dictionary.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import create_grid
    >>> np.random.seed(42)
    >>> p = {
    ...     "grid": {
    ...         "RasterModelGrid": [
    ...             (4, 5),
    ...             {"xy_spacing": (3, 4)},
    ...             {
    ...                 "fields": {
    ...                     "node": {
    ...                         "spam": {
    ...                             "plane": [
    ...                                 {"point": (1, 1, 1), "normal": (-2, -1, 1)}
    ...                             ],
    ...                             "random": [
    ...                                 {"distribution": "uniform", "low": 1, "high": 4}
    ...                             ],
    ...                         }
    ...                     },
    ...                     "link": {
    ...                         "eggs": {
    ...                             "constant": [{"where": "ACTIVE_LINK", "value": 12}]
    ...                         }
    ...                     },
    ...                 }
    ...             },
    ...             {
    ...                 "boundary_conditions": [
    ...                     {
    ...                         "set_closed_boundaries_at_grid_edges": [
    ...                             True,
    ...                             True,
    ...                             True,
    ...                             True,
    ...                         ]
    ...                     }
    ...                 ]
    ...             },
    ...         ]
    ...     }
    ... }
    >>> mg = create_grid(p, section="grid")
    >>> mg.number_of_nodes
    20
    >>> "spam" in mg.at_node
    True
    >>> "eggs" in mg.at_link
    True
    >>> mg.x_of_node
    array([  0.,   3.,   6.,   9.,  12.,
             0.,   3.,   6.,   9.,  12.,
             0.,   3.,   6.,   9.,  12.,
             0.,   3.,   6.,   9.,  12.])
    >>> mg.status_at_node
    array([4, 4, 4, 4, 4,
           4, 0, 0, 0, 4,
           4, 0, 0, 0, 4,
           4, 4, 4, 4, 4], dtype=uint8)
    >>> np.round(mg.at_node["spam"].reshape(mg.shape), decimals=2)
    array([[ 0.12,   7.85,  13.2 ,  18.8 ,  23.47],
           [ 3.47,   9.17,  17.6 ,  22.8 ,  29.12],
           [ 7.06,  15.91,  21.5 ,  25.64,  31.55],
           [11.55,  17.91,  24.57,  30.3 ,  35.87]])
    """
    if isinstance(file_like, dict):
        params = file_like
    else:
        params = load_params(file_like)

    if section:
        grids = params[section]
    else:
        grids = params

    new_grids = []
    for grid_type, grid_desc in as_list_of_tuples(grids):
        grid_desc = norm_grid_description(grid_desc)

        fields = grid_desc.pop("fields", {})
        boundary_conditions = grid_desc.pop("boundary_conditions", {})

        grid = grid_from_dict(grid_type, grid_desc)
        add_fields_from_dict(grid, fields)
        add_boundary_conditions(grid, boundary_conditions)

        new_grids.append(grid)

    if len(new_grids) == 1:
        return new_grids[0]
    else:
        return new_grids


def norm_grid_description(grid_desc):
    """Normalize a grid description into a canonical form.

    Examples
    --------
    >>> from landlab.grid.create import norm_grid_description

    >>> grid_desc = [(3, 4), {"xy_spacing": 4.0, "xy_of_lower_left": (1.0, 2.0)}]
    >>> normed_items = list(norm_grid_description(grid_desc).items())
    >>> normed_items.sort()
    >>> normed_items
    [('args', [(3, 4)]), ('xy_of_lower_left', (1.0, 2.0)), ('xy_spacing', 4.0)]
    """
    if not isinstance(grid_desc, dict):
        args, kwds = [], {}
        for arg in grid_desc:
            if isinstance(arg, dict) and {"fields", "boundary_conditions"} & set(
                arg.keys()
            ):
                kwds.update(arg)
            else:
                args.append(arg)
        if isinstance(args[-1], dict):
            kwds.update(args.pop())
        kwds.update({"args": args})
        return kwds
    return grid_desc


def _parse_args_kwargs(list_of_args_kwargs):
    if isinstance(list_of_args_kwargs, dict):
        args, kwargs = list_of_args_kwargs.pop("args", ()), list_of_args_kwargs
        if not isinstance(args, (tuple, list)):
            args = (args,)
    else:
        args, kwargs = [], {}
        for arg in list(list_of_args_kwargs):
            if isinstance(arg, dict) and {"fields", "boundary_conditions"} & set(
                arg.keys()
            ):
                kwargs.update(arg)  # TODO: not tested.
            else:
                args.append(arg)
        if isinstance(args[-1], dict):
            kwargs.update(args.pop())

    return tuple(args), kwargs



================================================
File: src/landlab/grid/create_network.py
================================================
"""
Created on Tue Feb  2 17:50:09 2021

@author: sahrendt
"""

from dataclasses import dataclass
from itertools import tee

import numpy as np
import numpy.typing as npt

from ..components import ChannelProfiler
from ..components import FlowAccumulator
from .network import NetworkModelGrid

try:
    from itertools import pairwise
except ImportError:
    # Not available before Python 3.10
    def pairwise(iterable):
        # pairwise('ABCDEFG') --> AB BC CD DE EF FG
        a, b = tee(iterable)
        next(b, None)
        return zip(a, b)


def network_grid_from_raster(
    grid, reducer=None, include="*", exclude=None, minimum_channel_threshold=0.0
):
    """Create a NetworkModelGrid from a RasterModelGrid.

    The optional *reducer* keyword is use to pass a function that reduces the number
    of nodes in each channel segment. The default is to keep all segment nodes.

    Parameters
    ----------
    grid : RasterModelGrid object
        A raster grid used to create a network grid
    reducer : func, optional
        A function used to reduce the number of nodes in each segment. The
        default is to include all segment nodes in the created NetworkModelGrid.
    include : str, or iterable of str, optional
        Glob-style pattern for field names to include.
    exclude : str, or iterable of str, optional
        Glob-style pattern for field names to exclude.
    minimum_channel_threshold : float, optional
        Value to use for the minimum drainage area associated with a
        plotted channel segment from the ChannelProfiler. Default values 10000.

    Returns
    -------
    network : NetworkModelGrid
        NetworkModelGrid object with .at_node['rmg_node_value'] attribute
        listing the RasterModelGrid node ids at each NetworkModelGrid node.
    """

    if "drainage_area" not in grid.at_node:
        FlowAccumulator(
            grid,
            "topographic__elevation",
            flow_director="D8",
            depression_finder="DepressionFinderAndRouter",
        ).run_one_step()

    if "drainage_area" not in grid.at_node:
        raise ValueError("'drainage_area' field is missing from the grid")

    channel_segments = get_channel_segments(
        grid, minimum_channel_threshold=minimum_channel_threshold
    )

    if reducer is not None:
        channel_segments = [reducer(segment) for segment in channel_segments]

    network_grid = network_grid_from_segments(
        grid, channel_segments, include=include, exclude=exclude
    )

    return network_grid


def get_channel_segments(grid, divergent_okay=False, minimum_channel_threshold=0.0):
    """Extract channel segments from a grid.

    Each segment includes nodes within the segment, upstream segments, and
    downstream segments.

    Parameters
    ----------
    grid : RasterModelGrid
        Grid from which to extract channel segments.
    divergent_okay : bool, optional
        If ``False``, raise an error if the network is divergent (i.e. a channel
        segment has more than one downstream segments).

    Returns
    -------
    segments : list
        Channel segments as lists of grid nodes. Nodes are ordered from downstream
        to upstream.
    """
    # delineate channel
    profiler = ChannelProfiler(
        grid,
        number_of_watersheds=1,
        minimum_channel_threshold=minimum_channel_threshold,
        # outlet_nodes=outlet_nodes,
        main_channel_only=False,
    )
    profiler.run_one_step()

    if len(profiler.data_structure) > 1:
        raise RuntimeError(
            "number of watersheds is greater than the requested number "
            f"({len(profiler.data_structure)} > 1)"
        )

    # obtain watershed key (should only be one)
    watershed = list(profiler.data_structure.keys())[0]

    segments = [
        segment["ids"] for segment in profiler.data_structure[watershed].values()
    ]

    return segments


def network_grid_from_segments(grid, nodes_at_segment, include="*", exclude=None):
    """Create a NetworkModelGrid from channel segments."""
    channel_network = ChannelSegmentConnector(*nodes_at_segment)

    for segment in channel_network.root:
        if len(segment.upstream) == 1 and len(segment.upstream[0]) > 0:
            print("segments can be joined")

    xy_of_node = create_xy_of_node(channel_network.root, grid)
    at_node = get_node_fields(
        channel_network.root, grid, include=include, exclude=exclude
    )

    reindex_network_nodes(channel_network.root)
    nodes_at_link = create_network_links(channel_network.root)

    grid = NetworkModelGrid((xy_of_node[:, 1], xy_of_node[:, 0]), links=nodes_at_link)

    for name, values in at_node.items():
        grid.at_node[name] = values[grid._sorted_nodes]

    return grid


class SegmentReducer:
    """Base class for reducing the nodes in a segment."""

    def reduce(self, segment):
        """Reduce the number of nodes in a channel segment."""
        raise NotImplementedError("reduce")

    def __call__(self, segment):
        return self.reduce(segment)


@dataclass
class SpacingAtLeast(SegmentReducer):
    """Remove segment nodes to ensure a minimum along-channel spacing."""

    xy_of_node: npt.ArrayLike
    spacing: npt.ArrayLike = 1.0

    def __post_init__(self):
        self.xy_of_node = np.asarray(self.xy_of_node)
        self.spacing = np.broadcast_to(self.spacing, len(self.xy_of_node))

    def calc_distance_along_segment(self, segment):
        """Calculate the along-channel distance of a segment.

        Parameters
        ----------
        segment : iterable of int
            Indices of nodes along a channel.

        Returns
        -------
        ndarray of int
            Distances to each node along the channel.
        """
        return np.sqrt(
            np.sum(
                np.diff(
                    self.xy_of_node[segment,],
                    axis=0,
                    prepend=self.xy_of_node[None, segment[0], :],
                )
                ** 2,
                axis=1,
            )
        ).cumsum()

    def reduce(self, segment):
        nodes = _reduce_to_fewest_nodes(
            self.xy_of_node[segment], spacing=self.spacing[segment]
        )
        return np.take(segment, nodes)


@dataclass
class AlongChannelSpacingAtLeast(SpacingAtLeast):
    """Remove segment nodes to ensure a minimum per-node along-channel spacing."""

    def reduce(self, segment):
        nodes = _reduce_nodes(
            self.calc_distance_along_segment(segment),
            spacing=self.spacing[segment,],
        )
        return np.take(segment, nodes)


class JustEndNodes(SegmentReducer):
    """Reduce a segment to just its end nodes."""

    def reduce(self, segment):
        return np.asarray([segment[0], segment[-1]])


@dataclass
class AtMostNodes(SegmentReducer):
    """Reduce a segment to a maximum number of nodes."""

    count: int = 3

    def __post_init__(self):
        if self.count < 2:
            raise ValueError(
                f"unable to reduce a segment to less than two nodes ({self.count})"
            )

    def reduce(self, segment: npt.ArrayLike) -> npt.ArrayLike:
        if self.count < len(segment):
            step = len(segment) // (self.count - 2 + 1)
            reduced_segment = np.append(
                segment[: -step + 1 : step][: self.count - 1], segment[-1]
            )
        else:
            reduced_segment = np.asarray(segment)
        return reduced_segment


def spacing_from_drainage_area(
    drainage_area,
    a=9.68,
    b=0.32,
    n_widths=20.0,
):
    """Calculate channel spacing based on upstream drainage area of each node.

    Parameters
    ----------
    drainage_area : number or ndarray
        Upstream drainage area in km ** 2.

    Returns
    -------
    ndarray
        Node spacing in meters.
    """
    return n_widths * (a * drainage_area / (1000**2)) ** b


def _reduce_nodes(distance_along_segment, spacing=1.0):
    """Reduce the number of nodes in a segment based on a minimum spacing.

    Parameters
    ----------
    distance_along_segment : array of float
        Distance along a segment to each of the segment's nodes.
    spacing : float or array of float, optional
        Minimum spacing for each node along a segment. If a scalar,
        a constant spacing is used along the segment.

    Returns
    -------
    list : nodes
        Indices of nodes to retain after the reduction.

    Examples
    --------
    >>> from landlab.grid.create_network import _reduce_nodes

    Maintain a spacing of at least 1.75.

    >>> distance = [0.0, 1.0, 2.0, 3.0, 4.0]
    >>> _reduce_nodes(distance, spacing=1.75)
    [0, 2, 4]

    If the requested minimum spacing is already smaller than the
    initial spacing, keep all the nodes.

    >>> distance = [0.0, 1.0, 2.0, 3.0, 4.0]
    >>> _reduce_nodes(distance, spacing=0.5)
    [0, 1, 2, 3, 4]

    The spacing can be variable from node to node.

    >>> distance = [0.0, 1.0, 2.0, 3.0, 4.0]
    >>> _reduce_nodes(distance, spacing=[0.5, 1.0, 2.0, 1.0, 0.5])
    [0, 1, 2, 4]

    The end nodes are always retained.

    >>> distance = [0.0, 1.0, 2.0, 3.0, 4.0]
    >>> _reduce_nodes(distance, spacing=100.0)
    [0, 4]

    """
    from bisect import bisect_left

    distance_along_segment = np.asarray(distance_along_segment)
    n_nodes = len(distance_along_segment)
    spacing = np.broadcast_to(spacing, n_nodes)

    nodes = []
    head_node = 0
    while head_node < n_nodes - 1:
        nodes.append(head_node)
        distance_to_tail_node = distance_along_segment[head_node] + spacing[head_node]

        tail_node = bisect_left(
            distance_along_segment, distance_to_tail_node, lo=head_node + 1
        )
        head_node = tail_node

    if nodes[-1] < n_nodes - 1:
        nodes.append(n_nodes - 1)

    return nodes


def calc_distance_to_point(point, points):
    """Find the euclidian distance between one point and a set of points."""
    return np.sqrt(np.sum((point - points) ** 2, axis=1))


def _reduce_to_fewest_nodes(xy_of_node, spacing=1.0):
    """Reduce to the fewest number of nodes while maintaining a minimum spacing.

    Parameters
    ----------
    xy_of_node : array of float shape (n_nodes, 2)
        x and y coordinates of each node along a segment.
    spacing : float or array of float, optional
        Minimum spacing for each node along a segment. If a scalar,
        a constant spacing is used along the segment.

    Returns
    -------
    list : nodes
        Indices of nodes to retain after the reduction.

    >>> from landlab.grid.create_network import _reduce_to_fewest_nodes

    Maintain a spacing of at least 1.75.

    >>> xy_of_node = [[0.0, 0.0], [1.0, 0.0], [2.0, 0.0], [3.0, 0.0], [4.0, 0.0]]
    >>> _reduce_to_fewest_nodes(xy_of_node, spacing=1.75)
    [0, 2, 4]

    If the requested minimum spacing is already smaller than the
    initial spacing, keep all the nodes.

    >>> xy_of_node = [[0.0, 0.0], [1.0, 0.0], [2.0, 0.0], [3.0, 0.0], [4.0, 0.0]]
    >>> _reduce_to_fewest_nodes(xy_of_node, spacing=0.5)
    [0, 1, 2, 3, 4]

    The spacing can be variable from node to node.

    >>> xy_of_node = [[0.0, 0.0], [1.0, 0.0], [2.0, 0.0], [3.0, 0.0], [4.0, 0.0]]
    >>> _reduce_to_fewest_nodes(xy_of_node, spacing=[0.5, 1.0, 2.0, 1.0, 0.5])
    [0, 1, 2, 4]

    The end nodes are always retained.

    >>> xy_of_node = [[0.0, 0.0], [1.0, 0.0], [2.0, 0.0], [3.0, 0.0], [4.0, 0.0]]
    >>> _reduce_to_fewest_nodes(xy_of_node, spacing=100.0)
    [0, 4]
    """
    xy_of_node = np.asarray(xy_of_node)
    n_nodes = len(xy_of_node)
    spacing = np.broadcast_to(spacing, n_nodes)

    nodes = []
    head_node = 0
    while head_node < n_nodes - 1:
        nodes.append(head_node)
        distance_from_head = calc_distance_to_point(
            xy_of_node[head_node], xy_of_node[head_node + 1 :, :]
        )

        try:
            tail_node = (
                np.where(distance_from_head < spacing[head_node])[0][-1] + head_node + 2
            )
        except IndexError:
            tail_node = head_node + 1
        head_node = tail_node

    if nodes[-1] != n_nodes - 1:
        nodes.append(n_nodes - 1)

    return nodes


class SegmentLinkCollector:
    """Collect links between nodes of segments."""

    def __init__(self, links=None):
        if links is None:
            self._links = []
        else:
            self._links = list(links)

    def __call__(self, segment):
        """Add links between segment nodes to those previously collected."""
        try:
            nodes = [segment.downstream._nodes[-1]]
        except AttributeError:
            nodes = [segment._nodes[0]]
        nodes.extend(segment._nodes[1:])
        for head, tail in pairwise(nodes):
            self._links.append((head, tail))

    @property
    def links(self):
        """Head and tail nodes of all collected links."""
        return self._links


class ChannelSegment:
    """A channel segment.

    Parameters
    ----------
    nodes : iterable of int
        The nodes of the channel, listed from downstream to upstream.
    """

    def __init__(self, nodes):
        self._nodes = None
        self._upstream = []
        self._downstream = None
        self.nodes = nodes

    def __iter__(self):
        yield self
        for upstream in self._upstream:
            yield from upstream

    def __len__(self):
        return len(self._nodes)

    def __repr__(self):
        return f"ChannelSegment({self._nodes})"

    def for_each(self, func):
        for segment in self:
            func(segment)

    def iter_downstream(self):
        yield self
        try:
            iter_downstream = self.downstream.iter_downstream
        except AttributeError:
            pass
        else:
            yield from iter_downstream()

    def count_segments(self, direction="upstream"):
        # count = 0
        if direction == "upstream":
            iter = self.__iter__
        elif direction == "downstream":
            iter = self.iter_downstream
        else:
            raise ValueError(f"direction not understood ({direction})")
        # for _ in iter():
        #     count += 1
        # return count - 1
        return sum(1 for _ in iter()) - 1

    @property
    def downstream(self):
        """The downstream segment."""
        return self._downstream

    @downstream.setter
    def downstream(self, segment):
        self._downstream = segment
        segment.add_upstream(self)

    @property
    def upstream(self):
        """The upstream segments."""
        return tuple(self._upstream)

    def add_upstream(self, segment):
        """Add an upstream segment."""
        self._upstream.append(segment)
        segment._downstream = self

    @property
    def downstream_node(self):
        """The most downstream node of the channel segment."""
        return self._nodes[0]

    @property
    def upstream_node(self):
        """The most upstream node of the channel segment."""
        return self._nodes[-1]

    @property
    def nodes(self):
        """The nodes of the segment, from downstream to upstream."""
        return self._nodes

    @nodes.setter
    def nodes(self, nodes):
        self._nodes = np.array(nodes, copy=True)


class DisconnectedSegmentError(Exception):
    """Raise this exception if a channel segment cannot be connected to a network."""

    pass


class ChannelSegmentConnector:
    """Connect channel segments to form a network."""

    def __init__(self, *args):
        """ChannelSegmentConnector(channel1, channel2, ...)"""
        self._root = None
        self._orphans = []
        for segment in args:
            self.add(segment)

    @property
    def root(self):
        """The root (most downstream) channel of the network."""
        return self._root

    @property
    def orphans(self):
        """Channel segments that are not connected to the main network."""
        return tuple(self._orphans)

    def set_root(self, new_root):
        if self._root is None:
            pass
        elif self._root.downstream_node == new_root.upstream_node:
            new_root.add_upstream(self._root)
        else:
            self._orphans.append(self._root)
        self._root = new_root
        return self._root

    def _add_or_raise(self, new_segment):
        """Try to add a segment to the network, raise an error if disconnected."""
        is_orphan = True
        if (
            self._root is None
            or self._root.downstream_node == new_segment.upstream_node
        ):
            self._root = self.set_root(new_segment)
            is_orphan = False
        else:
            for segment in self._root:
                if new_segment.downstream_node == segment.upstream_node:
                    segment.add_upstream(new_segment)
                    is_orphan = False
                    break

        if is_orphan:
            raise DisconnectedSegmentError()
        return self._root

    def _add_orphans(self):
        """Add orphans to the root."""
        orphans = []
        for orphan in self._orphans:
            try:
                self._root = self._add_or_raise(orphan)
            except DisconnectedSegmentError:
                orphans.append(orphan)
        return orphans

    def add(self, new_segment):
        """Add a new segment to the network."""
        if not isinstance(new_segment, ChannelSegment):
            new_segment = ChannelSegment(new_segment)
        try:
            self._root = self._add_or_raise(new_segment)
        except DisconnectedSegmentError:
            is_orphan = True
        else:
            is_orphan = False

        if not is_orphan:
            self._orphans = self._add_orphans()
        else:
            self._orphans.append(new_segment)

    def __repr__(self):
        return f"ChannelConnector({self._root})"


def create_xy_of_node(network, grid):
    """Create an array of coordinates for each node of a channel network."""
    xy_of_node_collector = SegmentNodeCoordinateCollector(grid)
    network.for_each(xy_of_node_collector)
    return np.asarray(xy_of_node_collector.xy_of_node)


class SegmentNodeCoordinateCollector:
    """Collect xy coordinates for each node along segments."""

    def __init__(self, grid):
        self._grid = grid
        self._xy_of_node = []

    def __call__(self, segment):
        """Add coordinates of the nodes of a segment to previously collected coordinates."""
        if segment.downstream is None:
            nodes = segment._nodes
        else:
            nodes = segment._nodes[1:]
        self._xy_of_node.extend(
            zip(self._grid.x_of_node[nodes], self._grid.y_of_node[nodes])
        )

    @property
    def xy_of_node(self):
        """Coordinates of all collected nodes."""
        return self._xy_of_node


def get_node_fields(network, grid, include="*", exclude=None):
    """Get field values for each node of a channel network.

    Parameters
    ----------
    network : ChannelSegment
        A channel network to extract fields for.
    grid : ModelGrid
        Grid from which to extract fields from.
    include : str or list of str, optional
        Patterns to use for including fields.
    exclude : str or list of str, optional
        Patterns to use for excluding fields.

    Returns
    -------
    at_node : dict
        Dictionary of node fields for each node of a channel network.
    """
    if isinstance(include, str):
        include = [include]

    include = [
        pattern if pattern.startswith("at_") else f"at_node:{pattern}"
        for pattern in include
    ]

    node_fields = set()
    for canonical_name in grid.fields(include=include, exclude=exclude):
        dim, name = canonical_name[len("at_") :].split(":")
        dim == "node" and node_fields.add(name)

    at_node = {}
    for name in node_fields:
        field_value_collector = SegmentFieldCollector(grid.at_node[name])
        network.for_each(field_value_collector)
        at_node[name] = np.asarray(field_value_collector.values)

    return at_node


class SegmentFieldCollector:
    """Collect field values for each node along segments."""

    def __init__(self, field):
        self._field = field
        self._values = []

    def __call__(self, segment):
        """Add field values for nodes along a segment to previously collected values."""
        if segment.downstream is None:
            nodes = segment._nodes
        else:
            nodes = segment._nodes[1:]

        self._values.extend(self._field[nodes])

    @property
    def values(self):
        """Field values of all collected nodes."""
        return self._values


def reindex_network_nodes(network):
    """Reindex the nodes of a channel network."""
    node_reindexer = SegmentNodeReindexer()
    network.for_each(node_reindexer)

    return network


class SegmentNodeReindexer:
    """Reindex nodes along segments."""

    def __init__(self, nodes=None):
        if nodes is None:
            self._nodes = []
        else:
            self._nodes = list(nodes)

    def __call__(self, segment):
        """Reindex nodes of a segment based on previously collected nodes."""
        try:
            start = self._nodes[-1] + 1
        except IndexError:
            start = 0

        try:
            downstream_node = segment.downstream._nodes[-1]
        except AttributeError:
            segment._nodes = list(range(start, start + len(segment)))
        else:
            segment._nodes = [downstream_node] + list(
                range(start, start + len(segment) - 1)
            )

        self._nodes.extend(segment._nodes)

    @property
    def nodes(self):
        """Reindexed nodes of all collected nodes."""
        return self._nodes


def create_network_links(network):
    """Create links between nodes of the channels of a network.

    Parameters
    ----------
    network : ChannelSegment
        Channel network to create links for.

    Returns
    -------
    links : list of tuple
        Links for network as *(head_node, tail_node)*."""
    collect_segment_links = SegmentLinkCollector()
    network.for_each(collect_segment_links)

    return collect_segment_links.links



================================================
File: src/landlab/grid/decorators.py
================================================
"""This module defines decorators used with ModelGrid objects.

Grid decorators
+++++++++++++++

.. autosummary::

    ~override_array_setitem_and_reset
    ~return_id_array
    ~return_readonly_id_array
"""

from functools import wraps

import numpy as np

from ..core.utils import as_id_array


class override_array_setitem_and_reset:
    """Decorator that calls a grid method after setting array values.

    This decorator wraps `ModelGrid` methods that return a numpy array
    so that it returns a wrapped array that overrides the numpy array
    `__setitem__`, `__setslice__`, and `itemset` methods. The wrapped methods
    set values in the array but then also call a grid method that resets some
    state variables of the grid.

    Parameters
    ----------
    reset : str
        The name of the grid method to call after setting values. The
        corresponding method must take no arguments.
    """

    def __init__(self, reset):
        """Initialize the decorator with an argument.

        Parameters
        ----------
        reset : str
            The name of the grid method to call after setting values. The
            corresponding method must take no arguments.
        """
        self._reset = reset

    def __call__(self, func):
        """Get a wrapped version of the method.

        Parameters
        ----------
        func : function
            The grid method to wrap.

        Returns
        -------
        function
            The wrapped function.
        """
        reset = self._reset

        def _wrapped(grid):
            """Embed a grid into a numpy array and override set methods."""

            class array(np.ndarray):
                """Override numpy setters and reset grid topology."""

                def __new__(cls, arr):
                    """Instantiate the class with a view of the base array."""
                    obj = np.asarray(arr).view(cls)
                    obj.grid = grid
                    return obj

                def __array_finalize__(self, obj):
                    if obj is None:
                        return

                def __setitem__(self, ind, value):
                    """Set value of array, then call reset function."""
                    np.ndarray.__setitem__(self, ind, value)
                    getattr(self.grid, reset)()

                def __setslice__(self, start, stop, value):
                    """Set values of array, then call reset function."""
                    np.ndarray.__setslice__(self, start, stop, value)
                    getattr(self.grid, reset)()

            return array(func(grid))

        _wrapped.__name__ = func.__name__
        _wrapped.__doc__ = func.__doc__

        return _wrapped


def return_id_array(func):
    """Decorate a function to return an array of ids.

    Parameters
    ----------
    func : function
        A function that returns a numpy array.

    Returns
    -------
    func
        A wrapped function that returns an id array.
    """

    @wraps(func)
    def _wrapped(self, *args, **kwds):
        """Create a function that returns an id array."""
        return as_id_array(func(self, *args, **kwds))

    return _wrapped


def return_readonly_id_array(func):
    """Decorate a function to return a read-only array of ids.

    Parameters
    ----------
    func : function
        A function that returns a numpy array.

    Returns
    -------
    func
        A wrapped function that returns an id array.
    """

    @wraps(func)
    def _wrapped(self, *args, **kwds):
        """Create a function that returns an id array."""
        id_array = as_id_array(func(self, *args, **kwds))
        try:
            immutable_array = id_array.view()
            immutable_array.flags.writeable = False
        except ValueError:
            return id_array
        else:
            return immutable_array

    return _wrapped



================================================
File: src/landlab/grid/diagonals.py
================================================
#! /usr/bin/env python
import contextlib

import numpy as np

from ..utils.decorators import cache_result_in_object
from ..utils.decorators import make_return_array_immutable
from .decorators import return_readonly_id_array
from .linkstatus import LinkStatus
from .linkstatus import set_status_at_link


def create_nodes_at_diagonal(shape, out=None):
    """Create array of tail and head nodes for diagonals.

    Parameters
    ----------
    shape : tuple of *(n_rows, n_cols)*
        Shape as number of node rows and node columns.
    out : ndarray of shape *(n_diagonals, 2)*, optional
        Output buffer to place nodes at each diagonal.

    Returns
    -------
    out : ndarray of shape *(n_diagonals, 2)*
        Tail and head node for each diagonal.

    Examples
    --------
    >>> from landlab.grid.diagonals import create_nodes_at_diagonal
    >>> create_nodes_at_diagonal((3, 4))
    array([[ 0, 5], [ 1, 4], [ 1,  6], [ 2, 5], [ 2,  7], [ 3,  6],
           [ 4, 9], [ 5, 8], [ 5, 10], [ 6, 9], [ 6, 11], [ 7, 10]])
    """
    shape = np.asarray(shape)
    n_diagonals = np.prod(shape - 1) * 2
    n_nodes = np.prod(shape)
    if out is None:
        out = np.empty((n_diagonals, 2), dtype=int)

    nodes = np.arange(n_nodes).reshape(shape)

    out[::2, 0] = nodes[:-1, :-1].flat
    out[::2, 1] = nodes[1:, 1:].flat
    out[1::2, 0] = nodes[:-1, 1:].flat
    out[1::2, 1] = nodes[1:, :-1].flat

    return out


def create_diagonals_at_node(shape, out=None):
    """Create array of diagonals at node.

    Create an array that gives the diagonal touching each node
    for a structured grid of quadrilaterals. For each node, links
    are ordered clockwise from axis=1.

    Parameters
    ----------
    shape : tuple of *(n_rows, n_cols)*
        Shape as number of node rows and node columns.
    out : ndarray of shape *(n_nodes, 4)*, optional
        Output buffer to place diagonal ids at each node.

    Returns
    -------
    out : ndarray of shape *(n_nodes, 4)*
        Diagonals at node with -1 for missing diagonals.

    Examples
    --------
    >>> from landlab.grid.diagonals import create_diagonals_at_node
    >>> create_diagonals_at_node((3, 4))
    array([[ 0, -1, -1, -1],
           [ 2,  1, -1, -1],
           [ 4,  3, -1, -1],
           [-1,  5, -1, -1],
           [ 6, -1, -1,  1],
           [ 8,  7,  0,  3],
           [10,  9,  2,  5],
           [-1, 11,  4, -1],
           [-1, -1, -1,  7],
           [-1, -1,  6,  9],
           [-1, -1,  8, 11],
           [-1, -1, 10, -1]])
    """
    shape = np.asarray(shape)
    n_diagonals = np.prod(shape - 1) * 2
    n_nodes = np.prod(shape)
    if out is None:
        out = np.full((n_nodes, 4), -1, dtype=int)

    diagonals = np.full(shape + 1, -1, dtype=int)

    diagonals[1:-1, 1:-1] = np.arange(0, n_diagonals, 2).reshape(shape - 1)
    out[:, 0] = diagonals[1:, 1:].flat
    out[:, 2] = diagonals[:-1, :-1].flat

    diagonals[1:-1, 1:-1] = np.arange(1, n_diagonals, 2).reshape(shape - 1)
    out[:, 1] = diagonals[1:, :-1].flat
    out[:, 3] = diagonals[:-1, 1:].flat

    return out


class DiagonalsMixIn:
    """Add diagonals to a structured quad grid."""

    @property
    @cache_result_in_object()
    def number_of_diagonals(self):
        """Number of diagonals in the grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.number_of_diagonals
        12
        """
        return 2 * np.prod(np.asarray(self.shape) - 1)

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def diagonals_at_node(self):
        """Diagonals attached to nodes.

        Returns
        -------
        ndarray of int, shape `(n_nodes, 4)`
            Diagonals at each node.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.diagonals_at_node.shape == (grid.number_of_nodes, 4)
        True
        >>> grid.diagonals_at_node
        array([[ 0, -1, -1, -1], [ 2,  1, -1, -1], [-1,  3, -1, -1],
               [ 4, -1, -1,  1], [ 6,  5,  0,  3], [-1,  7,  2, -1],
               [ 8, -1, -1,  5], [10,  9,  4,  7], [-1, 11,  6, -1],
               [-1, -1, -1,  9], [-1, -1,  8, 11], [-1, -1, 10, -1]])

        :meta landlab: info-node, info-link, connectivity
        """
        return create_diagonals_at_node(self.shape)

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def diagonal_dirs_at_node(self):
        """Directions of diagonals attached to nodes.

        Array of diagonal directions relative to each node. If the
        diagonal is directed away from the node the direction is -1, if the
        diagonal is directed toward the node its direction is 1. Each
        node is assumed to have exactly four diagonals attached to it.
        However, perimeter nodes will have fewer diagonals (corner nodes
        will only have one diagonal and edge nodes two). In such cases,
        placeholders of 0 are used.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.diagonal_dirs_at_node.shape == (grid.number_of_nodes, 4)
        True
        >>> grid.diagonal_dirs_at_node
        array([[-1,  0,  0,  0], [-1, -1,  0,  0], [ 0, -1,  0,  0],
               [-1,  0,  0,  1], [-1, -1,  1,  1], [ 0, -1,  1,  0],
               [-1,  0,  0,  1], [-1, -1,  1,  1], [ 0, -1,  1,  0],
               [ 0,  0,  0,  1], [ 0,  0,  1,  1], [ 0,  0,  1,  0]],
               dtype=int8)

        The lower-right corner node only has one diagonal.

        >>> grid.diagonal_dirs_at_node[2]
        array([ 0, -1,  0,  0], dtype=int8)

        A node on one of the edges has two diagonals.

        >>> grid.diagonal_dirs_at_node[3]
        array([-1,  0,  0,  1], dtype=int8)
        """
        diagonals_at_node = self.diagonals_at_node
        dirs_at_node = np.zeros_like(diagonals_at_node, dtype=np.int8)
        dirs_at_node[diagonals_at_node >= 0] = 1
        dirs_at_node[:, (0, 1)] *= -1

        return dirs_at_node

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def diagonal_adjacent_nodes_at_node(self):
        """Get adjacent nodes along diagonals.

        Order is the landlab standard, counterclockwise starting from
        east.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.diagonal_adjacent_nodes_at_node
        array([[ 4, -1, -1, -1], [ 5,  3, -1, -1], [-1,  4, -1, -1],
               [ 7, -1, -1,  1], [ 8,  6,  0,  2], [-1,  7,  1, -1],
               [10, -1, -1,  4], [11,  9,  3,  5], [-1, 10,  4, -1],
               [-1, -1, -1,  7], [-1, -1,  6,  8], [-1, -1,  7, -1]])

        :meta landlab: info-node, connectivity
        """
        node_is_at_tail = np.choose(
            self.diagonal_dirs_at_node + 1, np.array((1, -1, 0), dtype=np.int8)
        )
        out = self.nodes_at_diagonal[self.diagonals_at_node, node_is_at_tail]
        out[node_is_at_tail == -1] = -1

        return out

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def d8_adjacent_nodes_at_node(self):
        return np.vstack(
            (
                super().adjacent_nodes_at_node,
                self.diagonal_adjacent_nodes_at_node,
            )
        )

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_diagonal(self):
        """Nodes at diagonal tail and head.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.nodes_at_diagonal.shape == (grid.number_of_diagonals, 2)
        True
        >>> grid.nodes_at_diagonal
        array([[ 0,  4], [ 1,  3], [ 1,  5], [ 2,  4],
               [ 3,  7], [ 4,  6], [ 4,  8], [ 5,  7],
               [ 6, 10], [ 7,  9], [ 7, 11], [ 8, 10]])

        The first column is diagonal tail and the second the head.

        >>> grid.diagonals_at_node[3]
        array([ 4, -1, -1,  1])
        >>> grid.nodes_at_diagonal[(4, 1),]
        array([[3, 7],
               [1, 3]])
        >>> grid.diagonal_dirs_at_node[3]
        array([-1,  0,  0,  1], dtype=int8)
        """
        return create_nodes_at_diagonal(self.shape)

    @property
    @cache_result_in_object()
    def number_of_d8(self):
        """Number of links and diagonals.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))
        >>> grid.number_of_d8
        29
        """
        return super().number_of_links + self.number_of_diagonals

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def nodes_at_d8(self):
        return np.vstack((self.nodes_at_link, self.nodes_at_diagonal))

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def d8s_at_node(self):
        """Links and diagonals attached to nodes.

        Returns
        -------
        ndarray of int, shape `(n_nodes, 8)`
            Links and diagonals at each node.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid

        >>> grid = RasterModelGrid((3, 4))
        >>> grid.d8s_at_node.shape == (grid.number_of_nodes, 8)
        True
        >>> grid.d8s_at_node
        array([[ 0,  3, -1, -1, 17, -1, -1, -1],
               [ 1,  4,  0, -1, 19, 18, -1, -1],
               [ 2,  5,  1, -1, 21, 20, -1, -1],
               [-1,  6,  2, -1, -1, 22, -1, -1],
               [ 7, 10, -1,  3, 23, -1, -1, 18],
               [ 8, 11,  7,  4, 25, 24, 17, 20],
               [ 9, 12,  8,  5, 27, 26, 19, 22],
               [-1, 13,  9,  6, -1, 28, 21, -1],
               [14, -1, -1, 10, -1, -1, -1, 24],
               [15, -1, 14, 11, -1, -1, 23, 26],
               [16, -1, 15, 12, -1, -1, 25, 28],
               [-1, -1, 16, 13, -1, -1, 27, -1]])
        >>> np.all(grid.d8s_at_node[:, :4] == grid.links_at_node)
        True

        >>> diagonals_at_node = grid.d8s_at_node[:, 4:] - grid.number_of_links
        >>> diagonals_at_node[grid.d8s_at_node[:, 4:] == -1] = -1
        >>> np.all(diagonals_at_node == grid.diagonals_at_node)
        True

        :meta landlab: info-node, info-link, connectivity
        """
        diagonals_at_node = self.diagonals_at_node.copy()
        diagonals_at_node[diagonals_at_node >= 0] += self.number_of_links
        return np.hstack((super().links_at_node, diagonals_at_node))

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def d8_dirs_at_node(self):
        return np.hstack((super().link_dirs_at_node, self.diagonal_dirs_at_node))

    @property
    # @cache_result_in_object()
    @make_return_array_immutable
    def d8_status_at_node(self):
        return self.status_at_d8[self.d8s_at_node]

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def length_of_diagonal(self):
        return np.sqrt(
            np.power(np.diff(self.xy_of_node[self.nodes_at_diagonal], axis=1), 2.0).sum(
                axis=2
            )
        ).flatten()

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def length_of_d8(self):
        """Length of links and diagonals.

        Return the lengths links and diagonals in the grid. Links are
        listed first and then diagonals.

        Returns
        -------
        ndarray of float
            Link lengths.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 3), xy_spacing=(4, 3))

        >>> grid.length_of_link
        array([4.,  4.,  3.,  3.,  3.,  4.,  4.,  3.,  3.,  3.,  4.,  4.])

        >>> grid.length_of_d8
        array([4.,  4.,  3.,  3.,  3.,
               4.,  4.,  3.,  3.,  3.,
               4.,  4.,  5.,  5.,  5.,
               5.,  5.,  5.,  5.,  5.])

        :meta landlab: info-link, quantity
        """
        return np.hstack((super().length_of_link, self.length_of_diagonal))

    def reset_status_at_node(self):
        super().reset_status_at_node()
        attrs = [
            "_status_at_diagonal",
            "_diagonal_status_at_node",
            "_active_diagonals",
            "_active_diagonal_dirs_at_node",
            "_status_at_d8",
            "_active_d8",
            "_active_d8_dirs_at_node",
        ]

        for attr in attrs:
            with contextlib.suppress(KeyError):
                del self.__dict__[attr]

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def status_at_diagonal(self):
        """Status at diagonals.

        Examples
        --------
        >>> from landlab import LinkStatus, NodeStatus, RasterModelGrid
        >>> grid = RasterModelGrid((4, 3))

        An inactive link (or diagonal) is one that joins two
        boundary nodes or has one end that is a closed boundary.

        >>> grid.status_at_node
        array([1, 1, 1,
               1, 0, 1,
               1, 0, 1,
               1, 1, 1], dtype=uint8)
        >>> NodeStatus.CORE, NodeStatus.FIXED_VALUE
        (<NodeStatus.CORE: 0>, <NodeStatus.FIXED_VALUE: 1>)

        Diagonals that connect two boundary nodes are inactive.

        >>> grid.status_at_diagonal
        array([0, 4, 4, 0,
               0, 0, 0, 0,
               4, 0, 0, 4], dtype=uint8)
        >>> LinkStatus.ACTIVE, LinkStatus.INACTIVE
        (<LinkStatus.ACTIVE: 0>, <LinkStatus.INACTIVE: 4>)

        By setting a node to closed that wasn't before, a new link
        becomes inactive.

        >>> grid.status_at_node[5] = NodeStatus.CLOSED
        >>> grid.status_at_diagonal
        array([0, 4, 4, 0,
               0, 0, 0, 4,
               4, 0, 0, 4], dtype=uint8)
        """
        return set_status_at_link(self.status_at_node[self.nodes_at_diagonal])

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def diagonal_status_at_node(self):
        return self.status_at_diagonal[self.diagonals_at_node]

    @property
    @cache_result_in_object()
    @return_readonly_id_array
    def active_diagonals(self):
        return np.where(self.status_at_diagonal == LinkStatus.ACTIVE)[0]

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def active_diagonal_dirs_at_node(self):
        return np.choose(
            self.diagonal_status_at_node == LinkStatus.ACTIVE,
            (0, self.diagonal_dirs_at_node),
        )

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def status_at_d8(self):
        return np.hstack((super().status_at_link, self.status_at_diagonal))

    @property
    @cache_result_in_object()
    @return_readonly_id_array
    def active_d8(self):
        return np.where(self.status_at_d8 == LinkStatus.ACTIVE)[0]

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def active_d8_dirs_at_node(self):
        return np.choose(
            self.d8_status_at_node == LinkStatus.ACTIVE, (0, self.d8_dirs_at_node)
        )



================================================
File: src/landlab/grid/divergence.py
================================================
#! /usr/bin/env python
"""Calculate vector divergence and related quantities at nodes or cells."""
import numpy as np

from landlab.utils.decorators import use_field_name_or_array


@use_field_name_or_array("link")
def calc_flux_div_at_node(grid, unit_flux, out=None):
    """Calculate divergence of link-based fluxes at nodes.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each node (zero
    or "out" value for nodes without cells).

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux : ndarray or field name
        Flux per unit width along links (x number of links).

    Returns
    -------
    ndarray (x number of nodes)
        Flux divergence at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.divergence import calc_flux_div_at_node
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)  # there are 17 links
    >>> lg
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])
    >>> calc_flux_div_at_node(rg, -lg)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.64,  0.94,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_links = np.zeros(rg.number_of_links)
    >>> unit_flux_at_links[rg.active_links] = -lg[rg.active_links]
    >>> calc_flux_div_at_node(rg, unit_flux_at_links)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.14,  0.22,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])
    >>> _ = rg.add_field("neg_grad_at_link", -lg, at="link")
    >>> calc_flux_div_at_node(rg, "neg_grad_at_link")
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.64,  0.94,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])


    Notes
    -----
    Performs a numerical flux divergence operation on nodes.

    :meta landlab: info-node, gradient
    """
    if unit_flux.size != grid.number_of_links:
        raise ValueError("Parameter unit_flux must be num links " "long")
    if out is None:
        out = grid.zeros(at="node")
    elif out.size != grid.number_of_nodes:
        raise ValueError("output buffer length mismatch with number of nodes")

    out[grid.node_at_cell] = (
        _calc_net_face_flux_at_cell(grid, unit_flux[grid.link_at_face])
        / grid.area_of_cell
    )

    return out


@use_field_name_or_array("link")
def calc_flux_div_at_cell(grid, unit_flux, out=None):
    """Calculate divergence of link-based fluxes at cells.

    This function is very similar to the function *calc_flux_div_at_node*.

    Given a flux per unit width across each cell face in the grid, calculate
    the net outflux (or influx, if negative) divided by cell area, at each
    cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_links_across_faces : ndarray or field name
        Flux per unit width along links at faces (x number of faces) or link
        field.

    Returns
    -------
    ndarray (x number of cells)
        Flux divergence at cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.divergence import calc_flux_div_at_cell
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> import numpy as np
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)  # there are 17 links
    >>> lg
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])
    >>> fg = lg[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> calc_flux_div_at_cell(rg, -fg)
    array([1.64,  0.94])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_faces = np.zeros(rg.number_of_faces)
    >>> unit_flux_at_faces[rg.active_faces] = -fg[rg.active_faces]
    >>> calc_flux_div_at_cell(rg, unit_flux_at_faces)
    array([1.14,  0.22])
    >>> _ = rg.add_field("neg_grad_at_link", -lg, at="link")
    >>> calc_flux_div_at_cell(rg, "neg_grad_at_link")
    array([1.64,  0.94])

    Notes
    -----
    Performs a numerical flux divergence operation at cells.

    :meta landlab: info-node, gradient
    """
    if unit_flux.size not in (grid.number_of_links, grid.number_of_faces):
        raise ValueError(
            "Parameter unit_flux must be num faces long"
            "or the field name for a at_link array"
        )
    if out is None:
        out = grid.zeros(at="cell")
    elif out.size != grid.number_of_cells:
        raise ValueError("output buffer length mismatch with number of cells")

    if unit_flux.size == grid.number_of_links:
        out = (
            _calc_net_face_flux_at_cell(grid, unit_flux[grid.link_at_face])
            / grid.area_of_cell
        )
    elif unit_flux.size == grid.number_of_faces:
        out = _calc_net_face_flux_at_cell(grid, unit_flux) / grid.area_of_cell

    return out


@use_field_name_or_array("link")
def calc_net_flux_at_node(grid, unit_flux_at_links, out=None):
    """Calculate net link fluxes at nodes.

    Given a flux per unit width along each link in the grid, calculate the net
    outflux (or influx, if negative) at each node. Fluxes are treated as zero
    for links that have no faces, and net fluxes are treated as zero for nodes
    that have no cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_links : ndarray or field name
        Flux per unit width associated with links.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of cells)
        Net flux at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)  # there are 17 links
    >>> lg
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])
    >>> calc_net_flux_at_node(rg, -lg)
    array([   0.,    0.,    0.,    0.,    0.,  164.,   94.,    0.,    0.,
              0.,    0.,    0.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_links = np.zeros(rg.number_of_links)
    >>> unit_flux_at_links[rg.active_links] = -lg[rg.active_links]
    >>> nlfn = calc_net_flux_at_node(rg, unit_flux_at_links)
    >>> np.round(nlfn)
    array([   0.,    0.,    0.,    0.,    0.,  114.,   22.,    0.,    0.,
              0.,    0.,    0.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> lg = hg.calc_grad_at_link(z)  # there are ? links
    >>> lg
    array([ 0. ,  0. ,  0. ,  5. ,  5. ,  3.6,  3.6,  0. ,  5. , -1.4, -3.6,
            0. , -5. , -5. , -3.6, -3.6,  0. ,  0. ,  0. ])
    >>> nlfn = calc_net_flux_at_node(hg, -lg)
    >>> np.round(nlfn)
    array([   0.,    0.,    0.,    0.,  152.,   96.,    0.,    0.,    0.,    0.])

    Notes
    -----
    This is essentially a line integral for the fluxes along the boundaries of
    each cell. Hence, the resulting output has dimensions of total flux (so,
    if the unit flux happens to be mass per time per face width, the output
    will be in mass per unit time). Because a line integral is undefined where
    there are no cells (i.e., perimeter nodes), the result is given as zeros
    for these nodes. The current algorithm uses fancy indexing (calling
    _calc_net_face_flux_at_cells) and could probably be made faster.

    :meta landlab: info-node, gradient
    """
    if out is None:
        out = grid.zeros(at="node")

    out[grid.node_at_cell] = _calc_net_face_flux_at_cell(
        grid, unit_flux_at_links[grid.link_at_face]
    )
    return out


@use_field_name_or_array("face")
def _calc_net_face_flux_at_cell(grid, unit_flux_at_faces, out=None):
    """Calculate net face fluxes at cells.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) at each cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name
        Flux per unit width associated with faces.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of cells)
        Net flux at cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)
    >>> fg = lg[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_net_face_flux_at_cell(rg, -fg)
    array([164.,   94.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_faces = np.zeros(rg.number_of_faces)
    >>> unit_flux_at_faces[rg.active_faces] = -fg[rg.active_faces]
    >>> _calc_net_face_flux_at_cell(rg, unit_flux_at_faces)
    array([114.,   22.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> lg = hg.calc_grad_at_link(z)
    >>> fg = lg[hg.link_at_face]  # there are 11 faces
    >>> fg
    array([ 5. ,  5. ,  3.6,  3.6,  5. , -1.4, -3.6, -5. , -5. , -3.6, -3.6])
    >>> nffc = _calc_net_face_flux_at_cell(hg, -fg)
    >>> np.round(nffc)
    array([152.,   96.])

    Notes
    -----
    This is essentially a line integral for the fluxes along the boundaries of
    each cell. Hence, the resulting output has dimensions of total flux (so,
    if the unit flux happens to be mass per time per face width, the output
    will be in mass per unit time).
    """
    if out is None:
        out = grid.empty(at="cell")
    total_flux = unit_flux_at_faces * grid.length_of_face
    out = np.zeros(grid.number_of_cells)
    fac = grid.faces_at_cell
    for c in range(grid.link_dirs_at_node.shape[1]):
        out -= total_flux[fac[:, c]] * grid.link_dirs_at_node[grid.node_at_cell, c]
    return out


@use_field_name_or_array("face")
def _calc_face_flux_divergence_at_cell(grid, unit_flux_at_faces):
    """Calculate divergence of face-based fluxes at cells.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name
        Flux per unit width associated with faces.

    Returns
    -------
    ndarray (x number of cells)
        Flux divergence at cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)
    >>> lg[rg.link_at_face]
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_face_flux_divergence_at_cell(rg, -lg[rg.link_at_face])
    array([1.64,  0.94])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_faces = np.zeros(rg.number_of_faces)
    >>> fg = lg[rg.link_at_face]
    >>> unit_flux_at_faces[rg.active_faces] = -fg[rg.active_faces]
    >>> _calc_face_flux_divergence_at_cell(rg, unit_flux_at_faces)
    array([1.14,  0.22])

    Notes
    -----
    Performs a numerical flux divergence operation on cells.
    """
    return _calc_net_face_flux_at_cell(grid, unit_flux_at_faces) / grid.area_of_cell


@use_field_name_or_array("face")
def _calc_net_active_face_flux_at_cell(grid, unit_flux_at_faces, out=None):
    """Calculate net face fluxes at cells, ignoring values on inactive faces.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) at each cell. Same as
    `_calc_net_face_flux_at_cell` except that flux values on inactive faces
    are ignored.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name (x number of faces)
        Flux per unit width associated with faces.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of cells)
        Net flux at cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> fg = rg.calc_grad_at_link(z)[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_net_active_face_flux_at_cell(rg, -fg)
    array([164.,   94.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> _calc_net_active_face_flux_at_cell(rg, -fg)
    array([114.,   22.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> fg = hg.calc_grad_at_link(z)[hg.link_at_face]  # there are 11 faces
    >>> fg
    array([ 5. ,  5. ,  3.6,  3.6,  5. , -1.4, -3.6, -5. , -5. , -3.6, -3.6])
    >>> nffc = _calc_net_active_face_flux_at_cell(hg, -fg)
    >>> np.round(nffc)
    array([152.,   96.])

    Notes
    -----
    This is essentially a line integral for the fluxes along the boundaries of
    each cell. Hence, the resulting output has dimensions of total flux (so,
    if the unit flux happens to be mass per time per face width, the output
    will be in mass per unit time).
    """
    if out is None:
        out = grid.empty(at="cell")
    total_flux = unit_flux_at_faces * grid.length_of_face
    out = np.zeros(grid.number_of_cells)
    fac = grid.faces_at_cell
    for c in range(grid.active_link_dirs_at_node.shape[1]):
        out -= (
            total_flux[fac[:, c]] * grid.active_link_dirs_at_node[grid.node_at_cell, c]
        )
    return out


@use_field_name_or_array("face")
def _calc_active_face_flux_divergence_at_cell(grid, unit_flux_at_faces):
    """Calculate divergence of face-based fluxes at cells, ignoring values on
    inactive faces.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each cell. Same
    as `_calc_face_flux_divergence_at_cell` except that flux values at inactive
    faces are ignored.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name (x number of faces)
        Flux per unit width associated with faces.

    Returns
    -------
    ndarray (x number of cells)
        Flux divergence at cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> fg = rg.calc_grad_at_link(z)[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_active_face_flux_divergence_at_cell(rg, -fg)
    array([1.64,  0.94])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> _calc_active_face_flux_divergence_at_cell(rg, -fg)
    array([1.14,  0.22])

    Notes
    -----
    Performs a numerical flux divergence operation on cells.
    """
    return (
        _calc_net_active_face_flux_at_cell(grid, unit_flux_at_faces) / grid.area_of_cell
    )


@use_field_name_or_array("link")
def _calc_net_active_link_flux_at_node(grid, unit_flux_at_links, out=None):
    """Calculate net link fluxes at nodes, ignoring fluxes on inactive links.

    Given a flux per unit width along each link in the grid, calculate the net
    outflux (or influx, if negative) at each node. Fluxes are treated as zero
    for links that have no faces, and net fluxes are treated as zero for nodes
    that have no cell. Same as `_calc_net_link_flux_at_node` except that it
    ignores any flux values on inactive links.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_links : ndarray or field name (x number of links)
        Flux per unit width associated with links.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of cells)
        Net flux at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)  # there are 17 links
    >>> lg
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])
    >>> _calc_net_active_link_flux_at_node(rg, -lg)
    array([   0.,    0.,    0.,    0.,    0.,  164.,   94.,    0.,    0.,
              0.,    0.,    0.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> nlfn = _calc_net_active_link_flux_at_node(rg, -lg)
    >>> np.round(nlfn)
    array([   0.,    0.,    0.,    0.,    0.,  114.,   22.,    0.,    0.,
              0.,    0.,    0.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> lg = hg.calc_grad_at_link(z)  # there are ? links
    >>> lg
    array([ 0. ,  0. ,  0. ,  5. ,  5. ,  3.6,  3.6,  0. ,  5. , -1.4, -3.6,
            0. , -5. , -5. , -3.6, -3.6,  0. ,  0. ,  0. ])
    >>> nlfn = _calc_net_active_link_flux_at_node(hg, -lg)
    >>> np.round(nlfn)
    array([   0.,    0.,    0.,    0.,  152.,   96.,    0.,    0.,    0.,    0.])

    Notes
    -----
    This is essentially a line integral for the fluxes along the boundaries of
    each cell. Hence, the resulting output has dimensions of total flux (so,
    if the unit flux happens to be mass per time per face width, the output
    will be in mass per unit time). Because a line integral is undefined where
    there are no cells (i.e., perimeter nodes), the result is given as zeros
    for these nodes. The current algorithm uses fancy indexing (calling
    _calc_net_face_flux_at_cells) and could probably be made faster.
    """
    if out is None:
        out = grid.zeros(at="node")

    out[grid.node_at_cell] = _calc_net_active_face_flux_at_cell(
        grid, unit_flux_at_links[grid.link_at_face]
    )
    return out


@use_field_name_or_array("link")
def _calc_active_link_flux_divergence_at_node(grid, unit_flux_at_links, out=None):
    """Calculate divergence of link-based fluxes at nodes, ignoring any fluxes
    at inactive links.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each node (zero
    or "out" value for nodes without cells).

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_links : ndarray or field name (x number of links)
        Flux per unit width associated with links.

    Returns
    -------
    ndarray (x number of nodes)
        Flux divergence at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> lg = rg.calc_grad_at_link(z)  # there are 17 links
    >>> lg
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])
    >>> _calc_active_link_flux_divergence_at_node(rg, -lg)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.64,  0.94,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> _calc_active_link_flux_divergence_at_node(rg, -lg)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.14,  0.22,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])

    Notes
    -----
    Performs a numerical flux divergence operation on nodes.
    """
    if out is None:
        out = grid.zeros(at="node")

    out[grid.node_at_cell] = (
        _calc_net_active_face_flux_at_cell(grid, unit_flux_at_links[grid.link_at_face])
        / grid.area_of_cell
    )
    return out


@use_field_name_or_array("face")
def _calc_net_face_flux_at_node(grid, unit_flux_at_faces, out=None):
    """Calculate net face fluxes at nodes.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) at each node (nodes without cells are
    zero, or unchanged from `out` parameter if provided)

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name
        Flux per unit width associated with faces.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of nodes)
        Net flux at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> fg = rg.calc_grad_at_link(z)[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_net_face_flux_at_node(rg, -fg)
    array([   0.,    0.,    0.,    0.,    0.,  164.,   94.,    0.,    0.,
              0.,    0.,    0.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_faces = np.zeros(rg.number_of_faces)
    >>> unit_flux_at_faces[rg.active_faces] = -fg[rg.active_faces]
    >>> _calc_net_face_flux_at_node(rg, unit_flux_at_faces)
    array([   0.,    0.,    0.,    0.,    0.,  114.,   22.,    0.,    0.,
              0.,    0.,    0.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> fg = hg.calc_grad_at_link(z)[hg.link_at_face]  # there are 11 faces
    >>> fg
    array([ 5. ,  5. ,  3.6,  3.6,  5. , -1.4, -3.6, -5. , -5. , -3.6, -3.6])
    >>> nffc = _calc_net_face_flux_at_node(hg, -fg)
    >>> np.round(nffc)
    array([   0.,    0.,    0.,    0.,  152.,   96.,    0.,    0.,    0.,    0.])

    Notes
    -----
    Like _calc_net_face_flux_at_cells, this essentially performs a line integral
    for the fluxes along the boundaries of each cell. Nodes without cells are
    either assigned a zero value, or if `out` is provided, they retain their
    previous values.
    """
    if out is None:
        out = grid.zeros(at="node")

    out[grid.node_at_cell] = _calc_net_face_flux_at_cell(grid, unit_flux_at_faces)
    return out


@use_field_name_or_array("face")
def _calc_net_active_face_flux_at_node(grid, unit_flux_at_faces, out=None):
    """Calculate net face fluxes at nodes, ignore inactive faces.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) at each node (nodes without cells are
    zero, or unchanged from `out` parameter if provided). Same as
    `_calc_net_face_flux_at_node` except that it ignores inactive faces.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name (x number of faces)
        Flux per unit width associated with faces.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of nodes)
        Net flux at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> fg = rg.calc_grad_at_link(z)[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_net_active_face_flux_at_node(rg, -fg)
    array([   0.,    0.,    0.,    0.,    0.,  164.,   94.,    0.,    0.,
              0.,    0.,    0.])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> _calc_net_active_face_flux_at_node(rg, -fg)
    array([   0.,    0.,    0.,    0.,    0.,  114.,   22.,    0.,    0.,
              0.,    0.,    0.])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> fg = hg.calc_grad_at_link(z)[hg.link_at_face]  # there are 11 faces
    >>> fg
    array([ 5. ,  5. ,  3.6,  3.6,  5. , -1.4, -3.6, -5. , -5. , -3.6, -3.6])
    >>> nffc = _calc_net_active_face_flux_at_node(hg, -fg)
    >>> np.round(nffc)
    array([   0.,    0.,    0.,    0.,  152.,   96.,    0.,    0.,    0.,    0.])

    Notes
    -----
    Like _calc_net_face_flux_at_cells, this essentially performs a line integral
    for the fluxes along the boundaries of each cell. Nodes without cells are
    either assigned a zero value, or if `out` is provided, they retain their
    previous values.
    """
    if out is None:
        out = grid.zeros(at="node")

    out[grid.node_at_cell] = _calc_net_active_face_flux_at_cell(
        grid, unit_flux_at_faces
    )
    return out


@use_field_name_or_array("face")
def _calc_active_face_flux_divergence_at_node(grid, unit_flux_at_faces, out=None):
    """Calculate divergence of face-based fluxes at nodes (active faces only).

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each node that
    lies within a cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name (x number of faces)
        Flux per unit width associated with faces.
    out : ndarray (x number of nodes), optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of nodes)
        Flux divergence at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> fg = rg.calc_grad_at_link(z)[rg.link_at_face]  # there are 7 faces
    >>> fg
    array([ 5. ,  3.6,  5. , -1.4, -3.6, -5. , -3.6])
    >>> _calc_active_face_flux_divergence_at_node(rg, -fg)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.64,  0.94,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])
    >>> rg.set_status_at_node_on_edges(right=rg.BC_NODE_IS_CLOSED)
    >>> rg.set_status_at_node_on_edges(top=rg.BC_NODE_IS_CLOSED)
    >>> _calc_active_face_flux_divergence_at_node(rg, -fg)
    array([0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.14,  0.22,  0.  ,  0.  ,
           0.  ,  0.  ,  0.  ])

    Notes
    -----
    Performs a numerical flux divergence operation on cells, and returns the
    result in an array of length equal to the number of nodes. Nodes without
    cells (those on the grid perimeter) are not affected (i.e., their value
    is either zero, or if `out` is given, whatever the prior value in `out`
    was).
    """
    if out is None:
        out = grid.zeros(at="node")
    out[grid.node_at_cell] = (
        _calc_net_active_face_flux_at_cell(grid, unit_flux_at_faces) / grid.area_of_cell
    )
    return out



================================================
File: src/landlab/grid/framed_voronoi.py
================================================
#! /usr/env/python
"""Python implementation of :class:`~.FramedVoronoiGrid`, a grid class used to create and
manage unstructured Voronoi-Delaunay grids for 2D numerical models, with a structured
perimeter layout

.. codeauthor:: sebastien lenard
"""

import numpy

from ..graph import DualFramedVoronoiGraph
from .base import ModelGrid


class FramedVoronoiGrid(DualFramedVoronoiGraph, ModelGrid):
    """A grid of Voronoi Delaunay cells with a structured perimeter layout.

    This inherited class implements a irregular 2D grid with Voronoi Delaunay cells and
    irregular patches. It is a special type of :class:`~.VoronoiDelaunayGrid` grid in which
    the initial set of points is arranged in a fixed lattice (e.g. like a
    :class:`~.RasterModelGrid`), named here "layout", and the core points are
    then moved a random distance from their initial positions, bounded by a user-supplied
    threshold.

    Examples
    --------
    Create a grid with 3 rows and 2 columns of nodes.

    >>> from landlab import FramedVoronoiGrid
    >>> grid = FramedVoronoiGrid((3, 2), xy_spacing=1.0)
    >>> grid.number_of_nodes
    6

    >>> grid = FramedVoronoiGrid(
    ...     (4, 3), xy_spacing=(10.0, 10.0), xy_min_spacing=(5.0, 5.0), seed=200
    ... )
    >>> grid.status_at_node.reshape(grid.shape)
    array([[1, 1, 1],
           [1, 0, 1],
           [1, 0, 1],
           [1, 1, 1]], dtype=uint8)
    >>> grid.x_of_node[3]
    0.0
    >>> grid.x_of_node[5]
    20.0
    >>> grid.y_of_node[0::3]
    array([  0.   ,   7.499,  17.499,  30.   ])

    >>> grid = FramedVoronoiGrid(
    ...     (3, 5), xy_spacing=(10.0, 10.0), xy_min_spacing=5.0, seed=None
    ... )
    >>> grid.boundary_nodes
    array([ 0,  1,  2,  3,  4,  5,  9, 10, 11, 12, 13, 14])
    """

    # Inheritance diagram:
    #
    # FramedVoronoiGrid
    # |-- ModelGrid
    # `-- DualFramedVoronoiGraph
    #     |-- FramedVoronoiGraph (Layout: HorizontalRectVoronoiGraph)
    #     |   `-- DelaunayGraph
    #     `-- DualGraph (use of static Graph.sort())

    def __init__(
        self,
        shape,
        xy_spacing=(1.0, 1.0),
        xy_of_lower_left=(0.0, 0.0),
        xy_min_spacing=(0.5, 0.5),
        seed=200,
        xy_of_reference=(0.0, 0.0),
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
    ):
        """Create a grid of voronoi cells with a structured perimeter.

        Create an irregular 2D grid with voronoi cells and triangular patches.
        It is a special type of :class:`~.VoronoiDelaunayGrid` in which the initial set
        of points is arranged in a regular lattice determined by the parameters
        *shape*, and *xy_spacing*. The coordinates of
        the core points are then randomly moved while the perimeter points
        remaining fixed, in a way determined by the parameters *xy_min_spacing*, and
        *seed*.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of nodes.
        xy_spacing : float or tuple of float, optional
            Node spacing along x and y coordinates. If ``float``, same spacing at *x* and *y*.
        xy_of_lower_left : tuple, optional
            Minimum *x*-of-node and *y*-of-node values. Depending on the grid,
            there may not be a node at this coordinate.
        xy_min_spacing: float or tuple of float, optional
            Final minimal spacing between nodes. Random moves of the core nodes
            from their initial positions cannot be above this threshold:
            ``(xy_spacing - xy_min_spacing) / 2``
            If ``float``, same minimal spacing for *x* and *y*.
        seed: int, optional
            Seed used to generate the random *x* and *y* moves.
            When set, controls the pseudo-randomness of moves to ensure
            reproducibility.
            When ``None``, the seed is random and the moves of coordinates are
            completely random.
        xy_of_reference : tuple, optional
            Coordinate value in projected space of the reference point,
            *xy_of_lower_left*.
        xy_axis_name: tuple of str, optional
            *x* and *y* axis names.
        xy_axis_units: str, optional
            *x* and *y* axis units.

        Returns
        -------
        FramedVoronoiGrid
            A newly-created grid.

        Examples
        --------
        Create a grid with 3 rows and 2 columns of nodes.

        >>> from landlab import FramedVoronoiGrid
        >>> grid = FramedVoronoiGrid((3, 2), xy_spacing=1.0)
        >>> grid.number_of_nodes
        6
        """
        DualFramedVoronoiGraph.__init__(
            self,
            shape,
            xy_spacing=xy_spacing,
            xy_of_lower_left=xy_of_lower_left,
            sort=True,
            xy_min_spacing=xy_min_spacing,
            seed=seed,
        )
        ModelGrid.__init__(
            self,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
            xy_of_reference=xy_of_reference,
        )

        self._node_status = numpy.full(
            self.number_of_nodes, self.BC_NODE_IS_CORE, dtype=numpy.uint8
        )
        self._node_status[self.perimeter_nodes] = self.BC_NODE_IS_FIXED_VALUE

    @classmethod
    def from_dict(cls, kwds):
        args = ()
        return cls(*args, **kwds)



================================================
File: src/landlab/grid/gradients.py
================================================
#! /usr/bin/env python
"""Calculate gradients of quantities over links.

Gradient calculation functions
++++++++++++++++++++++++++++++

.. autosummary::

    ~calc_grad_at_link
    ~calc_diff_at_link
"""

import numpy as np

from landlab.core.utils import radians_to_degrees
from landlab.utils.decorators import use_field_name_or_array


@use_field_name_or_array("node")
def calc_grad_at_link(grid, node_values, out=None):
    """Calculate gradients of node values at links.

    Calculates the gradient in `node_values` at each link in the grid,
    returning an array of length `number_of_links`.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    node_values : ndarray or field name (x number of nodes)
        Values at grid nodes.
    out : ndarray, optional (x number of links)
        Buffer to hold the result.

    Returns
    -------
    ndarray
        Gradients across active links.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rg = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = rg.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> calc_grad_at_link(rg, z)  # there are 17 links
    array([ 0. ,  0. ,  0. ,  0. ,  5. ,  3.6,  0. ,  5. , -1.4, -3.6,  0. ,
           -5. , -3.6,  0. ,  0. ,  0. ,  0. ])

    >>> from landlab import HexModelGrid
    >>> hg = HexModelGrid((3, 3), spacing=10.0)
    >>> z = hg.add_zeros("topographic__elevation", at="node", clobber=True)
    >>> z[4] = 50.0
    >>> z[5] = 36.0
    >>> calc_grad_at_link(hg, z)  # there are 11 faces
    array([ 0. ,  0. ,  0. ,  5. ,  5. ,  3.6,  3.6,  0. ,  5. , -1.4, -3.6,
            0. , -5. , -5. , -3.6, -3.6,  0. ,  0. ,  0. ])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = grid.empty(at="link")
    return np.divide(
        node_values[grid.node_at_link_head] - node_values[grid.node_at_link_tail],
        grid.length_of_link,
        out=out,
    )


@use_field_name_or_array("node")
def calc_diff_at_link(grid, node_values, out=None):
    """Calculate differences of node values over links.

    Calculates the difference in quantity *node_values* at each link in the
    grid.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    node_values : ndarray or field name
        Values at grid nodes.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray
        Differences across links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> rmg = RasterModelGrid((3, 3))
    >>> z = np.zeros(9)
    >>> z[4] = 1.0
    >>> rmg.calc_diff_at_link(z)
    array([ 0.,  0.,  0.,  1.,  0.,  1., -1.,  0., -1.,  0.,  0.,  0.])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = grid.empty(at="link")
    node_values = np.asarray(node_values)
    return np.subtract(
        node_values[grid.node_at_link_head],
        node_values[grid.node_at_link_tail],
        out=out,
    )


def calc_unit_normal_at_patch(grid, elevs="topographic__elevation"):
    """Calculate and return the unit normal vector <a, b, c> to a patch.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or ndarray, optional
        Field name or array of node values.

    Returns
    -------
    nhat : num-patches x length-3 array
        The unit normal vector <a, b, c> to each patch.

    Examples
    --------
    >>> from landlab import HexModelGrid
    >>> mg = HexModelGrid((3, 3))
    >>> z = mg.node_x * 3.0 / 4.0
    >>> mg.calc_unit_normal_at_patch(z)
    array([[-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8],
           [-0.6,  0. ,  0.8]])

    :meta landlab: info-patch, gradient
    """
    try:
        z = grid.at_node[elevs]
    except TypeError:
        z = elevs
    # conceptualize patches as sets of 3 nodes, PQR
    diff_xyz_PQ = np.empty((grid.number_of_patches, 3))
    # ^this is the vector (xQ-xP, yQ-yP, zQ-yP)
    diff_xyz_PR = np.empty((grid.number_of_patches, 3))
    P = grid.nodes_at_patch[:, 0]
    Q = grid.nodes_at_patch[:, 1]
    R = grid.nodes_at_patch[:, 2]
    x_P = grid.node_x[P]
    y_P = grid.node_y[P]
    z_P = z[P]
    diff_xyz_PQ[:, 0] = grid.node_x[Q] - x_P
    diff_xyz_PQ[:, 1] = grid.node_y[Q] - y_P
    diff_xyz_PQ[:, 2] = z[Q] - z_P
    diff_xyz_PR[:, 0] = grid.node_x[R] - x_P
    diff_xyz_PR[:, 1] = grid.node_y[R] - y_P
    diff_xyz_PR[:, 2] = z[R] - z_P
    # cross product is orthogonal to both vectors, and is the normal
    # n = <a, b, c>, where plane is ax + by + cz = d
    nhat = np.cross(diff_xyz_PQ, diff_xyz_PR)  # <a, b, c>
    nmag = np.sqrt(np.square(nhat).sum(axis=1))

    return nhat / nmag.reshape(grid.number_of_patches, 1)


def calc_slope_at_patch(
    grid, elevs="topographic__elevation", ignore_closed_nodes=True, unit_normal=None
):
    """Calculate the slope (positive magnitude of gradient) at patches.

    If ignore_closed_nodes is True, closed nodes do not affect slope
    calculations. If a closed node is present in a patch, the
    patch slope is set to zero.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.
    unit_normal : array with shape (num_patches, 3) (optional)
        The unit normal vector to each patch, if already known.

    Returns
    -------
    slopes_at_patch : n_patches-long array
        The slope (positive gradient magnitude) of each patch.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_x
    >>> S = mg.calc_slope_at_patch(elevs=z)
    >>> S.size == mg.number_of_patches
    True
    >>> np.allclose(S, np.pi / 4.0)
    True

    :meta landlab: info-patch, gradient
    """
    if unit_normal is not None:
        assert unit_normal.shape[1] == 3
        nhat = unit_normal
    else:
        nhat = grid.calc_unit_normal_at_patch(elevs)
    dotprod = nhat[:, 2]  # by definition
    cos_slopes_at_patch = dotprod  # ...because it's now a unit vector
    slopes_at_patch = np.arccos(cos_slopes_at_patch)

    if ignore_closed_nodes:
        badnodes = grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED
        bad_patches = badnodes.sum(axis=1) > 0
        slopes_at_patch[bad_patches] = 0.0

    return slopes_at_patch


def calc_grad_at_patch(
    grid,
    elevs="topographic__elevation",
    ignore_closed_nodes=True,
    unit_normal=None,
    slope_magnitude=None,
):
    """Calculate the components of the gradient at each patch.

    If ignore_closed_nodes is True, closed nodes do not affect gradient
    calculations. If a closed node is present in a patch, the
    patch gradient is set to zero in both x and y directions.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.
    unit_normal : array with shape (num_patches, 3) (optional)
        The unit normal vector to each patch, if already known.
    slope_magnitude : array with size num_patches (optional)
        The slope of each patch, if already known.

    Returns
    -------
    gradient_tuple : (x_component_at_patch, y_component_at_patch)
        Len-2 tuple of arrays giving components of gradient in the x and y
        directions, in the units of *units*.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_y
    >>> (x_grad, y_grad) = mg.calc_grad_at_patch(elevs=z)
    >>> np.allclose(y_grad, np.pi / 4.0)
    True
    >>> np.allclose(x_grad, 0.0)
    True

    :meta landlab: info-patch, gradient
    """
    if unit_normal is not None:
        assert unit_normal.shape[1] == 3
        nhat = unit_normal
    else:
        nhat = grid.calc_unit_normal_at_patch(elevs)
    if slope_magnitude is not None:
        assert slope_magnitude.size == grid.number_of_patches
        slopes_at_patch = slope_magnitude
    else:
        slopes_at_patch = grid.calc_slope_at_patch(
            elevs=elevs, ignore_closed_nodes=ignore_closed_nodes, unit_normal=nhat
        )
    theta = np.arctan2(-nhat[:, 1], -nhat[:, 0])
    x_slope_patches = np.cos(theta) * slopes_at_patch
    y_slope_patches = np.sin(theta) * slopes_at_patch

    return (x_slope_patches, y_slope_patches)


def calc_slope_at_node(
    grid,
    elevs="topographic__elevation",
    method="patch_mean",
    ignore_closed_nodes=True,
    return_components=False,
    **kwds,
):
    """Array of slopes at nodes, averaged over neighboring patches.

    Produces a value for node slope (i.e., mean gradient magnitude)
    at each node in a manner analogous to a GIS-style slope map.
    It averages the gradient on each of the patches surrounding the
    node, creating a value for node slope that better incorporates
    nonlocal elevation information. Directional information can
    still be returned through use of the return_components keyword.

    Note that under these definitions, it is not always true that:

    .. code-block:: python

        mag, cmp = mg.calc_slope_at_node(z)
        mag**2 == cmp[0] ** 2 + cmp[1] ** 2  # not always true

    If ``ignore_closed_nodes`` is ``False``, all proximal elevation
    values will be used in the calculation. If ``True``, only unclosed
    nodes are used.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    method : {'patch_mean', 'Horn'}
        By equivalence to the raster version, ``'patch_mean'`` returns a scalar
        mean on the patches; ``'Horn'`` returns a vector mean on the patches.
    ignore_closed_nodes : bool
        If ``True``, do not incorporate values at closed nodes into the
        calculation.
    return_components : bool
        If ``True``, return a tuple, (array_of_magnitude,
        (array_of_slope_x_radians, array_of_slope_y_radians)).
        If ``False``, return an array of floats of the slope magnitude.

    Returns
    -------
    float array or length-2 tuple of float arrays
        If return_components, returns (array_of_magnitude,
        (array_of_slope_x_radians, array_of_slope_y_radians)).
        If not return_components, returns an array of slope magnitudes.

    Examples
    --------

    >>> import numpy as np
    >>> from landlab import RadialModelGrid, RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_x
    >>> slopes = mg.calc_slope_at_node(elevs=z)
    >>> np.allclose(slopes, 45.0 / 180.0 * np.pi)
    True

    >>> mg = RasterModelGrid((4, 5))
    >>> z = -mg.node_y
    >>> slope_mag, cmp = mg.calc_slope_at_node(elevs=z, return_components=True)
    >>> np.allclose(slope_mag, np.pi / 4.0)
    True
    >>> np.allclose(cmp[0], 0.0)
    True
    >>> np.allclose(cmp[1], -np.pi / 4.0)
    True

    >>> mg = RadialModelGrid(n_rings=3)
    >>> z = mg.radius_at_node
    >>> slope_at_node = np.round(mg.calc_slope_at_node(elevs=z), decimals=5)

    >>> nodes_at_ring = [
    ...     np.where(np.isclose(mg.radius_at_node, radius)) for radius in range(3)
    ... ]
    >>> slope_at_node[nodes_at_ring[0]]
    array([0.85707])
    >>> slope_at_node[nodes_at_ring[1]]
    array([0.79417,  0.79417,  0.79417,  0.79417,  0.79417,  0.79417])
    >>> slope_at_node[nodes_at_ring[2]]
    array([0.77542,  0.78453,  0.78453,  0.77542,  0.77542,  0.78453,
           0.78453,  0.77542,  0.77542,  0.78453,  0.78453,  0.77542])

    :meta landlab: info-node, gradient, surface
    """
    if method not in ("patch_mean", "Horn"):
        raise ValueError("method name not understood")

    if not ignore_closed_nodes:
        patches_at_node = np.ma.masked_where(
            grid.patches_at_node == -1, grid.patches_at_node, copy=False
        )
    else:
        patches_at_node = np.ma.masked_where(
            np.logical_not(grid.patches_present_at_node),
            grid.patches_at_node,
            copy=False,
        )

    nhat = grid.calc_unit_normal_at_patch(elevs=elevs)
    slopes_at_patch = grid.calc_slope_at_patch(
        elevs=elevs, ignore_closed_nodes=ignore_closed_nodes, unit_normal=nhat
    )

    # now CAREFUL - patches_at_node is MASKED
    slopes_at_node_unmasked = slopes_at_patch[patches_at_node]
    slopes_at_node_masked = np.ma.array(
        slopes_at_node_unmasked, mask=patches_at_node.mask
    )
    slope_mag = np.mean(slopes_at_node_masked, axis=1).data

    if return_components or method == "Horn":
        (x_slope_patches, y_slope_patches) = grid.calc_grad_at_patch(
            elevs=elevs,
            unit_normal=nhat,
            ignore_closed_nodes=ignore_closed_nodes,
            slope_magnitude=slopes_at_patch,
        )
        x_slope_unmasked = x_slope_patches[patches_at_node]
        x_slope_masked = np.ma.array(x_slope_unmasked, mask=patches_at_node.mask)
        x_slope = np.mean(x_slope_masked, axis=1).data
        y_slope_unmasked = y_slope_patches[patches_at_node]
        y_slope_masked = np.ma.array(y_slope_unmasked, mask=patches_at_node.mask)
        y_slope = np.mean(y_slope_masked, axis=1).data
        mean_grad_x = x_slope
        mean_grad_y = y_slope

        if method == "Horn":
            slope_mag = np.arctan(
                np.sqrt(np.tan(y_slope_masked) ** 2 + np.tan(x_slope_masked) ** 2)
            )
            return slope_mag
        else:
            return slope_mag, (mean_grad_x, mean_grad_y)

    else:
        return slope_mag


def calc_aspect_at_node(
    grid,
    slope_component_tuple=None,
    elevs="topographic__elevation",
    unit="degrees",
    ignore_closed_nodes=True,
):
    """Get array of aspect of a surface.

    Calculates at returns the aspect of a surface. Aspect is returned as
    radians clockwise of north, unless input parameter units is set to
    'degrees'.

    If slope_component_tuple is provided, i.e., (slope_x, slope_y), the
    aspect will be calculated from these data.

    If it is not, it will be derived from elevation data at the nodes,
    which can either be a string referring to a grid field (default:
    'topographic__elevation'), or an nnodes-long numpy array of the
    values themselves.

    If ignore_closed_nodes is False, all proximal elevation values will be used
    in the calculation. If True, only unclosed nodes are used.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    slope_component_tuple : (slope_x_array, slope_y_array) (optional)
        Tuple of components of slope in the x and y directions, defined
        on nodes, if already known. If not, provide *elevs*.
    elevs : str or array (optional)
        Node field name or node array of elevations.
        If *slope_component_tuple* is not provided, must be set, but unused
        otherwise.
    unit : {'degrees', 'radians'}
        Controls the unit that the aspect is returned as.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 4))
    >>> z = mg.node_x**2 + mg.node_y**2
    >>> mg.calc_aspect_at_node(elevs=z)
    array([225.        ,  240.16585039,  255.2796318 ,  258.69006753,
           209.83414961,  225.        ,  243.54632481,  248.77808974,
           194.7203682 ,  206.45367519,  225.        ,  231.94498651,
           191.30993247,  201.22191026,  218.05501349,  225.        ])
    >>> z = z.max() - z
    >>> mg.calc_aspect_at_node(elevs=z)
    array([45.        ,  60.16585039,  75.2796318 ,  78.69006753,
           29.83414961,  45.        ,  63.54632481,  68.77808974,
           14.7203682 ,  26.45367519,  45.        ,  51.94498651,
           11.30993247,  21.22191026,  38.05501349,  45.        ])

    >>> mg = RasterModelGrid((4, 4), xy_spacing=(3.0, 2.0))
    >>> z = mg.node_x**2 + mg.node_y**2
    >>> mg.calc_aspect_at_node(elevs=z)
    array([236.30993247,  247.52001262,  259.97326008,  262.40535663,
           220.75264634,  234.41577266,  251.13402374,  255.29210302,
           201.54258265,  215.47930877,  235.73541937,  242.24162456,
           196.69924423,  209.43534223,  229.19345757,  236.30993247])

    Note that a small amount of asymmetry arises at the grid edges due
    to the "missing" nodes beyond the edge of the grid.

    :meta landlab: info-node, surface
    """
    if slope_component_tuple:
        if not isinstance(slope_component_tuple, (tuple, list)):
            raise TypeError("slope_component_tuple must be tuple")
        if len(slope_component_tuple) != 2:
            raise ValueError("slope_component_tuple must be of length 2")
    else:
        try:
            elev_array = grid.at_node[elevs]
        except (KeyError, TypeError):
            assert elevs.size == grid.number_of_nodes
            elev_array = elevs

        _, slope_component_tuple = grid.calc_slope_at_node(
            elevs=elev_array,
            ignore_closed_nodes=ignore_closed_nodes,
            return_components=True,
        )

    angle_from_x_ccw = np.arctan2(-slope_component_tuple[1], -slope_component_tuple[0])

    if unit == "degrees":
        return radians_to_degrees(angle_from_x_ccw)
    elif unit == "radians":
        angle_from_north_cw = (5.0 * np.pi / 2.0 - angle_from_x_ccw) % (2.0 * np.pi)
        return angle_from_north_cw
    else:
        raise TypeError("unit must be 'degrees' or 'radians'")



================================================
File: src/landlab/grid/grid_funcs.py
================================================
"""
Utility functions that operate on landlab grids.
------------------------------------------------

"""

import numpy as np


def resolve_values_on_links(grid, link_values):
    """Resolve link values into x and y directions.

    Takes a set of values defined on active links, and returns those values
    resolved into the x and y directions.  Two link arrays are returned:
    x, then y.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    link_values : ndarray
        Values on links.

    Returns
    -------
    tuple of ndarray
        Values resolved into x-component and y-component.
    """
    return (
        np.multiply(
            (
                (
                    grid.node_x[grid.node_at_link_head]
                    - grid.node_x[grid.node_at_link_tail]
                )
                / grid.length_of_link
            ),
            link_values,
        ),
        np.multiply(
            (
                (
                    grid.node_y[grid.node_at_link_head]
                    - grid.node_y[grid.node_at_link_tail]
                )
                / grid.length_of_link
            ),
            link_values,
        ),
    )



================================================
File: src/landlab/grid/hex.py
================================================
#! /usr/env/python
"""Python implementation of HexModelGrid, a grid class used to create and
manage structured Voronoi-Delaunay grids for 2D numerical models.
"""
import numpy
import xarray as xr

from ..core.utils import as_id_array
from ..graph import DualHexGraph
from .base import ModelGrid


class HexModelGrid(DualHexGraph, ModelGrid):
    """A grid of hexagonal cells.

    This inherited class implements a regular 2D grid with hexagonal cells and
    triangular patches. It is a special type of VoronoiDelaunay grid in which
    the initial set of points is arranged in a triangular/hexagonal lattice.

    Examples
    --------
    Create a hex grid with 2 rows of nodes. The first and third rows will
    have 2 nodes, and the second nodes.

    >>> from landlab import HexModelGrid
    >>> grid = HexModelGrid((3, 2), spacing=1.0)
    >>> grid.number_of_nodes
    7

    >>> grid = HexModelGrid((3, 3), node_layout="rect", spacing=2.0)
    >>> grid.status_at_node
    array([1, 1, 1, 1, 0, 1, 1, 1, 1], dtype=uint8)
    >>> grid = HexModelGrid((3, 3), node_layout="rect", orientation="vertical")
    >>> grid.status_at_node
    array([1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=uint8)
    >>> grid = HexModelGrid((4, 4), node_layout="rect", orientation="vertical")
    >>> grid.status_at_node
    array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1], dtype=uint8)
    >>> grid.boundary_nodes
    array([ 0,  1,  2,  3,  4,  7,  8, 11, 12, 13, 14, 15])
    >>> grid = HexModelGrid((3, 4), node_layout="rect")
    >>> grid.status_at_node
    array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1], dtype=uint8)
    """

    def __init__(
        self,
        shape,
        spacing=1.0,
        xy_of_lower_left=(0.0, 0.0),
        orientation="horizontal",
        node_layout="hex",
        reorient_links=True,
        xy_of_reference=(0.0, 0.0),
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
    ):
        """Create a grid of hexagonal cells.

        Create a regular 2D grid with hexagonal cells and triangular patches.
        It is a special type of :class:`~.VoronoiModelGrid` in which the initial set
        of points is arranged in a triangular/hexagonal lattice.

        Parameters
        ----------
        shape : tuple of int
            Number of rows and columns of nodes.
        spacing : float, optional
            Node spacing.
        xy_of_lower_left : tuple of float, optional
            Minimum x-of-node and y-of-node values. Depending on the grid
            no node may be present at this coordinate. Default is (0., 0.).
        xy_of_reference : tuple of float, optional
            Coordinate value in projected space of the reference point,
            `xy_of_lower_left`. Default is (0., 0.)
        orientation : str, optional
            One of the 3 cardinal directions in the grid, either 'horizontal'
            (default) or 'vertical'
        node_layout : {"hex", "rect"}
            The grid layout of nodes.
        reorient_links : bool, optional
            Whether or not to re-orient all links to point between -45 deg
            and +135 deg clockwise from "north" (i.e., along y axis). default
            is True.

        Returns
        -------
        HexModelGrid
            A newly-created grid.

        Examples
        --------
        Create a hex grid with 2 rows of nodes. The first and third rows will
        have 2 nodes, and the second nodes.

        >>> from landlab import HexModelGrid
        >>> hmg = HexModelGrid((3, 2), spacing=1.0)
        >>> hmg.number_of_nodes
        7
        """
        self._xy_of_lower_left = tuple(numpy.asarray(xy_of_lower_left, dtype=float))

        DualHexGraph.__init__(
            self,
            shape,
            spacing=spacing,
            xy_of_lower_left=self.xy_of_lower_left,
            orientation=orientation,
            node_layout=node_layout,
            sort=True,
        )
        ModelGrid.__init__(
            self,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
            xy_of_reference=xy_of_reference,
        )

        self._node_status = numpy.full(
            self.number_of_nodes, self.BC_NODE_IS_CORE, dtype=numpy.uint8
        )
        self._node_status[self.perimeter_nodes] = self.BC_NODE_IS_FIXED_VALUE

    @classmethod
    def from_dict(cls, kwds):
        args = (kwds.pop("shape"),)
        return cls(*args, **kwds)

    @classmethod
    def from_dataset(cls, dataset):
        return cls(
            tuple(dataset["shape"].values),
            spacing=dataset["spacing"],
            xy_of_lower_left=dataset["xy_of_lower_left"],
            orientation=dataset.attrs["orientation"],
            node_layout=dataset.attrs["node_layout"],
        )

    def as_dataset(self, include="*", exclude=None, time=None):
        dataset = xr.Dataset(
            {
                "shape": (("dim",), list(self.shape)),
                "spacing": self.spacing,
                "xy_of_lower_left": (("dim",), list(self.xy_of_lower_left)),
            },
            attrs={
                "grid_type": "triangular",
                "node_layout": self.node_layout,
                "orientation": self.orientation,
            },
        )
        return dataset.update(
            super().as_dataset(include=include, exclude=exclude, time=None)
        )

    @property
    def xy_of_lower_left(self):
        """Return (x, y) of the reference point."""
        return self._xy_of_lower_left

    @xy_of_lower_left.setter
    def xy_of_lower_left(self, xy_of_lower_left):
        """Set a new value for the xy_of_lower_left."""
        dx = self.xy_of_lower_left[0] - xy_of_lower_left[0]
        dy = self.xy_of_lower_left[1] - xy_of_lower_left[1]
        # self._xy_of_node -= (dx, dy)
        with self.thawed():
            self.x_of_node[:] -= dx
            self.y_of_node[:] -= dy

        self._xy_of_lower_left = tuple(xy_of_lower_left)

    @property
    def number_of_node_columns(self):
        """Number of node columns hex grid.

        Number of node columns in a rectangular-shaped and/or
        vertically oriented hex grid.

        Returns the number of columns, including boundaries.

        Notes
        -----
        Will generate an error if called with a hex-shaped, horizontally
        aligned grid.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((5, 5), node_layout="rect")
        >>> grid.number_of_node_columns
        5

        :meta landlab: info-grid, info-node
        """
        return self.shape[1]

    @property
    def number_of_node_rows(self):
        """Number of node rows in a rectangular-shaped and/or horizontally
        oriented hex grid.

        Returns the number of rows, including boundaries.

        Notes
        -----
        Will generate an error if called with a hex-shaped, vertically
        aligned grid.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((5, 5), node_layout="rect")
        >>> grid.number_of_node_rows
        5

        :meta landlab: info-grid, info-node
        """
        return self._shape[0]

    def node_row_and_column(self, node_id):
        """Row and column from node ID, FOR VERT RECT CONFIGURATION ONLY.

        Examples
        --------
        >>> from landlab import HexModelGrid
        >>> grid = HexModelGrid((3, 4), node_layout="rect", orientation="vertical")
        >>> grid.node_row_and_column(5)
        (1, 2)
        >>> grid = HexModelGrid((3, 5), node_layout="rect", orientation="vertical")
        >>> grid.node_row_and_column(13)
        (2, 1)
        """
        assert self.orientation[0] == "v", "grid orientation must be vertical"
        try:
            (nr, nc) = self._shape
        except AttributeError as exc:
            raise AttributeError(
                "Only rectangular Hex grids have defined rows and columns."
            ) from exc

        row = node_id // nc
        n_mod_nc = node_id % nc
        half_nc = (nc + 1) // 2
        col = 2 * (n_mod_nc % half_nc) + n_mod_nc // half_nc
        return (row, col)

    def _configure_hexplot(self, data, data_label=None, color_map=None):
        """Sets up necessary information for making plots of the hexagonal grid
        colored by a given data element.

        Parameters
        ----------
        data : str or (n_link,) ndarray
            Data field to be colored
        data_label : str, optional
            Label for colorbar
        color_map : matplotlib colormap object, optional
            Color map to apply (defaults to "jet")

        Notes
        -----
        Creates and stores a PatchCollection representing the hexagons. Also
        stores a handle to the current plotting axis. Both of these are then
        used by hexplot().
        """
        import matplotlib
        from matplotlib.collections import PatchCollection
        from matplotlib.patches import Polygon
        from numpy import array
        from numpy import sqrt
        from numpy import zeros

        # color
        if color_map is None:
            color_map = matplotlib.cm.jet

        # geometry
        apothem = self.spacing / 2.0
        # distance from node to each hexagon cell vertex
        radius = 2.0 * apothem / sqrt(3.0)

        # offsets from node x,y position
        offsets = zeros((6, 2))
        poly_verts = zeros((6, 2))

        # Figure out whether the orientation is horizontal or vertical
        if self.orientation[0] == "h":  # horizontal
            offsets[:, 0] = array([0.0, apothem, apothem, 0.0, -apothem, -apothem])
            offsets[:, 1] = array(
                [
                    radius,
                    radius / 2.0,
                    -radius / 2.0,
                    -radius,
                    -radius / 2.0,
                    radius / 2.0,
                ]
            )
        else:  # vertical
            offsets[:, 0] = array(
                [
                    radius / 2.0,
                    radius,
                    radius / 2.0,
                    -radius / 2.0,
                    -radius,
                    -radius / 2.0,
                ]
            )
            offsets[:, 1] = array([apothem, 0.0, -apothem, -apothem, 0.0, apothem])

        patches = []
        for i in range(self.number_of_nodes):
            poly_verts[:, 0] = self.node_x[i] + offsets[:, 0]
            poly_verts[:, 1] = self.node_y[i] + offsets[:, 1]
            p = Polygon(poly_verts, True)
            patches.append(p)

        self._hexplot_pc = PatchCollection(
            patches, cmap=color_map, edgecolor="none", linewidth=0.0
        )

        self._hexplot_configured = True

    def hexplot(self, data, data_label=None, color_map=None):
        """Create a plot of the grid elements.

        Creates a plot of the grid and one node-data field, showing hexagonal
        cells colored by values in the field.

        Parameters
        ----------
        data : str or (n_nodes,) ndarray
            Data field to be colored.
        data_label : str, optional
            Label for colorbar.
        color_map : matplotlib colormap object, None
            Color map to apply (defaults to "jet")

        See also
        --------
        :func:`~.plot.imshow_grid`
            Another Landlab function capable of producing hexplots, with a
            fuller-featured set of options.


        :meta landlab: info-grid
        """
        import copy

        import matplotlib.pyplot as plt
        from numpy import amax
        from numpy import amin
        from numpy import array

        try:
            self._hexplot_configured
        except AttributeError:
            self._configure_hexplot(data, data_label, color_map)
        else:
            if self._hexplot_pc.cmap != color_map:
                self._configure_hexplot(data, data_label, color_map)

        # Handle *data*: if it's a numpy array, then we consider it the
        # data to be plotted. If it's a string, we consider it the name of the
        # node-field to plot, and we fetch it.
        if type(data) is str:
            data_label = data
            data = self.at_node[data]

        ax = plt.gca()
        self._hexplot_pc.set_array(array(data))
        copy_of_pc = copy.copy(self._hexplot_pc)
        ax.add_collection(copy_of_pc)
        plt.xlim([amin(self.node_x) - self.spacing, amax(self.node_x) + self.spacing])
        plt.ylim([amin(self.node_y) - self.spacing, amax(self.node_y) + self.spacing])

        return ax

    def set_watershed_boundary_condition_outlet_id(
        self, outlet_id, node_data, nodata_value=-9999.0
    ):
        """Set the boundary conditions for a watershed.

        All nodes with ``nodata_value`` are set to :attr:`~.NodeStatus.CLOSED`.
        All nodes with data values are set to :attr:`~.NodeStatus.CORE`, with the
        exception that the outlet node is set to a :attr:`~.NodeStatus.FIXED_VALUE`.

        Note that the outer ring of the HexModelGrid is set to
        :attr:`~.NodeStatus.CLOSED`, even if there are nodes that have values.
        The only exception to this would be if the outlet node is on the boundary,
        which is acceptable.

        Assumes that the id of the outlet is already known.

        This assumes that the grid has a single watershed.  If this is not
        the case this will not work.

        Parameters
        ----------
        outlet_id : int
            id of the outlet node
        node_data : str or (n_nodes,) ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        nodata_value : float, optional
            Value that indicates an invalid value.

        Examples
        --------
        The example will use a *HexModelGrid* with node data values
        as illustrated::

                1. ,  2. ,  3. ,  4. ,
            0.5,  1.5,  2.5,  3.5,  4.5,
          0. ,  1. ,  2. ,  3. ,  4. ,  5.,
            0.5,  1.5,  2.5,  3.5,  4.5,
                1. ,  2. ,  3. ,  4.

        >>> from landlab import HexModelGrid
        >>> hmg = HexModelGrid((5, 4))
        >>> z = hmg.add_zeros("topographic__elevation", at="node")
        >>> z += hmg.x_of_node + 1.0

        >>> hmg.status_at_node
        array([1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,
           1], dtype=uint8)

        >>> outlet = hmg.set_watershed_boundary_condition_outlet_id(9, z, -9999.0)
        >>> hmg.status_at_node
        array([4, 4, 4, 4, 4, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4,
           4], dtype=uint8)

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        # make ring of no data nodes
        self.status_at_node[self.boundary_nodes] = self.BC_NODE_IS_CLOSED

        # set no data nodes to inactive boundaries
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

        # set the boundary condition (fixed value) at the outlet_node
        self.status_at_node[outlet_id] = self.BC_NODE_IS_FIXED_VALUE

    def set_watershed_boundary_condition(
        self, node_data, nodata_value=-9999.0, return_outlet_id=False
    ):
        """Find the node adjacent to a boundary node with the smallest value.

        This node is set as the outlet.  The outlet node must have a data
        value.  Can return the outlet id as a one element numpy array if
        ``return_outlet_id`` is set to `True`.

        All nodes with ``nodata_value`` are set to :attr:`~.NodeStatus.CLOSED`
        (grid.status_at_node == 4). All nodes with data values are set to
        :attr:`~.NodeStatus.CORE` (grid.status_at_node == 0), with the exception
        that the outlet node is set to a :attr:`~.NodeStatus.FIXED_VALUE`
        (grid.status_at_node == 1).

        Note that the outer ring (perimeter) of the grid is set to
        :attr:`~.NodeStatus.CLOSED`, even if there are nodes that have values. The only
        exception to this would be if the outlet node is on the perimeter, which
        is acceptable.

        This routine assumes that all of the ``nodata_value`` are on the outside of
        the data values. In other words, there are no islands of ``nodata_value``
        surrounded by nodes with data.

        This also assumes that the grid has a single watershed (that is a single
        outlet node).

        Parameters
        ----------
        node_data : str or (n_nodes,) ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        nodata_value : float, optional
            Value that indicates an invalid value.
        return_outlet_id : bool, optional
            Indicates whether or not to return the id of the found outlet

        Examples
        --------
        The example will use a :class:`~.HexModelGrid` with node data values
        as illustrated::

                1. ,  2. ,  3. ,  4. ,
            0.5,  1.5,  2.5,  3.5,  4.5,
          0. ,  1. ,  2. ,  3. ,  4. ,  5.,
            0.5,  1.5,  2.5,  3.5,  4.5,
                1. ,  2. ,  3. ,  4.

        >>> from landlab import HexModelGrid
        >>> hmg = HexModelGrid((5, 4))
        >>> z = hmg.add_zeros("topographic__elevation", at="node")
        >>> z += hmg.x_of_node + 1.0
        >>> out_id = hmg.set_watershed_boundary_condition(z, -9999.0, True)
        >>> out_id
        array([9])
        >>> hmg.status_at_node
        array([4, 4, 4, 4, 4, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4,
           4], dtype=uint8)

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        # make ring of no data nodes
        self.status_at_node[self.boundary_nodes] = self.BC_NODE_IS_CLOSED

        # set no data nodes to inactive boundaries
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

        # locs is a list that contains locations where
        # node data is not equal to the nodata value
        locs = numpy.where(node_data != nodata_value)
        if len(locs) < 1:
            raise ValueError("All data values are no_data values")

        # now find minimum of the data values
        min_val = numpy.min(node_data[locs])

        # now find where minimum values are
        min_locs = numpy.where(node_data == min_val)[0]

        # check all the locations with the minimum value to see if one
        not_found = True
        while not_found:
            # now check the min locations to see if any are next to
            # a boundary node
            local_not_found = True
            # next_to_boundary = []

            # check all nodes rather than selecting the first node that meets
            # the criteria
            # for i in range(len(min_locs)):
            #     next_to_boundary.append(self.node_has_boundary_neighbor()[min_locs[i])]
            next_to_boundary = self.node_has_boundary_neighbor()[(min_locs,)]
            # if any of those nodes were adjacent to the boundary, check
            # that  there is only one. If only one, set as outlet loc, else,
            # raise a value error
            if numpy.any(next_to_boundary):
                local_not_found = False
                if sum(next_to_boundary) > 1:
                    potential_locs = min_locs[
                        numpy.where(numpy.asarray(next_to_boundary))[0]
                    ]
                    raise ValueError(
                        "Grid has two potential outlet nodes."
                        "They have the following node IDs: \n"
                        + str(potential_locs)
                        + "\nUse the method set_watershed_boundary_condition_outlet_id "
                        "to explicitly select one of these "
                        "IDs as the outlet node."
                    )
                else:
                    outlet_loc = min_locs[numpy.where(next_to_boundary)[0][0]]

            # checked all of the min vals, (so done with inner while)
            # and none of the min values were outlet candidates
            if local_not_found:
                # need to find the next largest minimum value
                # first find the locations of all values greater
                # than the old minimum
                # not done with outer while
                locs = numpy.where((node_data > min_val) & (node_data != nodata_value))
                # now find new minimum of these values
                min_val = numpy.min(node_data[locs])
                min_locs = numpy.where(node_data == min_val)[0]
            else:
                # if locally found, it is also globally found
                # so done with outer while
                not_found = False

        # set outlet boundary condition
        self.status_at_node[outlet_loc] = self.BC_NODE_IS_FIXED_VALUE

        if return_outlet_id:
            return as_id_array(numpy.array([outlet_loc]))



================================================
File: src/landlab/grid/hex_mappers.py
================================================
#!/usr/bin/env python3
"""Grid element mappers that are specific to hex grids.

Mapping functions unique to hex grids
+++++++++++++++++++++++++++++++++++++

.. autosummary::

    ~map_link_vector_components_to_node_hex
"""
import enum

import numpy as np


class LinkAtNode(enum.IntEnum):
    EAST = 0  # array column of link to east/right of node, horizontal grid
    ENE = 0  # array column of link to ene/upper right of node, vertical grid
    NNE = 1  # array column of link to nne/upper right of node, horizontal grid
    NORTH = 1  # array column of link to north/top of node, vertical grid
    NNW = 2  # array column of link to nnw/upper left of node, horizontal grid
    WNW = 2  # array column of link to wnw/upper left of node, vertical grid
    WEST = 3  # array column of link to west/left of node, horizontal grid
    WSW = 3  # array column of link to wsw/lower left of node, vertical grid
    SSW = 4  # array column of link to ssw/lower left of node, horizontal grid
    SOUTH = 4  # array column of link to south/bottom of node, vertical grid
    SSE = 5  # array column of link to sse/lower right of node, horizontal grid
    ESE = 5  # array column of link to ese/lower right of node, vertical grid


SIN60 = np.sin(np.deg2rad(60.0))


def map_link_vector_components_to_node_hex(grid, data_at_link):
    """Map (x,y) components of link data data_at_link onto nodes of hex grid.

    Parameters
    ----------
    grid : HexModelGrid
        Landlab HexModelGrid object
    data_at_links : ndarray of float x number of links
        Data to be mapped

    Returns
    -------
    (x_component, y_component) : tuple of ndarray
        The *x* and *y* components of the field at each node. Both *x*
        and *y* components for non-*core* nodes are set to zero.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import HexModelGrid
    >>> from landlab.grid.mappers import map_link_vector_components_to_node

    >>> grid = HexModelGrid((3, 3))
    >>> link_data = np.full(grid.number_of_links, 0.5 * 3.0**0.5)
    >>> link_data[np.isclose(grid.angle_of_link, 0.0)] = 0.0

    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vx
    array([0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
    >>> vy
    array([0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.])

    >>> link_data = np.arange(grid.number_of_links)
    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vx
    array([0. ,  0. ,  0. ,  0. ,  8.5,  9.5,  0. ,  0. ,  0. ,  0. ])

    >>> link_data = np.full(grid.number_of_links, 0.5 * 3.0**0.5)
    >>> link_data[np.isclose(grid.angle_of_link, 2.0 / 3.0 * np.pi)] = 0.0

    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> np.round(vx, 3)
    array([0. ,  0. ,  0. ,  0. ,  0.866,  0.866,  0. ,  0. ,  0. ,  0. ])
    >>> vy
    array([0. ,  0. ,  0. ,  0. ,  0.5,  0.5,  0. ,  0. ,  0. ,  0. ])

    >>> grid = HexModelGrid((3, 3), orientation="vertical")
    >>> link_data = np.arange(grid.number_of_links)

    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vy
    array([ 0. , 0. ,  0. ,  5.5,  0. ,  0. , 12.5,  0. ,  0. ,  0. ])

    >>> link_data = np.full(grid.number_of_links, 0.5 * 3.0**0.5)
    >>> link_data[np.isclose(grid.angle_of_link, np.pi / 2.0)] = 0.0

    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vx
    array([0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.])
    >>> vy
    array([0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])

    Notes
    -----
    Calculation is only made for core nodes; boundary nodes receive zeros.

    For a grid with orientation='horizontal', one of the 3 link orientations
    is horizontal. The x component is therefore taken as the average value of
    the links to the east (right) and west (left). For a grid with
    orientation='vertical', the same principle applies for the y component:
    it is the average of the link values to the north/top and south/bottom.

    In general, the theory behind the approach is that there exists a
    "true" vector field that has been projected onto the links.
    Let $V = (v_x, v_y)$ be the true vector. The projection of $V$ onto two links
    with unit vectors $l_1 = (l_{1x}, l_{1y})$ and $l_2 = (l_{2x}, l_{2y})$
    yields the following formula for the scalar magnitude, or component, of
    the two link vectors::

        L_1 = V dot l_1
        L_2 = V dot l_2

    We know $L_1$ and $L_2$: they are the values associated with two adjacent
    links, and here we're interested either in the nne and nnw oriented links
    (in a horizontally oriented grid) or the ene and ese oriented links (on a
    vertically oriented grid). We also know the unit vectors $l_1$ and $l_2$,
    which derive from the link orientations (they involve sin 60 and
    cos 60). So we have two equations with two unknowns: the vector
    components $v_x$ and $v_y$.

    In practice, we use this math to obtain the $y$ component for a
    horizontal grid, and the $x$ component for a vertical grid. The opposite
    component is found directly from the horizontal or vertical links,
    respectively.

    Note that in the above doc tests, we take advantage of the fact that
    sin 60 deg = half the square root of 3 (no need to import math or numpy).
    """
    cores = grid.core_nodes

    x_component = np.zeros(grid.number_of_nodes)
    y_component = np.zeros(grid.number_of_nodes)

    if grid.orientation[0] == "h":
        east = grid.links_at_node[cores, LinkAtNode.EAST]
        nne = grid.links_at_node[cores, LinkAtNode.NNE]
        nnw = grid.links_at_node[cores, LinkAtNode.NNW]
        west = grid.links_at_node[cores, LinkAtNode.WEST]
        sse = grid.links_at_node[cores, LinkAtNode.SSE]
        ssw = grid.links_at_node[cores, LinkAtNode.SSW]

        x_component[cores] = (data_at_link[west] + data_at_link[east]) / 2
        vyn = (3.0 * data_at_link[nnw] - data_at_link[nne]) / (2 * SIN60)
        vys = (3.0 * data_at_link[ssw] - data_at_link[sse]) / (2 * SIN60)
        y_component[cores] = (vyn + vys) / 2
    else:
        ene = grid.links_at_node[cores, LinkAtNode.ENE]
        north = grid.links_at_node[cores, LinkAtNode.NORTH]
        wnw = grid.links_at_node[cores, LinkAtNode.WNW]
        wsw = grid.links_at_node[cores, LinkAtNode.WSW]
        south = grid.links_at_node[cores, LinkAtNode.SOUTH]
        ese = grid.links_at_node[cores, LinkAtNode.ESE]
        y_component[cores] = (data_at_link[north] + data_at_link[south]) / 2

        vxe = (3.0 * data_at_link[ese] - data_at_link[ene]) / (2 * SIN60)
        vxw = (3.0 * data_at_link[wsw] - data_at_link[wnw]) / (2 * SIN60)
        x_component[cores] = (vxe + vxw) / 2

    return x_component, y_component



================================================
File: src/landlab/grid/icosphere.py
================================================
"""
IcosphereGlobalGrid class

Greg Tucker, CU Boulder, November 2023
"""

import numpy as np

from landlab.graph.quasi_spherical.dual_icosphere import DualIcosphereGraph
from landlab.grid.base import ModelGrid
from landlab.grid.nodestatus import NodeStatus


class IcosphereGlobalGrid(DualIcosphereGraph, ModelGrid):
    """
    Icosphere-based quasi-spherical ("global") Landlab grid.

    The default configuration is a spherical grid of unit radius that
    forms the spherical version an icosahedron (20 triangular patches,
    12 nodes), with the dual complement representing a dodecahedron
    (12 hexagonal cells, 20 corners). The mesh_densification_level
    parameter allows you to densify this initial shape by subdividing
    each triangular patch into four triangles, with corresponding
    addition of nodes (as the triangle vertices), together with
    corresponding cells and corners.

    If you specify mesh_densification_level=1, you get a soccer ball:
    a combination of pentagons and hexagons as cells. Further
    densification produces more hexagons (as cells; the patches are
    always triangles).

    Because there are no boundaries, there is a 1:1 relationship between
    nodes and cells (every node has a cell, and the ID of every cell is
    the same as the ID of its node), and similarly for corners and patches.

    Link length is calculated as the arc-length of the sphere between
    the link's two nodes. Patch area is calculated as the spherical
    (not flat) triangle area. Cell area is calculated by summing
    spherical triangles (pentagonal cell area is the sum of 5 triangles
    within the pentagon, while hexagonal cell area is the sum of 6
    triangles).

    Topography relative to the sphere can be created by adding a field
    that represents height relative to the sphere's surface. Topography
    could, if desired, be configured to represent an ellipsoid or
    geoid surface, but the patch/cell areas and link/face lengths are
    computed as if on a sphere (i.e., the present version of the
    component does not include algorithms to calculate distances or
    areas on an ellipsoid).

    The grid-generation and refinement algorithms are implemented in the
    superclass DualIcosphereGraph.

    Parameters
    ----------
    radius : float, optional
        Radius of the icosphere (default 1)
    mesh_densification_level : int, optional
        Number of times to densify the initial icosahedron (default 0)

    Examples
    --------
    >>> ico = IcosphereGlobalGrid()
    >>> ico.number_of_nodes
    12
    >>> ico.number_of_patches
    20
    >>> ico.number_of_corners
    20
    >>> ico.number_of_cells
    12
    """

    def __init__(self, radius=1.0, mesh_densification_level=0):
        """Initialize the IcosphereGlobalGrid"""
        DualIcosphereGraph.__init__(self, radius, mesh_densification_level)
        ModelGrid.__init__(self)

        self._node_status = np.full(
            self.number_of_nodes, NodeStatus.CORE, dtype=np.uint8
        )



================================================
File: src/landlab/grid/linkorientation.py
================================================
from enum import IntFlag


class LinkOrientation(IntFlag):
    """Define the link orientations."""

    E = 1
    ENE = 2
    NNE = 4
    N = 8
    NNW = 16
    ESE = 32



================================================
File: src/landlab/grid/linkstatus.py
================================================
#! /usr/bin/env python
from enum import IntEnum
from enum import unique

import numpy as np

from .nodestatus import NodeStatus


@unique
class LinkStatus(IntEnum):
    """Define the link types"""

    #: Indicate a link is *active*, and can carry flux
    ACTIVE = 0
    #: Indicate a link has a fixed (gradient) value, & behaves as a boundary
    FIXED = 2
    #: Indicate a link is *inactive*, and cannot carry flux
    INACTIVE = 4


def is_fixed_link(node_status_at_link):
    """Find links that are fixed.

    A link is fixed if it connects a core node with a fixed value
    boundary node.

    Parameters
    ----------
    node_status_at_link : ndarray of int, shape `(n_links, 2)`
        Node status a link tail and head.

    Returns
    -------
    ndarray of bool, shape `(n_links, )`
        True if link is fixed.

    Examples
    --------
    >>> from landlab.grid.linkstatus import is_fixed_link
    >>> from landlab import NodeStatus
    >>> is_fixed_link([NodeStatus.CORE, NodeStatus.FIXED_GRADIENT])
    array([ True])

    >>> is_fixed_link([NodeStatus.CORE, NodeStatus.FIXED_VALUE])
    array([False])

    >>> is_fixed_link(
    ...     [
    ...         [NodeStatus.FIXED_GRADIENT, NodeStatus.CORE],
    ...         [NodeStatus.CORE, NodeStatus.CORE],
    ...     ]
    ... )
    array([ True, False])
    """
    node_status_at_link = np.asarray(node_status_at_link).reshape((-1, 2))

    is_core_node = node_status_at_link == NodeStatus.CORE
    is_fixed_gradient_node = node_status_at_link == NodeStatus.FIXED_GRADIENT

    return (is_core_node[:, 0] & is_fixed_gradient_node[:, 1]) | (
        is_fixed_gradient_node[:, 0] & is_core_node[:, 1]
    )


def is_inactive_link(node_status_at_link):
    """Find links that are inactive.

    A link is inactive if it connects two boundary nodes or one of
    its nodes is closed.

    Parameters
    ----------
    node_status_at_link : ndarray of int, shape `(n_links, 2)`
        Node status a link tail and head.

    Returns
    -------
    ndarray of bool, shape `(n_links, )`
        True if link is isactive.

    Examples
    --------
    >>> from landlab.grid.linkstatus import is_inactive_link
    >>> from landlab import NodeStatus
    >>> is_inactive_link([NodeStatus.CORE, NodeStatus.CLOSED])
    array([ True])

    >>> is_inactive_link([NodeStatus.FIXED_GRADIENT, NodeStatus.FIXED_VALUE])
    array([ True])

    >>> is_inactive_link(
    ...     [
    ...         [NodeStatus.FIXED_GRADIENT, NodeStatus.CLOSED],
    ...         [NodeStatus.CORE, NodeStatus.CORE],
    ...     ]
    ... )
    array([ True, False])
    """
    node_status_at_link = np.asarray(node_status_at_link).reshape((-1, 2))

    is_core = node_status_at_link == NodeStatus.CORE
    is_fixed_value = node_status_at_link == NodeStatus.FIXED_VALUE
    is_fixed_gradient = node_status_at_link == NodeStatus.FIXED_GRADIENT
    is_closed = node_status_at_link == NodeStatus.CLOSED
    is_boundary_node = is_fixed_value | is_fixed_gradient | is_closed

    return (
        (is_boundary_node[:, 0] & is_boundary_node[:, 1])
        | (is_closed[:, 0] & is_core[:, 1])
        | (is_core[:, 0] & is_closed[:, 1])
    )


def is_active_link(node_status_at_link):
    """Find links that are active.

    A link is active if it connects a core node with another core
    node or a fixed value boundary.

    Parameters
    ----------
    node_status_at_link : ndarray of int, shape `(n_links, 2)`
        Node status a link tail and head.

    Returns
    -------
    ndarray of bool, shape `(n_links, )`
        True if link is isactive.

    Examples
    --------
    >>> from landlab.grid.linkstatus import is_active_link
    >>> from landlab import NodeStatus
    >>> is_active_link([NodeStatus.CORE, NodeStatus.FIXED_GRADIENT])
    array([False])

    >>> is_active_link([NodeStatus.CORE, NodeStatus.FIXED_VALUE])
    array([ True])

    >>> is_active_link(
    ...     [
    ...         [NodeStatus.FIXED_GRADIENT, NodeStatus.CORE],
    ...         [NodeStatus.CORE, NodeStatus.CORE],
    ...     ]
    ... )
    array([False, True])
    """
    node_status_at_link = np.asarray(node_status_at_link).reshape((-1, 2))

    is_core_node = node_status_at_link == NodeStatus.CORE
    is_fixed_value_node = node_status_at_link == NodeStatus.FIXED_VALUE
    return (
        (is_core_node[:, 0] & is_core_node[:, 1])
        | (is_core_node[:, 0] & is_fixed_value_node[:, 1])
        | (is_fixed_value_node[:, 0] & is_core_node[:, 1])
    )


def set_status_at_link(node_status_at_link, out=None):
    n_links = len(node_status_at_link)

    if out is None:
        out = np.full(n_links, 255, dtype=np.uint8)

    _is_fixed_link = is_fixed_link(node_status_at_link)
    _is_active_link = is_active_link(node_status_at_link)
    _is_inactive_link = is_inactive_link(node_status_at_link)

    assert np.all(
        np.sum(np.vstack((_is_active_link, _is_inactive_link, _is_fixed_link)), axis=0)
        == 1
    )

    out[_is_inactive_link] = LinkStatus.INACTIVE
    out[_is_active_link] = LinkStatus.ACTIVE
    out[_is_fixed_link] = LinkStatus.FIXED

    return out



================================================
File: src/landlab/grid/mappers.py
================================================
#! /usr/bin/env python
"""Map values from one grid element to another.

Grid mapping functions
+++++++++++++++++++++++

.. autosummary::

    ~map_link_head_node_to_link
    ~map_link_tail_node_to_link
    ~map_min_of_link_nodes_to_link
    ~map_max_of_link_nodes_to_link
    ~map_mean_of_link_nodes_to_link
    ~map_value_at_min_node_to_link
    ~map_value_at_max_node_to_link
    ~map_node_to_cell
    ~map_min_of_node_links_to_node
    ~map_max_of_node_links_to_node
    ~map_upwind_node_link_max_to_node
    ~map_downwind_node_link_max_to_node
    ~map_upwind_node_link_mean_to_node
    ~map_downwind_node_link_mean_to_node
    ~map_value_at_upwind_node_link_max_to_node
    ~map_value_at_downwind_node_link_max_to_node
    ~map_link_vector_components_to_node
    ~map_node_to_link_linear_upwind
    ~map_node_to_link_lax_wendroff

Each link has a *tail* and *head* node. The *tail* nodes are located at the
start of a link, while the head nodes are located at end of a link.

Below, the numbering scheme for links in :class:`~.RasterModelGrid` is illustrated
with an example of a four-row by five column grid (4x5). In this example,
each ``*`` (or ``X``) is a node, the lines represent links, and the ``^`` and ``>`` symbols
indicate the direction and *head* of each link. Link heads in the
:class:`~.RasterModelGrid` always point in the cardinal directions North (N) or East
(E).::

    *--27-->*--28-->*--29-->*--30-->*
    ^       ^       ^       ^       ^
   22      23      24      25      26
    |       |       |       |       |
    *--18-->*--19-->*--20-->*--21-->*
    ^       ^       ^       ^       ^
    13      14      15      16     17
    |       |       |       |       |
    *---9-->*--10-->X--11-->*--12-->*
    ^       ^       ^       ^       ^
    4       5       6       7       8
    |       |       |       |       |
    *--0--->*---1-->*--2--->*---3-->*

For example, node ``X`` has four link-neighbors. From south and going clockwise,
these neighbors are ``[6, 10, 15, 11]``. Both link 6 and link 10 have node ``X`` as
their *head* node, while links 15 and 11 have node ``X`` as their *tail* node.
"""

import numpy as np


def cartesian_to_polar(x, y):
    """Return 2d polar coordinates (r, theta) equivalent to given cartesian
    coordinates (x, y).

    Examples
    --------
    >>> r, theta = cartesian_to_polar(1.0, 1.0)
    >>> int(r * 1000)
    1414
    >>> int(theta * 1000)
    785
    """
    return np.sqrt(x**2 + y**2), np.arctan2(y, x)  # r, theta


def map_link_head_node_to_link(grid, var_name, out=None):
    """Map values from a link head nodes to links.

    Iterate over a grid and identify the node at the *head*. For each link,
    the value of *var_name* at the *head* node is mapped to the corresponding
    link.

    In a RasterModelGrid, each one node has two adjacent "link heads". This
    means each node value is mapped to two corresponding links.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_link_head_node_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["z"] = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
    >>> map_link_head_node_to_link(rmg, "z")
    array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   5.,   6.,   7.,   8.,
          9.,  10.,  11.,   9.,  10.,  11.])

    >>> values_at_links = rmg.empty(at="link")
    >>> rtn = map_link_head_node_to_link(rmg, "z", out=values_at_links)
    >>> values_at_links
    array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   5.,   6.,   7.,   8.,
          9.,  10.,  11.,   9.,  10.,  11.])
    >>> rtn is values_at_links
    True

    :meta landlab: info-node, info-link, map
    """
    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    if out is None:
        out = grid.empty(at="link")
    out[:] = var_name[grid.node_at_link_head]

    return out


def map_link_tail_node_to_link(grid, var_name, out=None):
    """Map values from a link tail nodes to links.

    map_link_tail_node_to_link iterates across the grid and
    identifies the node at the "tail", or the "from" node for each link. For
    each link, the value of 'var_name' at the "from" node is mapped to the
    corresponding link.

    In a RasterModelGrid, each one node has two adjacent "link tails". This
    means each node value is mapped to two corresponding links.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_link_tail_node_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["z"] = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
    >>> map_link_tail_node_to_link(rmg, "z")
    array([  0.,   1.,   2.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   4.,
             5.,   6.,   7.,   8.,   9.,  10.])

    >>> values_at_links = rmg.empty(at="link")
    >>> rtn = map_link_tail_node_to_link(rmg, "z", out=values_at_links)
    >>> values_at_links
    array([  0.,   1.,   2.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   4.,
             5.,   6.,   7.,   8.,   9.,  10.])
    >>> rtn is values_at_links
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    out[:] = var_name[grid.node_at_link_tail]

    return out


def map_min_of_link_nodes_to_link(grid, var_name, out=None):
    """Map the minimum of a link's nodes to the link.

    map_min_of_link_nodes_to_link iterates across the grid and
    identifies the node values at both the "head" and "tail" of a given link.
    This function evaluates the value of 'var_name' at both the "to" and
    "from" node. The minimum value of the two node values is then mapped to
    the link.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_min_of_link_nodes_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field(
    ...     "z",
    ...     [
    ...         [0, 1, 2, 3],
    ...         [7, 6, 5, 4],
    ...         [8, 9, 10, 11],
    ...     ],
    ...     at="node",
    ... )
    >>> map_min_of_link_nodes_to_link(rmg, "z")
    array([  0.,   1.,   2.,   0.,   1.,   2.,   3.,   6.,   5.,   4.,   7.,
             6.,   5.,   4.,   8.,   9.,  10.])

    >>> values_at_links = rmg.empty(at="link")
    >>> rtn = map_min_of_link_nodes_to_link(rmg, "z", out=values_at_links)
    >>> values_at_links
    array([  0.,   1.,   2.,   0.,   1.,   2.,   3.,   6.,   5.,   4.,   7.,
             6.,   5.,   4.,   8.,   9.,  10.])
    >>> rtn is values_at_links
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    np.minimum(
        var_name[grid.node_at_link_head], var_name[grid.node_at_link_tail], out=out
    )

    return out


def map_max_of_link_nodes_to_link(grid, var_name, out=None):
    """Map the maximum of a link's nodes to the link.

    map_max_of_link_nodes_to_link iterates across the grid and
    identifies the node values at both the "head" and "tail" of a given link.
    This function evaluates the value of 'var_name' at both the "to" and
    "from" node. The maximum value of the two node values is then mapped to
    the link.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_max_of_link_nodes_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field(
    ...     "z",
    ...     [
    ...         [0, 1, 2, 3],
    ...         [7, 6, 5, 4],
    ...         [8, 9, 10, 11],
    ...     ],
    ...     at="node",
    ... )
    >>> map_max_of_link_nodes_to_link(rmg, "z")
    array([  1.,   2.,   3.,   7.,   6.,   5.,   4.,   7.,   6.,   5.,   8.,
             9.,  10.,  11.,   9.,  10.,  11.])

    >>> values_at_links = rmg.empty(at="link")
    >>> rtn = map_max_of_link_nodes_to_link(rmg, "z", out=values_at_links)
    >>> values_at_links
    array([  1.,   2.,   3.,   7.,   6.,   5.,   4.,   7.,   6.,   5.,   8.,
             9.,  10.,  11.,   9.,  10.,  11.])
    >>> rtn is values_at_links
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    np.maximum(
        var_name[grid.node_at_link_head], var_name[grid.node_at_link_tail], out=out
    )

    return out


def map_mean_of_link_nodes_to_link(grid, var_name, out=None):
    """Map the mean of a link's nodes to the link.

    map_mean_of_link_nodes_to_link iterates across the grid and
    identifies the node values at both the "head" and "tail" of a given link.
    This function takes the sum of the two values of 'var_name' at both the
    "to" and "from" node. The average value of the two node values of
    'var_name' is then mapped to the link.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_mean_of_link_nodes_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["z"] = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
    >>> map_mean_of_link_nodes_to_link(rmg, "z")
    array([  0.5,   1.5,   2.5,   2. ,   3. ,   4. ,   5. ,   4.5,   5.5,
             6.5,   6. ,   7. ,   8. ,   9. ,   8.5,   9.5,  10.5])

    >>> values_at_links = rmg.empty(at="link")
    >>> rtn = map_mean_of_link_nodes_to_link(rmg, "z", out=values_at_links)
    >>> values_at_links
    array([  0.5,   1.5,   2.5,   2. ,   3. ,   4. ,   5. ,   4.5,   5.5,
             6.5,   6. ,   7. ,   8. ,   9. ,   8.5,   9.5,  10.5])
    >>> rtn is values_at_links
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    out[:] = 0.5 * (var_name[grid.node_at_link_head] + var_name[grid.node_at_link_tail])

    return out


def map_value_at_min_node_to_link(grid, control_name, value_name, out=None):
    """Map the the value found in one node array to a link, based on the
    minimum value found in a second node field or array.

    map_value_at_min_node_to_link iterates across the grid and
    identifies the node values at both the "head" and "tail" of a given link.
    This function evaluates the value of 'control_name' at both the "to" and
    "from" node. The value of 'value_name' at the node with the minimum value
    of the two values of 'control_name' is then mapped to the link.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    control_name : array or field name
        Name of field defined at nodes or a node array that dictates which end
        of the link to draw values from.
    value_name : array or field name
        Name of field defined at nodes or  node array from which values are
        drawn, based on control_name.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_value_at_min_node_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field(
    ...     "z",
    ...     [
    ...         [0, 1, 2, 3],
    ...         [7, 6, 5, 4],
    ...         [8, 9, 10, 11],
    ...     ],
    ...     at="node",
    ... )
    >>> _ = rmg.add_field(
    ...     "vals_to_map",
    ...     [
    ...         [0, 10, 20, 30],
    ...         [70, 60, 50, 40],
    ...         [80, 90, 100, 110],
    ...     ],
    ...     at="node",
    ... )
    >>> map_value_at_min_node_to_link(rmg, "z", "vals_to_map")
    array([   0.,   10.,   20.,    0.,   10.,   20.,   30.,   60.,   50.,
             40.,   70.,   60.,   50.,   40.,   80.,   90.,  100.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(control_name) is str:
        control_name = grid.at_node[control_name]
    if type(value_name) is str:
        value_name = grid.at_node[value_name]
    head_control = control_name[grid.node_at_link_head]
    tail_control = control_name[grid.node_at_link_tail]
    head_vals = value_name[grid.node_at_link_head]
    tail_vals = value_name[grid.node_at_link_tail]

    out[:] = np.where(tail_control < head_control, tail_vals, head_vals)
    return out


def map_value_at_max_node_to_link(grid, control_name, value_name, out=None):
    """Map the the value found in one node array to a link, based on the
    maximum value found in a second node field or array.

    map_value_at_max_node_to_link iterates across the grid and
    identifies the node values at both the "head" and "tail" of a given link.
    This function evaluates the value of 'control_name' at both the "to" and
    "from" node. The value of 'value_name' at the node with the maximum value
    of the two values of 'control_name' is then mapped to the link.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    control_name : array or field name
        Name of field defined at nodes or a node array that dictates which end
        of the link to draw values from.
    value_name : array or field name
        Name of field defined at nodes or  node array from which values are
        drawn, based on control_name.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_value_at_max_node_to_link
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field(
    ...     "z",
    ...     [
    ...         [0, 1, 2, 3],
    ...         [7, 6, 5, 4],
    ...         [8, 9, 10, 11],
    ...     ],
    ...     at="node",
    ... )
    >>> _ = rmg.add_field(
    ...     "vals_to_map",
    ...     [
    ...         [0, 10, 20, 30],
    ...         [70, 60, 50, 40],
    ...         [80, 90, 100, 110],
    ...     ],
    ...     at="node",
    ... )
    >>> map_value_at_max_node_to_link(rmg, "z", "vals_to_map")
    array([  10.,   20.,   30.,   70.,   60.,   50.,   40.,   70.,   60.,
             50.,   80.,   90.,  100.,  110.,   90.,  100.,  110.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="link")

    if type(control_name) is str:
        control_name = grid.at_node[control_name]
    if type(value_name) is str:
        value_name = grid.at_node[value_name]
    head_control = control_name[grid.node_at_link_head]
    tail_control = control_name[grid.node_at_link_tail]
    head_vals = value_name[grid.node_at_link_head]
    tail_vals = value_name[grid.node_at_link_tail]

    out[:] = np.where(tail_control > head_control, tail_vals, head_vals)
    return out


def map_node_to_cell(grid, var_name, out=None):
    """Map values for nodes to cells.

    map_node_to_cell iterates across the grid and
    identifies the all node values of 'var_name'.

    This function takes node values of 'var_name' and mapes that value to the
    corresponding cell area for each node.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at cells.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_node_to_cell
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(12.0), at="node")
    >>> map_node_to_cell(rmg, "z")
    array([5.,  6.])

    >>> values_at_cells = rmg.empty(at="cell")
    >>> rtn = map_node_to_cell(rmg, "z", out=values_at_cells)
    >>> values_at_cells
    array([5.,  6.])
    >>> rtn is values_at_cells
    True

    :meta landlab: info-cell, info-node, map
    """
    if out is None:
        out = grid.empty(at="cell")

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    out[:] = var_name[grid.node_at_cell]

    return out


def map_min_of_node_links_to_node(grid, var_name, out=None):
    """Map the minimum value of a nodes' links to the node.

    map_min_of_node_links_to_node iterates across the grid and
    identifies the link values at each link connected to  a node.
    This function finds the minimum value of 'var_name' of each set
    of links, and then maps this value to the node. Note no attempt is made
    to honor the directionality of the links.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_min_of_node_links_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = np.arange(rmg.number_of_links)
    >>> map_min_of_node_links_to_node(rmg, "grad")
    array([  0.,   0.,   1.,   2.,
             3.,   4.,   5.,   6.,
            10.,  11.,  12.,  13.])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_min_of_node_links_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes
    array([  0.,   0.,   1.,   2.,
             3.,   4.,   5.,   6.,
            10.,  11.,  12.,  13.])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    values_at_linksX = np.empty(grid.number_of_links + 1, dtype=float)
    values_at_linksX[-1] = np.finfo(dtype=float).max
    if type(var_name) is str:
        values_at_linksX[:-1] = grid.at_link[var_name]
    else:
        values_at_linksX[:-1] = var_name
    np.amin(values_at_linksX[grid.links_at_node], axis=1, out=out)

    return out


def map_max_of_node_links_to_node(grid, var_name, out=None):
    """Map the maximum value of a nodes' links to the node.

    map_max_of_node_links_to_node iterates across the grid and
    identifies the link values at each link connected to  a node.
    This function finds the maximum value of 'var_name' of each set
    of links, and then maps this value to the node. Note no attempt is made
    to honor the directionality of the links.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_max_of_node_links_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = np.arange(rmg.number_of_links)
    >>> map_max_of_node_links_to_node(rmg, "grad")
    array([  3.,   4.,   5.,   6.,
            10.,  11.,  12.,  13.,
            14.,  15.,  16.,  16.])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_max_of_node_links_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes
    array([  3.,   4.,   5.,   6.,
            10.,  11.,  12.,  13.,
            14.,  15.,  16.,  16.])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    values_at_linksX = np.empty(grid.number_of_links + 1, dtype=float)
    values_at_linksX[-1] = np.finfo(dtype=float).min
    if type(var_name) is str:
        values_at_linksX[:-1] = grid.at_link[var_name]
    else:
        values_at_linksX[:-1] = var_name
    np.amax(values_at_linksX[grid.links_at_node], axis=1, out=out)

    return out


def map_upwind_node_link_max_to_node(grid, var_name, out=None):
    """Map the largest magnitude of the links bringing flux into the node to
    the node.

    map_upwind_node_link_max_to_node iterates across the grid and identifies
    the link values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links bringing flux into the
    node, then maps the maximum magnitude of 'var_name' found on these links
    onto the node. If no upwind link is found, the value will be recorded as
    zero.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_upwind_node_link_max_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.1,
    ...     -1.2,
    ...     -1.3,
    ...     1.4,
    ...     1.5,
    ...     1.6,
    ...     -1.7,
    ...     -1.8,
    ...     -1.9,
    ...     2.0,
    ...     2.1,
    ...     2.2,
    ...     -2.3,
    ...     2.4,
    ...     2.5,
    ...     2.6,
    ...     -2.7,
    ... ]
    >>> map_upwind_node_link_max_to_node(rmg, "grad").reshape((3, 4))
    array([[1.4,  1.5,  1.6,  1.3],
           [2.1,  2.2,  2. ,  2.4],
           [2.5,  2.6,  2.3,  2.7]])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_upwind_node_link_max_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes.reshape((3, 4))
    array([[1.4,  1.5,  1.6,  1.3],
           [2.1,  2.2,  2. ,  2.4],
           [2.5,  2.6,  2.3,  2.7]])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    if type(var_name) is str:
        var_name = grid.at_link[var_name]
    values_at_links = var_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    np.amax(-values_at_links, axis=1, out=out)

    return out


def map_downwind_node_link_max_to_node(grid, var_name, out=None):
    """Map the largest magnitude of the links carrying flux from the node to
    the node.

    map_downwind_node_link_max_to_node iterates across the grid and identifies
    the link values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links carrying flux out of the
    node, then maps the maximum magnitude of 'var_name' found on these links
    onto the node. If no downwind link is found, the value will be recorded as
    zero.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_downwind_node_link_max_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ... ]
    >>> map_downwind_node_link_max_to_node(rmg, "grad")
    array([1.,  2.,  1.,  0.,
           1.,  2.,  1.,  0.,
           1.,  2.,  1.,  0.])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_downwind_node_link_max_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes
    array([1.,  2.,  1.,  0.,
           1.,  2.,  1.,  0.,
           1.,  2.,  1.,  0.])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    if type(var_name) is str:
        var_name = grid.at_link[var_name]
    values_at_links = var_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    steepest_links_at_node = np.amax(values_at_links, axis=1)
    np.fabs(steepest_links_at_node, out=out)

    return out


def map_upwind_node_link_mean_to_node(grid, var_name, out=None):
    """Map the mean magnitude of the links bringing flux into the node to the
    node.

    map_upwind_node_link_mean_to_node iterates across the grid and identifies
    the link values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links bringing flux into the
    node, then maps the mean magnitude of 'var_name' found on these links
    onto the node. Links with zero values are not included in the means,
    and zeros are returned if no upwind links are found.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_upwind_node_link_mean_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     -2.0,
    ...     -3.0,
    ...     -4.0,
    ...     -5.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     -1.0,
    ...     -2.0,
    ...     -3.0,
    ...     -4.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ... ]
    >>> map_upwind_node_link_mean_to_node(rmg, "grad")
    array([0. ,  1. ,  2. ,  1. ,
           2. ,  2. ,  3. ,  3. ,
           1. ,  1.5,  2.5,  2.5])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_upwind_node_link_mean_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes
    array([0. ,  1. ,  2. ,  1. ,
           2. ,  2. ,  3. ,  3. ,
           1. ,  1.5,  2.5,  2.5])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")
    out[:] = 0.0

    if type(var_name) is str:
        var_name = grid.at_link[var_name]
    values_at_links = var_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    vals_in_positive = -values_at_links
    vals_above_zero = vals_in_positive > 0.0
    total_vals = np.sum(vals_in_positive * vals_above_zero, axis=1)
    link_count = np.sum(vals_above_zero, axis=1)
    np.divide(total_vals, link_count, out=out, where=link_count != 0)
    out[link_count == 0] = 0.0

    return out


def map_downwind_node_link_mean_to_node(grid, var_name, out=None):
    """Map the mean magnitude of the links carrying flux out of the node to the
    node.

    map_downwind_node_link_mean_to_node iterates across the grid and identifies
    the link values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links carrying flux out of the
    node, then maps the mean magnitude of 'var_name' found on these links
    onto the node. Links with zero values are not included in the means,
    and zeros are returned if no upwind links are found.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_downwind_node_link_mean_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     -2.0,
    ...     -3.0,
    ...     -4.0,
    ...     -5.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     -1.0,
    ...     -2.0,
    ...     -3.0,
    ...     -4.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ... ]
    >>> map_downwind_node_link_mean_to_node(rmg, "grad")
    array([1.5,  2.5,  2.5,  5. ,
           1. ,  2. ,  2. ,  4. ,
           1. ,  2. ,  1. ,  0. ])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_downwind_node_link_mean_to_node(rmg, "grad", out=values_at_nodes)
    >>> values_at_nodes
    array([1.5,  2.5,  2.5,  5. ,
           1. ,  2. ,  2. ,  4. ,
           1. ,  2. ,  1. ,  0. ])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")
    out[:] = 0.0

    if type(var_name) is str:
        var_name = grid.at_link[var_name]
    values_at_links = var_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    vals_in_positive = values_at_links
    vals_above_zero = vals_in_positive > 0.0
    total_vals = np.sum(vals_in_positive * vals_above_zero, axis=1)
    link_count = np.sum(vals_above_zero, axis=1)
    np.divide(total_vals, link_count, out=out, where=link_count != 0)

    return out


def map_value_at_upwind_node_link_max_to_node(grid, control_name, value_name, out=None):
    """Map the the value found in one link array to a node, based on the
    largest magnitude value of links bringing fluxes into the node, found in a
    second node array or field.

    map_upwind_node_link_max_to_node iterates across the grid and identifies
    the link control_values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links bringing flux into the
    node, then identifies the link with the maximum magnitude. The value of the
    second field 'value_name' at these links is then mapped onto the node.
    If no upwind link is found, the value will be recorded as zero.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    control_name : array or field name
        Values defined at nodes that dictate which end of the link to
        draw values from.
    value_name : array or field name
        Values defined at nodes from which values are drawn, based on
        control_name.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_value_at_upwind_node_link_max_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ... ]
    >>> rmg.at_link["vals"] = np.arange(rmg.number_of_links, dtype=float)
    >>> map_value_at_upwind_node_link_max_to_node(rmg, "grad", "vals")
    array([  0.,   0.,   1.,   2.,
             0.,   7.,   8.,   9.,
             0.,  14.,  15.,  16.])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_value_at_upwind_node_link_max_to_node(
    ...     rmg, "grad", "vals", out=values_at_nodes
    ... )
    >>> values_at_nodes
    array([  0.,   0.,   1.,   2.,
             0.,   7.,   8.,   9.,
             0.,  14.,  15.,  16.])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    if type(control_name) is str:
        control_name = grid.at_link[control_name]
    if type(value_name) is str:
        value_name = grid.at_link[value_name]
    values_at_nodes = control_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    which_link = np.argmax(-values_at_nodes, axis=1)
    invalid_links = values_at_nodes >= 0.0
    link_vals_without_invalids = value_name[grid.links_at_node]
    link_vals_without_invalids[invalid_links] = 0.0
    out[:] = link_vals_without_invalids[np.arange(grid.number_of_nodes), which_link]

    return out


def map_value_at_downwind_node_link_max_to_node(
    grid, control_name, value_name, out=None
):
    """Map the the value found in one link array to a node, based on the
    largest magnitude value of links carrying fluxes out of the node, found in
    a second node array or field.

    map_downwind_node_link_max_to_node iterates across the grid and identifies
    the link control_values at each link connected to a node. It then uses the
    link_dirs_at_node data structure to identify links carrying flux out of the
    node, then identifies the link with the maximum magnitude. The value of the
    second field 'value_name' at these links is then mapped onto the node.
    If no downwind link is found, the value will be recorded as zero.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    control_name : array or field name
        Values defined at nodes that dictate which end of the link to
        draw values from.
    value_name : array or field name
        Values defined at nodes from which values are drawn, based on
        control_name.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_value_at_downwind_node_link_max_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_link["grad"] = [
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     0.0,
    ...     -1.0,
    ...     -2.0,
    ...     -1.0,
    ... ]
    >>> rmg.at_link["vals"] = np.arange(rmg.number_of_links, dtype=float)
    >>> map_value_at_downwind_node_link_max_to_node(rmg, "grad", "vals")
    array([  0.,   1.,   2.,   0.,
             7.,   8.,   9.,   0.,
            14.,  15.,  16.,   0.])

    >>> values_at_nodes = rmg.add_empty("z", at="node")
    >>> rtn = map_value_at_downwind_node_link_max_to_node(
    ...     rmg, "grad", "vals", out=values_at_nodes
    ... )
    >>> values_at_nodes
    array([  0.,   1.,   2.,   0.,
             7.,   8.,   9.,   0.,
            14.,  15.,  16.,   0.])
    >>> rtn is values_at_nodes
    True

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(at="node")

    if type(control_name) is str:
        control_name = grid.at_link[control_name]
    if type(value_name) is str:
        value_name = grid.at_link[value_name]
    values_at_nodes = control_name[grid.links_at_node] * grid.link_dirs_at_node
    # this procedure makes incoming links NEGATIVE
    which_link = np.argmax(values_at_nodes, axis=1)
    invalid_links = values_at_nodes <= 0.0
    link_vals_without_invalids = value_name[grid.links_at_node]
    link_vals_without_invalids[invalid_links] = 0.0
    out[:] = link_vals_without_invalids[np.arange(grid.number_of_nodes), which_link]

    return out


def map_mean_of_patch_nodes_to_patch(
    grid, var_name, ignore_closed_nodes=True, out=None
):
    """Map the mean value of nodes around a patch to the patch.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    ignore_closed_nodes : bool
        If True, do not incorporate closed nodes into calc. If all nodes are
        masked at a patch, record zero if out is None or leave the existing
        value if out.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at patches.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_mean_of_patch_nodes_to_patch
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> map_mean_of_patch_nodes_to_patch(rmg, "vals")
    array([4.5, 3.5, 2.5,
           3.5, 2.5, 1.5])

    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> rmg.status_at_node[rmg.node_x > 1.5] = rmg.BC_NODE_IS_CLOSED
    >>> ans = np.zeros(6, dtype=float)
    >>> _ = map_mean_of_patch_nodes_to_patch(rmg, "vals", out=ans)
    >>> ans
    array([4.5, 4. , 0. ,
           3.5, 3. , 0. ])

    :meta landlab: info-patch, info-node, map
    """
    if out is None:
        out = np.zeros(grid.number_of_patches, dtype=float)

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    values_at_nodes = var_name[grid.nodes_at_patch]
    if ignore_closed_nodes:
        values_at_nodes = np.ma.masked_where(
            grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED,
            values_at_nodes,
            copy=False,
        )
        meanvals = np.mean(values_at_nodes, axis=1)
        if type(meanvals.mask) is not np.bool_:
            gooddata = np.logical_not(meanvals.mask)
            out[gooddata] = meanvals.data[gooddata]
        else:
            if not meanvals.mask:
                out[:] = meanvals.data
    else:
        np.mean(values_at_nodes, axis=1, out=out)

    return out


def map_max_of_patch_nodes_to_patch(grid, var_name, ignore_closed_nodes=True, out=None):
    """Map the maximum value of nodes around a patch to the patch.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    ignore_closed_nodes : bool
        If True, do not incorporate closed nodes into calc. If all nodes are
        masked at a patch, record zero if out is None or leave the existing
        value if out.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at patches.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_max_of_patch_nodes_to_patch
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> map_max_of_patch_nodes_to_patch(rmg, "vals")
    array([5., 4., 3.,
           4., 4., 3.])

    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> rmg.status_at_node[rmg.node_x > 1.5] = rmg.BC_NODE_IS_CLOSED
    >>> ans = np.zeros(6, dtype=float)
    >>> _ = map_max_of_patch_nodes_to_patch(rmg, "vals", out=ans)
    >>> ans
    array([5., 4., 0.,
           4., 4., 0.])

    :meta landlab: info-patch, info-node, map
    """
    if out is None:
        out = np.zeros(grid.number_of_patches, dtype=float)

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    values_at_nodes = var_name[grid.nodes_at_patch]
    if ignore_closed_nodes:
        values_at_nodes = np.ma.masked_where(
            grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED,
            values_at_nodes,
            copy=False,
        )
        maxvals = values_at_nodes.max(axis=1)
        if type(maxvals.mask) is not np.bool_:
            gooddata = np.logical_not(maxvals.mask)
            out[gooddata] = maxvals.data[gooddata]
        else:
            if not maxvals.mask:
                out[:] = maxvals.data
    else:
        np.amax(values_at_nodes, axis=1, out=out)

    return out


def map_min_of_patch_nodes_to_patch(grid, var_name, ignore_closed_nodes=True, out=None):
    """Map the minimum value of nodes around a patch to the patch.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at nodes.
    ignore_closed_nodes : bool
        If True, do not incorporate closed nodes into calc. If all nodes are
        masked at a patch, record zero if out is None or leave the existing
        value if out.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at patches.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_min_of_patch_nodes_to_patch
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> map_min_of_patch_nodes_to_patch(rmg, "vals")
    array([4., 3., 2.,
           2., 1., 0.])

    >>> rmg.at_node["vals"] = [
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [5.0, 4.0, 3.0, 2.0],
    ...     [3.0, 2.0, 1.0, 0.0],
    ... ]
    >>> rmg.status_at_node[rmg.node_x > 1.5] = rmg.BC_NODE_IS_CLOSED
    >>> ans = np.zeros(6, dtype=float)
    >>> _ = map_min_of_patch_nodes_to_patch(rmg, "vals", out=ans)
    >>> ans
    array([4., 4., 0.,
           2., 2., 0.])

    :meta landlab: info-patch, info-node, map
    """
    if out is None:
        out = np.zeros(grid.number_of_patches, dtype=float)

    if type(var_name) is str:
        var_name = grid.at_node[var_name]
    values_at_nodes = var_name[grid.nodes_at_patch]
    if ignore_closed_nodes:
        values_at_nodes = np.ma.masked_where(
            grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED,
            values_at_nodes,
            copy=False,
        )
        minvals = values_at_nodes.min(axis=1)
        if type(minvals.mask) is not np.bool_:
            gooddata = np.logical_not(minvals.mask)
            out[gooddata] = minvals.data[gooddata]
        else:
            if not minvals.mask:
                out[:] = minvals.data
    else:
        np.amin(values_at_nodes, axis=1, out=out)

    return out


def map_link_vector_sum_to_patch(grid, var_name, ignore_inactive_links=True, out=None):
    """Map the vector sum of links around a patch to the patch.

    The resulting vector is returned as a length-2 list, with the two
    items being arrays of the x component and the y component of the resolved
    vectors at the patches, respectively.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    ignore_inactive_links : bool
        If True, do not incorporate inactive links into calc. If all links are
        inactive at a patch, record zero if out is None or leave the existing
        value if out.
    out : len-2 list of npatches-long arrays, optional
        Buffer to place mapped values into or ``None`` to create a new array.

    Returns
    -------
    len-2 list of arrays
        [x_component_of_link_vals_at_patch, y_component_of_link_vals_at_patch].

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.mappers import map_link_vector_sum_to_patch
    >>> from landlab import HexModelGrid

    >>> mg = HexModelGrid((4, 3))
    >>> interior_nodes = mg.status_at_node == mg.BC_NODE_IS_CORE
    >>> exterior_nodes = mg.status_at_node != mg.BC_NODE_IS_CORE

    Add a ring of closed nodes at the edge:

    >>> mg.status_at_node[exterior_nodes] = mg.BC_NODE_IS_CLOSED

    This gives us 5 core nodes, 7 active links, and 3 present patches

    >>> (mg.number_of_core_nodes == 5 and mg.number_of_active_links == 7)
    True
    >>> A = mg.add_ones("vals", at="link")
    >>> A.fill(9.0)  # any old values on the inactive links
    >>> A[mg.active_links] = np.array([1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0])

    This setup should give present patch 0 pure east, patch 1 zero (vorticity),
    and patch 2 westwards and downwards components.

    >>> xcomp, ycomp = map_link_vector_sum_to_patch(mg, "vals")
    >>> xcomp, ycomp = np.round(xcomp, decimals=5), np.round(ycomp, decimals=5)
    >>> np.allclose(xcomp[(6, 9, 10),], [2.0, 0.0, -1.0])
    True
    >>> np.allclose(ycomp[(6, 9, 10),] / np.sqrt(3.0), [0.0, 0.0, -1.0])
    True

    These are the patches with ``LinksStatus.INACTIVE`` on all three sides:

    >>> absent_patches = np.array([0, 1, 2, 4, 8, 11, 12, 15, 16, 17, 18])
    >>> np.allclose(xcomp[absent_patches], 0.0)
    True
    >>> np.allclose(ycomp[absent_patches], 0.0)
    True

    Now demonstrate the remaining functionality:

    >>> A = mg.at_link["vals"].copy()
    >>> A.fill(1.0)
    >>> _ = map_link_vector_sum_to_patch(
    ...     mg, A, ignore_inactive_links=False, out=[xcomp, ycomp]
    ... )
    >>> np.allclose(xcomp[absent_patches], 0.0)
    False
    >>> np.allclose(ycomp[absent_patches], 0.0)
    False

    :meta landlab: info-patch, info-link, map
    """
    if out is None:
        out = [
            np.zeros(grid.number_of_patches, dtype=float),
            np.zeros(grid.number_of_patches, dtype=float),
        ]
    else:
        assert len(out) == 2

    if type(var_name) is str:
        var_name = grid.at_link[var_name]
    angles_at_links = grid.angle_of_link  # CCW round tail
    hoz_cpt = np.cos(angles_at_links)
    vert_cpt = np.sin(angles_at_links)
    hoz_vals = var_name * hoz_cpt
    vert_vals = var_name * vert_cpt
    hoz_vals_at_patches = hoz_vals[grid.links_at_patch]
    vert_vals_at_patches = vert_vals[grid.links_at_patch]
    if ignore_inactive_links:
        linkmask = grid.status_at_link[grid.links_at_patch] == grid.BC_LINK_IS_INACTIVE
        hoz_vals_at_patches = np.ma.array(
            hoz_vals_at_patches, mask=linkmask, copy=False
        )
        vert_vals_at_patches = np.ma.array(
            vert_vals_at_patches, mask=linkmask, copy=False
        )
        hoz_sum = np.sum(hoz_vals_at_patches, axis=1)
        vert_sum = np.sum(vert_vals_at_patches, axis=1)
        if type(hoz_sum.mask) is not np.bool_:  # the 2 comps have same mask
            gooddata = np.logical_not(hoz_sum.mask)
            out[0][gooddata] = hoz_sum.data[gooddata]
            out[1][gooddata] = vert_sum.data[gooddata]
        else:
            if not hoz_sum.mask:
                out[0][:] = hoz_sum.data
                out[1][:] = vert_sum.data

    else:
        hoz_sum = np.sum(hoz_vals_at_patches, axis=1, out=out[0])
        vert_sum = np.sum(vert_vals_at_patches, axis=1, out=out[1])

    return out


def map_link_vector_components_to_node(grid, data_at_link):
    """Map (x,y) components of link data data_at_link onto nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid, HexModelGrid

    >>> grid = RasterModelGrid((3, 4))
    >>> link_data = np.arange(grid.number_of_links)

    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vx[5:7]
    array([7.5, 8.5])

    >>> grid = HexModelGrid((3, 3))
    >>> link_data = np.zeros(grid.number_of_links) + 0.5 * 3.0**0.5
    >>> link_data[np.isclose(grid.angle_of_link, 0.0)] = 0.0
    >>> vx, vy = map_link_vector_components_to_node(grid, link_data)
    >>> vy
    array([0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.])
    """
    from landlab import HexModelGrid
    from landlab import RasterModelGrid

    if isinstance(grid, HexModelGrid):
        from .hex_mappers import map_link_vector_components_to_node_hex

        return map_link_vector_components_to_node_hex(grid, data_at_link)
    elif isinstance(grid, RasterModelGrid):
        from .raster_mappers import map_link_vector_components_to_node_raster

        return map_link_vector_components_to_node_raster(grid, data_at_link)
    else:
        raise NotImplementedError("Only available for HexModelGrid")


def map_node_to_link_linear_upwind(grid, v, u, out=None):
    """Assign values to links from upstream nodes.

    Assign to each link the value `v` associated with whichever of its two
    nodes lies upstream, according to link value `u`.

    Consider a link k with tail node `t(k)` and head node `t(h)`. Nodes have
    value `v(n)`. We want to assign a value to links, `v'(k)`. The assignment is::

        v'(k) = v(t(k)) where u(k) > 0,
        v'(k) = v(h(k)) where u(k) <= 0

    As an example, consider 3x5 raster grid with the following values
    at the nodes in the central row::

        0---1---2---3---4

    Consider a uniform velocity value `u = 1` at the horizontal links.
    The mapped link values should be::

        .-0-.-1-.-2-.-3-.

    If `u < 0`, the link values should be::

        .-1-.-2-.-3-.-4-.

    Parameters
    ----------
    grid : ModelGrid
        A *Landlab* grid.
    v : (n_nodes,), ndarray
        Values at grid nodes.
    u : (n_links,) ndarray
        Values at grid links.
    out : (n_links,) ndarray, optional
        If provided, place calculated values in this array. Otherwise, create a
        new array.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid

    >>> grid = RasterModelGrid((3, 5))
    >>> grid.at_node["node_value"] = [
    ...     [0.0, 0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 1.0, 2.0, 3.0, 4.0],
    ...     [0.0, 0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> v = grid.at_node["node_value"]

    >>> u = grid.add_zeros("advection_speed", at="link")
    >>> u[grid.horizontal_links] = 1.0

    Set values for the middle row of horizontal links.

    >>> val_at_link = map_node_to_link_linear_upwind(grid, v, u)
    >>> val_at_link[9:13]
    array([0.,  1.,  2.,  3.])
    >>> val_at_link = map_node_to_link_linear_upwind(grid, v, -u)
    >>> val_at_link[9:13]
    array([1.,  2.,  3.,  4.])
    """
    if out is None:
        out = np.empty_like(v, shape=(grid.number_of_links,))

    u_is_positive = u > 0.0
    out[u_is_positive] = v[grid.node_at_link_tail[u_is_positive]]
    out[~u_is_positive] = v[grid.node_at_link_head[~u_is_positive]]
    return out


def map_node_to_link_lax_wendroff(grid, v, c, out=None):
    """Assign values to links using a weighted combination of node values.

    Assign to each link a weighted combination of values `v` at nodes
    using the Lax-Wendroff method for upwind weighting.

    `c` is a scalar or link vector that gives the link-parallel signed
    Courant number. Where `c` is positive, velocity is in the direction of
    the link; where negative, velocity is in the opposite direction.

    As an example, consider 3x5 raster grid with the following values
    at the nodes in the central row::

        0---1---2---3---4

    Consider a uniform Courant value `c = +0.2` at the horizontal links.
    The mapped link values should be::

        .-0.4-.-1.4-.-2.4-.-3.4-.

    Values at links when `c = -0.2`::

        .-0.6-.-1.6-.-2.6-.-3.6-.

    Parameters
    ----------
    grid : ModelGrid
        A *Landlab* grid.
    v : (n_nodes,) ndarray
        Values at grid nodes.
    c : float or (n_links,) ndarray
        Courant number to use at links.
    out : (n_links,) ndarray, optional
        If provided, place calculated values in this array. Otherwise, create a
        new array.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid

    >>> grid = RasterModelGrid((3, 5))
    >>> grid.at_node["node_value"] = [
    ...     [0.0, 0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 1.0, 2.0, 3.0, 4.0],
    ...     [0.0, 0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> v = grid.at_node["node_value"]

    >>> c = grid.add_zeros("courant_number", at="link")
    >>> c[grid.horizontal_links] = 0.2

    Set values for the middle row of horizontal links.

    >>> val_at_link = map_node_to_link_lax_wendroff(grid, v, c)
    >>> val_at_link[9:13]
    array([0.4,  1.4,  2.4,  3.4])
    >>> val_at_link = map_node_to_link_lax_wendroff(grid, v, -c)
    >>> val_at_link[9:13]
    array([0.6,  1.6,  2.6,  3.6])
    """
    if out is None:
        out = np.empty_like(v, shape=(grid.number_of_links,))

    out[:] = 0.5 * (
        (1 + c) * v[grid.node_at_link_tail] + (1 - c) * v[grid.node_at_link_head]
    )

    return out


def map_vectors_to_links(grid, ux, uy, out=None):
    """Map magnitude and sign of vectors with components (ux, uy) onto grid links.

    Examples
    --------
    >>> from landlab import HexModelGrid
    >>> import numpy
    >>> hmg = HexModelGrid((3, 2))
    >>> (numpy.round(10 * map_vectors_to_links(hmg, 1.0, 0.0))).astype(int)
    array([10, -5,  5, -5,  5, 10, 10,  5, -5,  5, -5, 10])
    """
    if out is None:
        out = np.zeros(grid.number_of_links)
    u, theta_u = cartesian_to_polar(ux, uy)
    theta = theta_u - grid.angle_of_link
    out[:] = u * np.cos(theta)
    return out



================================================
File: src/landlab/grid/network.py
================================================
#! /usr/bin/env python
"""A class used to create and manage network models in 2D."""
import contextlib

import numpy as np

from landlab.utils.decorators import make_return_array_immutable

from ..core import load_params
from ..core.utils import add_module_functions_to_class
from ..field import GraphFields
from ..graph import NetworkGraph
from ..utils.decorators import cache_result_in_object
from .base import BAD_INDEX_VALUE
from .decorators import override_array_setitem_and_reset
from .decorators import return_readonly_id_array
from .linkstatus import LinkStatus
from .linkstatus import set_status_at_link
from .nodestatus import NodeStatus


class NetworkModelGrid(NetworkGraph, GraphFields):
    """Create a ModelGrid of just nodes and links.

    Parameters
    ----------
    yx_of_node : tuple of ndarray
        Node y and x coordinates.
    links : array of tuple of int
        Nodes at link tail and head.
    xy_of_reference : tuple, optional
        Coordinate value in projected space of (0., 0.)
        Default is (0., 0.)

    Examples
    --------
    >>> from landlab import NetworkModelGrid
    >>> y_of_node = (0, 1, 2, 2)
    >>> x_of_node = (0, 0, -1, 1)
    >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
    >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
    >>> grid.x_of_node
    array([ 0.,  0., -1.,  1.])
    >>> grid.y_of_node
    array([0.,  1.,  2.,  2.])
    >>> grid.nodes_at_link
    array([[0, 1],
           [2, 1],
           [1, 3]])
    """

    #: Indicates a node is *bad index*.
    BAD_INDEX = BAD_INDEX_VALUE

    #: Indicates a node is *core*.
    BC_NODE_IS_CORE = NodeStatus.CORE
    #: Indicates a boundary node has a fixed value.
    BC_NODE_IS_FIXED_VALUE = NodeStatus.FIXED_VALUE
    #: Indicates a boundary node has a fixed gradient.
    BC_NODE_IS_FIXED_GRADIENT = NodeStatus.FIXED_GRADIENT
    #: Indicates a boundary node is wrap-around.
    BC_NODE_IS_LOOPED = NodeStatus.LOOPED
    #: Indicates a boundary node is closed
    BC_NODE_IS_CLOSED = NodeStatus.CLOSED

    #: Indicates a link is *active*, and can carry flux
    BC_LINK_IS_ACTIVE = LinkStatus.ACTIVE
    #: Indicates a link has a fixed gradient value, and behaves as a boundary
    BC_LINK_IS_FIXED = LinkStatus.FIXED
    #: Indicates a link is *inactive*, and cannot carry flux
    BC_LINK_IS_INACTIVE = LinkStatus.INACTIVE

    #: Grid elements on which fields can be placed.
    VALID_LOCATIONS = ("node", "link", "grid")

    at_node = {}  # : Values defined at nodes
    at_link = {}  # : Values defined at links
    at_grid = {}  # : Values defined at grid

    def __init__(
        self,
        yx_of_node,
        links,
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
        xy_of_reference=(0.0, 0.0),
    ):
        NetworkGraph.__init__(self, yx_of_node, links=links, sort=True)
        GraphFields.__init__(
            self,
            {"node": self.number_of_nodes, "link": self.number_of_links, "grid": 1},
            default_group="node",
        )

        self._node_status = np.zeros(self.number_of_nodes, dtype=np.uint8)
        self.bc_set_code = 0

        self._axis_name = None
        self._axis_units = None
        self._ref_coord = None

        self.axis_name = xy_axis_name
        self.axis_units = np.broadcast_to(xy_axis_units, 2)
        self.xy_of_reference = xy_of_reference

    @classmethod
    def from_file(cls, file_like):
        params = load_params(file_like)
        return cls.from_dict(params)

    @classmethod
    def from_dict(cls, params):
        return cls(**params)

    @property
    def xy_of_reference(self):
        """Return the coordinates (x, y) of the reference point.

        For RasterModelGrid and HexModelGrid the reference point is the
        minimum of x_of_node and of y_of_node. By default it is (0, 0). For
        VoronoiDelaunayGrid the reference point is (0, 0). For RadialModelGrid
        it is the (x, y) of the center point.

        The intention of these coordinates is to provide a method to store
        the large float values of projected coordinates.

        Example
        -------

        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid(
        ...     (y_of_node, x_of_node), nodes_at_link, xy_of_reference=(12345, 678910)
        ... )
        >>> grid.xy_of_reference
        (12345, 678910)
        >>> grid.xy_of_reference = (98765, 43210)
        >>> grid.xy_of_reference
        (98765, 43210)
        """
        return self._ref_coord

    @xy_of_reference.setter
    def xy_of_reference(self, new_xy_of_reference):
        """Set a new value for the model grid xy_of_reference."""
        self._ref_coord = (new_xy_of_reference[0], new_xy_of_reference[1])

    @property
    def axis_units(self):
        """Get units for each axis.

        Returns
        -------
        tuple of str
            The units (as a string) for each of a grid's coordinates.

        Examples
        --------
        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.axis_units
        ('-', '-')
        >>> grid.axis_units = ("km", "km")
        >>> grid.axis_units
        ('km', 'km')

        :meta landlab: info-grid
        """
        return self._axis_units

    @axis_units.setter
    def axis_units(self, new_units):
        """Set the units for each coordinate axis."""
        if len(new_units) != self.ndim:
            raise ValueError("length of units does not match grid dimension")
        self._axis_units = tuple(new_units)

    @property
    def axis_name(self):
        """Get the name of each coordinate axis.

        Returns
        -------
        tuple of str
            The names of each axis.

        Examples
        --------
        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))

        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.axis_name
        ('x', 'y')
        >>> grid.axis_name = ("lon", "lat")
        >>> grid.axis_name
        ('lon', 'lat')

        >>> grid = NetworkModelGrid(
        ...     (y_of_node, x_of_node), nodes_at_link, xy_axis_name=("lon", "lat")
        ... )
        >>> grid.axis_name
        ('lon', 'lat')

        :meta landlab: info-grid
        """
        return self._axis_name

    @axis_name.setter
    def axis_name(self, new_names):
        """Set the names of a grid's coordinate axes.

        Raises
        ------
        ValueError
            If the number of dimension do not match.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.axis_name = ("lon", "lat")
        >>> grid.axis_name
        ('lon', 'lat')
        """
        if len(new_names) != self.ndim:
            raise ValueError("length of names does not match grid dimension")
        self._axis_name = tuple(new_names)

    @property
    @override_array_setitem_and_reset("reset_status_at_node")
    def status_at_node(self):
        """Get array of the boundary status for each node.

        Examples
        --------
        >>> from landlab import NetworkModelGrid

        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.status_at_node
        array([0, 0, 0, 0], dtype=uint8)
        >>> grid.status_at_link
        array([0, 0, 0], dtype=uint8)

        Now we change the status at node 0 to a closed boundary. This will
        result in changing the link status as well.

        >>> grid.status_at_node = [
        ...     grid.BC_NODE_IS_CLOSED,
        ...     grid.BC_NODE_IS_CORE,
        ...     grid.BC_NODE_IS_CORE,
        ...     grid.BC_NODE_IS_CORE,
        ... ]
        >>> grid.status_at_node
        array([4, 0, 0, 0], dtype=uint8)
        >>> grid.status_at_link
        array([4, 0, 0], dtype=uint8)

        :meta landlab: info-node, boundary-condition
        """
        return self._node_status

    @status_at_node.setter
    def status_at_node(self, new_status):
        """Set the array of node boundary statuses."""
        self._node_status[:] = new_status[:]
        self.reset_status_at_node()

    def reset_status_at_node(self):
        attrs = [
            "_active_link_dirs_at_node",
            "_status_at_link",
            "_active_links",
            "_fixed_links",
            "_activelink_fromnode",
            "_activelink_tonode",
            "_fixed_links",
            "_active_adjacent_nodes_at_node",
            "_fixed_value_boundary_nodes",
            "_link_status_at_node",
        ]
        for attr in attrs:
            with contextlib.suppress(KeyError):
                del self.__dict__[attr]

        self.bc_set_code += 1

    @property
    @make_return_array_immutable
    @cache_result_in_object()
    def status_at_link(self):
        """Get array of the status of all links.

        Examples
        --------
        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.status_at_link
        array([0, 0, 0], dtype=uint8)

        :meta landlab: info-link, boundary-condition
        """
        return set_status_at_link(self.status_at_node[self.nodes_at_link])

    @property
    @return_readonly_id_array
    @cache_result_in_object()
    def active_links(self):
        """Get array of active links.

        Examples
        --------
        >>> from landlab import NetworkModelGrid

        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.active_links
        array([0, 1, 2])

        :meta landlab: info-node, boundary-condition, subset
        """
        return np.where(self.status_at_link == LinkStatus.ACTIVE)[0]

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def x_of_link(self):
        """Get array of the x-coordinates of link midpoints.

        Examples
        --------
        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.x_of_link
        array([ 0. , -0.5,  0.5])

        :meta landlab: info-link, quantity
        """
        return np.mean(self.x_of_node[self.nodes_at_link], axis=1)

    @property
    @cache_result_in_object()
    @make_return_array_immutable
    def y_of_link(self):
        """Get array of the y-coordinates of link midpoints.

        Examples
        --------
        >>> from landlab import NetworkModelGrid
        >>> y_of_node = (0, 1, 2, 2)
        >>> x_of_node = (0, 0, -1, 1)
        >>> nodes_at_link = ((1, 0), (2, 1), (3, 1))
        >>> grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)
        >>> grid.y_of_link
        array([0.5,  1.5,  1.5])

        :meta landlab: info-link, quantity
        """
        return np.mean(self.y_of_node[self.nodes_at_link], axis=1)


# add only the correct functions
add_module_functions_to_class(
    NetworkModelGrid, "mappers.py", pattern="map_*", exclude="cell|patch"
)
add_module_functions_to_class(
    NetworkModelGrid, "gradients.py", pattern="calc_grad_at_link"
)



================================================
File: src/landlab/grid/nodestatus.py
================================================
#! /usr/bin/env python
from enum import IntEnum
from enum import unique


@unique
class NodeStatus(IntEnum):
    """Define the boundary-type codes"""

    #: Indicate a node is *core*.
    CORE = 0
    #: Indicate a boundary node is has a fixed values.
    FIXED_VALUE = 1
    #: Indicate a boundary node is has a fixed gradient.
    FIXED_GRADIENT = 2
    #: Indicate a boundary node is wrap-around.
    LOOPED = 3
    #: Indicate a boundary node is closed
    CLOSED = 4



================================================
File: src/landlab/grid/radial.py
================================================
#! /usr/env/python
"""Python implementation of RadialModelGrid, a grid class used to create and
manage structured Voronoi-Delaunay grids for 2D numerical models.
"""

import numpy as np
import xarray as xr

from ..graph import DualRadialGraph
from .base import ModelGrid


class RadialModelGrid(DualRadialGraph, ModelGrid):
    """Grid of concentric circles.

    This inherited class implements a circular grid in which grid nodes are
    placed at regular radial and semi-regular arc-wise intervals. That is,
    if the radial spacing between *shells* is *dr*, the nodes are placed around
    the circular shell at regular intervals that get as close as possible to
    *dr*. The points are then arranged in a Delaunay triangulation with Voronoi
    cells. Within each ring, nodes are numbered according to Landlab
    convention, from the first node counterclockwise of east. Numbering
    begins at the centermost node and works outwards through the rings.
    """

    def __init__(
        self,
        n_rings=0,
        nodes_in_first_ring=6,
        spacing=1.0,
        xy_of_center=(0.0, 0.0),
        xy_of_reference=(0.0, 0.0),
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
    ):
        """Create a circular grid.

        Create a circular grid in which grid nodes are placed at regular
        radial and semi-regular arc-wise intervals. That is, if the radial
        spacing between *shells* is *dr*, the nodes are placed around the
        circular shell at regular intervals that get as close as possible to
        *dr*.  The points are then arranged in a Delaunay triangulation with
        Voronoi cells.


        Parameters
        ----------
        n_rings : int
            Number of rings in the grid.
        nodes_in_first_ring : int, optional
            Number of nodes in the first ring.
        spacing : float, optional
            Distance between rings.
        xy_of_center : tuple, optional
            (x, y) coordinate of center point. Default
            is (0., 0.)
        xy_of_reference : tuple, optional
            Coordinate value in projected space of the reference point,
            `xy_of_lower_left`. Default is (0., 0.)

        Returns
        -------
        RadialModelGrid
            A newly-created grid.

        Examples
        --------
        A grid with just one ring will have a node at the origin surrounded
        by six other nodes by default. This can be changed by providing the
        keyword argument `nodes_in_first_ring`.

        >>> import numpy as np
        >>> from landlab import RadialModelGrid
        >>> omg = RadialModelGrid(
        ...     n_rings=1, nodes_in_first_ring=8, xy_of_center=(0.0, 0.0)
        ... )
        >>> omg.number_of_nodes
        9
        >>> omg.number_of_cells
        1

        A second rings will have 16 nodes (1 + 8 + 16 = 25).

        >>> omg = RadialModelGrid(2, nodes_in_first_ring=8)
        >>> omg.number_of_nodes
        25

        >>> np.round(omg.radius_at_node)
        array([2.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,  1.,  1.,  2.,  1.,  0.,
               1.,  2.,  1.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.])
        """
        xy_of_center = tuple(xy_of_center)

        DualRadialGraph.__init__(
            self,
            (n_rings, nodes_in_first_ring),
            spacing=spacing,
            xy_of_center=xy_of_center,
            sort=True,
        )
        ModelGrid.__init__(
            self,
            xy_of_reference=xy_of_reference,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
        )

        self._node_status = np.full(
            self.number_of_nodes, self.BC_NODE_IS_CORE, dtype=np.uint8
        )
        self._node_status[self.perimeter_nodes] = self.BC_NODE_IS_FIXED_VALUE
        self._xy_of_center = tuple(xy_of_center)

    @classmethod
    def from_dict(cls, kwds):
        args = ()
        return cls(*args, **kwds)

    @classmethod
    def from_dataset(cls, dataset):
        return cls(
            n_rings=int(dataset["n_rings"]),
            nodes_in_first_ring=int(dataset["nodes_in_first_ring"]),
            spacing=float(dataset["spacing"]),
            xy_of_center=dataset["xy_of_center"],
        )

    def as_dataset(self, include="*", exclude=None, time=None):
        dataset = xr.Dataset(
            {
                "n_rings": self.number_of_rings,
                "nodes_in_first_ring": self.number_of_nodes_in_ring[0],
                "spacing": self.spacing_of_rings,
                "xy_of_center": (("dim",), list(self.xy_of_center)),
            },
            attrs={"grid_type": "radial"},
        )
        return dataset.update(
            super().as_dataset(include=include, exclude=exclude, time=time)
        )

    @property
    def xy_of_center(self):
        """Return (x, y) of the reference point."""
        return self._xy_of_center

    @xy_of_center.setter
    def xy_of_center(self, xy_of_center):
        """Set a new value for the xy_of_lower_left."""
        dx = self.xy_of_center[0] - xy_of_center[0]
        dy = self.xy_of_center[1] - xy_of_center[1]
        with self.thawed():
            self.x_of_node[:] -= dx
            self.y_of_node[:] -= dy
        self._xy_of_center = xy_of_center



================================================
File: src/landlab/grid/raster.py
================================================
#! /usr/env/python
"""A class used to create and manage regular raster grids for 2D numerical
models in Landlab.
"""
import contextlib

import numpy as np
import xarray as xr

from landlab.utils import structured_grid as sgrid
from landlab.utils.decorators import make_return_array_immutable

from ..core.utils import add_module_functions_to_class
from ..core.utils import as_id_array
from ..field import FieldError
from ..graph import DualUniformRectilinearGraph
from . import raster_funcs as rfuncs
from .base import ModelGrid
from .decorators import return_id_array
from .diagonals import DiagonalsMixIn
from .nodestatus import NodeStatus


def _node_has_boundary_neighbor(mg, id, method="d8"):
    """Test if a RasterModelGrid node is next to a boundary.

    Test if one of the neighbors of node *id* is a boundary node.

    Parameters
    ----------
    mg : RasterModelGrid
        Source grid
    node_id : int
        ID of node to test.
    method: string, optional
        default is d8 neighbor, other method is 'd4'

    Returns
    -------
    boolean
        ``True`` if node has a neighbor on the boundary, ``False`` otherwise.
    """
    for neighbor in mg.active_adjacent_nodes_at_node[id]:
        try:
            if mg.status_at_node[neighbor] != NodeStatus.CORE:
                return True
        except IndexError:
            return True
    if method == "d8":
        for neighbor in mg.diagonal_adjacent_nodes_at_node[id]:
            try:
                if mg.status_at_node[neighbor] != NodeStatus.CORE:
                    return True
            except IndexError:
                return True
    return False


_node_has_boundary_neighbor = np.vectorize(_node_has_boundary_neighbor, excluded=["mg"])


def grid_edge_is_closed_from_dict(boundary_conditions):
    """Get a list of closed-boundary status at grid edges.

    Get a list that indicates grid edges that are closed boundaries. The
    returned list provides a boolean that gives the boundary condition status
    for edges order as [*bottom*, *left*, *top*, *right*].

    *boundary_conditions* is a dict whose keys indicate edge location (as
    "bottom", "left", "top", "right") and values must be one of "open", or
    "closed". If an edge location key is missing, that edge is assumed to be
    *open*.

    Parameters
    ----------
    boundary_conditions : dict
        Boundary condition for grid edges.

    Returns
    -------
    list
        List of booleans indicating if an edge is a closed boundary.

    Examples
    --------
    >>> from landlab.grid.raster import grid_edge_is_closed_from_dict
    >>> grid_edge_is_closed_from_dict(dict(bottom="closed", top="open"))
    [False, False, False, True]
    >>> grid_edge_is_closed_from_dict({})
    [False, False, False, False]
    """
    for condition in boundary_conditions.values():
        if condition not in ["open", "closed"]:
            raise ValueError("%s: boundary condition type not understood", condition)

    return [
        boundary_conditions.get(loc, "open") == "closed"
        for loc in ["right", "top", "left", "bottom"]
    ]


class RasterModelGrid(DiagonalsMixIn, DualUniformRectilinearGraph, ModelGrid):
    """A 2D uniform rectilinear grid.

    Examples
    --------
    Create a uniform rectilinear grid that has 4 rows and 5 columns of nodes.
    Nodes along the edges will be *open*. That is, links connecting these
    nodes to core nodes are *active*.

    >>> from landlab import RasterModelGrid
    >>> rmg = RasterModelGrid((4, 5))
    >>> rmg.number_of_node_rows, rmg.number_of_node_columns
    (4, 5)
    >>> rmg.number_of_active_links
    17

    Set the nodes along the top edge of the grid to be *closed* boundaries.
    This means that any links touching these nodes will be *inactive*.

    >>> rmg = RasterModelGrid((4, 5), bc={"top": "closed"})
    >>> rmg.number_of_node_rows, rmg.number_of_node_columns
    (4, 5)
    >>> rmg.number_of_active_links
    14

    A `RasterModelGrid` can have different node spacings in the *x* and *y*
    directions.

    >>> grid = RasterModelGrid((4, 5), xy_spacing=(2, 1))
    >>> grid.dx, grid.dy
    (2.0, 1.0)
    >>> grid.node_y.reshape(grid.shape)
    array([[0.,  0.,  0.,  0.,  0.],
           [1.,  1.,  1.,  1.,  1.],
           [2.,  2.,  2.,  2.,  2.],
           [3.,  3.,  3.,  3.,  3.]])
    >>> grid.node_x.reshape(grid.shape)
    array([[0.,  2.,  4.,  6.,  8.],
           [0.,  2.,  4.,  6.,  8.],
           [0.,  2.,  4.,  6.,  8.],
           [0.,  2.,  4.,  6.,  8.]])
    """

    def __init__(
        self,
        shape,
        xy_spacing=1.0,
        xy_of_lower_left=(0.0, 0.0),
        xy_of_reference=(0.0, 0.0),
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
        bc=None,
    ):
        """Create a 2D grid with equal spacing.

        Optionally takes numbers of rows and columns and cell size as
        inputs. If this are given, calls initialize() to set up the grid.
        At the moment, num_rows and num_cols MUST be specified. Both must be
        >=3 to allow correct automated setup of boundary conditions.

        Parameters
        ----------
        shape : tuple of int
            Shape of the grid in nodes as (nrows, ncols).
        xy_spacing : tuple or float, optional
            dx and dy spacing. Either provided as a float or a
            (dx, dy) tuple.
        xy_of_lower_left: tuple, optional
            (x, y) coordinates of the lower left corner.
        xy_of_reference : tuple, optional
            Coordinate value in projected space of the reference point,
            `xy_of_lower_left`. Default is (0., 0.)
        xy_axis_name: tuple of str
            Name to use for each axis.
        xy_axis_units: tuple of str, or str
            Units for coordinates of each axis.
        bc : dict, optional
            Edge boundary conditions.

        Returns
        -------
        RasterModelGrid
            A newly-created grid.

        Notes
        -----
        The option for NOT giving rows, cols, and dx no longer works,
        because the *field* init requires num_active_cells, etc., to be
        defined. Either we force users to give arguments on instantiation,
        or set it up such that one can create a zero-node grid.
        """
        shape = tuple(shape)
        xy_spacing = np.asarray(np.broadcast_to(xy_spacing, 2), dtype=float)
        self._xy_of_lower_left = tuple(np.asarray(xy_of_lower_left, dtype=float))

        if shape[0] <= 0 or shape[1] <= 0:
            raise ValueError("number of rows and columns must be positive")

        DualUniformRectilinearGraph.__init__(
            self, shape, spacing=xy_spacing[::-1], origin=self.xy_of_lower_left[::-1]
        )
        ModelGrid.__init__(
            self,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
            xy_of_reference=xy_of_reference,
        )

        self._node_status = np.full(
            self.number_of_nodes, NodeStatus.CORE, dtype=np.uint8
        )
        self._node_status[self.perimeter_nodes] = NodeStatus.FIXED_VALUE

        if bc is None:
            bc = {"right": "open", "top": "open", "left": "open", "bottom": "open"}

        if "closed" in bc.values():
            self.set_closed_boundaries_at_grid_edges(*grid_edge_is_closed_from_dict(bc))

        self.looped_node_properties = {}

        # List of looped neighbor cells (all 8 neighbors) for
        # given *cell ids* can be created if requested by the user.
        self._looped_cell_neighbor_list = None

        # List of second ring looped neighbor cells (all 16 neighbors) for
        # given *cell ids* can be created if requested by the user.
        self._looped_second_ring_cell_neighbor_list_created = False

    def __repr__(self):
        return "RasterModelGrid({}, xy_spacing={}, xy_of_lower_left={})".format(
            repr(self.shape),
            repr((self.dx, self.dy)),
            repr((self.x_of_node.min(), self.y_of_node.min())),
        )

    def __setstate__(self, state_dict):
        """Set state for of RasterModelGrid from pickled state_dict."""
        if state_dict["type"] != "RasterModelGrid":
            assert TypeError("Saved model instance not of " "RasterModelGrid type.")

        xy_spacing = state_dict["xy_spacing"]
        shape = state_dict["shape"]
        xy_of_lower_left = state_dict["xy_of_lower_left"]
        xy_of_reference = state_dict["xy_of_reference"]
        xy_axis_name = state_dict["xy_axis_name"]
        xy_axis_units = state_dict["xy_axis_units"]

        status_at_node = state_dict["status_at_node"]

        RasterModelGrid.__init__(
            self,
            shape,
            xy_spacing=xy_spacing,
            xy_of_lower_left=xy_of_lower_left,
            xy_of_reference=xy_of_reference,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
        )
        self.status_at_node = status_at_node

        # Add fields back to the grid
        fields = state_dict["fields"]
        for at in fields:
            for name in fields[at]:
                values = fields[at][name]["array"]
                units = fields[at][name]["units"]
                self.add_field(name, values, at=at, units=units)

    def __getstate__(self):
        """Get state for pickling."""
        state_dict = {}

        # save basic information about the shape and size of the grid
        state_dict = {
            "type": "RasterModelGrid",
            "xy_spacing": (self.dx, self.dy),
            "shape": self.shape,
            "xy_of_lower_left": self.xy_of_lower_left,
            "xy_of_reference": self.xy_of_reference,
            "xy_axis_name": self.axis_name,
            "xy_axis_units": self.axis_units,
            # save status information at nodes (status at link set based on status
            # at node
            "status_at_node": np.asarray(self._node_status),
        }

        groups = {}
        for at in ("node", "link", "patch", "corner", "face", "cell", "grid"):
            groups[at] = {}
            for name in self[at].keys():
                groups[at][name] = {
                    "array": self.field_values(name, at=at),
                    "units": self.field_units(name, at=at),
                }

        state_dict["fields"] = groups

        return state_dict

    @classmethod
    def from_dict(cls, params):
        """Create a RasterModelGrid from a dictionary.

        Parameters
        ----------
        params : dict_like
            Initialization parameters for a RasterModelGrid.

        Returns
        -------
        RasterModelGrid
            A newly-created grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid.from_dict({"shape": (3, 4), "bc": {"top": "closed"}})
        >>> grid.number_of_nodes
        12

        :meta landlab: info-grid
        """
        shape = params.pop("shape", None)
        return cls(shape, **params)

    @classmethod
    def from_dataset(cls, dataset):
        return cls(
            dataset["shape"],
            xy_spacing=dataset["xy_spacing"],
            xy_of_lower_left=dataset["xy_of_lower_left"],
        )

    def as_dataset(self, include="*", exclude=None, time=None):
        dataset = xr.Dataset(
            {
                "shape": (("dim",), list(self.shape)),
                "xy_spacing": (("dim",), [self.dx, self.dy]),
                "xy_of_lower_left": (("dim",), list(self.xy_of_lower_left)),
            },
            attrs={"grid_type": "uniform_rectilinear"},
        )
        return dataset.update(
            super().as_dataset(include=include, exclude=exclude, time=time)
        )

    @property
    def xy_of_lower_left(self):
        """Return (x, y) of the reference point."""
        return self._xy_of_lower_left

    @xy_of_lower_left.setter
    def xy_of_lower_left(self, xy_of_lower_left):
        """Set a new value for the xy_of_lower_left."""
        dx = self.xy_of_lower_left[0] - xy_of_lower_left[0]
        dy = self.xy_of_lower_left[1] - xy_of_lower_left[1]
        with self.thawed():
            self.x_of_node[:] -= dx
            self.y_of_node[:] -= dy
        self._xy_of_lower_left = tuple(np.asarray(xy_of_lower_left, dtype=float))

    @property
    def cell_grid_shape(self):
        """Get the shape of the cellular grid (grid with only cells).

        Returns
        -------
        shape : tuple of ints
            The shape of the cellular grid as number of cell rows and cell
            columns.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.cell_grid_shape
        (1, 2)

        :meta landlab: info-grid, info-cell
        """
        return (self.number_of_cell_rows, self.number_of_cell_columns)

    def _create_link_unit_vectors(self):
        """Make arrays to store the unit vectors associated with each link.

        Creates self.link_unit_vec_x and self.link_unit_vec_y. These contain,
        for each link, the x and y components of the link's unit vector (that
        is, the link's x and y dimensions if it were shrunk to unit length but
        retained its orientation). The length of these arrays is the number of
        links plus one. The last entry in each array is set to zero, and is
        used to handle references to "link -1" (meaning, a non-existent link,
        whose unit vector is (0,0)).

        Also builds arrays to store the unit-vector component sums for each
        node: node_unit_vector_sum_x and node_unit_vector_sum_y. These are
        designed to be used when mapping link vector values to nodes (one takes
        the average of the x- and y-components of all connected links).

        Notes
        -----
        .. note::

            Overrides ModelGrid._create_link_unit_vectors().

        Creates the following:

        *  `self.link_unit_vec_x`, `self.link_unit_vec_y` : `ndarray`
           x and y components of unit vectors at each link (extra 0
           entries at end)
        *  `self.node_vector_sum_x`, `self.node_vector_sum_y` : `ndarray`
           Sums of x & y unit vector components for each node. Sum is over all
           links connected to a given node.

        Examples
        --------
        In the example below, the first 8 links are vertical, and have unit
        vectors (0,1), whereas the remaining links are horizontal with (1,0).
        The middle columns have x-component vector sums equal to 2 (one
        horizontal inlink and one horizontal outlink), while the middle rows
        have y-component vector sums equal to 2 (one vertical inlink and one
        vertical outlink). The rest of the entries have ones, representing the
        left and right columns (only one horizontal link) and top and bottom
        rows (only one vertical link).

        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((3, 4), xy_spacing=(2.0, 2.0))

        >>> mg.unit_vector_at_link[:, 0]
        array([1.,  1.,  1.,  0.,  0.,  0.,  0.,
               1.,  1.,  1.,  0.,  0.,  0.,  0.,
               1.,  1.,  1.])
        >>> mg.unit_vector_at_link[:, 1]
        array([0.,  0.,  0.,  1.,  1.,  1.,  1.,
               0.,  0.,  0.,  1.,  1.,  1.,  1.,
               0.,  0.,  0.])

        >>> mg.unit_vector_at_node[:, 0]
        array([1.,  2.,  2.,  1.,  1.,  2.,  2.,  1.,  1.,  2.,  2.,  1.])
        >>> mg.unit_vector_at_node[:, 1]
        array([1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1.])
        """
        unit_vec_at_link = np.zeros((self.number_of_links + 1, 2), dtype=float)
        unit_vec_at_link[self.horizontal_links, 0] = 1.0
        unit_vec_at_link[self.vertical_links, 1] = 1.0

        self._unit_vec_at_node = unit_vec_at_link[self.links_at_node].sum(axis=1)
        self._unit_vec_at_link = unit_vec_at_link[:-1, :]

    @property
    def extent(self):
        """Extent of the grid in the y and x-dimensions.

        Return the y and x-dimension of the grid. Because boundary nodes
        don't have cells, the dimension of the grid is
        ``((num_rows - 1) * dy, (num_columns - 1) * dx)``, not
        ``(num_rows * dy, num_cols * dx)``.

        Returns
        -------
        (y_extent, x_extent) : tuple of float
            Length of the grid in the y and x-dimensions.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.extent
        (3.0, 4.0)

        >>> grid = RasterModelGrid((4, 5), xy_spacing=2.0)
        >>> grid.extent
        (6.0, 8.0)

        >>> grid = RasterModelGrid((4, 5), xy_spacing=(3, 2))
        >>> grid.extent
        (6.0, 12.0)

        :meta landlab: info-grid, quantity
        """
        # Method added 5/1/13 by DEJH, modified DEJH 4/3/14 to reflect fact
        # boundary nodes don't have defined
        return (
            (self.number_of_node_rows - 1) * self.dy,
            (self.number_of_node_columns - 1) * self.dx,
        )

    @property
    def number_of_interior_nodes(self):
        """Number of interior nodes.

        Returns the number of interior nodes on the grid, i.e., non-perimeter
        nodes. Compare self.number_of_core_nodes.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.number_of_interior_nodes
        6

        :meta landlab: info-node
        """
        return sgrid.interior_node_count(self.shape)

    @property
    def number_of_cell_columns(self):
        """Number of cell columns.

        Returns the number of columns, including boundaries.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.number_of_cell_columns
        3

        :meta landlab: info-grid, info-node
        """
        return self.shape[1] - 2

    @property
    def number_of_cell_rows(self):
        """Number of cell rows.

        Returns the number of rows, including boundaries.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.number_of_cell_rows
        2

        :meta landlab: info-grid, info-cell
        """
        return self.shape[0] - 2

    @property
    def cells_at_corners_of_grid(self):
        """Get array of cells in cellular grid (grid with only cells) corners.

        Return the IDs to the corner cells of the cellular grid, sorted by ID.

        Returns
        -------
        (4, ) ndarray
            Array of corner node IDs.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> grid.cells_at_corners_of_grid
        array([0, 2, 3, 5])

        :meta landlab: info-grid, info-cell, subset
        """
        return sgrid.corners(self.cell_grid_shape)

    def is_point_on_grid(self, xcoord, ycoord):
        """Check if a point is on the grid.

        This method takes x, y coordinates and tests whether they lie within
        the grid. The limits of the grid are taken to be links connecting the
        boundary nodes. We perform a special test to detect looped boundaries.

        Coordinates can be ints or arrays of ints. If arrays, will return an
        array of the same length of boolean truth values.

        Parameters
        ----------
        xcoord : float or array_like
            The point's x-coordinate.
        ycoord : float or array_like
            The point's y-coordinate.

        Returns
        -------
        bool
            ``True`` if the point is on the grid. Otherwise, ``False``.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5), xy_spacing=(1, 2))
        >>> grid.is_point_on_grid(1, 1)
        True
        >>> grid.is_point_on_grid(
        ...     (1, 1, 1),
        ...     (1, 3.1, 6.1),
        ... )
        array([ True,  True, False])
        >>> grid.is_point_on_grid((-0.1, 0.1, 3.9, 4.1), (1, 1, 1, 1))
        array([False,  True,  True, False])

        :meta landlab: info-grid, quantity, subset
        """
        xcoord, ycoord = np.asarray(xcoord), np.asarray(ycoord)

        x_condition = (xcoord > 0.0) & (xcoord < (self.shape[1] - 1) * self.dx)
        y_condition = (ycoord > 0.0) & (ycoord < (self.shape[0] - 1) * self.dy)

        if np.all(self._node_status[self.nodes_at_left_edge] == 3) or np.all(
            self._node_status[self.nodes_at_right_edge] == 3
        ):
            try:
                x_condition[:] = 1
            except IndexError:
                x_condition = 1
        if np.all(self._node_status[self.nodes_at_top_edge] == 3) or np.all(
            self._node_status[self.nodes_at_bottom_edge] == 3
        ):
            try:
                y_condition[:] = 1
            except IndexError:
                y_condition = 1

        return x_condition & y_condition

    def nodes_around_point(self, xcoord, ycoord):
        """Get the nodes surrounding a point.

        Return IDs of the four nodes of the area around a point with
        coordinates *xcoord*, *ycoord*. Node IDs are returned
        counter-clockwise order starting from the southwest node.

        If either *xcoord* or *ycoord* are arrays the usual numpy broadcasting
        rules apply.

        Parameters
        ----------
        xcoord : float, array-like
            x-coordinate of point
        ycoord : float, array-like
            y-coordinate of point

        Returns
        -------
        (4, N) ndarray
            IDs of nodes around the point.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.nodes_around_point(0.4, 1.2)
        array([4, 8, 9, 5])

        >>> grid.nodes_around_point([0.9, 1.1], 1.2)
        array([[ 4,  5],
               [ 8,  9],
               [ 9, 10],
               [ 5,  6]])

        >>> grid = RasterModelGrid((3, 4), xy_spacing=(1, 2))
        >>> grid.nodes_around_point(0.5, 1.5)
        array([0, 4, 5, 1])
        >>> grid = RasterModelGrid((3, 4))
        >>> grid.nodes_around_point(0.5, 1.5)
        array([4, 8, 9, 5])

        :meta landlab: info-node, subset
        """
        xcoord, ycoord = np.broadcast_arrays(xcoord, ycoord)

        # Method added 4/29/13 by DEJH, modified 9/24/13.
        id_ = ycoord // self.dy * self.number_of_node_columns + xcoord // self.dx
        try:
            id_ = int(id_)
        except TypeError:
            id_ = as_id_array(id_)
        return np.array(
            [
                id_,
                id_ + self.number_of_node_columns,
                id_ + self.number_of_node_columns + 1,
                id_ + 1,
            ]
        )

    def find_nearest_node(self, coords, mode="raise"):
        """Node nearest a point.

        Find the index to the node nearest the given x, y coordinates.
        Coordinates are provided as numpy arrays in the *coords* tuple.

        Use the *mode* keyword to specify what to do if the given coordinates
        are out-of-bounds. See :func:`np.ravel_multi_index` for a
        description of possible values for *mode*. Note that a coordinate is
        out-of-bounds if it is beyond one half the node spacing from the
        exterior nodes.

        Returns the indices of the nodes nearest the given coordinates.

        Parameters
        ----------
        coords : tuple of array-like
            Coordinates of points.
        mode : {'raise', 'wrap', 'clip'}, optional
            What to do if a point is off the grid.

        Returns
        -------
        array-like
            IDs of the nearest nodes.

        Notes
        -----
        For coordinates that are equidistant to two or more nodes, see
        the rounding rules for :func:`numpy.around`.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5))
        >>> rmg.find_nearest_node([0.2, 0.2])
        0
        >>> rmg.find_nearest_node((np.array([1.6, 3.6]), np.array([2.3, 0.7])))
        array([12,  9])
        >>> rmg.find_nearest_node((-0.4999, 1.0))
        5

        :meta landlab: info-node, subset
        """
        return rfuncs.find_nearest_node(self, coords, mode=mode)

    def set_closed_boundaries_at_grid_edges(
        self, right_is_closed, top_is_closed, left_is_closed, bottom_is_closed
    ):
        """Set boundary not to be closed.

        Sets the status of nodes along the specified side(s) of a raster
        grid (bottom, right, top, and/or left) to ``BC_NODE_IS_CLOSED``.

        Arguments are booleans indicating whether the bottom, left, top, and
        right are closed (``True``) or not (``False``).

        For a closed boundary:

        *  the nodes are flagged ``BC_NODE_IS_CLOSED`` (status type 4)
        *  all links that connect to a ``BC_NODE_IS_CLOSED`` node are
           flagged as inactive (so they appear on link-based lists, but
           not active_link-based lists)

        This means that if you call the calc_grad_at_active_link
        method, links connecting to closed boundaries will be ignored: there
        can be no gradients or fluxes calculated, because the links that
        connect to that edge of the grid are not included in the calculation.
        So, setting a grid edge to BC_NODE_IS_CLOSED is a convenient way to
        impose a no-flux boundary condition. Note, however, that this applies
        to the grid as a whole, rather than a particular variable that you
        might use in your application. In other words, if you want a no-flux
        boundary in one variable but a different boundary condition for
        another, then use another method.

        Parameters
        ----------
        right_is_closed : boolean
            If ``True`` right-edge nodes are closed boundaries.
        top_is_closed : boolean
            If ``True`` top-edge nodes are closed boundaries.
        left_is_closed : boolean
            If ``True`` left-edge nodes are closed boundaries.
        bottom_is_closed : boolean
            If ``True`` bottom-edge nodes are closed boundaries.

        Notes
        -----
        Note that the four corners are treated as follows:

        *  bottom left = BOTTOM
        *  bottom right = BOTTOM
        *  top right = TOP
        *  top left = TOP

        This scheme is necessary for internal consistency with looped
        boundaries.

        Examples
        --------
        The following example sets the top and left boundaries as closed in a
        four-row by five-column grid that initially has all boundaries open
        and all boundary nodes coded as BC_NODE_IS_FIXED_VALUE (=1):

        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5))  # rows, columns, spacing
        >>> rmg.number_of_active_links
        17
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[1, 1, 1, 1, 1],
               [1, 0, 0, 0, 1],
               [1, 0, 0, 0, 1],
               [1, 1, 1, 1, 1]], dtype=uint8)
        >>> rmg.set_closed_boundaries_at_grid_edges(True, True, False, False)
        >>> rmg.number_of_active_links
        12
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[1, 1, 1, 1, 1],
               [1, 0, 0, 0, 4],
               [1, 0, 0, 0, 4],
               [4, 4, 4, 4, 4]], dtype=uint8)

        :meta landlab: boundary-condition, subset
        """
        if bottom_is_closed:
            self._node_status[self.nodes_at_bottom_edge] = self.BC_NODE_IS_CLOSED

        if right_is_closed:
            self._node_status[self.nodes_at_right_edge[1:-1]] = self.BC_NODE_IS_CLOSED

        if top_is_closed:
            self._node_status[self.nodes_at_top_edge] = self.BC_NODE_IS_CLOSED

        if left_is_closed:
            self._node_status[self.nodes_at_left_edge[1:-1]] = self.BC_NODE_IS_CLOSED

        self.reset_status_at_node()

    def set_fixed_value_boundaries_at_grid_edges(
        self,
        right_is_fixed_val,
        top_is_fixed_val,
        left_is_fixed_val,
        bottom_is_fixed_val,
        value=None,
        value_of="topographic__elevation",
    ):
        """Create fixed values boundaries.

        Sets the status of nodes along the specified side(s) of a raster
        grid---bottom, right, top, and/or left---to NODE_IS_FIXED_VALUE

        Arguments are booleans indicating whether the bottom, right, top, and
        left sides are to be set (True) or not (False).

        *value* controls what values are held constant at these nodes. It can
        be either a float, an array of length number_of_fixed_nodes or
        number_of_nodes (total), or left blank. If left blank, the values will
        be set from the those already in the grid fields, according to
        'value_of'.

        *value_of* controls the name of the model field that contains the
        values. Remember, if you don't set value, the fixed values will be set
        from the field values ***at the time you call this method***. If no
        values are present in the field, the module will complain but accept
        this, warning that it will be unable to automatically update boundary
        conditions.

        The status of links (active or inactive) is automatically updated to
        reflect the changes.

        The following example sets the bottom and right boundaries as
        fixed-value in a four-row by five-column grid that initially has all
        boundaries closed (i.e., flagged as node_status=4):

        Parameters
        ----------
        bottom_is_fixed_val : boolean
            Set bottom edge as fixed boundary.
        left_is_fixed_val : boolean
            Set left edge as fixed boundary.
        top_is_fixed_val : boolean
            Set top edge as fixed boundary.
        right_is_fixed_val : boolean
            Set right edge as fixed boundary.
        value : float, array or None (default).
            Override value to be kept constant at nodes.
        value_of : string.
            The name of the grid field containing the values of interest.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5), xy_spacing=(1, 1))
        >>> rmg.number_of_active_links
        17

        Put some arbitrary values in the grid fields:

        >>> import numpy as np
        >>> rmg.at_node["topographic__elevation"] = np.random.rand(20)
        >>> rmg.set_closed_boundaries_at_grid_edges(True, True, True, True)
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[4, 4, 4, 4, 4],
               [4, 0, 0, 0, 4],
               [4, 0, 0, 0, 4],
               [4, 4, 4, 4, 4]], dtype=uint8)
        >>> rmg.set_fixed_value_boundaries_at_grid_edges(True, True, False, False)
        >>> rmg.number_of_active_links
        12
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[4, 4, 4, 4, 4],
               [4, 0, 0, 0, 1],
               [4, 0, 0, 0, 1],
               [1, 1, 1, 1, 1]], dtype=uint8)

        Note that the four corners are treated as follows:

        *  bottom left = BOTTOM
        *  bottom right = BOTTOM
        *  top right = TOP
        *  top left = TOP

        This scheme is necessary for internal consistency with looped
        boundaries.

        :meta landlab: boundary-condition, subset
        """
        bottom_edge = range(0, self.number_of_node_columns)
        right_edge = range(
            2 * self.number_of_node_columns - 1,
            self.number_of_nodes - 1,
            self.number_of_node_columns,
        )
        top_edge = range(
            (self.number_of_node_rows - 1) * self.number_of_node_columns,
            self.number_of_nodes,
        )
        left_edge = range(
            self.number_of_node_columns,
            self.number_of_nodes - self.number_of_node_columns,
            self.number_of_node_columns,
        )

        if bottom_is_fixed_val:
            self._node_status[bottom_edge] = NodeStatus.FIXED_VALUE

        if right_is_fixed_val:
            self._node_status[right_edge] = NodeStatus.FIXED_VALUE

        if top_is_fixed_val:
            self._node_status[top_edge] = NodeStatus.FIXED_VALUE

        if left_is_fixed_val:
            self._node_status[left_edge] = NodeStatus.FIXED_VALUE

        self.reset_status_at_node()

        # save some internal data to speed updating:
        self.fixed_value_node_properties = {}
        self.fixed_value_node_properties["boundary_node_IDs"] = as_id_array(
            np.where(self._node_status == NodeStatus.FIXED_VALUE)[0]
        )

        if value:
            if isinstance(value, (float, int)):
                values_to_use = float(value)
            elif isinstance(value, np.ndarray):
                if (
                    value.size
                    == self.fixed_value_node_properties["boundary_node_IDs"].size
                ):
                    values_to_use = value
                elif value.size == self.number_of_nodes:
                    values_to_use = value.take(
                        self.fixed_value_node_properties["boundary_node_IDs"]
                    )
                else:
                    raise TypeError(
                        "'value' must be of size nnodes or number of nodes " "to set!"
                    )
        else:
            try:
                values_to_use = self.at_node[value_of].take(
                    self.fixed_value_node_properties["boundary_node_IDs"]
                )
            except FieldError:
                pass  # we catch this case below
            else:
                # set a flag to indicate successful setting of internal values
                self.fixed_value_node_properties["internal_flag"] = True

        if not self.has_field(value_of, at="node"):
            print(
                """
                *************************************************
                WARNING: set_fixed_value_boundaries_at_grid_edges
                has not been provided with a grid field name to
                allow internal boundary condition control. You
                will not be able to automate BC control with grid
                methods like update_boundary_nodes()!
                Not expecting this error? Try calling this method
                after loading the starting conditions into the
                grid fields.
                *************************************************
                """
            )

            # set a flag to indicate no internal values
            self.fixed_value_node_properties["internal_flag"] = False
        else:
            self.fixed_value_node_properties["internal_flag"] = True
            self.fixed_value_node_properties["fixed_value_of"] = value_of
        with contextlib.suppress(NameError):
            self.fixed_value_node_properties["values"] = values_to_use

    def set_looped_boundaries(self, top_bottom_are_looped, sides_are_looped):
        """Create wrap-around boundaries.

        Handles boundary conditions by setting corresponding parallel grid
        edges as looped "tracks_cell" (==3) status, linked to each other.
        If top_bottom_are_looped is True, the top and bottom edges will link
        to each other. If sides_are_looped is True, the left and right edges
        will link to each other.

        Looped boundaries are experimental, and not as yet well integrated into
        the Landlab framework. Many functions may not recognise them, or
        silently create unforeseen errors. Use at your own risk!

        Note that because of the symmetries this BC implies, the corner nodes
        are all paired with the bottom/top edges, not the sides.

        Parameters
        ----------
        top_bottom_are_looped : bool
            Top and bottom are wrap-around.
        sides_are_looped : bool
            Left and right sides are wrap-around.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5))  # rows, columns, spacing
        >>> rmg.number_of_active_links
        17
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[1, 1, 1, 1, 1],
               [1, 0, 0, 0, 1],
               [1, 0, 0, 0, 1],
               [1, 1, 1, 1, 1]], dtype=uint8)
        >>> rmg.add_zeros("topographic__elevation", at="node")
        array([0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
               0.,  0.,  0.,  0.,  0.,  0.,  0.])
        >>> rmg.set_looped_boundaries(True, True)
        >>> rmg.looped_node_properties["boundary_node_IDs"]
        array([ 0,  1,  2,  3,  4,  5,  9, 10, 14, 15, 16, 17, 18, 19])
        >>> rmg.looped_node_properties["linked_node_IDs"]
        array([10, 11, 12, 13, 14,  8,  6, 13, 11,  5,  6,  7,  8,  9])

        :meta landlab: boundary-condition, subset
        """
        # Added DEJH Feb 2014
        # TODO: Assign BC_statuses also to *links*

        bottom_edge = np.array(range(0, self.number_of_node_columns))
        right_edge = np.array(
            range(
                2 * self.number_of_node_columns - 1,
                self.number_of_nodes - 1,
                self.number_of_node_columns,
            )
        )
        top_edge = np.array(
            range(
                (self.number_of_node_rows - 1) * self.number_of_node_columns,
                self.number_of_nodes,
            )
        )
        left_edge = np.array(
            range(
                self.number_of_node_columns,
                (self.number_of_nodes - self.number_of_node_columns),
                self.number_of_node_columns,
            )
        )
        these_boundary_IDs = np.array([])
        these_linked_nodes = np.array([])

        if top_bottom_are_looped:
            self._node_status[bottom_edge] = NodeStatus.LOOPED
            self._node_status[top_edge] = NodeStatus.LOOPED
            these_boundary_IDs = np.concatenate(
                (these_boundary_IDs, bottom_edge, top_edge)
            )
            these_linked_nodes = np.concatenate(
                (
                    these_linked_nodes,
                    top_edge - self.number_of_node_columns,
                    bottom_edge + self.number_of_node_columns,
                )
            )

        if sides_are_looped:
            self._node_status[right_edge] = NodeStatus.LOOPED
            self._node_status[left_edge] = NodeStatus.LOOPED
            these_boundary_IDs = np.concatenate(
                (these_boundary_IDs, left_edge, right_edge)
            )
            these_linked_nodes = np.concatenate(
                (these_linked_nodes, right_edge - 1, left_edge + 1)
            )

        self.reset_status_at_node()

        if not self.looped_node_properties:
            existing_IDs = np.array([])
            existing_links = np.array([])
        else:
            unrepeated_node_entries = np.logical_not(
                np.isin(
                    self.looped_node_properties["boundary_node_IDs"], these_linked_nodes
                )
            )
            existing_IDs = self.looped_node_properties["boundary_node_IDs"][
                unrepeated_node_entries
            ]
            existing_links = self.looped_node_properties["linked_node_IDs"][
                unrepeated_node_entries
            ]

        self.looped_node_properties = {}
        all_the_IDs = np.concatenate((these_boundary_IDs, existing_IDs))
        ID_ordering = np.argsort(all_the_IDs)
        self.looped_node_properties["boundary_node_IDs"] = as_id_array(
            all_the_IDs[ID_ordering]
        )
        self.looped_node_properties["linked_node_IDs"] = as_id_array(
            np.concatenate((these_linked_nodes, existing_links))[ID_ordering]
        )

        if np.any(
            self._node_status[self.looped_node_properties["boundary_node_IDs"]] == 2
        ):
            raise AttributeError(
                "Switching a boundary between fixed gradient and looped will "
                "result in bad BC handling! Bailing out..."
            )

    def node_vector_to_raster(self, u, flip_vertically=False):
        """Unravel an array of node values.

        Converts node vector *u* to a 2D array and returns it, so that it
        can be plotted, output, etc.

        If the *flip_vertically* keyword is True, this function returns an
        array that has the rows in reverse order. This is useful for use in
        plot commands (such as the image display functions) that puts the
        first row at the top of the image. In the landlab coordinate system,
        the first row is thought to be at the bottom. Thus, a flipped matrix
        will plot in the landlab style with the first row at the bottom.

        The returned array is a view of *u*, not a copy.

        See also
        --------
        RasterModelGrid.nodes
            An equivalent property, but without the option to flip the grid.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5))
        >>> u = rmg.zeros(centering="node")
        >>> u = u + range(0, len(u))
        >>> u
        array([ 0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,
               11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.])
        >>> ur = rmg.node_vector_to_raster(u)
        >>> ur
        array([[ 0.,   1.,   2.,   3.,   4.],
               [ 5.,   6.,   7.,   8.,   9.],
               [10.,  11.,  12.,  13.,  14.],
               [15.,  16.,  17.,  18.,  19.]])
        >>> ur = rmg.node_vector_to_raster(u, flip_vertically=True)
        >>> ur
        array([[15.,  16.,  17.,  18.,  19.],
               [10.,  11.,  12.,  13.,  14.],
               [ 5.,   6.,   7.,   8.,   9.],
               [ 0.,   1.,   2.,   3.,   4.]])

        :meta landlab: info-grid, info-node
        """
        return sgrid.reshape_array(self.shape, u, flip_vertically=flip_vertically)

    def cell_vector_to_raster(self, u, flip_vertically=False):
        """Unravel a 1D array.

        Converts cell vector u to a 2D array and returns it,
        so that it can be plotted, output, etc.

        If the optional argument flip_vertically=True, the function returns an
        array that has the rows in reverse order, for use in plot commands
        (such as the image display functions) that put the (0,0) axis at the
        top left instead of the bottom left.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 5))
        >>> u = rmg.zeros(centering="cell")
        >>> u = u + range(0, len(u))
        >>> u
        array([0.,  1.,  2.,  3.,  4.,  5.])
        >>> ur = rmg.cell_vector_to_raster(u)
        >>> ur
        array([[0.,  1.,  2.],
               [3.,  4.,  5.]])
        >>> ur = rmg.cell_vector_to_raster(u, flip_vertically=True)
        >>> ur
        array([[3.,  4.,  5.],
               [0.,  1.,  2.]])

        :meta landlab: info-grid, info-cell
        """
        return sgrid.reshape_array(
            (self.shape[0] - 2, self.shape[1] - 2), u, flip_vertically=flip_vertically
        )

    def roll_nodes_ud(self, data_name, shift, interior_only=False):
        """Roll (shift) specified data on nodes up or down in a raster grid.

        Similar to the Numpy roll() function, in that it shifts node values up
        by *shift* rows, wrapping the data in the top row(s) around to the
        bottom. If the *interior_only* is set, data along the left and right
        grid edges are not changed.

        Note that the contents of the *data_name* field are changed.

        Parameters
        ----------
        data_name : string
            Name of node-data item attached to grid.
        shift : int
            Number of rows to shift upward.
        interior_only : bool, optional
            If True, data along left and right edges are not shifted

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 3))
        >>> data = rmg.add_zeros("test_data", at="node")
        >>> data[:] = np.arange(12)
        >>> rmg.roll_nodes_ud("test_data", 1)
        >>> data.reshape(rmg.shape)
        array([[  9.,  10.,  11.],
               [  0.,   1.,   2.],
               [  3.,   4.,   5.],
               [  6.,   7.,   8.]])
        >>> rmg.roll_nodes_ud("test_data", 2)
        >>> data.reshape(rmg.shape)
        array([[  3.,   4.,   5.],
               [  6.,   7.,   8.],
               [  9.,  10.,  11.],
               [  0.,   1.,   2.]])
        >>> rmg.roll_nodes_ud("test_data", 1, interior_only=True)
        >>> data.reshape(rmg.shape)
        array([[  3.,   1.,   5.],
               [  6.,   4.,   8.],
               [  9.,   7.,  11.],
               [  0.,  10.,   2.]])

        :meta landlab: info-node
        """
        # Get the data
        data = self.at_node[data_name]

        # Get the IDs of the nodes in the top row, and number of rows and cols
        top_ids = self.nodes_at_top_edge
        ncols = self.number_of_node_columns
        nrows = self.number_of_node_rows

        # To handle "interior only" option, we use the variable *offset*,
        # which is zero if shifting everything, and 1 if shifting just the
        # interior -- we use this to go from column 1 to column N-2 (instead
        # of 0 to N-1) when interior_only is True.
        if interior_only:
            offset = 1
            top_ids = top_ids[1 : ncols - 1]
        else:
            offset = 0

        # Remember the top N rows
        top_rows_to_move = np.zeros((shift, ncols - 2 * offset))
        for i in range(0, shift):
            top_rows_to_move[shift - (i + 1), :] = data[top_ids - i * ncols]

        # Go row by row, starting from top
        for i in range(nrows - shift):
            to_row = nrows - (i + 1)
            from_row = to_row - shift
            data[ncols * to_row + offset : ncols * (to_row + 1) - offset] = data[
                ncols * from_row + offset : ncols * (from_row + 1) - offset
            ]

        # now replace the bottom *shift* rows
        for i in range(0, shift):
            data[ncols * i + offset : ncols * (i + 1) - offset] = top_rows_to_move[i, :]

    def node_has_boundary_neighbor(self, ids, method="d8"):
        """Check if nodes have neighbors that are boundary nodes.

        Checks to see if one of the eight neighbor nodes of node(s) with
        *id* has a boundary node.  Returns True if a node has a boundary node,
        False if all neighbors are interior.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((5, 5))
        >>> mg.node_has_boundary_neighbor(6)
        True
        >>> mg.node_has_boundary_neighbor(12)
        False
        >>> mg.node_has_boundary_neighbor([12, -1])
        array([False,  True])

        >>> mg.node_has_boundary_neighbor(25)
        Traceback (most recent call last):
        ...
        IndexError: index 25 is out of bounds for axis 0 with size 25

        :meta landlab: info-node, connectivity, boundary-condition
        """
        ans = _node_has_boundary_neighbor(self, ids, method=method)

        if ans.ndim == 0:
            return bool(ans)
        else:
            return ans

    @return_id_array
    def grid_coords_to_node_id(self, row, col, **kwds):
        """Convert node indices to node ID.

        Returns the ID of the node at the specified *row* and *col* of the
        raster grid. Since this is a wrapper for the numpy ravel_multi_index
        function, the keyword arguments are the same as that function. In
        addition, *row* and *col* can both be either scalars or arrays (of the
        same length) to get multiple ids.

        As with ravel_multi_index use the *mode* keyword to change the
        behavior of the method when passed an out-of-range *row* or *col*.
        The default is to raise ValueError (not IndexError, as you might
        expect).

        .. note::

            The syntax assumes that first row and column are 0,
            so max entry for a mg with 4 rows and 5 cols is row=3, col=4

        Parameters
        ----------
        row : array-like
            Row of node.
        col : array-like
            Column of node.

        Returns
        -------
        ndarray
            Node IDs.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((4, 5))
        >>> mg.grid_coords_to_node_id(2, 3)
        13

        >>> mg.grid_coords_to_node_id([2, 0], [3, 4])
        array([13,  4])

        :meta landlab: info-node, subset, quantity
        """
        return np.ravel_multi_index((row, col), self.shape, **kwds)

    def calc_unit_normal_at_patch(self, elevs="topographic__elevation"):
        """Calculate and return the unit normal vector <a, b, c> to a patch.

        This method is not defined on a raster, as there is no unique unit
        normal for a square patch. Use
        `_calc_unit_normals_to_patch_subtriangles` instead.

        :meta landlab: info-patch, gradient
        """
        raise NotImplementedError(
            "This method is not defined on a raster, as there is no unique "
            "unit normal for a square patch. Use "
            "`_calc_unit_normals_to_patch_subtriangles` instead."
        )

    def calculate_slope_aspect_at_nodes_burrough(self, ids=None, vals="Elevation"):
        """Calculate topographic slope.

        Calculates the local topographic slope (i.e., the down-dip slope, and
        presented as positive), and the aspect (dip direction in degrees
        clockwise from north), at the given nodes, *ids*. All *ids* must be of
        core nodes.
        This method uses Burrough's 1998 Pg. 190 method similar to the methods
        used by ArcMap to calculate slope and aspect.

        If *ids* is not provided, the slope will be returned for nodes at all
        cells.

        *vals* is either the name of an existing grid field from which to draw
        topographic data, or an array of values to use. If an array of values
        is passed, it must be nnodes long.
        If *vals* is not provided, this method will default to trying to use
        the field 'Elevation'.

        Returns
        -------
        (slope, aspect) : tuple of float
            *slope*, a len(ids) array of slopes at each node provided.
            *aspect*, a len(ids) array of aspects at each node provided.

        Examples
        --------
        >>> import pytest
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 4))
        >>> z = np.array([0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3, 6.0, 6.0, 6.0, 6.0])
        >>> slope, aspect = grid.calculate_slope_aspect_at_nodes_burrough(vals=z)
        >>> np.tan(slope)
        array([0.75,  0.75])
        >>> np.degrees(aspect)
        array([180.,  180.])

        We recommend using the following functions instead of this one:
        - :py:meth:`~landlab.grid.RasterModelGrid.calc_slope_at_node`
        - :py:meth:`~landlab.grid.RasterModelGrid.calc_aspect_at_node`
        Notice that :py:meth:`~landlab.grid.RasterModelGrid.calc_slope_at_node`
        and `:py:meth:`~landlab.grid.RasterModelGrid.calc_aspect_at_node` return
        values for all nodes, not just core nodes. In addition,
        `:py:meth:`~landlab.grid.RasterModelGrid.calc_aspect_at_node` returns
        compass-style angles in degrees.

        >>> np.tan(grid.calc_slope_at_node(elevs=z)[grid.core_nodes])
        array([0.75,  0.75])
        >>> grid.calc_aspect_at_node(elevs=z)[grid.core_nodes]
        array([180.,  180.])

        :meta landlab: info-node, surface, gradient
        """
        if ids is None:
            ids = self.node_at_cell
        if not isinstance(ids, np.ndarray):
            ids = np.array([ids])
        if isinstance(vals, str):
            vals = self.at_node[vals]
        else:
            if len(vals) != self.number_of_nodes:
                raise IndexError("*vals* was not of a compatible length!")

        neighbors = np.zeros([ids.shape[0], 4], dtype=int)
        diagonals = np.zeros([ids.shape[0], 4], dtype=int)
        # [right, top, left, bottom]
        neighbors[:] = self.active_adjacent_nodes_at_node[ids]
        # [topright, topleft, bottomleft, bottomright]
        diagonals[:] = self.diagonal_adjacent_nodes_at_node[ids]

        right = vals[neighbors[:, 0]]
        top = vals[neighbors[:, 1]]
        left = vals[neighbors[:, 2]]
        bottom = vals[neighbors[:, 3]]
        top_right = vals[diagonals[:, 0]]
        top_left = vals[diagonals[:, 1]]
        bottom_left = vals[diagonals[:, 2]]
        bottom_right = vals[diagonals[:, 3]]

        dz_dx = (
            (top_right + 2 * right + bottom_right) - (top_left + 2 * left + bottom_left)
        ) / (8.0 * self.dx)
        dz_dy = (
            (bottom_left + 2 * bottom + bottom_right) - (top_left + 2 * top + top_right)
        ) / (8.0 * self.dy)

        slope = np.zeros([ids.shape[0]], dtype=float)
        aspect = np.zeros([ids.shape[0]], dtype=float)
        slope = np.arctan(np.sqrt(dz_dx**2 + dz_dy**2))
        aspect = np.arctan2(dz_dy, -dz_dx)
        aspect = np.pi * 0.5 - aspect
        aspect[aspect < 0.0] = aspect[aspect < 0.0] + 2.0 * np.pi
        aspect[slope == 0.0] = -1.0

        return slope, aspect

    def save(self, path, names=None, format=None, at=None):
        """Save a grid and fields.

        If more than one field name is specified for names when saving to ARC
        ascii, multiple files will be produced, suffixed with the field names.

        When saving to netCDF (.nc), the fields are incorporated into the
        single named .nc file.

        Parameters
        ----------
        path : str
            Path to output file.
        names : iterable of strings, optional
            List of field names to save, defaults to all if not specified.
        format : {'netcdf', 'esri-ascii'}, optional
            Output file format. Guess from file extension if not given.
        at : str
            Grid element where values are defined.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> import os
        >>> from tempfile import mkdtemp

        >>> grid = RasterModelGrid((4, 5))
        >>> fname = os.path.join(mkdtemp(), "mysave.nc")
        >>> grid.save(fname)
        >>> os.path.isfile(fname)
        True
        >>> os.remove(fname)

        :meta landlab: info-grid
        """
        from ..io import write_esri_ascii
        from ..io.netcdf import write_netcdf

        format = format or _guess_format_from_name(path)
        path = _add_format_extension(path, format)

        if format == "netcdf":
            write_netcdf(path, self, format="NETCDF3_64BIT", names=names, at=at)
        elif format == "esri-ascii":
            write_esri_ascii(path, self, names=names)
        else:
            raise ValueError("format not understood")

    @property
    @make_return_array_immutable
    def looped_neighbors_at_cell(self):
        """For each cell in a raster, return the D8 neighboring cells, looping
        across grid boundaries as necessary.

        Returns lists of looped neighbor cell IDs of given *cell ids*.
        If *cell ids* are not given, it returns a 2D array of size
        (self.number_of_cells, 8).
        Order or neighbors is [ E, NE, N, NW, W, SW, S, SE ]

        Output is looped, regardless of boundary conditions! (see examples)

        Returns
        -------
        ndarray (num_cells, 8)
            The eight neighbors of each cell.

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> neighbors = grid.looped_neighbors_at_cell
        >>> neighbors[1, :]
        array([2, 5, 4, 3, 0, 3, 4, 5])
        >>> neighbors[5, :]
        array([3, 0, 2, 1, 4, 1, 2, 0])
        >>> grid.looped_neighbors_at_cell[np.array([1, 5]), :]
        array([[2, 5, 4, 3, 0, 3, 4, 5],
               [3, 0, 2, 1, 4, 1, 2, 0]])

        :meta landlab: deprecated, info-cell, connectivity, boundary-condition
        """
        if self._looped_cell_neighbor_list is not None:
            return self._looped_cell_neighbor_list
        else:
            self._looped_cell_neighbor_list = self._create_looped_cell_neighbor_list()
            return self.looped_neighbors_at_cell

    def _create_looped_cell_neighbor_list(self):
        """Create a list of looped immediate cell neighbors (8 adjacent cells).

        Creates a list of looped immediate cell neighbors (*cell ids*) for each
        cell as a 2D array of size ( self.number_of_cells, 8 ).
        Order or neighbors is [ E, NE, N, NW, W, SW, S, SE ]

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> grid = RasterModelGrid((4, 5))
        >>> neighbors = grid._create_looped_cell_neighbor_list()
        >>> neighbors[1]
        array([2, 5, 4, 3, 0, 3, 4, 5])
        >>> neighbors[5]
        array([3, 0, 2, 1, 4, 1, 2, 0])
        """
        # CAUTION: Some terminology concerning cells in this module
        # is asynchronous to general understanding. This is intentionally
        # left as is until further discussion among dev group.
        # Any such instances are marked with (*TC - Terminoly Caution)
        nrows, ncols = self.cell_grid_shape
        interior_cells = sgrid.interior_nodes(self.cell_grid_shape)  # *TC
        cells_at_corners_of_grid = self.cells_at_corners_of_grid  # *TC

        # The cells along the edges minus the corner cells.
        top_edge_cells = self.cell_at_node[self.nodes[-2, :]][2:-2]
        bottom_edge_cells = self.cell_at_node[self.nodes[1, :]][2:-2]
        left_edge_cells = self.cell_at_node[self.nodes[:, 1]][2:-2]
        right_edge_cells = self.cell_at_node[self.nodes[:, -2]][2:-2]

        looped_cell_neighbors = np.empty([self.number_of_cells, 8], dtype=int)

        # order = [E,NE,N,NW,W,SW,S,SE]
        for cell in range(0, self.number_of_cells):
            if cell in interior_cells:
                neighbor_ = [
                    cell + 1,
                    cell + 1 + ncols,
                    cell + ncols,
                    cell + ncols - 1,
                    cell - 1,
                    cell - ncols - 1,
                    cell - ncols,
                    cell - ncols + 1,
                ]
            elif cell in bottom_edge_cells:
                neighbor_ = [
                    cell + 1,
                    cell + 1 + ncols,
                    cell + ncols,
                    cell + ncols - 1,
                    cell - 1,
                    cell + (nrows - 1) * ncols - 1,
                    cell + (nrows - 1) * ncols,
                    cell + (nrows - 1) * ncols + 1,
                ]
            elif cell in top_edge_cells:
                neighbor_ = [
                    cell + 1,
                    cell - (nrows - 1) * ncols + 1,
                    cell - (nrows - 1) * ncols,
                    cell - (nrows - 1) * ncols - 1,
                    cell - 1,
                    cell - ncols - 1,
                    cell - ncols,
                    cell - ncols + 1,
                ]
            elif cell in right_edge_cells:
                neighbor_ = [
                    cell - ncols + 1,
                    cell + 1,
                    cell + ncols,
                    cell + ncols - 1,
                    cell - 1,
                    cell - ncols - 1,
                    cell - ncols,
                    cell - 2 * ncols + 1,
                ]
            elif cell in left_edge_cells:
                neighbor_ = [
                    cell + 1,
                    cell + ncols + 1,
                    cell + ncols,
                    cell + 2 * ncols - 1,
                    cell + ncols - 1,
                    cell - 1,
                    cell - ncols,
                    cell - ncols + 1,
                ]
            elif cell == cells_at_corners_of_grid[0]:  # SW corner
                neighbor_ = [
                    cell + 1,
                    cell + ncols + 1,
                    cell + ncols,
                    cell + 2 * ncols - 1,
                    cell + ncols - 1,
                    cell + nrows * ncols - 1,
                    cell + (nrows - 1) * ncols,
                    cell + (nrows - 1) * ncols + 1,
                ]
            elif cell == cells_at_corners_of_grid[1]:  # SE corner
                neighbor_ = [
                    cell - ncols + 1,
                    cell + 1,
                    cell + ncols,
                    cell + ncols - 1,
                    cell - 1,
                    cell + (nrows - 1) * ncols - 1,
                    cell + (nrows - 1) * ncols,
                    cell + (nrows - 2) * ncols + 1,
                ]
            elif cell == cells_at_corners_of_grid[2]:  # NW corner
                neighbor_ = [
                    cell + 1,
                    cell - (nrows - 1) * ncols + 1,
                    cell - (nrows - 1) * ncols,
                    cell - (nrows - 2) * ncols - 1,
                    cell + ncols - 1,
                    cell - 1,
                    cell - ncols,
                    cell - ncols + 1,
                ]
            elif cell == cells_at_corners_of_grid[3]:  # NE corner
                neighbor_ = [
                    cell - ncols + 1,
                    cell - nrows * ncols + 1,
                    cell - (nrows - 1) * ncols,
                    cell - (nrows - 1) * ncols - 1,
                    cell - 1,
                    cell - ncols - 1,
                    cell - ncols,
                    cell - 2 * ncols + 1,
                ]
            looped_cell_neighbors[cell] = neighbor_

        return looped_cell_neighbors

    @property
    @make_return_array_immutable
    def second_ring_looped_neighbors_at_cell(self):
        """Get list of second ring looped neighbor cell IDs (all 16 neighbors).

        Returns lists of looped second ring neighbor cell IDs of
        given *cell ids*. If *cell ids* are not given, it returns
        a 2D array of size ( self.number_of_cells, 16 ).

        The cells are the 16 which encircle the nine true neighbor cells.
        Order of neighbors: Starts with E and goes counter clockwise

        Examples
        --------
        >>> from landlab import RasterModelGrid
        >>> mg = RasterModelGrid((10, 10))
        >>> mg.second_ring_looped_neighbors_at_cell[36, :]
        array([38, 46, 54, 53, 52, 51, 50, 42, 34, 26, 18, 19, 20, 21, 22, 30])
        >>> mg.second_ring_looped_neighbors_at_cell[8, :]
        array([10, 18, 26, 25, 24, 31, 30, 22, 14,  6, 62, 63, 56, 57, 58,  2])

        ...take a look at the cell grid to understand why::

            [56, 57, 58, 59, 60, 61, 62, 63]
            [48, 49, 50, 51, 52, 53, 54, 55]
            [40, 41, 42, 43, 44, 45, 46, 47]
            [32, 33, 34, 35, 36, 37, 38, 39]
            [24, 25, 26, 27, 28, 29, 30, 31]
            [16, 17, 18, 19, 20, 21, 22, 23]
            [ 8,  9, 10, 11, 12, 13, 14, 15]
            [ 0,  1,  2,  3,  4,  5,  6,  7]

        :meta landlab: info-cell, connectivity, boundary-condition
        """
        if self._looped_second_ring_cell_neighbor_list_created:
            return self.second_ring_looped_cell_neighbor_list
        else:
            self.second_ring_looped_cell_neighbor_list = (
                self._create_second_ring_looped_cell_neighbor_list()
            )
            return self.second_ring_looped_neighbors_at_cell

    def _create_second_ring_looped_cell_neighbor_list(self):
        """Create list of looped second ring cell neighbors (16 cells).

        Creates a list of looped immediate cell neighbors for each cell
        as a 2D array of size ( self.number_of_cells, 16 ). Order or
        neighbors: Starts with E and goes counter clockwise
        """
        inf = self.looped_neighbors_at_cell
        second_ring = np.empty([self.number_of_cells, 16], dtype=int)
        order = np.arange(-1, 15)
        order[0] = 15
        for cell in range(0, self.number_of_cells):
            cell1, cell2, cell3, cell4 = (
                inf[cell][1],
                inf[cell][3],
                inf[cell][5],
                inf[cell][7],
            )
            ring_tw = np.concatenate(
                (
                    inf[cell1][0:4],
                    inf[cell2][2:6],
                    inf[cell3][4:8],
                    inf[cell4][6:8],
                    inf[cell4][0:2],
                )
            )[order]
            second_ring[cell] = ring_tw

        self._looped_second_ring_cell_neighbor_list_created = True
        return second_ring

    def set_watershed_boundary_condition(
        self,
        node_data,
        nodata_value=-9999.0,
        return_outlet_id=False,
        remove_disconnected=False,
        adjacency_method="D8",
    ):
        """Finds the node adjacent to a boundary node with the smallest value.
        This node is set as the outlet.  The outlet node must have a data
        value.  Can return the outlet id as a one element numpy array if
        return_outlet_id is set to True.

        All nodes with nodata_value are set to ``BC_NODE_IS_CLOSED``
        (grid.status_at_node == 4). All nodes with data values are set to
        ``BC_NODE_IS_CORE`` (grid.status_at_node == 0), with the exception that the
        outlet node is set to a ``BC_NODE_IS_FIXED_GRADIENT`` (grid.status_at_node == 1).

        Note that the outer ring (perimeter) of the raster is set to
        ``BC_NODE_IS_CLOSED``, even if there are nodes that have values. The only
        exception to this would be if the outlet node is on the perimeter, which
        is acceptable.

        This routine assumes that all of the nodata_values are on the outside of
        the data values. In other words, there are no islands of nodata_values
        surrounded by nodes with data.

        This also assumes that the grid has a single watershed (that is a single
        outlet node).

        If you are considering running flow routing algorithms on this model
        grid, it is recommended that you verify the absence of non-closed nodes
        surrounded only by closed nodes. The presence of these isolated non-
        closed nodes may result from clipping a raster to a polygon and will
        prevent the flow router from functioning as intended.

        This can be acomplished by setting the
        parameter: *remove_disconnected* to True (default is False).

        This will run the function:
        set_open_nodes_disconnected_from_watershed_to_closed
        which will find any isolated open nodes that have no neigbors in the
        main watershed and set them to closed. The adjacency method used
        to assess connectivity can be set to either 'D8'(default) or 'D4' using
        the flag *adjacency_method*.

        Finally, the developer has seen cases in which DEM data that has been
        filled results in a different outlet from DEM data which has not been
        filled.  Be aware that if you identify an outlet on a filled DEM, make
        sure that the filled DEM is what is being used for your modeling.
        Otherwise, this may find a different outlet.  To force the outlet
        location, use either set_watershed_boundary_condition_outlet_coords
        or set_watershed_boundary_condition_outlet_id.

        Parameters
        ----------
        node_data : field name or ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        nodata_value : float, optional
            Value that indicates an invalid value.
        return_outlet_id : boolean, optional
            Indicates whether or not to return the id of the found outlet
        remove_disconnected : boolean, optional
            Indicates whether to search for and remove disconnected nodes.
        adjacency_method : string, optional. Default is 'D8'.
            Sets the connection method for use if remove_disconnected==True

        Returns
        --------
        outlet_loc : array
            Array of size 1 containing id of outlet location

        Examples
        --------

        The first example will use a 4,4 grid with node data values
        as illustrated::

            -9999. -9999. -9999. -9999.
            -9999.    67.     0. -9999.
            -9999.    67.    67. -9999.
            -9999. -9999. -9999. -9999.

        The second example will use a 4,4 grid with node data values
        as illustrated::

            -9999. -9999. -9999. -9999.
            -9999.    67.     0. -9999.
            -9999.    67.     67.   -2.
            -9999. -9999. -9999. -9999.

        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 4))
        >>> node_data = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -9999.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> out_id = rmg.set_watershed_boundary_condition(node_data, -9999.0, True)
        >>> out_id
        array([10])
        >>> rmg.status_at_node
        array([4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 1, 4, 4, 4, 4, 4], dtype=uint8)
        >>> rmg2 = RasterModelGrid((4, 4))
        >>> node_data2 = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -2.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> rmg2.set_watershed_boundary_condition(node_data2, -9999.0)
        >>> rmg2.status_at_node
        array([4, 4, 4, 4, 4, 0, 0, 1, 4, 0, 0, 4, 4, 4, 4, 4], dtype=uint8)

        The node data can also be provided as a model grid field.

        >>> rmg = RasterModelGrid((4, 4))
        >>> node_data = [
        ...     [-9999.0, -9999.0, -9999.0, -9999.0],
        ...     [-9999.0, 67.0, 67.0, -9999.0],
        ...     [-9999.0, 67.0, 0.0, -9999.0],
        ...     [-9999.0, -9999.0, -9999.0, -9999.0],
        ... ]
        >>> _ = rmg.add_field("topographic__elevation", node_data, at="node")
        >>> out_id = rmg.set_watershed_boundary_condition(
        ...     "topographic__elevation", -9999.0, True
        ... )
        >>> out_id
        array([10])
        >>> rmg.status_at_node
        array([4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 1, 4, 4, 4, 4, 4], dtype=uint8)

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        # For this to be a watershed, need to make sure that there is a ring
        # of closed boundary nodes around the outside of the watershed,
        # barring the outlet location.  So enforce that all perimeter nodes
        # are inactive boundaries now, then set the outlet location later.
        # By enforcing the perimeter of closed values first, then fixing the
        # outlet later, it should be OK if the outlet is on the perimeter.
        self.set_closed_boundaries_at_grid_edges(True, True, True, True)

        # Set no data nodes to inactive boundaries.
        # This may be redundant, but must do in case there are no data
        # values that are not on the perimeter.
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

        # need to find values that are not no_data

        # locs is a list that contains locations where
        # node data is not equal to the nodata value
        locs = np.where(node_data != nodata_value)
        if len(locs) < 1:
            raise ValueError("All data values are no_data values")

        # now find minimum of the data values
        min_val = np.min(node_data[locs])

        # now find where minimum values are
        min_locs = np.where(node_data == min_val)[0]

        # check all the locations with the minimum value to see if one
        # is adjacent to a boundary location.  If so, that will be the
        # watershed outlet.  If none of these points qualify, then
        # increase the minimum value and check again.  Keep checking
        # until a point next to the boundary is found.
        # NG I think the only way this would become an infinite loop
        # is if there are no interior nodes.  Should be checking for
        # this above.
        not_found = True
        while not_found:
            # now check the min locations to see if any are next to
            # a boundary node
            local_not_found = True
            next_to_boundary = []

            # check all nodes rather than selecting the first node that meets
            # the criteria
            for i in range(len(min_locs)):
                next_to_boundary.append(self.node_has_boundary_neighbor(min_locs[i]))

            # if any of those nodes were adjacent to the boundary, check
            # that  there is only one. If only one, set as outlet loc, else,
            # raise a value error
            if any(next_to_boundary):
                local_not_found = False
                if sum(next_to_boundary) > 1:
                    potential_locs = min_locs[np.where(np.asarray(next_to_boundary))[0]]
                    raise ValueError(
                        "Grid has two potential outlet nodes."
                        "They have the following node IDs: \n"
                        + str(potential_locs)
                        + "\nUse the method set_watershed_boundary_condition_outlet_id "
                        "to explicitly select one of these "
                        "IDs as the outlet node."
                    )
                else:
                    outlet_loc = min_locs[np.where(next_to_boundary)[0][0]]

            # checked all of the min vals, (so done with inner while)
            # and none of the min values were outlet candidates
            if local_not_found:
                # need to find the next largest minimum value
                # first find the locations of all values greater
                # than the old minimum
                # not done with outer while
                locs = np.where((node_data > min_val) & (node_data != nodata_value))
                # now find new minimum of these values
                min_val = np.min(node_data[locs])
                min_locs = np.where(node_data == min_val)[0]
            else:
                # if locally found, it is also globally found
                # so done with outer while
                not_found = False

        # set outlet boundary condition
        self.status_at_node[outlet_loc] = NodeStatus.FIXED_VALUE

        if remove_disconnected:
            self.set_open_nodes_disconnected_from_watershed_to_closed(
                node_data=node_data,
                outlet_id=as_id_array(np.array([outlet_loc])),
                nodata_value=nodata_value,
                adjacency_method=adjacency_method,
            )
        if return_outlet_id:
            return as_id_array(np.array([outlet_loc]))

    def set_open_nodes_disconnected_from_watershed_to_closed(
        self, node_data, outlet_id=None, nodata_value=-9999.0, adjacency_method="D8"
    ):
        """Identifys all non-closed nodes that are disconnected from the node
        given in.

        *outlet_id* and sets them as closed.

        If *outlet_id* is not given, the outlet will be identified as the node
        for which the status at the node is ``BC_NODE_IS_FIXED_VALUE``. If more than
        one node has this value, the algorithm will fail.

        If *outlet_id* is given, the algorithm will check that it is not a node
        with status of ``BC_NODE_IS_CLOSED``.

        The method supports both D4 and D8 (default) neighborhood evaluation in
        determining if a node is connected. This can be modified with the flag
        *adjacency_method*.

        This function can be run directly, or by setting the flag
        remove_disconnected to True in set_watershed_boundary_condition

        Parameters
        ----------
        node_data : field name or ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        outlet_id : one element numpy array, optional.
            The node ID of the outlet that all open nodes must be connected to.
            If a node ID is provided, it does not need have the status
            ``BC_NODE_IS_FIXED_VALUE``. However, it must not have the status of
            ``BC_NODE_IS_CLOSED``.
        nodata_value : float, optional, default is -9999.
            Value that indicates an invalid value.
        adjacency_method : string, optional. Default is 'D8'.
            Sets the connection method.

        Examples
        --------
        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> mg1 = RasterModelGrid((4, 6))
        >>> z1 = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -9999.0, 50.0, -9999.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> mg2 = RasterModelGrid((4, 6))
        >>> z2 = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -9999.0, 50.0, -9999.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> mg1.set_watershed_boundary_condition(z1, remove_disconnected=True)
        >>> mg2.set_watershed_boundary_condition(z2)
        >>> mg2.status_at_node.reshape(mg2.shape)
        array([[4, 4, 4, 4, 4, 4],
               [4, 0, 0, 4, 0, 4],
               [4, 0, 1, 4, 4, 4],
               [4, 4, 4, 4, 4, 4]], dtype=uint8)
        >>> mg2.set_open_nodes_disconnected_from_watershed_to_closed(z2)
        >>> np.allclose(mg1.status_at_node, mg2.status_at_node)
        True
        >>> np.allclose(z1, z2)
        True
        >>> mg2.status_at_node.reshape(mg2.shape)
        array([[4, 4, 4, 4, 4, 4],
               [4, 0, 0, 4, 4, 4],
               [4, 0, 1, 4, 4, 4],
               [4, 4, 4, 4, 4, 4]], dtype=uint8)
        >>> z1.reshape(mg1.shape)
        array([[-9999., -9999., -9999., -9999., -9999., -9999.],
               [-9999.,    67.,    67., -9999., -9999., -9999.],
               [-9999.,    67.,     0., -9999., -9999., -9999.],
               [-9999., -9999., -9999., -9999., -9999., -9999.]])

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        if outlet_id is None:
            # verify that there is one and only one node with the status
            # BC_NODE_IS_FIXED_VALUE.
            possible_outlets = np.where(self.status_at_node == NodeStatus.FIXED_VALUE)[
                0
            ]

            if len(possible_outlets) > 1:
                raise ValueError(
                    "Model grid must only have one node with node status of "
                    f"BC_NODE_IS_FIXED_VALUE. This grid has {len(possible_outlets)}."
                )
            if len(possible_outlets) < 1:
                raise ValueError(
                    "Model grid must only have one node with node status of "
                    "BC_NODE_IS_FIXED_VALUE. This grid has none"
                )

            outlet_id = possible_outlets

        elif outlet_id.size != 1 or (isinstance(outlet_id, np.ndarray) is False):
            # check that the value given by outlet_id is an integer
            raise ValueError("outlet_id must be a length 1 numpy array")
        else:
            # check that the node status at the node given by outlet_id is not
            # BC_NODE_IS_CLOSED
            if self.status_at_node[outlet_id] == self.BC_NODE_IS_CLOSED:
                raise ValueError(
                    "The node given by outlet_id must not have the status: BC_NODE_IS_CLOSED"
                )

        # now test that the method given is either 'D8' or 'D4'
        if adjacency_method != "D8":
            assert (
                adjacency_method == "D4"
            ), "Method must be either 'D8'(default) or 'D4'"

        # begin main code portion.
        # initialize list of core nodes and new nodes
        connected_nodes = list(outlet_id)
        newNodes = connected_nodes

        # keep track of the number of nodes added in the previous itteration.
        numAdded = len(newNodes)

        # continue running until no new nodes are added.
        while numAdded > 0:
            # find all potential new nodes by filtering the nodes connected to
            # the most recent set of new nodes based on their status.
            connected_orthogonal_nodes = self.adjacent_nodes_at_node[newNodes]
            potentialNewNodes = list(
                connected_orthogonal_nodes[
                    self.status_at_node[connected_orthogonal_nodes]
                    != self.BC_NODE_IS_CLOSED
                ]
            )

            # if method is D8 (default), add the diagonal nodes.
            if adjacency_method == "D8":
                connected_diagonal_nodes = self.diagonal_adjacent_nodes_at_node[
                    newNodes
                ]
                potentialNewNodes.extend(
                    connected_diagonal_nodes[
                        self.status_at_node[connected_diagonal_nodes]
                        != self.BC_NODE_IS_CLOSED
                    ]
                )

            # filter new nodes further based on if they are already present in
            # the connected node list
            newNodes = list(set(potentialNewNodes) - set(connected_nodes))
            connected_nodes.extend(newNodes)

            # update number added, when this is zero, the loop will end
            numAdded = len(newNodes)

        # create an array that identifies the nodes that should be closed
        # of closed boundary nodes
        not_connected = np.array((0 * self.status_at_node) + 1)
        not_connected[np.array(connected_nodes)] = 0

        # identify those nodes that should be closed, but are not yet closed.
        is_not_connected_to_outlet = (self.status_at_node != self.BC_NODE_IS_CLOSED) & (
            not_connected == 1
        )

        # modify the node_data array to set those that are disconnected
        # to the no data value.
        node_data[is_not_connected_to_outlet] = nodata_value  #

        # finally update the status of the nodes based on the modified node_data.
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

    def set_watershed_boundary_condition_outlet_coords(
        self, outlet_coords, node_data, nodata_value=-9999.0
    ):
        """Set the boundary conditions for a watershed. All nodes with
        nodata_value are set to ``BC_NODE_IS_CLOSED`` (grid.status_at_node == 4). All
        nodes with data values are set to CORE_NODES (grid.status_at_node ==
        0), with the exception that the outlet node is set to a
        BC_NODE_IS_FIXED_VALUE (grid.status_at_node == 1).

        Note that the outer ring of the raster is set to ``BC_NODE_IS_CLOSED``, even
        if there are nodes that have values.  The only exception to this would
        be if the outlet node is on the boundary, which is acceptable.

        Assumes that outlet is already known.

        This assumes that the grid has a single watershed.  If this is not
        the case this will not work.

        This must be passed the values of the outlet_row and outlet_column.
        Also takes node_data and optionally, nodata_value.

        Parameters
        ----------
        outlet_coords : list - two integer values
            row, column of outlet, NOT THE ABSOLUTE X AND Y LOCATIONS
        node_data : field name or ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        nodata_value : float, optional
            Value that indicates an invalid value.

        Examples
        --------
        The example will use a 4,4 grid with node data values
        as illustrated::

            -9999. -9999. -9999. -9999.
            -9999.    67.     0. -9999.
            -9999.    67.    67. -9999.
            -9999. -9999. -9999. -9999.

        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 4))
        >>> rmg.status_at_node
        array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1], dtype=uint8)
        >>> node_data = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -9999.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> rmg.set_watershed_boundary_condition_outlet_coords(
        ...     (2, 2), node_data, -9999.0
        ... )
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[4, 4, 4, 4],
               [4, 0, 0, 4],
               [4, 0, 1, 4],
               [4, 4, 4, 4]], dtype=uint8)

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        # make ring of no data nodes
        self.set_closed_boundaries_at_grid_edges(True, True, True, True)

        # set no data nodes to inactive boundaries
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

        # find the id of the outlet node
        outlet_node = self.grid_coords_to_node_id(outlet_coords[0], outlet_coords[1])
        # set the boundary condition (fixed value) at the outlet_node
        self.status_at_node[outlet_node] = NodeStatus.FIXED_VALUE

    def set_watershed_boundary_condition_outlet_id(
        self, outlet_id, node_data, nodata_value=-9999.0
    ):
        """Set the boundary conditions for a watershed. All nodes with
        nodata_value are set to ``BC_NODE_IS_CLOSED`` (4). All nodes with data values
        are set to ``BC_NODE_IS_CORE`` (0), with the exception that the outlet node is
        set to a ``BC_NODE_IS_FIXED_VALUE`` (1).

        Note that the outer ring of the raster is set to ``BC_NODE_IS_CLOSED``, even
        if there are nodes that have values.  The only exception to this would
        be if the outlet node is on the boundary, which is acceptable.

        Assumes that the id of the outlet is already known.

        This assumes that the grid has a single watershed.  If this is not
        the case this will not work.

        Parameters
        ----------
        outlet_id : integer
            id of the outlet node
        node_data : field name or ndarray
            At-node field name or at-node data values to use for identifying
            watershed location.
        nodata_value : float, optional
            Value that indicates an invalid value.

        Examples
        --------
        The example will use a 4,4 grid with node data values
        as illustrated:

            -9999. -9999. -9999. -9999.
            -9999.    67.     0. -9999.
            -9999.    67.    67. -9999.
            -9999. -9999. -9999. -9999.

        >>> import numpy as np
        >>> from landlab import RasterModelGrid
        >>> rmg = RasterModelGrid((4, 4))
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[1, 1, 1, 1],
               [1, 0, 0, 1],
               [1, 0, 0, 1],
               [1, 1, 1, 1]], dtype=uint8)
        >>> node_data = np.array(
        ...     [
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...         [-9999.0, 67.0, 67.0, -9999.0],
        ...         [-9999.0, 67.0, 0.0, -9999.0],
        ...         [-9999.0, -9999.0, -9999.0, -9999.0],
        ...     ]
        ... ).flatten()
        >>> outlet = rmg.set_watershed_boundary_condition_outlet_id(
        ...     10, node_data, -9999.0
        ... )
        >>> rmg.status_at_node.reshape(rmg.shape)
        array([[4, 4, 4, 4],
               [4, 0, 0, 4],
               [4, 0, 1, 4],
               [4, 4, 4, 4]], dtype=uint8)

        :meta landlab: boundary-condition
        """
        # get node_data if a field name
        node_data = self.return_array_or_field_values(node_data, at="node")

        # make ring of no data nodes
        self.set_closed_boundaries_at_grid_edges(True, True, True, True)

        # set no data nodes to inactive boundaries
        self.set_nodata_nodes_to_closed(node_data, nodata_value)

        # set the boundary condition (fixed value) at the outlet_node
        self.status_at_node[outlet_id] = NodeStatus.FIXED_VALUE


def _guess_format_from_name(path):
    """Get file format by name.

    Parameters
    ----------
    path : str
        Path to file.

    Returns
    -------
    str
        File format as a string.
    """
    import os

    fname = os.path.basename(path)

    if fname.endswith(".nc"):
        return "netcdf"
    elif fname.endswith(".asc"):
        return "esri-ascii"
    else:
        return None


def _add_format_extension(path, format):
    """Add format extension to a file name.

    Parameters
    ----------
    path : str
        File name.
    format : str
        File format.

    Returns
    -------
    str
        File name with the file-format extension added.
    """
    import os

    (base, ext) = os.path.splitext(path)
    if format == "netcdf":
        ext = ".nc"
    elif format == "esri-ascii":
        ext = ".asc"
    return base + ext


add_module_functions_to_class(RasterModelGrid, "raster_mappers.py", pattern="map_*")
add_module_functions_to_class(RasterModelGrid, "raster_gradients.py", pattern="calc_*")
add_module_functions_to_class(RasterModelGrid, "raster_divergence.py", pattern="calc_*")
add_module_functions_to_class(
    RasterModelGrid, "raster_set_status.py", pattern="set_status_at_node*"
)



================================================
File: src/landlab/grid/raster_aspect.py
================================================
#! /usr/bin/env python
"""Calculate slope aspects on a `RasterModelGrid`."""


def _one_line_slopes(input_array, grid, vals):
    node = input_array[0]
    diagonals = input_array[5:]
    neighbors = input_array[1:5]

    if not grid.status_at_node[node] == 0:
        raise IndexError("One or more of the provided nodes was closed!")

    try:
        slope_we = (
            (vals[diagonals[1]] + 2.0 * vals[neighbors[2]] + vals[diagonals[2]])
            - (vals[diagonals[0]] + 2.0 * vals[neighbors[0]] + vals[diagonals[3]])
        ) / (8.0 * grid.dx)
        slope_sn = (
            (vals[diagonals[2]] + 2.0 * vals[neighbors[3]] + vals[diagonals[3]])
            - (vals[diagonals[1]] + 2.0 * vals[neighbors[:, 1]] + vals[diagonals[0]])
        ) / (8.0 * grid.dy)
        return slope_we, slope_sn
    except IndexError:
        C = vals[node]
        weighting_verticals = 4.0
        weighting_horizontals = 4.0
        try:
            vertical_grad = (vals[neighbors[3]] - vals[neighbors[1]]) / (2.0 * grid.dy)
        except IndexError:
            try:
                vertical_grad = (C - vals[neighbors[1]]) / grid.dy
            except IndexError:
                try:
                    vertical_grad = (vals[neighbors[3]] - C) / grid.dy
                except IndexError:
                    vertical_grad = 0.0
                    weighting_verticals -= 2.0
        try:
            horizontal_grad = (vals[neighbors[2]] - vals[neighbors[0]]) / (
                2.0 * grid.dx
            )
        except IndexError:
            try:
                horizontal_grad = (C - vals[neighbors[0]]) / grid.dx
            except IndexError:
                try:
                    horizontal_grad = (vals[neighbors[2]] - C) / grid.dx
                except IndexError:
                    horizontal_grad = 0.0
                    weighting_horizontals -= 2.0
        try:
            left_grad = (vals[diagonals[2]] - vals[diagonals[1]]) / (2.0 * grid.dx)
        except IndexError:
            try:
                C = vals[neighbors[2]]
            except IndexError:
                left_grad = 0.0
                weighting_verticals -= 1.0
            else:
                try:
                    left_grad = (C - vals[diagonals[1]]) / grid.dx
                except IndexError:
                    left_grad = (vals[diagonals[2]] - C) / grid.dx
        try:
            right_grad = (vals[diagonals[3]] - vals[diagonals[0]]) / (2.0 * grid.dx)
        except IndexError:
            try:
                C = vals[neighbors[0]]
            except IndexError:
                right_grad = 0.0
                weighting_verticals -= 1.0
            else:
                try:
                    right_grad = (C - vals[diagonals[0]]) / grid.dx
                except IndexError:
                    right_grad = (vals[diagonals[3]] - C) / grid.dx
        try:
            top_grad = (vals[diagonals[1]] - vals[diagonals[0]]) / (2.0 * grid.dy)
        except IndexError:
            try:
                C = vals[neighbors[1]]
            except IndexError:
                top_grad = 0.0
                weighting_horizontals -= 1.0
            else:
                try:
                    top_grad = (C - vals[diagonals[0]]) / grid.dy
                except IndexError:
                    top_grad = (vals[diagonals[1]] - C) / grid.dy
        try:
            bottom_grad = (vals[diagonals[2]] - vals[diagonals[3]]) / (2.0 * grid.dy)
        except IndexError:
            try:
                C = vals[neighbors[3]]
            except IndexError:
                bottom_grad = 0.0
                weighting_horizontals -= 1.0
            else:
                try:
                    bottom_grad = (C - vals[diagonals[3]]) / grid.dy
                except IndexError:
                    bottom_grad = (vals[diagonals[2]] - C) / grid.dy

        slope_we = (
            top_grad + 2.0 * horizontal_grad + bottom_grad
        ) / weighting_horizontals
        slope_sn = (left_grad + 2.0 * vertical_grad + right_grad) / weighting_verticals

        return slope_we, slope_sn



================================================
File: src/landlab/grid/raster_divergence.py
================================================
#! /usr/bin/env python
"""Calculate flux divergence on a raster grid."""
import numpy as np

from landlab.grid.ext.raster_divergence import _calc_flux_div_at_node
from landlab.grid.ext.raster_divergence import _calc_net_face_flux_at_cell
from landlab.utils.decorators import use_field_name_or_array


@use_field_name_or_array("link")
def calc_flux_div_at_node(grid, unit_flux, out=None):
    """Calculate divergence of link-based fluxes at nodes.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) divided by cell area, at each node (zero
    or "out" value for nodes without cells).

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux : ndarray or field name
        Flux per unit width along links (x number of links).

    Returns
    -------
    ndarray (x number of nodes)
        Flux divergence at nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_divergence import calc_flux_div_at_node

    >>> grid = RasterModelGrid((3, 4), xy_spacing=10.0)
    >>> z = grid.add_zeros("topographic__elevation", at="node")
    >>> z[5] = 50.0
    >>> z[6] = 36.0
    >>> z.reshape(grid.shape)
    array([[  0.,   0.,   0.,   0.],
           [  0.,  50.,  36.,   0.],
           [  0.,   0.,   0.,   0.]])
    >>> grads = grid.calc_grad_at_link(z)
    >>> grads[grid.horizontal_links].reshape((3, 3))
    array([[ 0. ,  0. ,  0. ],
           [ 5. , -1.4, -3.6],
           [ 0. ,  0. ,  0. ]])
    >>> grads[grid.vertical_links].reshape((2, 4))
    array([[ 0. ,  5. ,  3.6,  0. ],
           [ 0. , -5. , -3.6,  0. ]])
    >>> calc_flux_div_at_node(grid, -grads).reshape(grid.shape)
    array([[0.  ,  0.  ,  0.  ,  0.  ],
           [0.  ,  1.64,  0.94,  0.  ],
           [0.  ,  0.  ,  0.  ,  0.  ]])

    >>> grid.set_status_at_node_on_edges(right=grid.BC_NODE_IS_CLOSED)
    >>> grid.set_status_at_node_on_edges(top=grid.BC_NODE_IS_CLOSED)
    >>> unit_flux_at_links = grid.zeros(at="link")
    >>> unit_flux_at_links[grid.active_links] = -grads[grid.active_links]
    >>> calc_flux_div_at_node(grid, unit_flux_at_links).reshape(grid.shape)
    array([[0.  ,  0.  ,  0.  ,  0.  ],
           [0.  ,  1.14,  0.22,  0.  ],
           [0.  ,  0.  ,  0.  ,  0.  ]])
    >>> _ = grid.add_field("neg_grad_at_link", -grads, at="link")
    >>> calc_flux_div_at_node(grid, "neg_grad_at_link").reshape(grid.shape)
    array([[0.  ,  0.  ,  0.  ,  0.  ],
           [0.  ,  1.64,  0.94,  0.  ],
           [0.  ,  0.  ,  0.  ,  0.  ]])

    Notes
    -----
    Performs a numerical flux divergence operation on nodes.

    :meta landlab: info-node, gradient
    """
    if unit_flux.size != grid.number_of_links:
        raise ValueError("Parameter unit_flux must be num links " "long")
    if out is None:
        out = grid.zeros(at="node")
    elif out.size != grid.number_of_nodes:
        raise ValueError("output buffer length mismatch with number of nodes")

    out.reshape(grid.shape)[:, (0, -1)] = 0.0
    out.reshape(grid.shape)[(0, -1), :] = 0.0

    _calc_flux_div_at_node(grid.shape, (grid.dx, grid.dy), unit_flux, out)

    return out


def calc_net_face_flux_at_cell(grid, unit_flux_at_face, out=None):
    """Calculate net face fluxes at cells.

    Given a flux per unit width across each face in the grid, calculate the net
    outflux (or influx, if negative) at each cell.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    unit_flux_at_faces : ndarray or field name
        Flux per unit width associated with faces.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray (x number of cells)
        Net flux at cells.
    """
    if len(unit_flux_at_face) != grid.number_of_faces:
        raise ValueError("Parameter unit_flux_at_face must be num faces long")

    if out is None:
        out = grid.empty(at="cell")

    _calc_net_face_flux_at_cell(
        grid.shape, (grid.dx, grid.dy), np.asarray(unit_flux_at_face), out
    )

    return out



================================================
File: src/landlab/grid/raster_funcs.py
================================================
import numpy as np

from ..core.utils import make_optional_arg_into_id_array


def _swap(a, b):
    return (b, a)


def _iround(x):
    return int(round(x))


def neighbor_node_at_cell(grid, inds, *args):
    """node_id_of_cell_neighbor(grid, neighbor_ids [, cell_ids])

    Return an array of the node ids for neighbors of *cell_id* cells.
    *neighbor_ids* is an index into the neighbors of a cell as measured
    clockwise starting from the south.

    If *cell_ids* is not given, return neighbors for all cells in the grid.

    Parameters
    ----------
    grid : RasterModelGrid
        Input grid.
    neighbor_ids : array_like
        IDs of the neighbor nodes.
    cell_ids : array_like, optional
        IDs of cell about which to get neighbors.

    Returns
    -------
    ndarray
        Node IDs for given neighbors of cells.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_funcs import neighbor_node_at_cell
    >>> grid = RasterModelGrid((4, 5), xy_spacing=1.0)
    >>> neighbor_node_at_cell(grid, 0, 0)
    array([1])

    Get the lower and the the upper neighbors for all the cells.

    >>> neighbor_node_at_cell(grid, 0)
    array([1, 2, 3, 6, 7, 8])
    >>> neighbor_node_at_cell(grid, 2)
    array([11, 12, 13, 16, 17, 18])

    As an alternative to the above, use fancy-indexing to get both sets of
    neighbors with one call.

    >>> neighbor_node_at_cell(grid, np.array([0, 2]), [1, 4])
    array([[ 2, 12],
           [ 7, 17]])
    """
    cell_ids = make_optional_arg_into_id_array(grid.number_of_cells, *args)
    node_ids = grid.node_at_cell[cell_ids]
    neighbors = grid.active_adjacent_nodes_at_node[node_ids]

    if not isinstance(inds, np.ndarray):
        inds = np.array(inds)

    # return neighbors[range(len(cell_ids)), 3 - inds]
    return np.take(np.take(neighbors, range(len(cell_ids)), axis=0), 3 - inds, axis=1)


def calculate_slope_aspect_bfp(xs, ys, zs):
    """Calculate slope and aspect.

    .. codeauthor:: Katy Barnhart <katherine.barnhart@colorado.edu>

    Fits a plane to the given N points with given *xs*, *ys*, and *zs* values
    using single value decomposition.

    Returns a tuple of (*slope*, *aspect*) based on the normal vector to the
    best fit plane.

    .. note::

        This function does not check if the points fall on a line, rather
        than a plane.
    """
    if not len(xs) == len(ys) == len(zs):
        raise ValueError("array must be the same length")

    # step 1: subtract the centroid from the points
    # step 2: create a 3XN matrix of the points for SVD
    # in python, the unit normal to the best fit plane is
    # given by the third column of the U matrix.
    mat = np.vstack((xs - np.mean(xs), ys - np.mean(ys), zs - np.mean(zs)))
    U, _, _ = np.linalg.svd(mat)
    normal = U[:, 2]

    # step 3: calculate the aspect
    asp = 90.0 - np.degrees(np.arctan2(normal[1], normal[0]))
    asp = asp % 360.0

    # step 4: calculate the slope
    slp = 90.0 - np.degrees(np.arcsin(normal[2]))

    return slp, asp


def find_nearest_node(rmg, coords, mode="raise"):
    """Find the node nearest a point.

    Find the index to the node nearest the given x, y coordinates.
    Coordinates are provided as numpy arrays in the *coords* tuple.
    *coords* is tuple of coordinates, one for each dimension.

    The *mode* keyword to indicate what to do if a point is outside of the
    grid. Valid choices are the same as that used with the numpy function
    `ravel_multi_index`.

    A point is considered to be outside of the grid if it is outside the
    perimeter of the grid by one half of the grid spacing.

    Parameters
    ----------
    rmg : RasterModelGrid
        The source grid.
    coords : tuple
        Coordinates of point as (x, y)
    mode : {'raise', 'wrap', 'clip'}, optional
        Action to take if a point is outside of the grid.

    Returns
    -------
    array_like :
        Indices of the nodes nearest the given coordinates.

    Examples
    --------
    Create a grid of 4 by 5 nodes with unit spacing.

    >>> import landlab
    >>> from landlab.grid.raster_funcs import find_nearest_node
    >>> rmg = landlab.RasterModelGrid((4, 5))

    The points can be either a tuple of scalars or of arrays.

    >>> find_nearest_node(rmg, (0.2, 0.6))
    5
    >>> find_nearest_node(rmg, (np.array([1.6, 3.6]), np.array([2.3, 0.7])))
    array([12,  9])

    The *mode* keyword indicates what to do if a point is outside of the
    grid.

    >>> find_nearest_node(rmg, (-0.6, 0.6), mode="raise")
    Traceback (most recent call last):
        ...
    ValueError: invalid entry in coordinates array
    >>> find_nearest_node(rmg, (-0.6, 0.6), mode="clip")
    5
    >>> find_nearest_node(rmg, (-0.6, 0.6), mode="wrap")
    9
    """
    if isinstance(coords[0], np.ndarray):
        return _find_nearest_node_ndarray(rmg, coords, mode=mode)
    else:
        return find_nearest_node(
            rmg, (np.array(coords[0]), np.array(coords[1])), mode=mode
        )


def _find_nearest_node_ndarray(rmg, coords, mode="raise"):
    """Find the node nearest to a point.

    Parameters
    ----------
    rmg : RasterModelGrid
        A RasterModelGrid.
    coords : tuple of float
        Coordinates of test points as *x*, then *y*.
    mode : {'raise', 'wrap', 'clip'}, optional
        What to do with out-of-bounds indices (as with
        numpy.ravel_multi_index).

    Returns
    -------
    ndarray
        Nodes that are closest to the points.

    Examples
    --------
    >>> from landlab.grid.raster_funcs import _find_nearest_node_ndarray
    >>> from landlab import RasterModelGrid
    >>> import numpy as np
    >>> grid = RasterModelGrid((4, 5))
    >>> _find_nearest_node_ndarray(grid, (0.25, 1.25))
    5
    >>> _find_nearest_node_ndarray(grid, (0.75, 2.25))
    11

    >>> grid = RasterModelGrid((4, 5), xy_spacing=(3, 4))
    >>> _find_nearest_node_ndarray(grid, (3.1, 4.1))
    6
    """
    column_indices = np.int_(np.around((coords[0] - rmg.node_x[0]) / rmg.dx))
    row_indices = np.int_(np.around((coords[1] - rmg.node_y[0]) / rmg.dy))

    return rmg.grid_coords_to_node_id(row_indices, column_indices, mode=mode)


def _value_is_in_bounds(value, bounds):
    """Check if a value is within bounds.

    Parameters
    ----------
    value : float or ndarray
        The test value.
    bounds : (lower, upper)
        The lower and upper bounds.

    Returns
    -------
    bool
        ``True`` if the value is within the bounds. Otherwise, ``False``.

    Examples
    --------
    >>> from landlab.grid.raster_funcs import _value_is_in_bounds
    >>> import numpy as np
    >>> _value_is_in_bounds(0.5, (0, 1))
    True
    >>> _value_is_in_bounds(1, (0, 1))
    False
    >>> _value_is_in_bounds(0, (0, 1))
    True
    >>> _value_is_in_bounds(np.array((0, 1)), (0, 1))
    array([ True, False])
    """
    dummy = value >= bounds[0]
    dummy &= value < bounds[1]
    return dummy


def _value_is_within_axis_bounds(rmg, value, axis):
    """Check if a value is within the bounds of a grid axis.

    Parameters
    ----------
    rmg : RasterModelGrid
        A RasterModelGrid.
    value : float
        The test value.
    axis : int
        The axis.

    Returns
    -------
    bool
        ``True`` if the value is within the axis bounds. Otherwise, ``False``.

    Examples
    --------
    >>> from landlab.grid.raster_funcs import _value_is_within_axis_bounds
    >>> from landlab import RasterModelGrid
    >>> rmg = RasterModelGrid((4, 5))
    >>> _value_is_within_axis_bounds(rmg, 3.1, 0)
    False
    >>> _value_is_within_axis_bounds(rmg, 2.9, 0)
    True
    >>> _value_is_within_axis_bounds(rmg, 4.1, 1)
    False
    >>> _value_is_within_axis_bounds(rmg, 3.9, 1)
    True
    """
    axis_coord = rmg.node_axis_coordinates(axis)
    return _value_is_in_bounds(value, (axis_coord[0], axis_coord[-1]))


def is_coord_on_grid(rmg, coords, axes=(0, 1)):
    """Check if coordinates are contained on a grid.

    Parameters
    ----------
    rmg : RasterModelGrid
        Source grid.
    coords : tuple
        Coordinates of point as (x, y)
    axes : tuple, optional
        Check bounds only on a particular axis

    Examples
    --------
    Create a grid that ranges from x=0 to x=4, and y=0 to y=3.

    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_funcs import is_coord_on_grid
    >>> grid = RasterModelGrid((4, 5))
    >>> is_coord_on_grid(grid, (3.999, 2.999))
    True

    Check two points with one call. Numpy broadcasting rules apply for the
    point coordinates.

    >>> is_coord_on_grid(grid, ([3.9, 4.1], 2.9))
    array([ True, False])

    >>> is_coord_on_grid(grid, ([3.9, 4.1], 2.9), axes=(0,))
    array([ True,  True])
    """
    coords = np.broadcast_arrays(*coords)

    is_in_bounds = _value_is_within_axis_bounds(rmg, coords[1 - axes[0]], axes[0])
    for axis in axes[1:]:
        is_in_bounds &= _value_is_within_axis_bounds(rmg, coords[1 - axis], axis)

    return is_in_bounds


def line_to_grid_coords(c0, r0, c1, r1):
    """Return integer grid coords forming line segment (c0, r0)->(c1, r1).

    Parameters
    ----------
    c0, r0 : int
        column and row coordinates of "starting" endpoint
    c1, r1 : int
        column and row coordinates of "ending" endpoint

    Returns
    -------
    rr, cc : (N,) ndarray of int
        row and column coordinates of nodes in the line

    Examples
    --------
    >>> line_to_grid_coords(0, 0, 4, 1)
    (array([0, 0, 0, 1, 1]), array([0, 1, 2, 3, 4]))

    Notes
    -----
    Inputs must be grid coordinates rather than actual (x, y) values (unless
    the grid has unit spacing, in which case they are the same). To convert
    from real (x, y) to (x_grid, y_grid) use x_grid = x / Dx, where Dx is
    horizontal grid spacing (and similarly for y).

    To convert a raster-grid node ID to column and row coords, use
    numpy.unravel_index(node_id, (num_rows, num_cols)).

    To convert the returned grid coordinates to node IDs, use the
    RasterModelGrid method grid_coords_to_node_id().

    This function uses an incremental algorithm for line scan-conversion
    (see, e.g., Foley et al., 1990, chapter 3). For a line with a slope
    0 > m > 1, start with the x coordinates for a set of grid columns that span
    the line. The corresponding y of the first one is just y0. The y for the
    next one is y0 + m, for the next y0 + 2m, etc. If m > 1, you use y instead
    of x. In the below, any line segments that "point" toward the lower-left
    half-grid (i.e., with azimuth between 135o and 315o) have their endpoints
    flipped first.
    """

    dx = c1 - c0
    dy = r1 - r0

    # Flip endpoints if needed to have segment point to up/right
    if (dx + dy) < 0:
        (c0, c1) = _swap(c0, c1)
        (r0, r1) = _swap(r0, r1)
        dx = -dx
        dy = -dy
        flip_array = True
    else:
        flip_array = False

    if dx > dy:  # more horizontal than vertical
        npts = _iround(c1 - c0) + 1
        cc = np.zeros(npts, dtype=int)
        rr = np.zeros(npts, dtype=int)
        cc[:] = np.arange(npts)
        rr[:] = np.round(r0 + (float(dy) / dx) * cc)
        cc[:] += _iround(c0)
    else:
        npts = _iround(r1 - r0) + 1
        cc = np.zeros(npts, dtype=int)
        rr = np.zeros(npts, dtype=int)
        rr[:] = np.arange(npts)
        cc[:] = np.round(c0 + (float(dx) / dy) * rr)
        rr[:] += _iround(r0)

    # If endpoints were flipped, here we "un-flip" again
    if flip_array:
        rr = np.flipud(rr)
        cc = np.flipud(cc)

    return rr, cc



================================================
File: src/landlab/grid/raster_gradients.py
================================================
#! /usr/bin/env python
"""Calculate gradients on a raster grid.

Gradient calculators for raster grids
+++++++++++++++++++++++++++++++++++++

.. autosummary::

    ~calc_grad_at_link
    ~calc_grad_across_cell_faces
    ~calc_grad_across_cell_corners
"""
from collections import deque

import numpy as np

from landlab.core.utils import make_optional_arg_into_id_array
from landlab.core.utils import radians_to_degrees
from landlab.utils.decorators import use_field_name_or_array

from .ext.raster_gradient import calc_diff_at_link as _calc_diff_at_link_c
from .ext.raster_gradient import calc_grad_at_link as _calc_grad_at_link_c


@use_field_name_or_array("node")
def calc_diff_at_d8(grid, node_values, out=None):
    """Calculate differences of node values over links and diagonals.

    Calculates the difference in quantity *node_values* at each link in the
    grid.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    node_values : ndarray or field name
        Values at grid nodes.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray
        Differences across links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 3))
    >>> z = [
    ...     [60.0, 60.0, 60.0, 60.0],
    ...     [60.0, 60.0, 0.0, 0.0],
    ...     [60.0, 0.0, 0.0, 0.0],
    ... ]
    >>> grid.calc_diff_at_d8(z)
    array([  0.,   0.,   0.,   0.,   0., -60., -60.,   0., -60.,   0.,   0.,
           -60.,   0.,   0., -60.,   0.,   0.,   0.,   0., -60.,   0., -60.,
           -60., -60.,   0., -60.,   0.,   0.,   0.])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = np.empty(grid.number_of_d8)
    node_values = np.asarray(node_values)
    return np.subtract(
        node_values[grid.nodes_at_d8[:, 1]],
        node_values[grid.nodes_at_d8[:, 0]],
        out=out,
    )


@use_field_name_or_array("node")
def calc_diff_at_diagonal(grid, node_values, out=None):
    """Calculate differences of node values over diagonals.

    Calculates the difference in quantity *node_values* at each link in the
    grid.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    node_values : ndarray or field name
        Values at grid nodes.
    out : ndarray, optional
        Buffer to hold the result.

    Returns
    -------
    ndarray
        Differences across links.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 3))
    >>> z = [
    ...     [5.0, 5.0, 5.0, 5.0],
    ...     [5.0, 5.0, 0.0, 0.0],
    ...     [5.0, 0.0, 0.0, 0.0],
    ... ]
    >>> grid.calc_diff_at_diagonal(z)
    array([ 0.,  0., -5.,  0., -5., -5., -5.,  0., -5.,  0.,  0.,  0.])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = np.empty(grid.number_of_diagonals)
    node_values = np.asarray(node_values)
    return np.subtract(
        node_values[grid.nodes_at_diagonal[:, 1]],
        node_values[grid.nodes_at_diagonal[:, 0]],
        out=out,
    )


def calc_grad_at_d8(grid, node_values, out=None):
    """Calculate gradients over all diagonals and links.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    node_values : array_like or field name
        Values at nodes.
    out : ndarray, optional
        Buffer to hold result. If `None`, create a new array.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> import numpy as np
    >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 3))
    >>> z = [
    ...     [60.0, 60.0, 60.0, 60.0],
    ...     [60.0, 60.0, 0.0, 0.0],
    ...     [60.0, 0.0, 0.0, 0.0],
    ... ]
    >>> grid.calc_grad_at_d8(z)
    array([  0.,   0.,   0.,   0.,   0., -20., -20.,   0., -15.,   0.,   0.,
           -20.,   0.,   0., -15.,   0.,   0.,   0.,   0., -12.,   0., -12.,
           -12., -12.,   0., -12.,   0.,   0.,   0.])

    :meta landlab: info-link, gradient
    """
    grads = calc_diff_at_d8(grid, node_values, out=out)
    grads /= grid.length_of_d8[: grid.number_of_d8]

    return grads


def calc_grad_at_diagonal(grid, node_values, out=None):
    """Calculate gradients over all diagonals.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    node_values : array_like or field name
        Values at nodes.
    out : ndarray, optional
        Buffer to hold result. If `None`, create a new array.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> import numpy as np
    >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 3))
    >>> z = [
    ...     [5.0, 5.0, 5.0, 5.0],
    ...     [5.0, 5.0, 0.0, 0.0],
    ...     [5.0, 0.0, 0.0, 0.0],
    ... ]
    >>> grid.calc_grad_at_diagonal(z)
    array([ 0.,  0., -1.,  0., -1., -1., -1.,  0., -1.,  0.,  0.,  0.])

    :meta landlab: info-link, gradient
    """
    grads = calc_diff_at_diagonal(grid, node_values, out=out)
    grads /= grid.length_of_diagonal[: grid.number_of_diagonals]

    return grads


@use_field_name_or_array("node")
def calc_diff_at_link(grid, value_at_node, out=None):
    """Calculate differences in node_values at links.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    value_at_node : array_like or field name
        Values at nodes.
    out : ndarray, optional
        Buffer to hold result. If `None`, create a new array.

    Returns
    -------
    ndarray
        Differences of the nodes values for each link.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 3))
    >>> node_values = [
    ...     [0.0, 0.0, 0.0],
    ...     [1.0, 3.0, 1.0],
    ...     [2.0, 2.0, 2.0],
    ... ]
    >>> grid.calc_diff_at_link(node_values)
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])

    >>> out = np.empty(grid.number_of_links, dtype=float)
    >>> rtn = grid.calc_diff_at_link(node_values, out=out)
    >>> rtn is out
    True
    >>> out
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])

    >>> grid = RasterModelGrid((3, 3), xy_spacing=(2, 1))
    >>> grid.calc_diff_at_link(node_values)
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])
    >>> _ = grid.add_field("elevation", node_values, at="node")
    >>> grid.calc_diff_at_link("elevation")
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = grid.empty(at="link")
    _calc_diff_at_link_c(grid.shape, np.asarray(value_at_node).reshape(-1), out)

    return out


@use_field_name_or_array("node")
def calc_grad_at_link(grid, value_at_node, out=None):
    """Calculate gradients in node_values at links.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    value_at_node : array_like or field name
        Values at nodes.
    out : ndarray, optional
        Buffer to hold result. If `None`, create a new array.

    Returns
    -------
    ndarray
        Gradients of the nodes values for each link.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 3))
    >>> node_values = [0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0]
    >>> grid.calc_grad_at_link(node_values)
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])

    >>> out = np.empty(grid.number_of_links, dtype=float)
    >>> rtn = grid.calc_grad_at_link(node_values, out=out)
    >>> rtn is out
    True
    >>> out
    array([ 0.,  0.,  1.,  3.,  1.,  2., -2.,  1., -1.,  1.,  0.,  0.])

    >>> grid = RasterModelGrid((3, 3), xy_spacing=(2, 1))
    >>> grid.calc_grad_at_link(node_values)
    array([ 0.,  0.,  1.,  3.,  1.,  1., -1.,  1., -1.,  1.,  0.,  0.])
    >>> _ = grid.add_field("elevation", node_values, at="node")
    >>> grid.calc_grad_at_link("elevation")
    array([ 0.,  0.,  1.,  3.,  1.,  1., -1.,  1., -1.,  1.,  0.,  0.])

    :meta landlab: info-link, gradient
    """
    if out is None:
        out = grid.empty(at="link")
    _calc_grad_at_link_c(
        grid.shape, (grid.dx, grid.dy), np.asarray(value_at_node).reshape(-1), out
    )

    return out


@use_field_name_or_array("node")
def calc_grad_across_cell_faces(grid, node_values, *args, **kwds):
    """calc_grad_across_cell_faces(grid, node_values, [cell_ids], out=None)

    Get gradients across the faces of a cell.

    Calculate gradient of the value field provided by *node_values* across
    each of the faces of the cells of a grid. The returned gradients are
    ordered as right, top, left, and bottom.

    Note that the returned gradients are masked to exclude neighbor nodes which
    are closed. Beneath the mask is the value -1.

    Parameters
    ----------
    grid : RasterModelGrid
        Source grid.
    node_values : array_like or field name
        Quantity to take the gradient of defined at each node.
    cell_ids : array_like, optional
        If provided, cell ids to measure gradients. Otherwise, find gradients
        for all cells.
    out : array_like, optional
        Alternative output array in which to place the result.  Must
        be of the same shape and buffer length as the expected output.

    Returns
    -------
    (N, 4) Masked ndarray
        Gradients for each face of the cell.

    Examples
    --------
    Create a grid with two cells.

    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 4))
    >>> x = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0])

    A decrease in quantity across a face is a negative gradient.

    >>> grid.calc_grad_across_cell_faces(x)
    masked_array(
      data=[[ 1.,  3.,  0.,  0.],
            [ 0.,  2., -1., -1.]],
      mask=False,
      fill_value=1e+20)

    >>> grid = RasterModelGrid((3, 4), xy_spacing=(1, 2))
    >>> grid.calc_grad_across_cell_faces(x)
    masked_array(
      data=[[ 1. , 1.5,  0. ,  0. ],
            [ 0. , 1. , -1. , -0.5]],
      mask=False,
      fill_value=1e+20)

    :meta landlab: info-face, gradient
    """
    padded_node_values = np.empty(node_values.size + 1, dtype=float)
    padded_node_values[-1] = grid.BAD_INDEX
    padded_node_values[:-1] = node_values
    cell_ids = make_optional_arg_into_id_array(grid.number_of_cells, *args)
    node_ids = grid.node_at_cell[cell_ids]

    neighbors = grid.active_adjacent_nodes_at_node[node_ids]
    if grid.BAD_INDEX != -1:
        neighbors = np.where(neighbors == grid.BAD_INDEX, -1, neighbors)
    values_at_neighbors = padded_node_values[neighbors]
    masked_neighbor_values = np.ma.array(
        values_at_neighbors, mask=neighbors == grid.BAD_INDEX
    )
    values_at_nodes = node_values[node_ids].reshape(len(node_ids), 1)

    out = np.subtract(masked_neighbor_values, values_at_nodes, **kwds)

    out[:, (0, 2)] /= grid.dx
    out[:, (1, 3)] /= grid.dy

    return out


@use_field_name_or_array("node")
def calc_grad_across_cell_corners(grid, node_values, *args, **kwds):
    """calc_grad_across_cell_corners(grid, node_values, [cell_ids], out=None)

    Get gradients to diagonally opposite nodes.

    Calculate gradient of the value field provided by *node_values* to
    the values at diagonally opposite nodes. The returned gradients are
    ordered as upper-right, upper-left, lower-left and lower-right.

    Parameters
    ----------
    grid : RasterModelGrid
        Source grid.
    node_values : array_like or field name
        Quantity to take the gradient of defined at each node.
    cell_ids : array_like, optional
        If provided, cell ids to measure gradients. Otherwise, find gradients
        for all cells.
    out : array_like, optional
        Alternative output array in which to place the result.  Must
        be of the same shape and buffer length as the expected output.

    Returns
    -------
    (N, 4) ndarray
        Gradients to each diagonal node.

    Examples
    --------
    Create a grid with two cells.

    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 4))
    >>> x = np.array([1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0])

    A decrease in quantity to a diagonal node is a negative gradient.

    >>> from math import sqrt
    >>> grid.calc_grad_across_cell_corners(x) * sqrt(2.0)
    array([[ 3.,  3.,  1.,  0.],
           [ 2.,  2., -1.,  0.]])

    >>> grid = RasterModelGrid((3, 4), xy_spacing=(4, 3))
    >>> grid.calc_grad_across_cell_corners(x)
    array([[ 0.6,  0.6,  0.2,  0. ],
           [ 0.4,  0.4, -0.2,  0. ]])

    :meta landlab: info-corner, gradient
    """
    cell_ids = make_optional_arg_into_id_array(grid.number_of_cells, *args)
    node_ids = grid.node_at_cell[cell_ids]

    values_at_diagonals = node_values[grid.diagonal_adjacent_nodes_at_node[node_ids]]
    values_at_nodes = node_values[node_ids].reshape(len(node_ids), 1)

    out = np.subtract(values_at_diagonals, values_at_nodes, **kwds)
    np.divide(out, np.sqrt(grid.dy**2.0 + grid.dx**2.0), out=out)

    return out


@use_field_name_or_array("node")
def calc_grad_along_node_links(grid, node_values, *args, **kwds):
    """calc_grad_along_node_links(grid, node_values, [cell_ids], out=None)

    Get gradients along links touching a node.

    Calculate gradient of the value field provided by *node_values* across
    each of the faces of the nodes of a grid. The returned gradients are
    ordered as right, top, left, and bottom. All returned values follow our
    standard sign convention, where a link pointing N or E and increasing in
    value is positive, a link pointing S or W and increasing in value is
    negative.

    Note that the returned gradients are masked to exclude neighbor nodes which
    are closed. Beneath the mask is the value -1.

    Parameters
    ----------
    grid : RasterModelGrid
        Source grid.
    node_values : array_like or field name
        Quantity to take the gradient of defined at each node.
    node_ids : array_like, optional
        If provided, node ids to measure gradients. Otherwise, find gradients
        for all nodes.
    out : array_like, optional
        Alternative output array in which to place the result.  Must
        be of the same shape and buffer length as the expected output.

    Returns
    -------
    (N, 4) Masked ndarray
        Gradients for each link of the node. Ordering is E,N,W,S.

    Examples
    --------
    Create a grid with nine nodes.

    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((3, 3))
    >>> x = np.array([0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0])

    A decrease in quantity across a face is a negative gradient.

    >>> grid.calc_grad_along_node_links(x)
    masked_array(
      data=[[--, --, --, --],
            [--, 1.0, --, --],
            [--, --, --, --],
            [1.0, --, --, --],
            [1.0, 1.0, 1.0, 1.0],
            [--, --, 1.0, --],
            [--, --, --, --],
            [--, --, --, 1.0],
            [--, --, --, --]],
      mask=[[ True,  True,  True,  True],
            [ True, False,  True,  True],
            [ True,  True,  True,  True],
            [False,  True,  True,  True],
            [False, False, False, False],
            [ True,  True, False,  True],
            [ True,  True,  True,  True],
            [ True,  True,  True, False],
            [ True,  True,  True,  True]],
      fill_value=1e+20)

    >>> grid = RasterModelGrid((3, 3), xy_spacing=(4, 2))
    >>> grid.calc_grad_along_node_links(x)
    masked_array(
      data=[[--, --, --, --],
            [--, 0.5, --, --],
            [--, --, --, --],
            [0.25, --, --, --],
            [0.25, 0.5, 0.25, 0.5],
            [--, --, 0.25, --],
            [--, --, --, --],
            [--, --, --, 0.5],
            [--, --, --, --]],
      mask=[[ True,  True,  True,  True],
            [ True, False,  True,  True],
            [ True,  True,  True,  True],
            [False,  True,  True,  True],
            [False, False, False, False],
            [ True,  True, False,  True],
            [ True,  True,  True,  True],
            [ True,  True,  True, False],
            [ True,  True,  True,  True]],
      fill_value=1e+20)

    :meta landlab: info-node, info-link, gradient
    """
    padded_node_values = np.empty(node_values.size + 1, dtype=float)
    padded_node_values[-1] = grid.BAD_INDEX
    padded_node_values[:-1] = node_values
    node_ids = make_optional_arg_into_id_array(grid.number_of_nodes, *args)

    neighbors = grid.active_adjacent_nodes_at_node[node_ids]
    values_at_neighbors = padded_node_values[neighbors]
    masked_neighbor_values = np.ma.array(
        values_at_neighbors, mask=values_at_neighbors == grid.BAD_INDEX
    )
    values_at_nodes = node_values[node_ids].reshape(len(node_ids), 1)

    out = np.ma.empty_like(masked_neighbor_values, dtype=float)
    np.subtract(masked_neighbor_values[:, :2], values_at_nodes, out=out[:, :2], **kwds)
    np.subtract(values_at_nodes, masked_neighbor_values[:, 2:], out=out[:, 2:], **kwds)

    out[:, (0, 2)] /= grid.dx
    out[:, (1, 3)] /= grid.dy

    return out


def calc_unit_normals_at_cell_subtriangles(grid, elevs="topographic__elevation"):
    """Calculate unit normals on a cell.

    Calculate the eight unit normal vectors <a, b, c> to the eight
    subtriangles of a four-cornered (raster) cell.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.

    Returns
    -------
    (n_ENE, n_NNE, n_NNW, n_WNW, n_WSW, n_SSW, n_SSE, n_ESE) :
        each a num-cells x length-3 array
        Len-8 tuple of the eight unit normal vectors <a, b, c> for the eight
        subtriangles in the cell. Order is from north of east, counter
        clockwise to south of east (East North East, North North East, North
        North West, West North West, West South West, South South West, South
        South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((3, 3))
    >>> z = mg.node_x**2
    >>> eight_tris = mg.calc_unit_normals_at_cell_subtriangles(z)
    >>> type(eight_tris) is tuple
    True
    >>> len(eight_tris)
    8
    >>> eight_tris[0].shape == (mg.number_of_cells, 3)
    True
    >>> eight_tris
    (array([[-0.9486833 ,  0.        ,  0.31622777]]),
     array([[-0.9486833 ,  0.        ,  0.31622777]]),
     array([[-0.70710678,  0.        ,  0.70710678]]),
     array([[-0.70710678,  0.        ,  0.70710678]]),
     array([[-0.70710678,  0.        ,  0.70710678]]),
     array([[-0.70710678,  0.        ,  0.70710678]]),
     array([[-0.9486833 ,  0.        ,  0.31622777]]),
     array([[-0.9486833 ,  0.        ,  0.31622777]]))

    :meta landlab: info-cell, gradient
    """

    # identify the grid neigbors at each location
    node_at_cell = grid.node_at_cell
    # calculate unit normals at all nodes.
    (
        n_ENE,
        n_NNE,
        n_NNW,
        n_WNW,
        n_WSW,
        n_SSW,
        n_SSE,
        n_ESE,
    ) = _calc_subtriangle_unit_normals_at_node(grid, elevs=elevs)

    # return only those at cell.
    return (
        n_ENE[node_at_cell, :],
        n_NNE[node_at_cell, :],
        n_NNW[node_at_cell, :],
        n_WNW[node_at_cell, :],
        n_WSW[node_at_cell, :],
        n_SSW[node_at_cell, :],
        n_SSE[node_at_cell, :],
        n_ESE[node_at_cell, :],
    )


def _calc_subtriangle_unit_normals_at_node(grid, elevs="topographic__elevation"):
    """Private Function: Calculate unit normals on subtriangles at all nodes.

    Calculate the eight unit normal vectors <a, b, c> to the eight
    subtriangles of a four-cornered (raster) cell. Unlike
    calc_unit_normals_at_node_subtriangles, this function also
    calculated unit normals at the degenerate part-cells around the
    boundary.

    On the grid boundaries where the cell is not fully defined, the unit normal
    is given as <nan, nan, nan>.

    Parameters
    ----------
    grid : RasterModelGrid
    A grid.
    elevs : str or ndarray, optional
    Field name or array of node values.

    Returns
    -------
    (n_ENE, n_NNE, n_NNW, n_WNW, n_WSW, n_SSW, n_SSE, n_ESE) :
    each a num-nodes x length-3 array
    Len-8 tuple of the eight unit normal vectors <a, b, c> for the eight
    subtriangles in the cell. Order is from north of east, counter
    clockwise to south of east (East North East, North North East, North
    North West, West North West, West South West, South South West, South
    South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_gradients import _calc_subtriangle_unit_normals_at_node
    >>> mg = RasterModelGrid((3, 3))
    >>> z = mg.node_x**2
    >>> eight_tris = _calc_subtriangle_unit_normals_at_node(mg, z)
    >>> type(eight_tris) is tuple
    True
    >>> len(eight_tris)
    8
    >>> eight_tris[0].shape == (mg.number_of_nodes, 3)
    True
    >>> eight_tris[0]
    array([[-0.70710678,  0.        ,  0.70710678],
           [-0.9486833 ,  0.        ,  0.31622777],
           [        nan,         nan,         nan],
           [-0.70710678,  0.        ,  0.70710678],
           [-0.9486833 ,  0.        ,  0.31622777],
           [        nan,         nan,         nan],
           [        nan,         nan,         nan],
           [        nan,         nan,         nan],
           [        nan,         nan,         nan]])

    :meta landlab: info-cell, gradient
    """
    try:
        z = grid.at_node[elevs]
    except TypeError:
        z = elevs
    #  cell has center node I
    # orthogonal neighbors P, R, T, V, counter clockwise from East
    # diagonal neihbors Q, S, U, W, counter clocwise from North East
    # There are 8 subtriangles that can be defined  with the following corners
    # (starting from the central node, and progressing counter-clockwise).
    # ENE: IPQ
    # NNE: IQR
    # NNW: IRS
    # WNW: IST
    # WSW: ITU
    # SSW: IUV
    # SSE: IVW
    # ESE: IWP

    # There are thus 8 vectors, IP, IQ, IR, IS, IT, IU, IV, IW

    # initialized difference matricies for cross product
    diff_xyz_IP = np.empty((grid.number_of_nodes, 3))  # East
    # ^this is the vector (xP-xI, yP-yI, zP-yI)
    diff_xyz_IQ = np.empty((grid.number_of_nodes, 3))  # Northeast
    diff_xyz_IR = np.empty((grid.number_of_nodes, 3))  # North
    diff_xyz_IS = np.empty((grid.number_of_nodes, 3))  # Northwest
    diff_xyz_IT = np.empty((grid.number_of_nodes, 3))  # West
    diff_xyz_IU = np.empty((grid.number_of_nodes, 3))  # Southwest
    diff_xyz_IV = np.empty((grid.number_of_nodes, 3))  # South
    diff_xyz_IW = np.empty((grid.number_of_nodes, 3))  # Southeast

    # identify the grid neigbors at each location
    node_at_cell = np.arange(grid.number_of_nodes)
    P = grid.adjacent_nodes_at_node[node_at_cell, 0]
    Q = grid.diagonal_adjacent_nodes_at_node[node_at_cell, 0]
    R = grid.adjacent_nodes_at_node[node_at_cell, 1]
    S = grid.diagonal_adjacent_nodes_at_node[node_at_cell, 1]
    T = grid.adjacent_nodes_at_node[node_at_cell, 2]
    U = grid.diagonal_adjacent_nodes_at_node[node_at_cell, 2]
    V = grid.adjacent_nodes_at_node[node_at_cell, 3]
    W = grid.diagonal_adjacent_nodes_at_node[node_at_cell, 3]

    # get x, y, z coordinates for each location
    x_I = grid.node_x[node_at_cell]
    y_I = grid.node_y[node_at_cell]
    z_I = z[node_at_cell]

    x_P = grid.node_x[P]
    y_P = grid.node_y[P]
    z_P = z[P]

    x_Q = grid.node_x[Q]
    y_Q = grid.node_y[Q]
    z_Q = z[Q]

    x_R = grid.node_x[R]
    y_R = grid.node_y[R]
    z_R = z[R]

    x_S = grid.node_x[S]
    y_S = grid.node_y[S]
    z_S = z[S]

    x_T = grid.node_x[T]
    y_T = grid.node_y[T]
    z_T = z[T]

    x_U = grid.node_x[U]
    y_U = grid.node_y[U]
    z_U = z[U]

    x_V = grid.node_x[V]
    y_V = grid.node_y[V]
    z_V = z[V]

    x_W = grid.node_x[W]
    y_W = grid.node_y[W]
    z_W = z[W]

    # calculate vectors by differencing
    diff_xyz_IP[:, 0] = x_P - x_I
    diff_xyz_IP[:, 1] = y_P - y_I
    diff_xyz_IP[:, 2] = z_P - z_I

    diff_xyz_IQ[:, 0] = x_Q - x_I
    diff_xyz_IQ[:, 1] = y_Q - y_I
    diff_xyz_IQ[:, 2] = z_Q - z_I

    diff_xyz_IR[:, 0] = x_R - x_I
    diff_xyz_IR[:, 1] = y_R - y_I
    diff_xyz_IR[:, 2] = z_R - z_I

    diff_xyz_IS[:, 0] = x_S - x_I
    diff_xyz_IS[:, 1] = y_S - y_I
    diff_xyz_IS[:, 2] = z_S - z_I

    diff_xyz_IT[:, 0] = x_T - x_I
    diff_xyz_IT[:, 1] = y_T - y_I
    diff_xyz_IT[:, 2] = z_T - z_I

    diff_xyz_IU[:, 0] = x_U - x_I
    diff_xyz_IU[:, 1] = y_U - y_I
    diff_xyz_IU[:, 2] = z_U - z_I

    diff_xyz_IV[:, 0] = x_V - x_I
    diff_xyz_IV[:, 1] = y_V - y_I
    diff_xyz_IV[:, 2] = z_V - z_I

    diff_xyz_IW[:, 0] = x_W - x_I
    diff_xyz_IW[:, 1] = y_W - y_I
    diff_xyz_IW[:, 2] = z_W - z_I

    # calculate cross product to get unit normal
    # cross product is orthogonal to both vectors, and is the normal
    # n = <a, b, c>, where plane is ax + by + cz = d
    nhat_ENE = np.cross(diff_xyz_IP, diff_xyz_IQ)  # <a, b, c>
    nhat_NNE = np.cross(diff_xyz_IQ, diff_xyz_IR)
    nhat_NNW = np.cross(diff_xyz_IR, diff_xyz_IS)
    nhat_WNW = np.cross(diff_xyz_IS, diff_xyz_IT)
    nhat_WSW = np.cross(diff_xyz_IT, diff_xyz_IU)
    nhat_SSW = np.cross(diff_xyz_IU, diff_xyz_IV)
    nhat_SSE = np.cross(diff_xyz_IV, diff_xyz_IW)
    nhat_ESE = np.cross(diff_xyz_IW, diff_xyz_IP)

    # now remove the bad subtriangles based on parts of the grid
    # make the bad subtriangle of length greater than one.
    bad = np.nan

    # first, corners:
    (northeast, northwest, southwest, southeast) = grid.nodes_at_corners_of_grid

    # lower left corner only has NNE and ENE
    for array in (nhat_NNW, nhat_WNW, nhat_WSW, nhat_SSW, nhat_SSE, nhat_ESE):
        array[southwest] = bad

    # lower right corner only has NNW and WNW
    for array in (nhat_ENE, nhat_NNE, nhat_WSW, nhat_SSW, nhat_SSE, nhat_ESE):
        array[southeast] = bad

    # upper left corner only has ESE and SSE
    for array in (nhat_ENE, nhat_NNE, nhat_NNW, nhat_WNW, nhat_WSW, nhat_SSW):
        array[northwest] = bad

    # upper right corner only has WSW and SSW
    for array in (nhat_ENE, nhat_NNE, nhat_NNW, nhat_WNW, nhat_SSE, nhat_ESE):
        array[northeast] = bad

    # next, sizes:
    # bottom row only has Norths
    bottom = grid.nodes_at_bottom_edge
    for array in (nhat_WSW, nhat_SSW, nhat_SSE, nhat_ESE):
        array[bottom] = bad

    # left side only has Easts
    left = grid.nodes_at_left_edge
    for array in (nhat_NNW, nhat_WNW, nhat_WSW, nhat_SSW):
        array[left] = bad

    # top row only has Souths
    top = grid.nodes_at_top_edge
    for array in (nhat_ENE, nhat_NNE, nhat_NNW, nhat_WNW):
        array[top] = bad

    # right side only has Wests
    right = grid.nodes_at_right_edge
    for array in (nhat_ENE, nhat_NNE, nhat_SSE, nhat_ESE):
        array[right] = bad

    # calculate magnitude of cross product so that the result is a unit normal
    nmag_ENE = np.sqrt(np.square(nhat_ENE).sum(axis=1))
    nmag_NNE = np.sqrt(np.square(nhat_NNE).sum(axis=1))
    nmag_NNW = np.sqrt(np.square(nhat_NNW).sum(axis=1))
    nmag_WNW = np.sqrt(np.square(nhat_WNW).sum(axis=1))
    nmag_WSW = np.sqrt(np.square(nhat_WSW).sum(axis=1))
    nmag_SSW = np.sqrt(np.square(nhat_SSW).sum(axis=1))
    nmag_SSE = np.sqrt(np.square(nhat_SSE).sum(axis=1))
    nmag_ESE = np.sqrt(np.square(nhat_ESE).sum(axis=1))

    # normalize the cross product with its magnitude so it is a unit normal
    # instead of a variable length normal.
    n_ENE = nhat_ENE / nmag_ENE.reshape(grid.number_of_nodes, 1)
    n_NNE = nhat_NNE / nmag_NNE.reshape(grid.number_of_nodes, 1)
    n_NNW = nhat_NNW / nmag_NNW.reshape(grid.number_of_nodes, 1)
    n_WNW = nhat_WNW / nmag_WNW.reshape(grid.number_of_nodes, 1)
    n_WSW = nhat_WSW / nmag_WSW.reshape(grid.number_of_nodes, 1)
    n_SSW = nhat_SSW / nmag_SSW.reshape(grid.number_of_nodes, 1)
    n_SSE = nhat_SSE / nmag_SSE.reshape(grid.number_of_nodes, 1)
    n_ESE = nhat_ESE / nmag_ESE.reshape(grid.number_of_nodes, 1)

    return (n_ENE, n_NNE, n_NNW, n_WNW, n_WSW, n_SSW, n_SSE, n_ESE)


def calc_slope_at_cell_subtriangles(
    grid, elevs="topographic__elevation", subtriangle_unit_normals=None
):
    """Calculate the slope (positive magnitude of gradient) at each of the
    eight cell subtriangles.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    subtriangle_unit_normals : tuple of 8 (ncells, 3) arrays (optional)
        The unit normal vectors for the eight subtriangles of each cell,
        if already known. Order is from north of east, counter
        clockwise to south of east (East North East, North North East, North
        North West, West North West, West South West, South South West, South
        South East, East South East).

    Returns
    -------
    (s_ENE, s_NNE, s_NNW, s_WNW, s_WSW, s_SSW, s_SSE, s_ESE) :
        each a length num-cells array
        Len-8 tuple of the slopes (positive gradient magnitude) of each of the
        eight cell subtriangles, in radians. Order is from north of east,
        counter clockwise to south of east (East North East, North North East,
        North North West, West North West, West South West, South South West,
        South South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((3, 3))
    >>> z = np.array(
    ...     [np.sqrt(3.0), 0.0, 4.0 / 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0 / np.sqrt(3.0)]
    ... )
    >>> eight_tris = mg.calc_unit_normals_at_cell_subtriangles(z)
    >>> S = mg.calc_slope_at_cell_subtriangles(z, eight_tris)
    >>> S0 = mg.calc_slope_at_cell_subtriangles(z)
    >>> np.allclose(S, S0)
    True
    >>> type(S) is tuple
    True
    >>> len(S)
    8
    >>> len(S[0]) == mg.number_of_cells
    True
    >>> np.allclose(S[0], S[1])
    True
    >>> np.allclose(S[2], S[3])
    True
    >>> np.allclose(S[4], S[5])
    True
    >>> np.allclose(S[6], S[7])
    True
    >>> np.allclose(np.rad2deg(S[0])[0], 30.0)
    True
    >>> np.allclose(np.rad2deg(S[2])[0], 45.0)
    True
    >>> np.allclose(np.rad2deg(S[4])[0], 60.0)
    True
    >>> np.allclose(np.cos(S[6])[0], 3.0 / 5.0)
    True

    :meta landlab: info-cell, gradient
    """

    # calculate all subtriangle slopes
    (
        s_ENE,
        s_NNE,
        s_NNW,
        s_WNW,
        s_WSW,
        s_SSW,
        s_SSE,
        s_ESE,
    ) = _calc_subtriangle_slopes_at_node(
        grid, elevs=elevs, subtriangle_unit_normals=subtriangle_unit_normals
    )
    # return only those at cell
    if s_ENE.shape[0] == grid.number_of_nodes:
        node_at_cell = grid.node_at_cell
    else:
        node_at_cell = np.arange(grid.number_of_cells)

    return (
        s_ENE[node_at_cell],
        s_NNE[node_at_cell],
        s_NNW[node_at_cell],
        s_WNW[node_at_cell],
        s_WSW[node_at_cell],
        s_SSW[node_at_cell],
        s_SSE[node_at_cell],
        s_ESE[node_at_cell],
    )


def _calc_subtriangle_slopes_at_node(
    grid, elevs="topographic__elevation", subtriangle_unit_normals=None
):
    """Private Function: Calculate subtriangles slope at all nodes.

    Calculate the slope (positive magnitude of gradient) at each of the
    eight subtriangles, including those at not-full cells along the
    boundary.

    Those subtriangles that that don't exist because they are on the edge
    of the grid have slopes of NAN.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    subtriangle_unit_normals : tuple of 8 (ncells, 3) or (nnodes, 3) arrays
        (optional)
        The unit normal vectors for the eight subtriangles of each cell or
        node,if already known. Order is from north of east, counter
        clockwise to south of east (East North East, North North East, North
        North West, West North West, West South West, South South West, South
        South East, East South East).

    Returns
    -------
    (s_ENE, s_NNE, s_NNW, s_WNW, s_WSW, s_SSW, s_SSE, s_ESE) :
        each a length num-cells array
        Len-8 tuple of the slopes (positive gradient magnitude) of each of the
        eight cell subtriangles, in radians. Order is from north of east,
        counter clockwise to south of east (East North East, North North East,
        North North West, West North West, West South West, South South West,
        South South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_gradients import (
    ...     _calc_subtriangle_unit_normals_at_node,
    ...     _calc_subtriangle_slopes_at_node,
    ... )
    >>> mg = RasterModelGrid((3, 3))
    >>> z = np.array(
    ...     [np.sqrt(3.0), 0.0, 4.0 / 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0 / np.sqrt(3.0)]
    ... )
    >>> eight_tris = _calc_subtriangle_unit_normals_at_node(mg, z)
    >>> S = _calc_subtriangle_slopes_at_node(mg, z, eight_tris)
    >>> S0 = _calc_subtriangle_slopes_at_node(mg, z)
    >>> np.allclose(S, S0, equal_nan=True)
    True
    >>> type(S) is tuple
    True
    >>> len(S)
    8
    >>> len(S[0]) == mg.number_of_nodes
    True
    >>> np.allclose(S[0][mg.core_nodes], S[1][mg.core_nodes])
    True
    >>> np.allclose(S[2][mg.core_nodes], S[3][mg.core_nodes])
    True
    >>> np.allclose(S[4][mg.core_nodes], S[5][mg.core_nodes])
    True
    >>> np.allclose(S[6][mg.core_nodes], S[7][mg.core_nodes])
    True
    >>> np.allclose(np.rad2deg(S[0][mg.core_nodes]), 30.0)
    True
    >>> np.allclose(np.rad2deg(S[2][mg.core_nodes]), 45.0)
    True
    >>> np.allclose(np.rad2deg(S[4])[mg.core_nodes], 60.0)
    True
    >>> np.allclose(np.cos(S[6])[mg.core_nodes], 3.0 / 5.0)
    True

    :meta landlab: info-cell, gradient
    """

    # verify that subtriangle_unit_normals is of the correct form.
    if subtriangle_unit_normals is not None:
        assert len(subtriangle_unit_normals) == 8
        assert subtriangle_unit_normals[0].shape[1] == 3
        assert subtriangle_unit_normals[1].shape[1] == 3
        assert subtriangle_unit_normals[2].shape[1] == 3
        assert subtriangle_unit_normals[3].shape[1] == 3
        assert subtriangle_unit_normals[4].shape[1] == 3
        assert subtriangle_unit_normals[5].shape[1] == 3
        assert subtriangle_unit_normals[6].shape[1] == 3
        assert subtriangle_unit_normals[7].shape[1] == 3
        (
            n_ENE,
            n_NNE,
            n_NNW,
            n_WNW,
            n_WSW,
            n_SSW,
            n_SSE,
            n_ESE,
        ) = subtriangle_unit_normals

        if subtriangle_unit_normals[7].shape[0] == grid.number_of_nodes:
            reshape_size = grid.number_of_nodes
        elif subtriangle_unit_normals[7].shape[0] == grid.number_of_cells:
            reshape_size = grid.number_of_cells
        else:
            ValueError("Subtriangles must be of lenght nnodes or ncells")
    else:
        (
            n_ENE,
            n_NNE,
            n_NNW,
            n_WNW,
            n_WSW,
            n_SSW,
            n_SSE,
            n_ESE,
        ) = _calc_subtriangle_unit_normals_at_node(grid, elevs)
        reshape_size = grid.number_of_nodes

    # combine z direction element of all eight so that the arccosine portion
    # only takes one function call.
    dotprod = np.empty((reshape_size, 8))
    dotprod[:, 0] = n_ENE[:, 2]  # by definition
    dotprod[:, 1] = n_NNE[:, 2]
    dotprod[:, 2] = n_NNW[:, 2]
    dotprod[:, 3] = n_WNW[:, 2]
    dotprod[:, 4] = n_WSW[:, 2]
    dotprod[:, 5] = n_SSW[:, 2]
    dotprod[:, 6] = n_SSE[:, 2]
    dotprod[:, 7] = n_ESE[:, 2]

    # take the inverse cosine of the z component to get the slope angle
    slopes_at_cell_subtriangles = np.arccos(dotprod)  #

    # split array into each subtriangle component.
    s_ENE = slopes_at_cell_subtriangles[:, 0].reshape(reshape_size)
    s_NNE = slopes_at_cell_subtriangles[:, 1].reshape(reshape_size)
    s_NNW = slopes_at_cell_subtriangles[:, 2].reshape(reshape_size)
    s_WNW = slopes_at_cell_subtriangles[:, 3].reshape(reshape_size)
    s_WSW = slopes_at_cell_subtriangles[:, 4].reshape(reshape_size)
    s_SSW = slopes_at_cell_subtriangles[:, 5].reshape(reshape_size)
    s_SSE = slopes_at_cell_subtriangles[:, 6].reshape(reshape_size)
    s_ESE = slopes_at_cell_subtriangles[:, 7].reshape(reshape_size)

    return (s_ENE, s_NNE, s_NNW, s_WNW, s_WSW, s_SSW, s_SSE, s_ESE)


def calc_aspect_at_cell_subtriangles(
    grid, elevs="topographic__elevation", subtriangle_unit_normals=None, unit="degrees"
):
    """Get tuple of arrays of aspect of each of the eight cell subtriangles.

    Aspect is returned as radians clockwise of north, unless input parameter
    units is set to 'degrees'.

    If subtriangle_unit_normals is provided the aspect will be calculated from
    these data.

    If it is not, it will be derived from elevation data at the nodes,
    which can either be a string referring to a grid field (default:
    'topographic__elevation'), or an nnodes-long numpy array of the
    values themselves.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or array (optional)
        Node field name or node array of elevations.
        If *subtriangle_unit_normals* is not provided, must be set, but unused
        otherwise.
    subtriangle_unit_normals : tuple of 8 (ncels, 3) arrays (optional)
        The unit normal vectors for the eight subtriangles of each cell,
        if already known. Order is from north of east, counter
        clockwise to south of east (East North East, North North East, North
        North West, West North West, West South West, South South West, South
        South East, East South East).
    unit : {'degrees', 'radians'}
        Controls the unit that the aspect is returned as.

    Returns
    -------
    (a_ENE, a_NNE, a_NNW, a_WNW, a_WSW, a_SSW, a_SSE, a_ESE) :
            each a length num-cells array
        Len-8 tuple of the aspect of each of the eight cell subtriangles.
        Aspect is returned as angle clockwise of north. Units are given as
        radians unless input parameter units is set to 'degrees'.
        Order is from north of east, counter clockwise to south of east (East
        North East, North North East, North North West, West North West, West
        South West, South South West, South South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((3, 3))
    >>> z = np.array([1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0])
    >>> eight_tris = mg.calc_unit_normals_at_cell_subtriangles(z)
    >>> A = mg.calc_aspect_at_cell_subtriangles(z, eight_tris)
    >>> A0 = mg.calc_aspect_at_cell_subtriangles(z)
    >>> np.allclose(A, A0)
    True
    >>> type(A) is tuple
    True
    >>> len(A)
    8
    >>> len(A[0]) == mg.number_of_cells
    True
    >>> A0
    (array([180.]), array([270.]), array([90.]), array([180.]),
     array([0.]), array([90.]), array([270.]), array([0.]))

    :meta landlab: info-cell, surface
    """

    # calculate all subtriangle slopes
    (
        angle_ENE,
        angle_NNE,
        angle_NNW,
        angle_WNW,
        angle_WSW,
        angle_SSW,
        angle_SSE,
        angle_ESE,
    ) = _calc_subtriangle_aspect_at_node(
        grid, elevs=elevs, subtriangle_unit_normals=subtriangle_unit_normals, unit=unit
    )
    # return only those at cell
    if angle_ESE.shape[0] == grid.number_of_nodes:
        node_at_cell = grid.node_at_cell
    else:
        node_at_cell = np.arange(grid.number_of_cells)

    if unit == "degrees" or unit == "radians":
        return (
            angle_ENE[node_at_cell],
            angle_NNE[node_at_cell],
            angle_NNW[node_at_cell],
            angle_WNW[node_at_cell],
            angle_WSW[node_at_cell],
            angle_SSW[node_at_cell],
            angle_SSE[node_at_cell],
            angle_ESE[node_at_cell],
        )
    else:
        raise TypeError("unit must be 'degrees' or 'radians'")


def _calc_subtriangle_aspect_at_node(
    grid, elevs="topographic__elevation", subtriangle_unit_normals=None, unit="degrees"
):
    """Private Function: Aspect of subtriangles at node.

    This function calculates the aspect of all subtriangles, including those
    that are at noded without cells (on the boundaries).

    Aspect is returned as radians clockwise of north, unless input parameter
    units is set to 'degrees'.

    If subtriangle_unit_normals is provided the aspect will be calculated from
    these data.

    If it is not, it will be derived from elevation data at the nodes,
    which can either be a string referring to a grid field (default:
    'topographic__elevation'), or an nnodes-long numpy array of the
    values themselves.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.
    elevs : str or array (optional)
        Node field name or node array of elevations.
        If *subtriangle_unit_normals* is not provided, must be set, but unused
        otherwise.
    subtriangle_unit_normals : tuple of 8 (ncells, 3) or (nnodes, 3) arrays
        (optional)
        The unit normal vectors for the eight subtriangles of each cell or
        node,if already known. Order is from north of east, counter
        clockwise to south of east (East North East, North North East, North
        North West, West North West, West South West, South South West, South
        South East, East South East).
    unit : {'degrees', 'radians'}
        Controls the unit that the aspect is returned as.

    Returns
    -------
    (a_ENE, a_NNE, a_NNW, a_WNW, a_WSW, a_SSW, a_SSE, a_ESE) :
            each a length num-cells array
        Len-8 tuple of the aspect of each of the eight cell subtriangles.
        Aspect is returned as angle clockwise of north. Units are given as
        radians unless input parameter units is set to 'degrees'.
        Order is from north of east, counter clockwise to south of east (East
        North East, North North East, North North West, West North West, West
        South West, South South West, South South East, East South East).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.grid.raster_gradients import (
    ...     _calc_subtriangle_unit_normals_at_node,
    ...     _calc_subtriangle_aspect_at_node,
    ... )
    >>> mg = RasterModelGrid((3, 3))
    >>> z = np.array([1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0])
    >>> eight_tris = _calc_subtriangle_unit_normals_at_node(mg, z)
    >>> A = _calc_subtriangle_aspect_at_node(mg, z, eight_tris)
    >>> A0 = _calc_subtriangle_aspect_at_node(mg, z)
    >>> np.allclose(A, A0, equal_nan=True)
    True
    >>> type(A) is tuple
    True
    >>> len(A)
    8
    >>> len(A[0]) == mg.number_of_nodes
    True
    >>> A0
    (array([  90.,  315.,   nan,   90.,  180.,   nan,   nan,   nan,   nan]),
     array([   0.,   90.,   nan,  135.,  270.,   nan,   nan,   nan,   nan]),
     array([  nan,   90.,    0.,   nan,   90.,  225.,   nan,   nan,   nan]),
     array([  nan,   45.,  270.,   nan,  180.,   90.,   nan,   nan,   nan]),
     array([  nan,   nan,   nan,   nan,    0.,   90.,   nan,  135.,  270.]),
     array([  nan,   nan,   nan,   nan,   90.,  315.,   nan,   90.,  180.]),
     array([  nan,   nan,   nan,   45.,  270.,   nan,  180.,   90.,   nan]),
     array([  nan,   nan,   nan,  270.,    0.,   nan,   90.,  225.,   nan]))

    :meta landlab: info-cell, surface
    """

    # verify that subtriangle_unit_normals is of the correct form.
    if subtriangle_unit_normals is not None:
        assert len(subtriangle_unit_normals) == 8
        assert subtriangle_unit_normals[0].shape[1] == 3
        assert subtriangle_unit_normals[1].shape[1] == 3
        assert subtriangle_unit_normals[2].shape[1] == 3
        assert subtriangle_unit_normals[3].shape[1] == 3
        assert subtriangle_unit_normals[4].shape[1] == 3
        assert subtriangle_unit_normals[5].shape[1] == 3
        assert subtriangle_unit_normals[6].shape[1] == 3
        assert subtriangle_unit_normals[7].shape[1] == 3

        if subtriangle_unit_normals[7].shape[0] == grid.number_of_nodes:
            reshape_size = grid.number_of_nodes
        elif subtriangle_unit_normals[7].shape[0] == grid.number_of_cells:
            reshape_size = grid.number_of_cells
        else:
            ValueError("Subtriangles must be of lenght nnodes or ncells")
        (
            n_ENE,
            n_NNE,
            n_NNW,
            n_WNW,
            n_WSW,
            n_SSW,
            n_SSE,
            n_ESE,
        ) = subtriangle_unit_normals

    # otherwise create it.
    else:
        (
            n_ENE,
            n_NNE,
            n_NNW,
            n_WNW,
            n_WSW,
            n_SSW,
            n_SSE,
            n_ESE,
        ) = _calc_subtriangle_unit_normals_at_node(grid, elevs)
        reshape_size = grid.number_of_nodes
    # calculate the aspect as an angle ccw from the x axis (math angle)
    angle_from_x_ccw_ENE = np.reshape(
        np.arctan2(n_ENE[:, 1], n_ENE[:, 0]), reshape_size
    )
    angle_from_x_ccw_NNE = np.reshape(
        np.arctan2(n_NNE[:, 1], n_NNE[:, 0]), reshape_size
    )
    angle_from_x_ccw_NNW = np.reshape(
        np.arctan2(n_NNW[:, 1], n_NNW[:, 0]), reshape_size
    )
    angle_from_x_ccw_WNW = np.reshape(
        np.arctan2(n_WNW[:, 1], n_WNW[:, 0]), reshape_size
    )
    angle_from_x_ccw_WSW = np.reshape(
        np.arctan2(n_WSW[:, 1], n_WSW[:, 0]), reshape_size
    )
    angle_from_x_ccw_SSW = np.reshape(
        np.arctan2(n_SSW[:, 1], n_SSW[:, 0]), reshape_size
    )
    angle_from_x_ccw_SSE = np.reshape(
        np.arctan2(n_SSE[:, 1], n_SSE[:, 0]), reshape_size
    )
    angle_from_x_ccw_ESE = np.reshape(
        np.arctan2(n_ESE[:, 1], n_ESE[:, 0]), reshape_size
    )
    # convert reference from math angle to angles clockwise from north
    # return as either  radians or degrees depending on unit.
    if unit == "degrees":
        return (
            radians_to_degrees(angle_from_x_ccw_ENE),
            radians_to_degrees(angle_from_x_ccw_NNE),
            radians_to_degrees(angle_from_x_ccw_NNW),
            radians_to_degrees(angle_from_x_ccw_WNW),
            radians_to_degrees(angle_from_x_ccw_WSW),
            radians_to_degrees(angle_from_x_ccw_SSW),
            radians_to_degrees(angle_from_x_ccw_SSE),
            radians_to_degrees(angle_from_x_ccw_ESE),
        )

    elif unit == "radians":
        angle_from_north_cw_ENE = (5.0 * np.pi / 2.0 - angle_from_x_ccw_ENE) % (
            2.0 * np.pi
        )
        angle_from_north_cw_NNE = (5.0 * np.pi / 2.0 - angle_from_x_ccw_NNE) % (
            2.0 * np.pi
        )
        angle_from_north_cw_NNW = (5.0 * np.pi / 2.0 - angle_from_x_ccw_NNW) % (
            2.0 * np.pi
        )
        angle_from_north_cw_WNW = (5.0 * np.pi / 2.0 - angle_from_x_ccw_WNW) % (
            2.0 * np.pi
        )
        angle_from_north_cw_WSW = (5.0 * np.pi / 2.0 - angle_from_x_ccw_WSW) % (
            2.0 * np.pi
        )
        angle_from_north_cw_SSW = (5.0 * np.pi / 2.0 - angle_from_x_ccw_SSW) % (
            2.0 * np.pi
        )
        angle_from_north_cw_SSE = (5.0 * np.pi / 2.0 - angle_from_x_ccw_SSE) % (
            2.0 * np.pi
        )
        angle_from_north_cw_ESE = (5.0 * np.pi / 2.0 - angle_from_x_ccw_ESE) % (
            2.0 * np.pi
        )

        return (
            angle_from_north_cw_ENE,
            angle_from_north_cw_NNE,
            angle_from_north_cw_NNW,
            angle_from_north_cw_WNW,
            angle_from_north_cw_WSW,
            angle_from_north_cw_SSW,
            angle_from_north_cw_SSE,
            angle_from_north_cw_ESE,
        )
    else:
        raise TypeError("unit must be 'degrees' or 'radians'")


def calc_unit_normals_at_patch_subtriangles(grid, elevs="topographic__elevation"):
    """Calculate unit normals on a patch.

    Calculate the four unit normal vectors <a, b, c> to the four possible
    subtriangles of a four-cornered (raster) patch.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.

    Returns
    -------
    (n_TR, n_TL, n_BL, n_BR) : each a num-patches x length-3 array
        Len-4 tuple of the four unit normal vectors <a, b, c> for the four
        possible subtriangles in the patch. Order is (topright, topleft,
        bottomleft, bottomright).

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_x**2
    >>> four_tris = mg.calc_unit_normals_at_patch_subtriangles(z)
    >>> type(four_tris) is tuple
    True
    >>> len(four_tris)
    4
    >>> np.allclose(four_tris[0], four_tris[1])
    True
    >>> np.allclose(four_tris[2], four_tris[3])
    True
    >>> np.allclose(four_tris[0], four_tris[2])
    True
    >>> np.allclose(np.square(four_tris[0]).sum(axis=1), 1.0)
    True
    >>> four_tris[0]
    array([[-0.70710678,  0.        ,  0.70710678],
           [-0.9486833 ,  0.        ,  0.31622777],
           [-0.98058068,  0.        ,  0.19611614],
           [-0.98994949,  0.        ,  0.14142136],
           [-0.70710678,  0.        ,  0.70710678],
           [-0.9486833 ,  0.        ,  0.31622777],
           [-0.98058068,  0.        ,  0.19611614],
           [-0.98994949,  0.        ,  0.14142136],
           [-0.70710678,  0.        ,  0.70710678],
           [-0.9486833 ,  0.        ,  0.31622777],
           [-0.98058068,  0.        ,  0.19611614],
           [-0.98994949,  0.        ,  0.14142136]])

    :meta landlab: info-patch, gradient
    """
    try:
        z = grid.at_node[elevs]
    except TypeError:
        z = elevs
    # conceptualize patches as TWO sets of 3 nodes
    # the corners are PQRS, CC from NE
    diff_xyz_PQ = np.empty((grid.number_of_patches, 3))  # TOP
    # ^this is the vector (xQ-xP, yQ-yP, zQ-yP)
    diff_xyz_PS = np.empty((grid.number_of_patches, 3))  # RIGHT
    # we have RS and QR implicitly in PQ and PS - but store them too
    diff_xyz_RS = np.empty((grid.number_of_patches, 3))  # BOTTOM
    diff_xyz_QR = np.empty((grid.number_of_patches, 3))  # LEFT
    P = grid.nodes_at_patch[:, 0]
    Q = grid.nodes_at_patch[:, 1]
    R = grid.nodes_at_patch[:, 2]
    S = grid.nodes_at_patch[:, 3]
    x_P = grid.node_x[P]
    y_P = grid.node_y[P]
    z_P = z[P]
    x_Q = grid.node_x[Q]
    y_Q = grid.node_y[Q]
    z_Q = z[Q]
    x_R = grid.node_x[R]
    y_R = grid.node_y[R]
    z_R = z[R]
    x_S = grid.node_x[S]
    y_S = grid.node_y[S]
    z_S = z[S]
    diff_xyz_PQ[:, 0] = x_Q - x_P
    diff_xyz_PQ[:, 1] = y_Q - y_P
    diff_xyz_PQ[:, 2] = z_Q - z_P
    diff_xyz_PS[:, 0] = x_S - x_P
    diff_xyz_PS[:, 1] = y_S - y_P
    diff_xyz_PS[:, 2] = z_S - z_P
    diff_xyz_RS[:, 0] = x_S - x_R
    diff_xyz_RS[:, 1] = y_S - y_R
    diff_xyz_RS[:, 2] = z_S - z_R
    diff_xyz_QR[:, 0] = x_R - x_Q
    diff_xyz_QR[:, 1] = y_R - y_Q
    diff_xyz_QR[:, 2] = z_R - z_Q
    # make the other ones
    # cross product is orthogonal to both vectors, and is the normal
    # n = <a, b, c>, where plane is ax + by + cz = d
    nhat_topleft = np.cross(diff_xyz_PQ, diff_xyz_QR)  # <a, b, c>
    nhat_bottomright = np.cross(diff_xyz_PS, diff_xyz_RS)
    nhat_topright = np.cross(diff_xyz_PQ, diff_xyz_PS)
    nhat_bottomleft = np.cross(diff_xyz_QR, diff_xyz_RS)
    nmag_topleft = np.sqrt(np.square(nhat_topleft).sum(axis=1))
    nmag_bottomright = np.sqrt(np.square(nhat_bottomright).sum(axis=1))
    nmag_topright = np.sqrt(np.square(nhat_topright).sum(axis=1))
    nmag_bottomleft = np.sqrt(np.square(nhat_bottomleft).sum(axis=1))
    n_TR = nhat_topright / nmag_topright.reshape(grid.number_of_patches, 1)
    n_TL = nhat_topleft / nmag_topleft.reshape(grid.number_of_patches, 1)
    n_BL = nhat_bottomleft / nmag_bottomleft.reshape(grid.number_of_patches, 1)
    n_BR = nhat_bottomright / nmag_bottomright.reshape(grid.number_of_patches, 1)

    return (n_TR, n_TL, n_BL, n_BR)


def calc_slope_at_patch(
    grid,
    elevs="topographic__elevation",
    ignore_closed_nodes=True,
    subtriangle_unit_normals=None,
):
    """Calculate the slope (positive magnitude of gradient) at raster patches.

    Returns the mean of the slopes of the four possible patch subtriangles.

    If ignore_closed_nodes is True, closed nodes do not affect slope
    calculations. If more than one closed node is present in a patch, the
    patch slope is set to zero.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.
    subtriangle_unit_normals : tuple of 4 (npatches, 3) arrays (optional)
        The unit normal vectors for the four subtriangles of each patch,
        if already known. Order is TR, TL, BL, BR.

    Returns
    -------
    slopes_at_patch : n_patches-long array
        The slope (positive gradient magnitude) of each patch, in radians.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_x
    >>> S = mg.calc_slope_at_patch(elevs=z)
    >>> S.size == mg.number_of_patches
    True
    >>> np.allclose(S, np.pi / 4.0)
    True
    >>> z = mg.node_y**2
    >>> mg.calc_slope_at_patch(elevs=z).reshape((3, 4))
    array([[0.78539816,  0.78539816,  0.78539816,  0.78539816],
           [1.24904577,  1.24904577,  1.24904577,  1.24904577],
           [1.37340077,  1.37340077,  1.37340077,  1.37340077]])

    >>> z = mg.node_x.copy()
    >>> mg.set_closed_boundaries_at_grid_edges(True, True, True, True)
    >>> mg.status_at_node[11] = mg.BC_NODE_IS_CLOSED
    >>> mg.status_at_node[9] = mg.BC_NODE_IS_FIXED_VALUE
    >>> z[11] = 100.0  # this should get ignored now
    >>> z[9] = 2.0  # this should be felt by patch 7 only
    >>> mg.calc_slope_at_patch(elevs=z, ignore_closed_nodes=True).reshape(
    ...     (3, 4)
    ... ) * 4.0 / np.pi
    array([[0.,  0.,  0.,  0.],
           [0.,  1.,  1.,  1.],
           [0.,  0.,  0.,  0.]])

    :meta landlab: info-patch, gradient
    """
    if subtriangle_unit_normals is not None:
        assert len(subtriangle_unit_normals) == 4
        assert subtriangle_unit_normals[0].shape[1] == 3
        assert subtriangle_unit_normals[1].shape[1] == 3
        assert subtriangle_unit_normals[2].shape[1] == 3
        assert subtriangle_unit_normals[3].shape[1] == 3
        n_TR, n_TL, n_BL, n_BR = subtriangle_unit_normals
    else:
        n_TR, n_TL, n_BL, n_BR = grid.calc_unit_normals_at_patch_subtriangles(elevs)
    dotprod_TL = n_TL[:, 2]  # by definition
    dotprod_BR = n_BR[:, 2]
    dotprod_TR = n_TR[:, 2]
    dotprod_BL = n_BL[:, 2]
    slopes_at_patch_TL = np.arccos(dotprod_TL)  # 1 node order
    slopes_at_patch_BR = np.arccos(dotprod_BR)  # 3
    slopes_at_patch_TR = np.arccos(dotprod_TR)  # 0
    slopes_at_patch_BL = np.arccos(dotprod_BL)  # 2
    if ignore_closed_nodes:
        badnodes = grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED
        tot_bad = badnodes.sum(axis=1)
        tot_tris = 4.0 - 3.0 * (tot_bad > 0)  # 4 where all good, 1 where not
        # now shut down the bad tris. Remember, one bad node => 3 bad tris.
        # anywhere where badnodes > 1 will have zero from summing, so div by 1
        # assert np.all(np.logical_or(np.isclose(tot_tris, 4.),
        #                             np.isclose(tot_tris, 1.)))
        corners_rot = deque(
            [
                slopes_at_patch_BR,
                slopes_at_patch_TR,
                slopes_at_patch_TL,
                slopes_at_patch_BL,
            ]
        )
        # note initial offset so we are centered around TR on first slice
        for i in range(4):
            for j in range(3):
                (corners_rot[j])[badnodes[:, i]] = 0.0
            corners_rot.rotate(-1)
    else:
        tot_tris = 4.0
    mean_slope_at_patch = (
        slopes_at_patch_TR
        + slopes_at_patch_TL
        + slopes_at_patch_BL
        + slopes_at_patch_BR
    ) / tot_tris

    return mean_slope_at_patch


def calc_grad_at_patch(
    grid,
    elevs="topographic__elevation",
    ignore_closed_nodes=True,
    subtriangle_unit_normals=None,
    slope_magnitude=None,
):
    """Calculate the components of the gradient of each raster patch.

    Returns the mean gradient of the four possible patch subtriangles,
    in radians.

    If ignore_closed_nodes is True, closed nodes do not affect gradient
    calculations. If more than one closed node is present in a patch, the
    patch gradients in both x and y directions are set to zero.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    elevs : str or ndarray, optional
        Field name or array of node values.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.
    subtriangle_unit_normals : tuple of 4 (npatches, 3) arrays (optional)
        The unit normal vectors for the four subtriangles of each patch,
        if already known. Order is TR, TL, BL, BR.
    slope_magnitude : array with size num_patches (optional)
        The mean slope of each patch, if already known. Units must be the
        same as provided here!

    Returns
    -------
    gradient_tuple : (x_component_at_patch, y_component_at_patch)
        Len-2 tuple of arrays giving components of gradient in the x and y
        directions, in the units of *radians*.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> mg = RasterModelGrid((4, 5))
    >>> z = mg.node_y
    >>> (x_grad, y_grad) = mg.calc_grad_at_patch(elevs=z)
    >>> np.allclose(y_grad, np.pi / 4.0)
    True
    >>> np.allclose(x_grad, 0.0)
    True

    >>> z = mg.node_x.copy()
    >>> mg.set_closed_boundaries_at_grid_edges(True, True, True, True)
    >>> mg.status_at_node[11] = mg.BC_NODE_IS_CLOSED
    >>> mg.status_at_node[[9, 2]] = mg.BC_NODE_IS_FIXED_VALUE
    >>> z[11] = 100.0  # this should get ignored now
    >>> z[9] = 2.0  # this should be felt by patch 7 only
    >>> z[2] = 1.0  # should be felt by patches 1 and 2
    >>> xgrad, ygrad = mg.calc_grad_at_patch(elevs=z, ignore_closed_nodes=True)
    >>> (xgrad.reshape((3, 4)) * 4.0 / np.pi)[1, 1:]
    array([ 1.,  1., -1.])
    >>> np.allclose(ygrad[1:3], xgrad[1:3])
    True

    :meta landlab: info-patch, gradient
    """
    if subtriangle_unit_normals is not None:
        assert len(subtriangle_unit_normals) == 4
        assert subtriangle_unit_normals[0].shape[1] == 3
        assert subtriangle_unit_normals[1].shape[1] == 3
        assert subtriangle_unit_normals[2].shape[1] == 3
        assert subtriangle_unit_normals[3].shape[1] == 3
        n_TR, n_TL, n_BL, n_BR = subtriangle_unit_normals
    else:
        n_TR, n_TL, n_BL, n_BR = grid.calc_unit_normals_at_patch_subtriangles(elevs)
    if slope_magnitude is not None:
        assert slope_magnitude.size == grid.number_of_patches
        slopes_at_patch = slope_magnitude
    else:
        slopes_at_patch = grid.calc_slope_at_patch(
            elevs=elevs,
            ignore_closed_nodes=ignore_closed_nodes,
            subtriangle_unit_normals=(n_TR, n_TL, n_BL, n_BR),
        )

    if ignore_closed_nodes:
        badnodes = grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED
        corners_rot = deque([n_BR, n_TR, n_TL, n_BL])
        # note initial offset so we are centered around TR on first slice
        for i in range(4):
            for j in range(3):
                (corners_rot[j])[badnodes[:, i], :] = 0.0
            corners_rot.rotate(-1)

    n_sum_x = n_TR[:, 0] + n_TL[:, 0] + n_BL[:, 0] + n_BR[:, 0]
    n_sum_y = n_TR[:, 1] + n_TL[:, 1] + n_BL[:, 1] + n_BR[:, 1]
    theta_sum = np.arctan2(-n_sum_y, -n_sum_x)
    x_slope_patches = np.cos(theta_sum) * slopes_at_patch
    y_slope_patches = np.sin(theta_sum) * slopes_at_patch

    return (x_slope_patches, y_slope_patches)


def calc_slope_at_node(
    grid,
    elevs="topographic__elevation",
    method="patch_mean",
    ignore_closed_nodes=True,
    return_components=False,
):
    """Array of slopes at nodes, averaged over neighboring patches.

    Produces a value for node slope (i.e., mean gradient magnitude)
    at each node in a manner analogous to a GIS-style slope map.
    If method=='patch_mean', it averages the gradient on each of the
    patches surrounding the node; if method=='Horn', it returns the
    resolved slope direction. Directional information can still be
    returned through use of the return_components keyword.
    All values are returned in radians, including the components;
    take the tan to recover the rise/run.

    Note that under these definitions, it is not always true that::

        mag, cmp = mg.calc_slope_at_node(z)
        mag**2 == cmp[0]**2 + cmp[1]**2  # only if method=='Horn'

    If ignore_closed_nodes is False, all proximal elevation values will be used
    in the calculation. If True, only unclosed nodes are used.

    This is a verion of this code specialized for a raster. It subdivides
    the four square patches around each node into subtriangles,
    in order to ensure more correct solutions that incorporate equally
    weighted information from all surrounding nodes on rough surfaces.

    Parameters
    ----------
    elevs : str or ndarray, optional
        Field name or array of node values.
    method : {'patch_mean', 'Horn'}
        Controls the slope algorithm. Current options are 'patch_mean',
        which takes the mean slope of each pf the four neighboring
        square patches, and 'Horn', which is the standard ArcGIS slope
        algorithm. These produce very similar solutions; the Horn method
        gives a vector mean and the patch_mean gives a scalar mean.
    ignore_closed_nodes : bool
        If True, do not incorporate values at closed nodes into the calc.
    return_components : bool
        If True, return a tuple, (array_of_magnitude,
        (array_of_slope_x_radians, array_of_slope_y_radians)).
        If false, return an array of floats of the slope magnitude.

    Returns
    -------
    float array or length-2 tuple of float arrays
        If return_components, returns (array_of_magnitude,
        (array_of_slope_x_radians, array_of_slope_y_radians)).
        If not return_components, returns an array of slope magnitudes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RadialModelGrid, RasterModelGrid
    >>> mg = RasterModelGrid((5, 5))
    >>> z = mg.node_x
    >>> slopes = mg.calc_slope_at_node(elevs=z)
    >>> np.allclose(slopes, np.pi / 4.0)
    True
    >>> mg = RasterModelGrid((4, 5), xy_spacing=2.0)
    >>> z = -mg.node_y
    >>> slope_mag, cmp = mg.calc_slope_at_node(elevs=z, return_components=True)
    >>> np.allclose(slope_mag, np.pi / 4.0)
    True
    >>> np.allclose(cmp[0], 0.0)
    True
    >>> np.allclose(cmp[1], -np.pi / 4.0)
    True
    >>> mg = RasterModelGrid((4, 4))
    >>> z = mg.node_x**2 + mg.node_y**2
    >>> slopes, cmp = mg.calc_slope_at_node(z, return_components=True)
    >>> slopes
    array([0.95531662,  1.10991779,  1.32082849,  1.37713803,  1.10991779,
           1.20591837,  1.3454815 ,  1.38904403,  1.32082849,  1.3454815 ,
           1.39288142,  1.41562833,  1.37713803,  1.38904403,  1.41562833,
           1.43030663])

    Check radial symmetry.

    >>> np.allclose(cmp[0].reshape((4, 4))[:, 0], cmp[1].reshape((4, 4))[0, :])
    True

    :meta landlab: info-node, gradient, surface
    """
    if method not in ("patch_mean", "Horn"):
        raise ValueError("method name not understood")
    try:
        patches_at_node = grid.patches_at_node()
    except TypeError:  # was a property, not a fn (=> new style)
        if not ignore_closed_nodes:
            patches_at_node = np.ma.masked_where(
                grid.patches_at_node == -1, grid.patches_at_node, copy=False
            )
        else:
            patches_at_node = np.ma.masked_where(
                np.logical_not(grid.patches_present_at_node),
                grid.patches_at_node,
                copy=False,
            )
    # now, we also want to mask any "closed" patches (any node closed)
    closed_patches = (
        grid.status_at_node[grid.nodes_at_patch] == grid.BC_NODE_IS_CLOSED
    ).sum(axis=1) > 0
    closed_patch_mask = np.logical_or(
        patches_at_node.mask, closed_patches[patches_at_node.data]
    )

    if method == "patch_mean":
        n_TR, n_TL, n_BL, n_BR = grid.calc_unit_normals_at_patch_subtriangles(elevs)

        mean_slope_at_patches = grid.calc_slope_at_patch(
            elevs=elevs,
            ignore_closed_nodes=ignore_closed_nodes,
            subtriangle_unit_normals=(n_TR, n_TL, n_BL, n_BR),
        )

        # now CAREFUL - patches_at_node is MASKED
        slopes_at_node_unmasked = mean_slope_at_patches[patches_at_node]
        slopes_at_node_masked = np.ma.array(
            slopes_at_node_unmasked, mask=closed_patch_mask
        )
        slope_mag = np.mean(slopes_at_node_masked, axis=1).data
        if return_components:
            (x_slope_patches, y_slope_patches) = grid.calc_grad_at_patch(
                elevs=elevs,
                ignore_closed_nodes=ignore_closed_nodes,
                subtriangle_unit_normals=(n_TR, n_TL, n_BL, n_BR),
                slope_magnitude=mean_slope_at_patches,
            )
            x_slope_unmasked = x_slope_patches[patches_at_node]
            x_slope_masked = np.ma.array(x_slope_unmasked, mask=closed_patch_mask)
            x_slope = np.mean(x_slope_masked, axis=1).data
            y_slope_unmasked = y_slope_patches[patches_at_node]
            y_slope_masked = np.ma.array(y_slope_unmasked, mask=closed_patch_mask)
            y_slope = np.mean(y_slope_masked, axis=1).data
            mean_grad_x = x_slope
            mean_grad_y = y_slope
    elif method == "Horn":
        z = np.empty(grid.number_of_nodes + 1, dtype=float)
        mean_grad_x = grid.empty(at="node", dtype=float)
        mean_grad_y = grid.empty(at="node", dtype=float)
        z[-1] = 0.0
        try:
            z[:-1] = grid.at_node[elevs]
        except TypeError:
            z[:-1] = elevs
        # proof code for bad indexing:
        diags = grid.diagonal_adjacent_nodes_at_node.copy()  # LL order
        orthos = grid.adjacent_nodes_at_node.copy()
        # these have closed node neighbors...
        for dirs in (diags, orthos):
            dirs[dirs == grid.BAD_INDEX] = -1  # indexing to work
        # now make an array like patches_at_node to store the interim calcs
        patch_slopes_x = np.ma.zeros(patches_at_node.shape, dtype=float)
        patch_slopes_y = np.ma.zeros(patches_at_node.shape, dtype=float)
        diff_E = z[orthos[:, 0]] - z[:-1]
        diff_W = z[:-1] - z[orthos[:, 2]]
        diff_N = z[orthos[:, 1]] - z[:-1]
        diff_S = z[:-1] - z[orthos[:, 3]]
        patch_slopes_x[:, 0] = z[diags[:, 0]] - z[orthos[:, 1]] + diff_E
        patch_slopes_x[:, 1] = z[orthos[:, 1]] - z[diags[:, 1]] + diff_W
        patch_slopes_x[:, 2] = z[orthos[:, 3]] - z[diags[:, 2]] + diff_W
        patch_slopes_x[:, 3] = z[diags[:, 3]] - z[orthos[:, 3]] + diff_E
        patch_slopes_y[:, 0] = z[diags[:, 0]] - z[orthos[:, 0]] + diff_N
        patch_slopes_y[:, 1] = z[diags[:, 1]] - z[orthos[:, 2]] + diff_N
        patch_slopes_y[:, 2] = z[orthos[:, 2]] - z[diags[:, 2]] + diff_S
        patch_slopes_y[:, 3] = z[orthos[:, 0]] - z[diags[:, 3]] + diff_S
        patch_slopes_x /= 2.0 * grid.dx
        patch_slopes_y /= 2.0 * grid.dy
        patch_slopes_x.mask = closed_patch_mask
        patch_slopes_y.mask = closed_patch_mask
        mean_grad_x = patch_slopes_x.mean(axis=1).data
        mean_grad_y = patch_slopes_y.mean(axis=1).data
        slope_mag = np.arctan(np.sqrt(np.square(mean_grad_x) + np.square(mean_grad_y)))
        if return_components:
            mean_grad_x = np.arctan(mean_grad_x)
            mean_grad_y = np.arctan(mean_grad_y)

    if return_components:
        return slope_mag, (mean_grad_x, mean_grad_y)

    else:
        return slope_mag



================================================
File: src/landlab/grid/raster_mappers.py
================================================
#! /usr/bin/env python
"""Grid element mappers that are specific to raster grids.

Mapping functions unique to raster grids
++++++++++++++++++++++++++++++++++++++++

.. autosummary::

    ~map_sum_of_inlinks_to_node
    ~map_mean_of_inlinks_to_node
    ~map_max_of_inlinks_to_node
    ~map_min_of_inlinks_to_node
    ~map_sum_of_outlinks_to_node
    ~map_mean_of_outlinks_to_node
    ~map_max_of_outlinks_to_node
    ~map_min_of_outlinks_to_node
    ~map_mean_of_links_to_node
    ~map_mean_of_horizontal_links_to_node
    ~map_mean_of_horizontal_active_links_to_node
    ~map_mean_of_vertical_links_to_node
    ~map_mean_of_vertical_active_links_to_node
"""

import numpy as np


def _node_out_link_ids(shape):
    """Links leaving each node.

    Parameters
    ----------
    shape : tuple of int
        Shape of grid of nodes.

    Returns
    -------
    tuple :
        Tuple of array of link IDs as (vertical_links, horizontal_links).

    Examples
    --------
    >>> from landlab.grid.raster_mappers import _node_out_link_ids
    >>> (vert, horiz) = _node_out_link_ids((3, 4))
    >>> vert
    array([[ 3,  4,  5,  6],
           [10, 11, 12, 13],
           [-1, -1, -1, -1]])
    >>> horiz
    array([[ 0,  1,  2, -1],
           [ 7,  8,  9, -1],
           [14, 15, 16, -1]])
    """
    from ..graph.structured_quad.structured_quad import StructuredQuadGraphTopology

    layout = StructuredQuadGraphTopology(shape)

    node_horizontal_link_ids = np.empty(shape, int)
    node_horizontal_link_ids[:, :-1] = layout.horizontal_links.reshape(
        (shape[0], shape[1] - 1)
    )
    node_horizontal_link_ids[:, -1] = -1

    node_vertical_link_ids = np.empty(shape, int)
    node_vertical_link_ids[:-1, :] = layout.vertical_links.reshape(
        (shape[0] - 1, shape[1])
    )
    node_vertical_link_ids[-1, :] = -1

    return node_vertical_link_ids, node_horizontal_link_ids


def _node_in_link_ids(shape):
    """Links entering each node.

    Parameters
    ----------
    shape : tuple of int
        Shape of grid of nodes.

    Returns
    -------
    tuple :
        Tuple of array of link IDs as (vertical_links, horizontal_links).

    Examples
    --------
    >>> from landlab.grid.raster_mappers import _node_in_link_ids
    >>> (vert, horiz) = _node_in_link_ids((3, 4))
    >>> vert
    array([[-1, -1, -1, -1],
           [ 3,  4,  5,  6],
           [10, 11, 12, 13]])
    >>> horiz
    array([[-1,  0,  1,  2],
           [-1,  7,  8,  9],
           [-1, 14, 15, 16]])
    """
    from ..graph.structured_quad.structured_quad import StructuredQuadGraphTopology

    layout = StructuredQuadGraphTopology(shape)

    node_horizontal_link_ids = np.empty(shape, int)
    node_horizontal_link_ids[:, 1:] = layout.horizontal_links.reshape(
        (shape[0], shape[1] - 1)
    )
    node_horizontal_link_ids[:, 0] = -1

    node_vertical_link_ids = np.empty(shape, int)
    node_vertical_link_ids[1:, :] = layout.vertical_links.reshape(
        (shape[0] - 1, shape[1])
    )
    node_vertical_link_ids[0, :] = -1

    return node_vertical_link_ids, node_horizontal_link_ids


def _number_of_links_per_node(shape):
    """Number of links touching each node.

    Parameters
    ----------
    shape : tuple of int
        Shape of grid of nodes.

    Returns
    -------
    ndarray :
        Array of number of links per node.

    Examples
    --------
    >>> from landlab.grid.raster_mappers import _number_of_links_per_node
    >>> _number_of_links_per_node((3, 4))
    array([[2, 3, 3, 2],
           [3, 4, 4, 3],
           [2, 3, 3, 2]])
    """
    from ..graph.structured_quad.structured_quad import StructuredQuadGraphTopology

    layout = StructuredQuadGraphTopology(shape)

    n_links_at_node = np.full(shape[0] * shape[1], 4, int)
    n_links_at_node[layout.perimeter_nodes] = 3
    n_links_at_node[layout.corner_nodes] = 2

    return n_links_at_node.reshape(shape)


def map_sum_of_inlinks_to_node(grid, var_name, out=None):
    """Map the sum of links entering a node to the node.

    map_sum_of_inlinks_to_node takes an array *at the links* and finds the
    inlink values for each node in the grid. it sums the inlinks and returns
    values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_sum_of_inlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_sum_of_inlinks_to_node(rmg, "z")
    array([  0.,   0.,   1.,   2.,   3.,  11.,  13.,  15.,  10.,  25.,  27.,
            29.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)

    south, west = _node_in_link_ids(grid.shape)
    south, west = south.reshape(south.size), west.reshape(west.size)
    out[:] = values_at_links[south] + values_at_links[west]

    return out


def map_mean_of_inlinks_to_node(grid, var_name, out=None):
    """Map the mean of links entering a node to the node.

    map_mean_of_inlinks_to_node takes an array *at the links* and finds the
    inlink values for each node in the grid. It finds the average of
    the inlinks and returns values at the nodes.

    This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_mean_of_inlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_mean_of_inlinks_to_node(rmg, "z")
    array([  0. ,   0. ,   0.5,   1. ,   1.5,   5.5,   6.5,   7.5,   5. ,
            12.5,  13.5,  14.5])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    south, west = _node_in_link_ids(grid.shape)
    south, west = south.reshape(south.size), west.reshape(west.size)
    out[:] = 0.5 * (values_at_links[south] + values_at_links[west])

    return out


def map_max_of_inlinks_to_node(grid, var_name, out=None):
    """Map the maximum of links entering a node to the node.

    map_max_of_inlinks_to_node takes an array *at the links* and finds the
    inlink values for each node in the grid. it finds the maximum value at the
    the inlinks and returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_max_of_inlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_max_of_inlinks_to_node(rmg, "z")
    array([  0.,   0.,   1.,   2.,
             3.,   7.,   8.,   9.,
            10.,  14.,  15.,  16.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    south, west = _node_in_link_ids(grid.shape)
    south, west = south.reshape(south.size), west.reshape(west.size)
    out[:] = np.maximum(values_at_links[south], values_at_links[west])

    return out


def map_min_of_inlinks_to_node(grid, var_name, out=None):
    """Map the minimum of links entering a node to the node.

    map_min_of_inlinks_to_node takes an array *at the links* and finds the
    inlink values for each node in the grid. it finds the minimum value at the
    the inlinks and returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_min_of_inlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_min_of_inlinks_to_node(rmg, "z")
    array([  0.,   0.,   0.,   0.,   0.,   4.,   5.,   6.,   0.,  11.,  12.,
            13.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    south, west = _node_in_link_ids(grid.shape)
    south, west = south.reshape(south.size), west.reshape(west.size)
    out[:] = np.minimum(values_at_links[south], values_at_links[west])

    return out


def map_sum_of_outlinks_to_node(grid, var_name, out=None):
    """Map the sum of links leaving a node to the node.

    map_sum_of_outlinks_to_node takes an array *at the links* and finds the
    outlink values for each node in the grid. it sums the outlinks and returns
    values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_sum_of_outlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_sum_of_outlinks_to_node(rmg, "z")
    array([  3.,  5.,  7.,   6.,  17.,  19.,  21.,  13.,  14.,  15.,  16.,
             0.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    north, east = _node_out_link_ids(grid.shape)
    north, east = north.reshape(north.size), east.reshape(east.size)
    out[:] = values_at_links[north] + values_at_links[east]

    return out


def map_mean_of_outlinks_to_node(grid, var_name, out=None):
    """Map the mean of links leaving a node to the node.

    map_mean_of_outlinks_to_node takes an array *at the links* and finds the
    outlink values for each node in the grid. it finds the average of
    the outlinks and returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_mean_of_outlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_mean_of_outlinks_to_node(rmg, "z")
    array([  1.5,   2.5,   3.5,   3. ,   8.5,   9.5,  10.5,   6.5,   7. ,
             7.5,   8. ,   0. ])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    north, east = _node_out_link_ids(grid.shape)
    north, east = north.reshape(north.size), east.reshape(east.size)
    out[:] = 0.5 * (values_at_links[north] + values_at_links[east])

    return out


def map_max_of_outlinks_to_node(grid, var_name, out=None):
    """Map the max of links leaving a node to the node.

    map_max_of_outlinks_to_node takes an array *at the links* and finds the
    outlink values for each node in the grid. it finds the maximum value at the
    the outlinks and returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_max_of_outlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_max_of_outlinks_to_node(rmg, "z")
    array([  3.,   4.,   5.,   6.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,
             0.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    north, east = _node_out_link_ids(grid.shape)
    north, east = north.reshape(north.size), east.reshape(east.size)
    np.maximum(values_at_links[north], values_at_links[east], out=out)

    return out


def map_min_of_outlinks_to_node(grid, var_name, out=None):
    """Map the min of links leaving a node to the node.

    map_min_of_outlinks_to_node takes an array *at the links* and finds the
    outlink values for each node in the grid. It finds the minimum value at the
    the outlinks and returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_min_of_outlinks_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_min_of_outlinks_to_node(rmg, "z")
    array([0.,  1.,  2.,  0.,  7.,  8.,  9.,  0.,  0.,  0.,  0.,  0.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)
    north, east = _node_out_link_ids(grid.shape)
    north, east = north.reshape(north.size), east.reshape(east.size)
    np.minimum(values_at_links[north], values_at_links[east], out=out)

    return out


def map_mean_of_links_to_node(grid, var_name, out=None):
    """Map the mean of links touching a node to the node.

    map_mean_all_links_to_node takes an array *at the links* and finds the
    average of all ~existing~ link neighbor values for each node in the grid.
    it returns values at the nodes.

    .. note::

        This considers all inactive links to have a value of 0.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_mean_of_links_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_mean_of_links_to_node(rmg, "z")
    array([  1.5       ,   1.66666667,   2.66666667,   4.        ,
             6.66666667,   7.5       ,   8.5       ,   9.33333333,
            12.        ,  13.33333333,  14.33333333,  14.5       ])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    values_at_links = np.append(values_at_links, 0)

    north, east = _node_out_link_ids(grid.shape)
    north, east = north.reshape(north.size), east.reshape(east.size)
    south, west = _node_in_link_ids(grid.shape)
    south, west = south.reshape(south.size), west.reshape(west.size)

    number_of_links = _number_of_links_per_node(grid.shape)
    number_of_links = number_of_links.reshape(number_of_links.size)
    number_of_links.astype(float, copy=False)
    out[:] = (
        values_at_links[north]
        + values_at_links[east]
        + values_at_links[south]
        + values_at_links[west]
    ) / number_of_links

    return out


def map_mean_of_horizontal_links_to_node(grid, var_name, out=None):
    """Map the mean of links in the x direction touching a node to the node.

    map_mean_of_horizontal_links_to_node takes an array *at the links* and
    finds the average of all horizontal (x-direction) link neighbor values
    for each node in the grid.
    It returns an array at the nodes of the mean of these values. If a link
    is absent, it is ignored.
    Note that here a positive returned value means flux to the east, and
    a negative to the west.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_mean_of_horizontal_links_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_mean_of_horizontal_links_to_node(rmg, "z")
    array([  0. ,   0.5,   1.5,   2. ,   7. ,   7.5,   8.5,   9. ,  14. ,
            14.5,  15.5,  16. ])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    hoz_links = grid.links_at_node[:, [0, 2]]
    hoz_link_dirs = np.fabs(grid.link_dirs_at_node[:, [0, 2]])
    # ^retain "true" directions of links
    valid_links = values_at_links[hoz_links] * hoz_link_dirs  # invalids = 0
    num_valid_links = hoz_link_dirs.sum(axis=1)
    np.divide(valid_links.sum(axis=1), num_valid_links, out=out)
    return out


def map_mean_of_horizontal_active_links_to_node(grid, var_name, out=None):
    """Map the mean of active links in the x direction touching node to the
    node.

    map_mean_of_horizontal_active_links_to_node takes an array *at the links*
    and finds the average of all horizontal (x-direction) link neighbor values
    for each node in the grid.
    It returns an array at the nodes of the mean of these values. If a link
    is absent, it is ignored. If a node has no active links, it receives 0.
    Note that here a positive returned value means flux to the east, and
    a negative to the west.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import (
    ...     map_mean_of_horizontal_active_links_to_node,
    ... )
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", -np.arange(17, dtype=float), at="link")
    >>> rmg.status_at_node[rmg.nodes_at_left_edge] = rmg.BC_NODE_IS_CLOSED
    >>> map_mean_of_horizontal_active_links_to_node(rmg, "z")
    array([ 0. ,  0. ,  0. ,  0. ,  0. , -8. , -8.5, -9. ,  0. ,  0. ,  0. ,
            0. ])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.zeros(centering="node", dtype=float)
    else:
        out.fill(0.0)

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    hoz_links = grid.links_at_node[:, [0, 2]]
    hoz_link_dirs = np.fabs(grid.active_link_dirs_at_node[:, [0, 2]])
    # ^retain "true" directions of links; no inactives now
    valid_links = values_at_links[hoz_links] * hoz_link_dirs  # invalids = 0
    num_valid_links = hoz_link_dirs.sum(axis=1)
    good_nodes = num_valid_links != 0
    out[good_nodes] = valid_links.sum(axis=1)[good_nodes] / num_valid_links[good_nodes]
    return out


def map_mean_of_vertical_links_to_node(grid, var_name, out=None):
    """Map the mean of links in the y direction touching a node to the node.

    map_mean_of_vertical_links_to_node takes an array *at the links* and
    finds the average of all vertical (y-direction) link neighbor values
    for each node in the grid.
    It returns an array at the nodes of the mean of these values. If a link
    is absent, it is ignored.
    Note that here a positive returned value means flux to the north, and
    a negative to the south.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import map_mean_of_vertical_links_to_node
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", np.arange(17.0), at="link")
    >>> map_mean_of_vertical_links_to_node(rmg, "z")
    array([  3. ,   4. ,   5. ,   6. ,   6.5,   7.5,   8.5,   9.5,  10. ,
            11. ,  12. ,  13. ])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.empty(centering="node")

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    vert_links = grid.links_at_node[:, [1, 3]]
    vert_link_dirs = np.fabs(grid.link_dirs_at_node[:, [1, 3]])
    # ^retain "true" directions of links
    valid_links = values_at_links[vert_links] * vert_link_dirs  # invalids = 0
    num_valid_links = vert_link_dirs.sum(axis=1)
    np.divide(valid_links.sum(axis=1), num_valid_links, out=out)
    return out


def map_mean_of_vertical_active_links_to_node(grid, var_name, out=None):
    """Map the mean of active links in the y direction touching node to the
    node.

    map_mean_of_vertical_active_links_to_node takes an array *at the links*
    and finds the average of all vertical (y-direction) link neighbor values
    for each node in the grid.
    It returns an array at the nodes of the mean of these values. If a link
    is absent, it is ignored. If a node has no active links, it receives 0.
    Note that here a positive returned value means flux to the north, and
    a negative to the south.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    var_name : array or field name
        Values defined at links.
    out : ndarray, optional
        Buffer to place mapped values into or `None` to create a new array.

    Returns
    -------
    ndarray
        Mapped values at nodes.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.raster_mappers import (
    ...     map_mean_of_vertical_active_links_to_node,
    ... )
    >>> from landlab import RasterModelGrid

    >>> rmg = RasterModelGrid((3, 4))
    >>> _ = rmg.add_field("z", -np.arange(17, dtype=float), at="link")
    >>> rmg.status_at_node[rmg.nodes_at_bottom_edge] = rmg.BC_NODE_IS_CLOSED
    >>> map_mean_of_vertical_active_links_to_node(rmg, "z")
    array([  0.,   0.,   0.,   0.,   0., -11., -12.,   0.,   0., -11., -12.,
             0.])

    :meta landlab: info-node, info-link, map
    """
    if out is None:
        out = grid.zeros(centering="node", dtype=float)
    else:
        out.fill(0.0)

    if type(var_name) is str:
        values_at_links = grid.at_link[var_name]
    else:
        values_at_links = var_name
    vert_links = grid.links_at_node[:, [1, 3]]
    vert_link_dirs = np.fabs(grid.active_link_dirs_at_node[:, [1, 3]])
    # ^retain "true" directions of links; no inactives now
    valid_links = values_at_links[vert_links] * vert_link_dirs  # invalids = 0
    num_valid_links = vert_link_dirs.sum(axis=1)
    good_nodes = num_valid_links != 0
    out[good_nodes] = valid_links.sum(axis=1)[good_nodes] / num_valid_links[good_nodes]
    return out


def map_link_vector_components_to_node_raster(grid, data_at_link):
    """Map (x,y) vector components of data_at_link onto nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> rmg = RasterModelGrid((3, 4))
    >>> link_data = np.arange(rmg.number_of_links)
    >>> x, y = map_link_vector_components_to_node_raster(rmg, link_data)
    >>> x[5:7]
    array([7.5,  8.5])
    >>> y[5:7]
    array([7.5,  8.5])
    """
    x = grid.map_mean_of_horizontal_links_to_node(data_at_link)
    y = grid.map_mean_of_vertical_links_to_node(data_at_link)
    return x, y



================================================
File: src/landlab/grid/raster_set_status.py
================================================
def set_status_at_node_on_edges(grid, right=None, top=None, left=None, bottom=None):
    """Set node status on grid edges.

    Parameters
    ----------
    grid : RasterModelGrid
        A grid.
    right : int, optional
        Node status along right edge.
    top : int, optional
        Node status along top edge.
    left : int, optional
        Node status along left edge.
    bottom : int, optional
        Node status along bottom edge.

    Examples
    --------
    >>> from landlab import RasterModelGrid

    >>> grid = RasterModelGrid((3, 4))
    >>> grid.status_at_node.reshape(grid.shape)
    array([[1, 1, 1, 1],
           [1, 0, 0, 1],
           [1, 1, 1, 1]], dtype=uint8)

    >>> grid.set_status_at_node_on_edges(right=grid.BC_NODE_IS_CLOSED)
    >>> grid.status_at_node.reshape(grid.shape)
    array([[1, 1, 1, 4],
           [1, 0, 0, 4],
           [1, 1, 1, 4]], dtype=uint8)

    >>> grid = RasterModelGrid((3, 4))

    The status of a corner is set along with its clockwise edge. That is,
    if setting the status for the top and right edges, the upper-right corner
    has the status of the right edge.

    >>> grid.set_status_at_node_on_edges(
    ...     top=grid.BC_NODE_IS_CLOSED, right=grid.BC_NODE_IS_FIXED_GRADIENT
    ... )
    >>> grid.status_at_node.reshape(grid.shape)
    array([[1, 1, 1, 2],
           [1, 0, 0, 2],
           [4, 4, 4, 2]], dtype=uint8)

    In the above example, if you wanted the corner to have the status of the
    top edge, you need to make two calls to `set_status_at_node_on_edges`,

    >>> grid = RasterModelGrid((3, 4))
    >>> grid.set_status_at_node_on_edges(right=grid.BC_NODE_IS_FIXED_GRADIENT)
    >>> grid.set_status_at_node_on_edges(top=grid.BC_NODE_IS_CLOSED)
    >>> grid.status_at_node.reshape(grid.shape)
    array([[1, 1, 1, 2],
           [1, 0, 0, 2],
           [4, 4, 4, 4]], dtype=uint8)

    An example that sets all of the edges shows how corners are set.

    >>> grid.set_status_at_node_on_edges(right=1, top=2, left=3, bottom=4)
    >>> grid.status_at_node.reshape(grid.shape)
    array([[3, 4, 4, 4],
           [3, 0, 0, 1],
           [2, 2, 2, 1]], dtype=uint8)

    :meta landlab: boundary-condition
    """
    status_at_edge = (
        ("bottom", bottom),
        ("left", left),
        ("top", top),
        ("right", right),
    )

    for edge, val in status_at_edge:
        if val is not None:
            nodes = grid.nodes_at_edge(edge)
            grid.status_at_node[nodes] = val

    if right is not None and bottom is not None:
        lr = grid.nodes_at_right_edge[0]
        grid.status_at_node[lr] = bottom



================================================
File: src/landlab/grid/voronoi.py
================================================
#! /usr/env/python
"""Python implementation of VoronoiDelaunayGrid, a class used to create and
manage unstructured, irregular grids for 2D numerical models.
"""
import pathlib

import numpy as np

from ..graph import DualVoronoiGraph
from .base import ModelGrid


def simple_poly_area(x, y):
    """Calculates and returns the area of a 2-D simple polygon.

    Input vertices must be in sequence (clockwise or counterclockwise). *x*
    and *y* are arrays that give the x- and y-axis coordinates of the
    polygon's vertices.

    Parameters
    ----------
    x : ndarray
        x-coordinates of of polygon vertices.
    y : ndarray
        y-coordinates of of polygon vertices.

    Returns
    -------
    out : float
        Area of the polygon

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.grid.voronoi import simple_poly_area
    >>> x = np.array([3.0, 1.0, 1.0, 3.0])
    >>> y = np.array([1.5, 1.5, 0.5, 0.5])
    >>> simple_poly_area(x, y)
    2.0

    If the input coordinate arrays are 2D, calculate the area of each polygon.
    Note that when used in this mode, all polygons must have the same
    number of vertices, and polygon vertices are listed column-by-column.

    >>> x = np.array([[3.0, 1.0, 1.0, 3.0], [-2.0, -2.0, -1.0, -1.0]]).T
    >>> y = np.array([[1.5, 1.5, 0.5, 0.5], [0.0, 1.0, 2.0, 0.0]]).T
    >>> simple_poly_area(x, y)
    array([2. ,  1.5])
    """
    # For short arrays (less than about 100 elements) it seems that the
    # Python sum is faster than the numpy sum. Likewise for the Python
    # built-in abs.
    return 0.5 * abs(sum(x[:-1] * y[1:] - x[1:] * y[:-1]) + x[-1] * y[0] - x[0] * y[-1])


class VoronoiDelaunayGrid(DualVoronoiGraph, ModelGrid):
    """This inherited class implements an unstructured grid in which cells are
    Voronoi polygons and nodes are connected by a Delaunay triangulation. Uses
    scipy.spatial module to build the triangulation.

    Create an unstructured grid from points whose coordinates are given
    by the arrays *x*, *y*.

    Returns
    -------
    VoronoiDelaunayGrid
        A newly-created grid.

    Examples
    --------
    >>> import numpy as np
    >>> from numpy.random import rand
    >>> from landlab.grid import VoronoiDelaunayGrid

    >>> x, y = rand(25), rand(25)
    >>> vmg = VoronoiDelaunayGrid(x, y)  # node_x_coords, node_y_coords
    >>> vmg.number_of_nodes
    25

    >>> x = np.array(
    ...     [
    ...         [0, 0.1, 0.2, 0.3],
    ...         [1, 1.1, 1.2, 1.3],
    ...         [2, 2.1, 2.2, 2.3],
    ...     ]
    ... ).flatten()
    >>> y = np.array(
    ...     [
    ...         [0.0, 1.0, 2.0, 3.0],
    ...         [0.0, 1.0, 2.0, 3.0],
    ...         [0.0, 1.0, 2.0, 3.0],
    ...     ]
    ... ).flatten()

    >>> vmg = VoronoiDelaunayGrid(x, y)
    >>> vmg.node_x
    array([0. ,  1. ,  2. ,
           0.1,  1.1,  2.1,
           0.2,  1.2,  2.2,
           0.3,  1.3,  2.3])
    >>> vmg.node_y
    array([0.,  0.,  0.,
           1.,  1.,  1.,
           2.,  2.,  2.,
           3.,  3.,  3.])
    >>> vmg.adjacent_nodes_at_node
    array([[ 1,  3, -1, -1, -1, -1],
           [ 2,  4,  3,  0, -1, -1],
           [ 5,  4,  1, -1, -1, -1],
           [ 4,  6,  0,  1, -1, -1],
           [ 5,  7,  6,  3,  1,  2],
           [ 8,  7,  4,  2, -1, -1],
           [ 7,  9,  3,  4, -1, -1],
           [ 8, 10,  9,  6,  4,  5],
           [11, 10,  7,  5, -1, -1],
           [10,  6,  7, -1, -1, -1],
           [11,  9,  7,  8, -1, -1],
           [10,  8, -1, -1, -1, -1]])
    """

    def __init__(
        self,
        x=None,
        y=None,
        reorient_links=True,
        xy_of_reference=(0.0, 0.0),
        xy_axis_name=("x", "y"),
        xy_axis_units="-",
    ):
        """Create a Voronoi Delaunay grid from a set of points.

        Create an unstructured grid from points whose coordinates are given
        by the arrays *x*, *y*.

        Parameters
        ----------
        x : array_like
            x-coordinate of points
        y : array_like
            y-coordinate of points
        reorient_links (optional) : bool
            whether to point all links to the upper-right quadrant
        xy_of_reference : tuple, optional
            Coordinate value in projected space of (0., 0.)
            Default is (0., 0.)

        Returns
        -------
        VoronoiDelaunayGrid
            A newly-created grid.

        Examples
        --------
        >>> from numpy.random import rand
        >>> from landlab.grid import VoronoiDelaunayGrid
        >>> x, y = rand(25), rand(25)
        >>> vmg = VoronoiDelaunayGrid(x, y)  # node_x_coords, node_y_coords
        >>> vmg.number_of_nodes
        25
        """
        DualVoronoiGraph.__init__(self, (y, x), sort=True)
        ModelGrid.__init__(
            self,
            xy_axis_name=xy_axis_name,
            xy_axis_units=xy_axis_units,
            xy_of_reference=xy_of_reference,
        )

        self._node_status = np.full(
            self.number_of_nodes, self.BC_NODE_IS_CORE, dtype=np.uint8
        )
        self._node_status[self.perimeter_nodes] = self.BC_NODE_IS_FIXED_VALUE

        # DualVoronoiGraph.__init__(self, (y, x), **kwds)
        # ModelGrid.__init__(self, **kwds)

    @classmethod
    def from_dict(cls, kwds):
        args = (kwds.pop("x"), kwds.pop("y"))
        return cls(*args, **kwds)

    def save(self, path, clobber=False):
        """Save a grid and fields.

        This method uses pickle to save a Voronoi grid as a pickle file.
        At the time of coding, this is the only convenient output format
        for Voronoi grids, but support for netCDF is likely coming.

        All fields will be saved, along with the grid.

        The recommended suffix for the save file is '.grid'. This will
        be added to your save if you don't include it.

        This method is equivalent to
        :py:func:`~landlab.io.native_landlab.save_grid`, and
        :py:func:`~landlab.io.native_landlab.load_grid` can be used to
        load these files.

        Caution: Pickling can be slow, and can produce very large files.
        Caution 2: Future updates to Landlab could potentially render old
        saves unloadable.

        Parameters
        ----------
        path : str
            Path to output file.
        clobber : bool (defaults to false)
            Set to true to allow overwriting

        Returns
        -------
        str
            The name of the saved file (with the ".grid" extension).

        Examples
        --------
        >>> from landlab import VoronoiDelaunayGrid
        >>> import numpy as np

        >>> grid = VoronoiDelaunayGrid(np.random.rand(20), np.random.rand(20))
        >>> grid.save("mytestsave.grid")  # doctest: +SKIP
        'mytestsave.grid'

        :meta landlab: info-grid
        """
        import pickle

        path = pathlib.Path(path)

        if path.suffix != ".grid":
            path = path.with_suffix(path.suffix + ".grid")

        if path.exists() and not clobber:
            raise ValueError(
                f"File exists: {str(path)!r}. "
                "Either remove this file and try again or set the "
                "'clobber' keyword to True"
            )

        with open(path, "wb") as fp:
            pickle.dump(self, fp)

        return str(path)



================================================
File: src/landlab/grid/warnings.py
================================================
import os

from ..core.messages import deprecation_message


class DeprecatedSignature(DeprecationWarning):
    msg = "You are using a deprecated calling signature."

    def __init__(self, name, old=None, new=None):
        self._name = name
        self._old = old
        self._new = new

        if old:
            self._old = self._construct_call(name, self._old[0], self._old[1])
        if new:
            self._new = self._construct_call(name, self._new[0], self._new[1])

    @staticmethod
    def _construct_call(name, args, kwds):
        signature = ", ".join(
            [repr(arg) for arg in args] + [f"{k}={repr(v)}" for k, v in kwds.items()]
        )
        return f"{name}({signature})"

    def __str__(self):
        if self._new:
            use = f">>> grid = {self._new}"
        else:
            use = None

        return os.linesep + deprecation_message(self.msg, use=use)



================================================
File: src/landlab/grid/ext/raster_divergence.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused float_or_int:
    cython.integral
    long long
    cython.floating


@cython.boundscheck(False)
@cython.wraparound(False)
def _calc_flux_div_at_node(
    shape,
    xy_spacing,
    const float_or_int[:] value_at_link,
    cython.floating[:] out,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef double dx = xy_spacing[0]
    cdef double dy = xy_spacing[1]
    cdef int links_per_row = 2 * n_cols - 1
    cdef double inv_area_of_cell = 1.0 / (dx * dy)
    cdef int row, col
    cdef int node, link

    for row in prange(1, n_rows - 1, nogil=True, schedule="static"):
        node = row * n_cols
        link = row * links_per_row

        for col in range(1, n_cols - 1):
            out[node + col] = (
                dy * (value_at_link[link + 1] - value_at_link[link])
                + dx * (value_at_link[link + n_cols] - value_at_link[link - n_cols + 1])
            ) * inv_area_of_cell
            link = link + 1


@cython.boundscheck(False)
@cython.wraparound(False)
def _calc_net_face_flux_at_cell(
    shape,
    xy_spacing,
    const float_or_int[:] unit_flux_at_face,
    cython.floating[:] out,
):
    cdef double dx = xy_spacing[0]
    cdef double dy = xy_spacing[1]
    cdef int n_cols = shape[1] - 2
    cdef int n_rows = shape[0] - 2
    cdef int n_cells = n_rows * n_cols
    cdef int cell
    cdef int col
    cdef int face
    cdef int row

    for cell in prange(n_cells, nogil=True, schedule="static"):
        out[cell] = 0.0

    for row in prange(n_rows, nogil=True, schedule="static"):
        cell = row * n_cols
        face = n_cols + row * (2 * n_cols + 1)

        for col in range(n_cols):
            out[cell + col] = dy * (
                unit_flux_at_face[face] - unit_flux_at_face[face + 1]
            ) + dx * (
                unit_flux_at_face[face - n_cols] - unit_flux_at_face[face + n_cols + 1]
            )
            face = face + 1



================================================
File: src/landlab/grid/ext/raster_gradient.pyx
================================================
cimport cython
from cython.parallel cimport prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused float_or_int:
    cython.integral
    long long
    cython.floating


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_diff_at_link(
    shape,
    const float_or_int[:] value_at_node,
    cython.floating[:] out,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef int row, col
    cdef int link, node
    cdef int n_links = (2 * n_cols - 1) * n_rows - n_cols
    cdef int links_per_row = 2 * n_cols - 1

    for row in prange(0, n_rows - 1, nogil=True, schedule="static"):
        # Horizontal links
        link = row * links_per_row
        node = row * n_cols
        for col in range(n_cols - 1):
            out[link + col] = value_at_node[node + 1] - value_at_node[node]
            node = node + 1

        # Vertical links
        node = row * n_cols
        for col in range(n_cols - 1, links_per_row):
            out[link + col] = value_at_node[node + n_cols] - value_at_node[node]
            node = node + 1

    # The last row of horizontal links
    node = (n_rows - 1) * n_cols
    for link in range((n_rows - 1) * links_per_row, n_links):
        out[link] = value_at_node[node + 1] - value_at_node[node]
        node = node + 1


@cython.boundscheck(False)
@cython.wraparound(False)
def calc_grad_at_link(
    shape,
    xy_spacing,
    const float_or_int[:] value_at_node,
    cython.floating[:] out,
):
    cdef int n_rows = shape[0]
    cdef int n_cols = shape[1]
    cdef double dx = xy_spacing[0]
    cdef double dy = xy_spacing[1]

    cdef int row, col
    cdef int link, node
    cdef int n_links = (2 * n_cols - 1) * n_rows - n_cols
    cdef int links_per_row = 2 * n_cols - 1
    cdef double inv_dx = 1.0 / dx
    cdef double inv_dy = 1.0 / dy

    for row in prange(0, n_rows - 1, nogil=True, schedule="static"):
        # Horizontal links
        link = row * links_per_row
        node = row * n_cols
        for col in range(n_cols - 1):
            out[link + col] = (value_at_node[node + 1] - value_at_node[node]) * inv_dx
            node = node + 1

        # Vertical links
        node = row * n_cols
        for col in range(n_cols - 1, links_per_row):
            out[link + col] = inv_dy * (
                value_at_node[node + n_cols] - value_at_node[node]
            )
            node = node + 1

    # The last row of horizontal links
    node = (n_rows - 1) * n_cols
    for link in range((n_rows - 1) * links_per_row, n_links):
        out[link] = (value_at_node[node + 1] - value_at_node[node]) * inv_dx
        node = node + 1



================================================
File: src/landlab/grid/unstructured/__init__.py
================================================



================================================
File: src/landlab/grid/unstructured/base.py
================================================
import numpy as np

from .cells import CellGrid
from .links import LinkGrid
from .links import _split_link_ends
from .links import find_active_links
from .nodes import NodeGrid
from .status import StatusGrid


def _default_axis_names(n_dims):
    """Returns a tuple of the default axis names."""
    _DEFAULT_NAMES = ("z", "y", "x")
    return _DEFAULT_NAMES[-n_dims:]


def _default_axis_units(n_dims):
    """Returns a tuple of the default axis units."""
    return ("-",) * n_dims


class BaseGrid:
    """__init__([coord0, coord1, ...], axis_name=None, axis_units=None)

    Parameters
    ----------
    coord0, coord1, ... : sequence of array-like
        Coordinates of grid nodes
    axis_name : sequence of strings, optional
        Names of coordinate axes
    axis_units : sequence of strings, optional
        Units of coordinate axes

    Returns
    -------
    BaseGrid :
        A newly-created BaseGrid

    Examples
    --------
    >>> from landlab.grid.unstructured.base import BaseGrid
    >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
    >>> ngrid.number_of_nodes
    4
    >>> ngrid.x_at_node
    array([0.,  1.,  0.,  1.])
    >>> ngrid.x_at_node[2]
    0.0
    >>> ngrid.point_at_node[2]
    array([1.,  0.])
    >>> ngrid.coord_at_node[:, [2, 3]]
    array([[1.,  1.],
           [0.,  1.]])

    >>> cells = ([0, 1, 2, 1, 3, 2], [3, 3], [0, 1])
    >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]), cells=cells)
    >>> ngrid.number_of_cells
    2
    >>> ngrid.node_at_cell
    array([0, 1])

    >>> links = [(0, 2), (1, 3), (0, 1), (1, 2), (0, 3)]
    >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]), links=zip(*links))
    >>> ngrid.number_of_links
    5
    >>> ngrid.links_leaving_at_node(0)
    array([0, 2, 4])
    >>> len(ngrid.links_entering_at_node(0)) == 0
    True

    >>> tails, heads = zip(*links)
    >>> grid = BaseGrid(
    ...     ([0, 0, 1, 1], [0, 1, 0, 1]), node_status=[0, 0, 0, 4], links=[tails, heads]
    ... )
    >>> grid.status_at_node
    array([0, 0, 0, 4])
    >>> len(grid.active_links_entering_at_node(0)) == 0
    True
    >>> grid.active_links_leaving_at_node(0)
    array([0, 2])
    """

    def __init__(
        self,
        nodes,
        axis_name=None,
        axis_units=None,
        node_status=None,
        links=None,
        cells=None,
    ):
        """__init__([coord0, coord1, ...], axis_name=None, axis_units=None)

        Parameters
        ----------
        coord0, coord1, ... : sequence of array-like
            Coordinates of grid nodes
        axis_name : sequence of strings, optional
            Names of coordinate axes
        axis_units : sequence of strings, optional
            Units of coordinate axes

        Returns
        -------
        BaseGrid :
            A newly-created BaseGrid

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
        >>> ngrid.number_of_nodes
        4
        >>> ngrid.x_at_node
        array([0.,  1.,  0.,  1.])
        >>> ngrid.x_at_node[2]
        0.0
        >>> ngrid.point_at_node[2]
        array([1.,  0.])
        >>> ngrid.coord_at_node[:, [2, 3]]
        array([[1.,  1.],
               [0.,  1.]])

        >>> cells = ([0, 1, 2, 1, 3, 2], [3, 3], [0, 1])
        >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]), cells=cells)
        >>> ngrid.number_of_cells
        2
        >>> ngrid.node_at_cell
        array([0, 1])

        >>> links = [(0, 2), (1, 3), (0, 1), (1, 2), (0, 3)]
        >>> ngrid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]), links=zip(*links))
        >>> ngrid.number_of_links
        5
        >>> ngrid.links_leaving_at_node(0)
        array([0, 2, 4])
        >>> len(ngrid.links_entering_at_node(0)) == 0
        True

        >>> tails, heads = zip(*links)
        >>> grid = BaseGrid(
        ...     ([0, 0, 1, 1], [0, 1, 0, 1]),
        ...     node_status=[0, 0, 0, 4],
        ...     links=[tails, heads],
        ... )
        >>> grid.status_at_node
        array([0, 0, 0, 4])
        >>> len(grid.active_links_entering_at_node(0)) == 0
        True
        >>> grid.active_links_leaving_at_node(0)
        array([0, 2])
        """
        self._node_grid = NodeGrid(nodes)

        self._axis_name = tuple(axis_name or _default_axis_names(self.ndim))
        self._axis_units = tuple(axis_units or _default_axis_units(self.ndim))

        if cells is not None:
            try:
                self._cell_grid = CellGrid(*cells)
            except TypeError:
                self._cell_grid = cells

        if links is not None:
            try:
                self._link_grid = LinkGrid(links, self.number_of_nodes)
            except TypeError:
                self._link_grid = links

        if node_status is not None:
            self._status_grid = StatusGrid(node_status)

        if links is not None and node_status is not None:
            links = _split_link_ends(links)
            self._active_link_grid = BaseGrid.create_active_link_grid(
                self.status_at_node, links, self.number_of_nodes
            )

    @staticmethod
    def create_active_link_grid(node_status, links, number_of_nodes):
        active_link_ids = find_active_links(node_status, links)
        return LinkGrid(
            (links[0][active_link_ids], links[1][active_link_ids]),
            number_of_nodes,
            link_ids=active_link_ids,
        )

    @property
    def ndim(self):
        return self._node_grid.ndim

    @property
    def axis_units(self):
        """Coordinate units of each axis.

        Returns
        -------
        tuple of strings :
            Coordinate units of each axis.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> ngrid = BaseGrid(([0, 1, 0], [1, 1, 0]))
        >>> ngrid.axis_units
        ('-', '-')

        >>> ngrid = BaseGrid(
        ...     ([0, 1, 0], [1, 1, 0]), axis_units=["degrees_north", "degrees_east"]
        ... )
        >>> ngrid.axis_units
        ('degrees_north', 'degrees_east')
        """
        return self._axis_units

    @property
    def axis_name(self):
        """Name of each axis.

        Returns
        -------
        tuple of strings :
            Names of each axis.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> ngrid = BaseGrid(([0, 1, 0], [1, 1, 0]))
        >>> ngrid.axis_name
        ('y', 'x')

        >>> ngrid = BaseGrid(([0, 1, 0], [1, 1, 0]), axis_name=["lat", "lon"])
        >>> ngrid.axis_name
        ('lat', 'lon')
        """
        return self._axis_name

    @property
    def number_of_links(self):
        """Number of links."""
        return self._link_grid.number_of_links

    @property
    def number_of_cells(self):
        """Number of cells."""
        return self._cell_grid.number_of_cells

    @property
    def number_of_nodes(self):
        """Number of nodes."""
        return self._node_grid.number_of_nodes

    @property
    def coord_at_node(self):
        return self._node_grid.coord

    @property
    def x_at_node(self):
        return self._node_grid.x

    @property
    def y_at_node(self):
        return self._node_grid.y

    @property
    def point_at_node(self):
        return self._node_grid.point

    def links_leaving_at_node(self, node):
        return self._link_grid.out_link_at_node(node)

    def links_entering_at_node(self, node):
        return self._link_grid.in_link_at_node(node)

    def active_links_leaving_at_node(self, node):
        return self._active_link_grid.out_link_at_node(node)

    def active_links_entering_at_node(self, node):
        return self._active_link_grid.in_link_at_node(node)

    @property
    def node_at_link_start(self):
        return self._link_grid.node_at_link_start

    @property
    def node_at_link_end(self):
        return self._link_grid.node_at_link_end

    @property
    def node_at_cell(self):
        return self._cell_grid.node_at_cell

    @property
    def cell_at_node(self):
        return self._cell_grid.cell_at_node

    def core_cells(self):
        return self.cell_at_node[self.core_nodes]

    @property
    def status_at_node(self):
        return self._status_grid.node_status

    @status_at_node.setter
    def status_at_node(self, status):
        self._status_grid.node_status = status
        self._active_link_grid = BaseGrid.create_active_link_grid(
            self.status_at_node,
            (self.node_at_link_start, self.node_at_link_end),
            self.number_of_nodes,
        )

    def active_nodes(self):
        return self._status_grid.active_nodes()

    def core_nodes(self):
        return self._status_grid.core_nodes()

    def boundary_nodes(self):
        return self._status_grid.boundary_nodes()

    def closed_boundary_nodes(self):
        return self._status_grid.closed_boundary_nodes()

    def fixed_gradient_boundary_nodes(self):
        return self._status_grid.fixed_gradient_boundary_nodes()

    def fixed_value_boundary_nodes(self):
        return self._status_grid.fixed_value_boundary_nodes()

    def active_links(self):
        return self._active_link_grid.link_id

    def length_of_link(self, link=None):
        """Length of grid links.

        Parameters
        ----------
        link : array-like, optional
            Link IDs

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> links = [(0, 2), (1, 3), (0, 1), (2, 3), (0, 3)]
        >>> grid = BaseGrid(([0, 0, 4, 4], [0, 3, 0, 3]), links=links)
        >>> grid.length_of_link()
        array([4.,  4.,  3.,  3.,  5.])
        >>> grid.length_of_link(0)
        array([4.])

        >>> grid.length_of_link().min()
        3.0
        >>> grid.length_of_link().max()
        5.0
        """
        if link is None:
            node0, node1 = (self.node_at_link_start, self.node_at_link_end)
        else:
            node0, node1 = (self.node_at_link_start[link], self.node_at_link_end[link])

        return self.node_to_node_distance(node0, node1)

    def node_to_node_distance(self, node0, node1, out=None):
        """Distance between nodes.

        Parameters
        ----------
        node0 : array-like
            Node ID of start
        node1 : array-like
            Node ID of end

        Returns
        -------
        array :
            Distances between nodes.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> grid = BaseGrid(([0, 0, 4, 4], [0, 3, 0, 3]))
        >>> grid.node_to_node_distance(0, 3)
        array([5.])
        >>> grid.node_to_node_distance(0, [0, 1, 2, 3])
        array([0.,  3.,  4.,  5.])
        """
        return point_to_point_distance(
            self._get_coord_at_node(node0), self._get_coord_at_node(node1), out=out
        )

        node0, node1 = np.broadcast_arrays(node0, node1)
        return np.sqrt(
            np.sum(
                (self.coord_at_node[:, node1] - self.coord_at_node[:, node0]) ** 2,
                axis=0,
            )
        )

    def point_to_node_distance(self, point, node=None, out=None):
        """Distance from a point to a node.

        Parameters
        ----------
        point : tuple
            Coordinates of point
        node : array-like
            Node IDs

        Returns
        -------
        array :
            Distances from point to node.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> grid = BaseGrid(([0, 0, 4, 4], [0, 3, 0, 3]))
        >>> grid.point_to_node_distance((0.0, 0.0), [1, 2, 3])
        array([3.,  4.,  5.])
        >>> grid.point_to_node_distance((0.0, 0.0))
        array([0.,  3.,  4.,  5.])
        >>> out = np.empty(4)
        >>> out is grid.point_to_node_distance((0.0, 0.0), out=out)
        True
        >>> out
        array([0.,  3.,  4.,  5.])
        """
        return point_to_point_distance(point, self._get_coord_at_node(node), out=out)

    def point_to_node_angle(self, point, node=None, out=None):
        """Angle from a point to a node.

        Parameters
        ----------
        point : tuple
            Coordinates of point
        node : array-like
            Node IDs

        Returns
        -------
        array :
            Angles from point to node as radians.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> grid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
        >>> grid.point_to_node_angle((0.0, 0.0), [1, 2, 3]) / np.pi
        array([0.  ,  0.5 ,  0.25])
        >>> grid.point_to_node_angle((0.0, 0.0)) / np.pi
        array([0.  ,  0.  ,  0.5 ,  0.25])
        >>> out = np.empty(4)
        >>> out is grid.point_to_node_angle((0.0, 0.0), out=out)
        True
        >>> out / np.pi
        array([0.  ,  0.  ,  0.5 ,  0.25])
        """
        return point_to_point_angle(point, self._get_coord_at_node(node), out=out)

    def point_to_node_azimuth(self, point, node=None, out=None):
        """Azimuth from a point to a node.

        Parameters
        ----------
        point : tuple
            Coordinates of point
        node : array-like
            Node IDs

        Returns
        -------
        array :
            Azimuths from point to node.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> grid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
        >>> grid.point_to_node_azimuth((0.0, 0.0), [1, 2, 3])
        array([90.,   0.,  45.])
        >>> grid.point_to_node_azimuth((0.0, 0.0))
        array([90.,  90.,   0.,  45.])
        >>> grid.point_to_node_azimuth((0.0, 0.0), 1)
        array([90.])
        >>> out = np.empty(4)
        >>> out is grid.point_to_node_azimuth((0.0, 0.0), out=out)
        True
        >>> out
        array([90.,  90.,   0.,  45.])
        """
        return point_to_point_azimuth(point, self._get_coord_at_node(node), out=out)

    def point_to_node_vector(self, point, node=None, out=None):
        """Azimuth from a point to a node.

        Parameters
        ----------
        point : tuple
            Coordinates of point
        node : array-like
            Node IDs

        Returns
        -------
        array :
            Vector from point to node.

        Examples
        --------
        >>> from landlab.grid.unstructured.base import BaseGrid
        >>> grid = BaseGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
        >>> grid.point_to_node_vector((0.0, 0.0), [1, 2, 3])
        array([[0.,  1.,  1.],
               [1.,  0.,  1.]])
        >>> grid.point_to_node_vector((0.0, 0.0))
        array([[0.,  0.,  1.,  1.],
               [0.,  1.,  0.,  1.]])
        >>> grid.point_to_node_vector((0.0, 0.0), 1)
        array([[0.],
               [1.]])
        >>> out = np.empty((2, 1))
        >>> out is grid.point_to_node_vector((0.0, 0.0), 1, out=out)
        True
        >>> out
        array([[0.],
               [1.]])
        """
        return point_to_point_vector(point, self._get_coord_at_node(node), out=out)

    def _get_coord_at_node(self, node=None):
        if node is None:
            return self.coord_at_node
        else:
            return self.coord_at_node[:, node].reshape((2, -1))


def point_to_point_distance(point0, point1, out=None):
    """Length of vector that joins two points.

    Parameters
    ----------
    (y0, x0) : tuple of array_like
    (y1, x1) : tuple of array_like
    out : array_like, optional
        An array to store the output. Must be the same shape as the output
        would have.

    Returns
    -------
    l : array_like
        Length of vector joining points; if *out* is provided, *v* will be
        equal to *out*.

    Examples
    --------
    >>> from landlab.grid.unstructured.base import point_to_point_distance
    >>> point_to_point_distance((0, 0), (3, 4))
    array([5.])
    >>> point_to_point_distance((0, 0), ([3, 6], [4, 8]))
    array([ 5.,  10.])
    """
    point0 = np.reshape(point0, (2, -1))
    point1 = np.reshape(point1, (2, -1))
    if out is None:
        sum_of_squares = np.sum((point1 - point0) ** 2.0, axis=0)
        return np.sqrt(sum_of_squares)
    else:
        sum_of_squares = np.sum((point1 - point0) ** 2.0, axis=0, out=out)
        return np.sqrt(sum_of_squares, out=out)


def point_to_point_angle(point0, point1, out=None):
    """Angle of vector that joins two points.

    Parameters
    ----------
    (y0, x0) : tuple of array_like
    (y1, x1) : tuple of array_like
    out : array_like, optional
        An array to store the output. Must be the same shape as the output
        would have.

    Returns
    -------
    a : array_like
        Angle of vector joining points; if *out* is provided, *v* will be equal
        to *out*.
    """
    point0 = np.reshape(point0, (-1, 1))
    diff = point_to_point_vector(point0, point1)
    if out is None:
        return np.arctan2(diff[0], diff[1])
    else:
        return np.arctan2(diff[0], diff[1], out=out)


def point_to_point_azimuth(point0, point1, out=None):
    """Azimuth of vector that joins two points.

    Parameters
    ----------
    (y0, x0) : tuple of array_like
    (y1, x1) : tuple of array_like
    out : array_like, optional
        An array to store the output. Must be the same shape as the output
        would have.

    Returns
    -------
    azimuth : array_like
        Azimuth of vector joining points; if *out* is provided, *v* will be
        equal to *out*.

    Examples
    --------
    >>> from landlab.grid.unstructured.base import point_to_point_azimuth
    >>> point_to_point_azimuth((0, 0), (1, 0))
    array([0.])
    >>> point_to_point_azimuth([(0, 1), (0, 1)], (1, 0))
    array([ 0., -90.])
    >>> point_to_point_azimuth([(0, 1, 0), (0, 1, 2)], [(1, 1, 2), (0, 0, 4)])
    array([ 0., -90.,  45.])
    """
    azimuth_in_rads = point_to_point_angle(point0, point1, out=out)
    if out is None:
        return (np.pi * 0.5 - azimuth_in_rads) * 180.0 / np.pi
    else:
        np.subtract(np.pi * 0.5, azimuth_in_rads, out=out)
        return np.multiply(out, 180.0 / np.pi, out=out)


def point_to_point_vector(point0, point1, out=None):
    """Vector that joins two points.

    Parameters
    ----------
    (y0, x0) : tuple of array_like
    (y1, x1) : tuple of array_like
    out : array_like, optional
        An array to store the output. Must be the same shape as the output
        would have.

    Returns
    -------
    (dy, dx) : tuple of array_like
        Vectors between points; if *out* is provided, *v* will be equal to
        *out*.

    Examples
    --------
    >>> from landlab.grid.unstructured.base import point_to_point_vector
    >>> point_to_point_vector((0, 0), (1, 2))
    array([[1],
           [2]])
    >>> point_to_point_vector([(0, 1), (0, 1)], (1, 2))
    array([[1, 0],
           [2, 1]])
    >>> point_to_point_vector([(0, 0, 0), (0, 1, 2)], [(1, 2, 2), (2, 4, 4)])
    array([[1, 2, 2],
           [2, 3, 2]])
    """
    point0 = np.reshape(point0, (2, -1))
    point1 = np.reshape(point1, (2, -1))

    if out is None:
        return np.subtract(point1, point0)
    else:
        return np.subtract(point1, point0, out=out)



================================================
File: src/landlab/grid/unstructured/cells.py
================================================
import numpy as np

from ...utils.jaggedarray import JaggedArray


class CellGrid:
    """
    Parameters
    ----------
    vertices : array-like
        Vertex IDs at each grid cell
    vertices_per_cell : array-like
        Number of vertices per grid cell

    Returns
    -------
    CellGrid :
        A newly-created CellGrid

    Examples
    --------
    Create a grid of two cells where the first cell has four vertices and
    the second has three.

    >>> from landlab.grid.unstructured.cells import CellGrid
    >>> cgrid = CellGrid([0, 1, 3, 2, 1, 4, 3], [4, 3])
    >>> cgrid.number_of_cells
    2
    >>> cgrid.number_of_vertices_at_cell(0)
    4
    >>> cgrid.number_of_vertices_at_cell(1)
    3
    >>> cgrid.vertices_at_cell(0)
    array([0, 1, 3, 2])
    >>> cgrid.vertices_at_cell(1)
    array([1, 4, 3])

    Associate nodes with each cell.

    >>> cgrid = CellGrid([0, 1, 2, 3, 1, 3, 4], [4, 3], node_at_cell=[10, 11])
    >>> cgrid.node_at_cell
    array([10, 11])
    >>> cgrid.cell_at_node[10]
    0
    >>> cgrid.cell_at_node[11]
    1
    """

    def __init__(self, vertices, vertices_per_cell, node_at_cell=None):
        """
        Parameters
        ----------
        vertices : array-like
            Vertex IDs at each grid cell
        vertices_per_cell : array-like
            Number of vertices per grid cell

        Returns
        -------
        CellGrid :
            A newly-created CellGrid

        Examples
        --------
        Create a grid of two cells where the first cell has four vertices and
        the second has three.

        >>> from landlab.grid.unstructured.cells import CellGrid
        >>> cgrid = CellGrid([0, 1, 3, 2, 1, 4, 3], [4, 3])
        >>> cgrid.number_of_cells
        2
        >>> cgrid.number_of_vertices_at_cell(0)
        4
        >>> cgrid.number_of_vertices_at_cell(1)
        3
        >>> cgrid.vertices_at_cell(0)
        array([0, 1, 3, 2])
        >>> cgrid.vertices_at_cell(1)
        array([1, 4, 3])

        Associate nodes with each cell.

        >>> cgrid = CellGrid([0, 1, 2, 3, 1, 3, 4], [4, 3], node_at_cell=[10, 11])
        >>> cgrid.node_at_cell
        array([10, 11])
        >>> cgrid.cell_at_node[10]
        0
        >>> cgrid.cell_at_node[11]
        1
        """
        self._vertices_at_cell = JaggedArray(vertices, vertices_per_cell)
        self._number_of_cells = len(vertices_per_cell)

        if node_at_cell:
            self._node_at_cell = np.array(node_at_cell)
            self._cell_at_node = np.ma.masked_all(max(node_at_cell) + 1, dtype=int)
            self._cell_at_node[self._node_at_cell] = range(len(node_at_cell))
            # self._cell_id_map = dict(zip(node_at_cell, range(len(node_at_cell))))

    @property
    def number_of_cells(self):
        return self._number_of_cells

    @property
    def node_at_cell(self):
        return self._node_at_cell

    @property
    def cell_at_node(self):
        return self._cell_at_node

    def number_of_vertices_at_cell(self, cell):
        return self._vertices_at_cell.length_of_row(cell)

    def vertices_at_cell(self, cell):
        return self._vertices_at_cell.row(cell)

    def iter(self):
        """Iterate over the cells of the grid.

        Returns
        -------
        ndarray :
            Nodes entering and leaving each node
        """
        for cell in range(self.number_of_cells):
            yield self.vertices_at_cell(cell)

    @property
    def cell_id(self):
        try:
            return self._cell_ids
        except AttributeError:
            return np.arange(self.number_of_cells)

    def vertices_at_cell_id(self, cell_id):
        try:
            return self.vertices_at_cell(self._cell_id_map[cell_id])
        except AttributeError:
            return self.vertices_at_cell(cell_id)



================================================
File: src/landlab/grid/unstructured/links.py
================================================
import numpy as np

from ...core.utils import as_id_array
from ...utils.jaggedarray import JaggedArray
from ..nodestatus import NodeStatus


def _split_link_ends(link_ends):
    """
    Examples
    --------
    >>> from landlab.grid.unstructured.links import _split_link_ends
    >>> _split_link_ends(((0, 1, 2), (3, 4, 5)))
    (array([0, 1, 2]), array([3, 4, 5]))
    >>> _split_link_ends([(0, 3), (1, 4), (2, 5)])
    (array([0, 1, 2]), array([3, 4, 5]))
    >>> _split_link_ends((0, 3))
    (array([0]), array([3]))
    """
    links = np.array(list(link_ends), ndmin=2, dtype=int)
    if len(links) != 2:
        links = links.transpose()

    if links.size == 0:
        return (np.array([], dtype=int), np.array([], dtype=int))
    else:
        return links[0], links[1]


def link_is_active(status_at_link_ends):
    """link_is_active((status0, status1)) Check if a link is active.

    Links are *inactive* if they connect two boundary nodes or touch a
    closed boundary. Otherwise, the link is *active*.

    Parameters
    ----------
    status0, status1 : sequence of array-like
        Status at link start and end

    Returns
    -------
    ndarray, boolean :
        Boolean array that indicates if a link is active.
    """
    (status_at_link_start, status_at_link_end) = _split_link_ends(status_at_link_ends)

    return (
        (status_at_link_start == NodeStatus.CORE)
        & ~(status_at_link_end == NodeStatus.CLOSED)
    ) | (
        (status_at_link_end == NodeStatus.CORE)
        & ~(status_at_link_start == NodeStatus.CLOSED)
    )


def find_active_links(node_status, node_at_link_ends):
    """find_active_links(node_status, (node0, node1)) IDs of active links.

    Parameters
    ----------
    node_status : ndarray
        Status of nodes.
    node0, node1 : sequence of array-like
        Node ID at link start and end.

    Returns
    -------
    ndarray :
        Links IDs of active links.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import find_active_links
    >>> links = [(0, 2), (1, 3), (0, 1), (1, 2), (0, 3)]
    >>> status = np.array([0, 0, 0, 0])
    >>> find_active_links(status, links)
    array([0, 1, 2, 3, 4])
    """
    node_at_link_start, node_at_link_end = _split_link_ends(node_at_link_ends)

    if len(node_at_link_end) != len(node_at_link_start):
        raise ValueError("Link arrays must be the same length")

    status_at_link_ends = (
        node_status[node_at_link_start],
        node_status[node_at_link_end],
    )

    (active_link_ids,) = np.where(link_is_active(status_at_link_ends))

    return as_id_array(active_link_ids)


def in_link_count_per_node(node_at_link_ends, number_of_nodes=0):
    """in_link_count_per_node((node0, node1), number_of_nodes=0) Number of
    links entering nodes.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    ndarray :
        Number of links entering nodes.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import in_link_count_per_node
    >>> link_ends = [(0, 3), (1, 4), (2, 5), (3, 6), (4, 7), (5, 8)]
    >>> in_link_count_per_node(zip(*link_ends))
    array([0, 0, 0, 1, 1, 1, 1, 1, 1])
    """
    node_at_link_start, node_at_link_end = _split_link_ends(node_at_link_ends)

    # if len(node_at_link_end) != len(node_at_link_start):
    #    raise ValueError('Link arrays must be the same length')
    return as_id_array(np.bincount(node_at_link_end, minlength=number_of_nodes))


def out_link_count_per_node(node_at_link_ends, number_of_nodes=0):
    """out_link_count_per_node((node0, node1), number_of_nodes=0) Number of
    links leaving nodes.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    ndarray :
        Number of links leaving nodes.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import out_link_count_per_node
    >>> out_link_count_per_node(([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]))
    array([1, 1, 1, 1, 1, 1])
    >>> out_link_count_per_node(
    ...     ([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]), number_of_nodes=9
    ... )
    array([1, 1, 1, 1, 1, 1, 0, 0, 0])
    """
    node_at_link_start, node_at_link_end = _split_link_ends(node_at_link_ends)
    if len(node_at_link_end) != len(node_at_link_start):
        raise ValueError("Link arrays must be the same length")
    return as_id_array(np.bincount(node_at_link_start, minlength=number_of_nodes))


def link_count_per_node(node_at_link_ends, number_of_nodes=None):
    """link_count_per_node((node0, node1), number_of_nodes=None) Number of
    links per node.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    ndarray :
        Number of links per nodes.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import link_count_per_node
    >>> link_count_per_node(([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]))
    array([1, 1, 1, 2, 2, 2, 1, 1, 1])
    """
    in_count = in_link_count_per_node(node_at_link_ends)
    out_count = out_link_count_per_node(node_at_link_ends)

    node_count = number_of_nodes or max(len(in_count), len(out_count))

    if len(in_count) < node_count:
        in_count = np.pad(in_count, (0, node_count - len(in_count)), mode="constant")
    if len(out_count) < node_count:
        out_count = np.pad(out_count, (0, node_count - len(out_count)), mode="constant")

    return in_count + out_count


def _sort_links_by_node(node_at_link_ends, link_ids=None, sortby=0):
    sorted_links = np.argsort(node_at_link_ends[sortby], kind="stable")

    if link_ids is not None:
        return np.array(link_ids, dtype=int)[sorted_links]
    else:
        return as_id_array(sorted_links)


def in_link_ids_at_node(node_at_link_ends, link_ids=None, number_of_nodes=0):
    """in_link_ids_at_node((node0, node1), number_of_nodes=0) Links entering
    nodes.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    tuple :
        Tuple of link id array and offset into link id array.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import in_link_ids_at_node
    >>> (links, count) = in_link_ids_at_node(([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]))
    >>> links
    array([0, 1, 2, 3, 4, 5])
    >>> count
    array([0, 0, 0, 1, 1, 1, 1, 1, 1])


    >>> (links, count) = in_link_ids_at_node(
    ...     ([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]), link_ids=range(1, 7)
    ... )
    >>> links
    array([1, 2, 3, 4, 5, 6])
    >>> count
    array([0, 0, 0, 1, 1, 1, 1, 1, 1])
    """
    node_at_link_ends = _split_link_ends(node_at_link_ends)

    link_ids = _sort_links_by_node(node_at_link_ends, link_ids=link_ids, sortby=1)
    links_per_node = in_link_count_per_node(
        node_at_link_ends, number_of_nodes=number_of_nodes
    )
    return link_ids, links_per_node


def out_link_ids_at_node(node_at_link_ends, link_ids=None, number_of_nodes=None):
    """out_link_ids_at_node((node0, node1), number_of_nodes=None) Links leaving
    nodes.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    tuple :
        Tuple of link id array and offset into link id array.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import out_link_ids_at_node
    >>> (links, count) = out_link_ids_at_node(
    ...     ([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]),
    ...     link_ids=range(-1, 5),
    ...     number_of_nodes=9,
    ... )
    >>> links
    array([-1,  0,  1,  2,  3,  4])
    >>> count
    array([1, 1, 1, 1, 1, 1, 0, 0, 0])


    >>> (links, count) = out_link_ids_at_node(
    ...     ([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]), number_of_nodes=9
    ... )
    >>> links
    array([0, 1, 2, 3, 4, 5])
    >>> count
    array([1, 1, 1, 1, 1, 1, 0, 0, 0])
    """
    node_at_link_ends = _split_link_ends(node_at_link_ends)

    link_ids = _sort_links_by_node(node_at_link_ends, link_ids=link_ids, sortby=0)
    links_per_node = out_link_count_per_node(
        node_at_link_ends, number_of_nodes=number_of_nodes
    )
    return link_ids, links_per_node


def link_ids_at_node(node_at_link_ends, number_of_nodes=None):
    """link_ids_at_node((node0, node1), number_of_nodes=None) Links entering
    and leaving nodes.

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    tuple :
        Tuple of link id array and offset into link id array.

    Examples
    --------
    >>> from landlab.grid.unstructured.links import link_ids_at_node
    >>> (links, count) = link_ids_at_node(
    ...     ([0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]), number_of_nodes=9
    ... )
    >>> links
    array([0, 1, 2, 0, 3, 1, 4, 2, 5, 3, 4, 5])
    >>> count
    array([1, 1, 1, 2, 2, 2, 1, 1, 1])
    """
    links_per_node = link_count_per_node(
        node_at_link_ends, number_of_nodes=number_of_nodes
    )

    in_links = JaggedArray(
        *in_link_ids_at_node(node_at_link_ends, number_of_nodes=number_of_nodes)
    )
    out_links = JaggedArray(
        *out_link_ids_at_node(node_at_link_ends, number_of_nodes=number_of_nodes)
    )

    links = np.empty(in_links.size + out_links.size, dtype=int)

    offset = 0
    for node, link_count in enumerate(links_per_node):
        links[offset : offset + link_count] = np.concatenate(
            (in_links.row(node), out_links.row(node))
        )
        offset += link_count

    return links, links_per_node


class LinkGrid:
    """Create a grid of links that enter and leave nodes. __init__((node0,
    node1), number_of_nodes=None)

    Parameters
    ----------
    node0, node1 : sequence of array-like
        Node ID at link start and end.
    number_of_nodes : int, optional
        Number of nodes in the grid

    Returns
    -------
    LinkGrid :
        A newly-created grid

    Examples
    --------
    >>> from landlab.grid.unstructured.links import LinkGrid
    >>> lgrid = LinkGrid([(0, 1, 0, 2, 0), (2, 3, 1, 3, 3)], 4)
    >>> lgrid.number_of_links
    5
    >>> lgrid.number_of_nodes
    4
    >>> lgrid.number_of_in_links_at_node(0)
    0
    >>> lgrid.number_of_out_links_at_node(0)
    3
    >>> lgrid.out_link_at_node(0)
    array([0, 2, 4])
    >>> lgrid.nodes_at_link_id(1)
    array([1, 3])

    >>> lgrid = LinkGrid([(0, 1, 0, 2, 0), (2, 3, 1, 3, 3)], 4, link_ids=range(1, 6))
    >>> lgrid.nodes_at_link
    array([[0, 2],
           [1, 3],
           [0, 1],
           [2, 3],
           [0, 3]])
    >>> lgrid.out_link_at_node(0)
    array([1, 3, 5])
    >>> lgrid.nodes_at_link_id(1)
    array([0, 2])
    """

    def __init__(self, link_ends, number_of_nodes, link_ids=None, node_status=None):
        """Create a grid of links that enter and leave nodes. __init__((node0,
        node1), number_of_nodes=None)

        Parameters
        ----------
        node0, node1 : sequence of array-like
            Node ID at link start and end.
        number_of_nodes : int, optional
            Number of nodes in the grid

        Returns
        -------
        LinkGrid :
            A newly-created grid

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2, 0), (2, 3, 1, 3, 3)], 4)
        >>> lgrid.number_of_links
        5
        >>> lgrid.number_of_nodes
        4
        >>> lgrid.number_of_in_links_at_node(0)
        0
        >>> lgrid.number_of_out_links_at_node(0)
        3
        >>> lgrid.out_link_at_node(0)
        array([0, 2, 4])
        >>> lgrid.nodes_at_link_id(1)
        array([1, 3])

        >>> lgrid = LinkGrid(
        ...     [(0, 1, 0, 2, 0), (2, 3, 1, 3, 3)], 4, link_ids=range(1, 6)
        ... )
        >>> lgrid.nodes_at_link
        array([[0, 2],
               [1, 3],
               [0, 1],
               [2, 3],
               [0, 3]])
        >>> lgrid.out_link_at_node(0)
        array([1, 3, 5])
        >>> lgrid.nodes_at_link_id(1)
        array([0, 2])
        """
        link_ends = _split_link_ends(link_ends)

        self._in_link_at_node = JaggedArray(
            *in_link_ids_at_node(
                link_ends, link_ids=link_ids, number_of_nodes=number_of_nodes
            )
        )
        self._out_link_at_node = JaggedArray(
            *out_link_ids_at_node(
                link_ends, link_ids=link_ids, number_of_nodes=number_of_nodes
            )
        )
        self._link_ends = np.array(link_ends)
        if link_ids is not None:
            self._link_id_map = dict(zip(link_ids, range(len(link_ids))))
            self._link_ids = link_ids

        self._number_of_links = len(link_ends[0])
        self._number_of_nodes = number_of_nodes

        self._node_status = node_status

    @property
    def number_of_links(self):
        """Number of links in the grid."""
        return self._number_of_links

    @property
    def number_of_nodes(self):
        """Number of nodes in the grid."""
        return self._number_of_nodes

    def number_of_in_links_at_node(self, node):
        """Number of links entering a node.

        Parameters
        ----------
        node : int
            Node ID

        Returns
        -------
        int :
            Number of links entering the node.

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> [lgrid.number_of_in_links_at_node(node) for node in range(4)]
        [0, 1, 1, 2]
        """
        return self._in_link_at_node.length_of_row(node)

    def number_of_out_links_at_node(self, node):
        """Number of links leaving a node.

        Parameters
        ----------
        node : int
            Node ID

        Returns
        -------
        int :
            Number of links leaving the node.

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> [lgrid.number_of_out_links_at_node(node) for node in range(4)]
        [2, 1, 1, 0]
        """
        return self._out_link_at_node.length_of_row(node)

    def number_of_links_at_node(self, node):
        """Number of links entering and leaving a node.

        Parameters
        ----------
        node : int
            Node ID

        Returns
        -------
        int :
            Number of links entering and leaving the node.

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> [lgrid.number_of_links_at_node(node) for node in range(4)]
        [2, 2, 2, 2]
        """
        return self.number_of_in_links_at_node(node) + self.number_of_out_links_at_node(
            node
        )

    @property
    def node_at_link_start(self):
        return self._link_ends[0]

    @property
    def node_at_link_end(self):
        return self._link_ends[1]

    @property
    def nodes_at_link(self):
        return self._link_ends.T

    @property
    def link_id(self):
        try:
            return self._link_ids
        except AttributeError:
            return np.arange(self.number_of_links)

    def nodes_at_link_id(self, link_id):
        try:
            return self.nodes_at_link[self._link_id_map[link_id]]
        except AttributeError:
            return self.nodes_at_link[link_id]

    def in_link_at_node(self, node):
        """Links entering a node.

        Parameters
        ----------
        node : int
            Node ID

        Returns
        -------
        ndarray :
            Links entering the node

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> len(lgrid.in_link_at_node(0)) == 0
        True
        >>> lgrid.in_link_at_node(3)
        array([1, 3])
        """
        return self._in_link_at_node.row(node)

    def out_link_at_node(self, node):
        """Links leaving a node.

        Parameters
        ----------
        node : int
            Node ID

        Returns
        -------
        ndarray :
            Links leaving the node

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> lgrid.out_link_at_node(0)
        array([0, 2])
        >>> len(lgrid.out_link_at_node(3)) == 0
        True
        """
        return self._out_link_at_node.row(node)

    def iter_nodes(self):
        """Iterate of the nodes of the grid.

        Returns
        -------
        ndarray :
            Links entering and leaving each node

        Examples
        --------
        >>> from landlab.grid.unstructured.links import LinkGrid
        >>> lgrid = LinkGrid([(0, 1, 0, 2), (2, 3, 1, 3)], 4)
        >>> for link in lgrid.iter_nodes():
        ...     link
        ...
        array([0, 2])
        array([2, 1])
        array([0, 3])
        array([1, 3])
        """
        for node in range(self.number_of_nodes):
            yield np.concatenate(
                (self.in_link_at_node(node), self.out_link_at_node(node))
            )

    @property
    def node_status_at_link_start(self):
        return self._node_status[self.node_at_link_start]

    @property
    def node_status_at_link_end(self):
        return self._node_status[self.node_at_link_end]



================================================
File: src/landlab/grid/unstructured/nodes.py
================================================
import numpy as np


class NodeGrid:
    """__init__((coord0, coord1)) Create a grid of nodes.

    Parameters
    ----------
    coord0, coord1 : sequence of array-like
        Coordinates of grid nodes

    Returns
    -------
    NodeGrid :
        A newly-created NodeGrid

    Examples
    --------
    >>> from landlab.grid.unstructured.nodes import NodeGrid
    >>> ngrid = NodeGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
    >>> ngrid.ndim == 2
    True
    >>> ngrid.number_of_nodes == 4
    True
    >>> ngrid.x
    array([0.,  1.,  0.,  1.])
    >>> ngrid.y
    array([0.,  0.,  1.,  1.])

    Create a 1D grid.

    >>> ngrid = NodeGrid(((0, 1, 3),))
    >>> ngrid.ndim == 1
    True
    >>> ngrid.number_of_nodes
    3
    >>> ngrid.x
    array([0.,  1.,  3.])
    >>> ngrid.y
    Traceback (most recent call last):
    AttributeError: Grid has no y-coordinate
    """

    def __init__(self, nodes):
        """__init__((coord0, coord1)) Create a grid of nodes.

        Parameters
        ----------
        coord0, coord1 : sequence of array-like
            Coordinates of grid nodes

        Returns
        -------
        NodeGrid :
            A newly-created NodeGrid

        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1, 1], [0, 1, 0, 1]))
        >>> ngrid.ndim == 2
        True
        >>> ngrid.number_of_nodes == 4
        True
        >>> ngrid.x
        array([0.,  1.,  0.,  1.])
        >>> ngrid.y
        array([0.,  0.,  1.,  1.])

        Create a 1D grid.

        >>> ngrid = NodeGrid(((0, 1, 3),))
        >>> ngrid.ndim == 1
        True
        >>> ngrid.number_of_nodes
        3
        >>> ngrid.x
        array([0.,  1.,  3.])
        >>> ngrid.y
        Traceback (most recent call last):
        AttributeError: Grid has no y-coordinate
        """
        self._coords = np.vstack([np.array(coord, dtype=float) for coord in nodes])
        self._coords.flags["WRITEABLE"] = False

        self._number_of_nodes = len(nodes[0])

    @property
    def ndim(self):
        return self._coords.shape[0]

    @property
    def number_of_nodes(self):
        """
        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.number_of_nodes
        3
        """
        return self._number_of_nodes

    @property
    def x(self):
        """Node coordinates of the "fast" dimension.

        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.x
        array([0.,  1.,  0.])
        """
        return self._coords[-1]

    @property
    def y(self):
        """Node y-coordinates.

        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.y
        array([0.,  0.,  1.])
        """
        try:
            return self._coords[-2]
        except IndexError as exc:
            raise AttributeError("Grid has no y-coordinate") from exc

    @property
    def z(self):
        """Node z-coordinates.

        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.y
        array([0.,  0.,  1.])
        """
        try:
            return self._coords[-2]
        except IndexError as exc:
            raise AttributeError("Grid has no z-coordinate") from exc

    @property
    def coord(self):
        """
        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.coord[0]
        array([0.,  0.,  1.])
        >>> ngrid.coord[1]
        array([0.,  1.,  0.])
        """
        return self._coords

    @property
    def point(self):
        """
        Examples
        --------
        >>> from landlab.grid.unstructured.nodes import NodeGrid
        >>> ngrid = NodeGrid(([0, 0, 1], [0, 1, 0]))
        >>> ngrid.point
        array([[0.,  0.],
               [0.,  1.],
               [1.,  0.]])
        >>> ngrid.point[1]
        array([0.,  1.])
        """
        return self._coords.T



================================================
File: src/landlab/grid/unstructured/status.py
================================================
import numpy as np

from ..nodestatus import NodeStatus


class StatusGrid:
    def __init__(self, node_status):
        self._node_status = np.array(node_status)

    @property
    def node_status(self):
        """Status of nodes.

        Return an array of the status of a grid's nodes. The node status can
        be one of the following:
        - ``NodeStatus.CORE``
        - ``NodeStatus.FIXED_VALUE``
        - ``NodeStatus.FIXED_GRADIENT``
        - ``NodeStatus.LOOPED``
        - ``NodeStatus.CLOSED``
        """
        return self._node_status

    @node_status.setter
    def node_status(self, node_status):
        self._node_status = node_status

    def active_nodes(self):
        """Node IDs of all active (core & open boundary) nodes.

        core_nodes will return just core nodes.
        """
        (active_node_ids,) = np.where(self.node_status != NodeStatus.CLOSED)
        return active_node_ids

    def core_nodes(self):
        """Node IDs of all core nodes."""
        (core_node_ids,) = np.where(self.node_status == NodeStatus.CORE)
        return core_node_ids

    def boundary_nodes(self):
        """Node IDs of all boundary nodes."""
        (boundary_node_ids,) = np.where(self.node_status != NodeStatus.CORE)
        return boundary_node_ids

    def open_boundary_nodes(self):
        """Node id of all open boundary nodes."""
        (open_boundary_node_ids,) = np.where(
            (self.node_status != NodeStatus.CLOSED)
            & (self.node_status != NodeStatus.CORE)
        )
        return open_boundary_node_ids

    def closed_boundary_nodes(self):
        """Node id of all closed boundary nodes."""
        (closed_boundary_node_ids,) = np.where(self.node_status == NodeStatus.CLOSED)
        return closed_boundary_node_ids

    def fixed_gradient_boundary_nodes(self):
        """Node id of all fixed gradient boundary nodes."""
        (fixed_gradient_boundary_node_ids,) = np.where(
            self.node_status == NodeStatus.FIXED_GRADIENT
        )
        return fixed_gradient_boundary_node_ids

    def fixed_value_boundary_nodes(self):
        """Node id of all fixed value boundary nodes."""
        (fixed_value_boundary_node_ids,) = np.where(
            self.node_status == NodeStatus.FIXED_VALUE
        )
        return fixed_value_boundary_node_ids



================================================
File: src/landlab/io/__init__.py
================================================
"""Modules that read/write ModelGrids from various file formats."""

from landlab.io._deprecated_esri_ascii import BadHeaderLineError
from landlab.io._deprecated_esri_ascii import DataSizeError
from landlab.io._deprecated_esri_ascii import KeyTypeError
from landlab.io._deprecated_esri_ascii import KeyValueError
from landlab.io._deprecated_esri_ascii import MismatchGridDataSizeError
from landlab.io._deprecated_esri_ascii import MismatchGridXYLowerLeft
from landlab.io._deprecated_esri_ascii import MismatchGridXYSpacing
from landlab.io._deprecated_esri_ascii import MissingRequiredKeyError
from landlab.io._deprecated_esri_ascii import read_asc_header
from landlab.io._deprecated_esri_ascii import read_esri_ascii
from landlab.io._deprecated_esri_ascii import write_esri_ascii
from landlab.io.legacy_vtk import write_legacy_vtk
from landlab.io.obj import write_obj
from landlab.io.shapefile import read_shapefile

__all__ = [
    "read_esri_ascii",
    "read_asc_header",
    "read_shapefile",
    "write_esri_ascii",
    "write_legacy_vtk",
    "write_obj",
    "MissingRequiredKeyError",
    "KeyTypeError",
    "DataSizeError",
    "BadHeaderLineError",
    "KeyValueError",
    "MismatchGridDataSizeError",
    "MismatchGridXYSpacing",
    "MismatchGridXYLowerLeft",
]



================================================
File: src/landlab/io/_deprecated_esri_ascii.py
================================================
import os
import pathlib
import re
import warnings
from collections.abc import Generator
from collections.abc import Iterable
from typing import TextIO

import numpy as np
from numpy.typing import NDArray

from landlab.grid.raster import RasterModelGrid
from landlab.utils.add_halo import add_halo

_VALID_HEADER_KEYS = (
    "ncols",
    "nrows",
    "xllcorner",
    "xllcenter",
    "yllcorner",
    "yllcenter",
    "cellsize",
    "nodata_value",
)
_HEADER_KEY_REGEX_PATTERN = re.compile(r"\s*(?P<key>[a-zA-z]\w+)")
_HEADER_REGEX_PATTERN = re.compile(r"\s*(?P<key>[a-zA-Z]\w+)\s+(?P<value>[\w.+-]+)")
_HEADER_VALUE_TESTS = {
    "nrows": (int, lambda x: x > 0),
    "ncols": (int, lambda x: x > 0),
    "cellsize": (float, lambda x: x > 0),
    "xllcorner": (float, lambda x: True),
    "xllcenter": (float, lambda x: True),
    "yllcorner": (float, lambda x: True),
    "yllcenter": (float, lambda x: True),
    "nodata_value": (float, lambda x: True),
}


class Error(Exception):
    """Base class for errors in this module."""

    pass


class BadHeaderLineError(Error):
    """Raise this error for a bad header is line."""

    def __init__(self, line: str) -> None:
        self._line = line

    def __str__(self) -> str:
        return self._line


class MissingRequiredKeyError(Error):
    """Raise this error when a header is missing a required key."""

    def __init__(self, key: str) -> None:
        self._key = key

    def __str__(self) -> str:
        return self._key


class KeyTypeError(Error):
    """Raise this error when a header's key value is of the wrong type."""

    def __init__(self, key: str, expected_type: type | str):
        self._key = key
        self._type = str(expected_type)

    def __str__(self) -> str:
        return f"Unable to convert {self._key} to {self._type}"


class KeyValueError(Error):
    """Raise this error when a header's key value has a bad value."""

    def __init__(self, key: str, message: str) -> None:
        self._key = key
        self._msg = message

    def __str__(self) -> str:
        return f"{self._key}: {self._msg}"  # this line not yet tested


class DataSizeError(Error):
    """Raise this error if the size of data does not match the header."""

    def __init__(self, size: int, expected_size: int) -> None:
        self._actual = size
        self._expected = expected_size

    def __str__(self) -> str:
        return f"{self._actual} != {self._expected}"


class MismatchGridDataSizeError(Error):
    """Raise this error if the data size does not match the grid size."""

    def __init__(self, size: int, expected_size: int) -> None:
        self._actual = size
        self._expected = expected_size

    def __str__(self) -> str:
        return f"(data size) {self._actual} != {self._expected} (grid size)"


class MismatchGridXYSpacing(Error):
    """Raise this error if the file cell size does not match the grid dx."""

    def __init__(
        self, dx: tuple[float, float], expected_dx: tuple[float, float]
    ) -> None:
        self._actual = dx
        self._expected = expected_dx

    def __str__(self):
        return f"(data dx) {self._actual} != {self._expected} (grid dx)"


class MismatchGridXYLowerLeft(Error):
    """Raise this error if the file lower left does not match the grid."""

    def __init__(
        self, llc: tuple[float, float], expected_llc: tuple[float, float]
    ) -> None:
        self._actual = llc
        self._expected = expected_llc

    def __str__(self) -> str:
        return f"(data lower-left) {self._actual} != {self._expected} (grid lower-left)"


def read_esri_ascii(
    asc_file: str | TextIO,
    grid: RasterModelGrid | None = None,
    reshape: bool = False,
    name: str | None = None,
    halo: int = 0,
) -> tuple[RasterModelGrid, NDArray]:
    """Read :py:class:`~.RasterModelGrid` from an ESRI ASCII file.

    Read data from *asc_file*, an *ESRI ASCII file* [1]_, into a
    :class:`~.RasterModelGrid`.  *asc_file* is either the name of
    the data file or is a file-like object.

    The grid and data read from the file are returned as a tuple
    (*grid*, *data*) where *grid* is an instance of
    :py:class:`~.RasterModelGrid` and *data* is a numpy
    array of doubles with that has been reshaped to have the number of rows
    and columns given in the header.

    Parameters
    ----------
    asc_file : str of file-like
        Data file to read.
    reshape : boolean, optional
        Reshape the returned array, otherwise return a flattened array.
    name : str, optional
        Add data to the grid as a named field.
    grid : *grid* , optional
        Adds data to an existing *grid* instead of creating a new one.
    halo : integer, optional
        Adds outer border of depth halo to the *grid*.

    Returns
    -------
    (grid, data) : tuple
        A newly-created :class:`~.RasterModelGrid` and the associated node data.

    Raises
    ------
    :class:`~landlab.io.esri_ascii.DataSizeError`
        Data are not the same size as indicated by the header file.
    :class:`~landlab.io.esri_ascii.MismatchGridDataSizeError`
        If a grid is passed, and the size of the grid does not agree with the
        size of the data.
    :class:`~landlab.io.esri_ascii.MismatchGridXYSpacing`
        If a grid is passed, and the *cellsize* listed in the heading does not
        match the node spacing of the grid.
    :class:`~landlab.io.esri_ascii.MismatchGridXYLowerLeft`
        If a grid is passed and the *xllcorner* and *yllcorner* do not match that
        of the grid.

    References
    ----------

    .. [1] https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/esri-ascii-raster-format.htm

    Examples
    --------

    >>> from landlab.io import read_esri_ascii
    >>> from io import StringIO

    >>> contents = '''
    ... ncols         3
    ... nrows         4
    ... xllcorner     1.
    ... yllcorner     2.
    ... cellsize      10.
    ... NODATA_value  -1
    ... 0. 1. 2.
    ... 3. 4. 5.
    ... 6. 7. 8.
    ... 9. 10. 11.
    ... '''

    >>> (grid, data) = read_esri_ascii(StringIO(contents))

    The returned grid is a :class:`~.RasterModelGrid` with 4 rows and 3 columns.

    >>> grid
    RasterModelGrid((4, 3), xy_spacing=(10.0, 10.0), xy_of_lower_left=(1.0, 2.0))

    Note that the first row of values is the bottom-most of the data file.

    >>> data.reshape(grid.shape)
    array([[  9.,  10.,  11.],
           [  6.,   7.,   8.],
           [  3.,   4.,   5.],
           [  0.,   1.,   2.]])

    >>> (grid, data) = read_esri_ascii(StringIO(contents), halo=1)

    Because of the halo, the returned grid now has two more rows and columns than before.

    >>> grid
    RasterModelGrid((6, 5), xy_spacing=(10.0, 10.0), xy_of_lower_left=(-9.0, -8.0))
    >>> data.reshape(grid.shape)
    array([[-1.,  -1.,  -1.,  -1.,  -1.],
           [-1.,   9.,  10.,  11.,  -1.],
           [-1.,   6.,   7.,   8.,  -1.],
           [-1.,   3.,   4.,   5.,  -1.],
           [-1.,   0.,   1.,   2.,  -1.],
           [-1.,  -1.,  -1.,  -1.,  -1.]])
    """  # noqa: B950
    warnings.warn(
        "landlab.io.read_esri_ascii has been deprecated, use"
        " landlab.io.esri_ascii.load instead",
        DeprecationWarning,
        stacklevel=3,
    )

    if halo < 0:
        raise ValueError("negative halo")

    # if the asc_file is provided as a string, open it and pass the pointer to
    # _read_asc_header, and _read_asc_data
    if isinstance(asc_file, (str, pathlib.Path)):
        with open(asc_file) as f:
            header = read_asc_header(f)
            data = _read_asc_data(f)

    # otherwise, pass asc_file directly.
    else:
        header = read_asc_header(asc_file)
        data = _read_asc_data(asc_file)

    shape = (int(header["nrows"]) + 2 * halo, int(header["ncols"]) + 2 * halo)
    nodata_value = header.get("nodata_value", -9999.0)
    if data.size != (shape[0] - 2 * halo) * (shape[1] - 2 * halo):
        raise DataSizeError(shape[0] * shape[1], data.size)

    xy_spacing = (header["cellsize"], header["cellsize"])
    xy_of_lower_left = (
        header["xllcorner"] - halo * header["cellsize"],
        header["yllcorner"] - halo * header["cellsize"],
    )

    data = np.flipud(data)

    if halo > 0:
        data = add_halo(
            data.reshape((int(header["nrows"]), int(header["ncols"]))),
            halo=halo,
            halo_value=nodata_value,
        ).reshape((-1,))

    if not reshape:
        data = data.flatten()

    if grid is not None:
        if (grid.number_of_node_rows != shape[0]) or (
            grid.number_of_node_columns != shape[1]
        ):
            raise MismatchGridDataSizeError(
                shape[0] * shape[1],
                grid.number_of_node_rows * grid.number_of_node_columns,
            )
        if (grid.dx, grid.dy) != xy_spacing:
            raise MismatchGridXYSpacing((grid.dx, grid.dy), xy_spacing)

        if grid.xy_of_lower_left != xy_of_lower_left:
            raise MismatchGridXYLowerLeft(grid.xy_of_lower_left, xy_of_lower_left)

    if grid is None:
        grid = RasterModelGrid(
            shape, xy_spacing=xy_spacing, xy_of_lower_left=xy_of_lower_left
        )
    if name:
        grid.add_field(name, data, at="node")

    return (grid, data)


def write_esri_ascii(
    path: str,
    fields: RasterModelGrid,
    names: Iterable[str] | None = None,
    clobber: bool = False,
) -> list[str]:
    """Write landlab fields to ESRI ASCII.

    Write the data and grid information for *fields* to *path* in the ESRI
    ASCII format.

    Parameters
    ----------
    path : str
        Path to output file.
    fields : field-like
        Landlab field object that holds a grid and associated values.
    names : iterable of str, optional
        Names of the fields to include in the output file. If not provided,
        write all fields.
    clobber : boolean
        If *path* exists, clobber the existing file, otherwise raise an
        exception.

    Examples
    --------
    >>> import numpy as np
    >>> import os
    >>> from landlab import RasterModelGrid
    >>> from landlab.io import write_esri_ascii

    >>> grid = RasterModelGrid((4, 5), xy_spacing=(2.0, 2.0))
    >>> grid.at_node["air__temperature"] = np.arange(20.0)
    >>> files = write_esri_ascii("test.asc", grid)  # doctest: +SKIP
    >>> [os.path.basename(name) for name in sorted(files)]  # doctest: +SKIP
    ['test.asc']

    >>> _ = grid.add_field("land_surface__elevation", np.arange(20.0), at="node")
    >>> grid.at_node["land_surface__elevation"] = np.arange(20.0)
    >>> files = write_esri_ascii("test.asc", grid)  # doctest: +SKIP
    >>> [os.path.basename(name) for name in sorted(files)]  # doctest: +SKIP
    ['test_air__temperature.asc', 'test_land_surface__elevation.asc']
    """
    warnings.warn(
        "landlab.io.write_esri_ascii has been deprecated, use"
        " landlab.io.esri_ascii.dump instead",
        DeprecationWarning,
        stacklevel=3,
    )

    if os.path.exists(path) and not clobber:
        raise ValueError("file exists")

    if isinstance(names, (str, pathlib.Path)):
        names = [names]

    names = tuple(names or fields.at_node)

    if len(names) == 1:
        paths = [path]
    elif len(names) > 1:
        (base, ext) = os.path.splitext(path)
        paths = [base + "_" + name + ext for name in names]
    else:
        raise ValueError("no node fields to write")

    bad_names = set(names) - set(fields.at_node.keys())
    if len(bad_names) > 0:
        raise ValueError("unknown field name(s): %s" % ",".join(bad_names))

    header = {
        "ncols": fields.number_of_node_columns,
        "nrows": fields.number_of_node_rows,
        "xllcorner": fields.node_x[0],
        "yllcorner": fields.node_y[0],
        "cellsize": fields.dx,
    }

    for path, name in zip(paths, names):
        header_lines = [f"{key} {str(val)}" for key, val in list(header.items())]
        data = fields.at_node[name].reshape(header["nrows"], header["ncols"])
        np.savetxt(
            path, np.flipud(data), header=os.linesep.join(header_lines), comments=""
        )

    return paths


def read_asc_header(asc_file: TextIO) -> dict[str, int | float]:
    """Read header information from an ESRI ASCII raster file.

    The header contains the following variables,

    * ``ncols``: Number of cell columns
    * ``nrows``: Number of cell rows
    * ``xllcenter`` or ``xllcorner``: X (column) coordinate of lower-left
        coordinate of grid (by center or lower-left corner of the cell)
    * ``yllcenter``, ``yllcorner``: Y (row) coordinate of lower-left
        coordinate of grid (by center or lower-left corner of the cell)
    * ``cellsize``: Grid spacing between rows and columns
    * ``nodata_value``: No-data value (optional)

    Parameters
    ----------
    asc_file : file_like
        File-like object from which to read header.

    Returns
    -------
    dict
        Header as key-value pairs.

    Raises
    ------
    :class:`~landlab.io.esri_ascii.MissingRequiredKeyError`
        The header is missing a required key.
    :class:`~landlab.io.esri_ascii.KeyTypeError`
        The header has the key but its values is of the wrong type.

    Examples
    --------
    >>> from io import StringIO
    >>> from landlab.io import read_asc_header

    >>> contents = '''
    ... nrows 100
    ... ncols 200
    ... cellsize 1.5
    ... xllcenter 0.5
    ... yllcenter -0.5
    ... '''

    >>> hdr = read_asc_header(StringIO(contents))
    >>> hdr["nrows"], hdr["ncols"]
    (100, 200)
    >>> hdr["cellsize"]
    1.5
    >>> hdr["xllcenter"], hdr["yllcenter"]
    (0.5, -0.5)

    :class:`~landlab.io.esri_ascii.MissingRequiredKeyError` is raised if the
    header does not contain all of the necessary keys.

    >>> contents = '''
    ... ncols 200
    ... cellsize 1.5
    ... xllcenter 0.5
    ... yllcenter -0.5
    ... '''
    >>> read_asc_header(StringIO(contents))
    Traceback (most recent call last):
    MissingRequiredKeyError: nrows

    :class:`~landlab.io.esri_ascii.KeyTypeError` is raised if a value is of
    the wrong type. For instance, *nrows* and *ncols* must be ``int``.

    >>> contents = '''
    ... nrows 100.5
    ... ncols 200
    ... cellsize 1.5
    ... xllcenter 0.5
    ... yllcenter -0.5
    ... '''
    >>> read_asc_header(StringIO(contents))
    Traceback (most recent call last):
    KeyTypeError: Unable to convert nrows to <type 'int'>
    """
    warnings.warn(
        "landlab.io.read_asc_header has been deprecated, use"
        " landlab.io.esri_ascii.parse instead",
        DeprecationWarning,
        stacklevel=3,
    )

    header = {}
    for key, value in _header_lines(asc_file):
        header[key] = value

    return _header_is_valid(header)


def _header_lines(asc_file: TextIO) -> Generator[tuple[str, str], None, None]:
    """Iterate over header lines for a ESRI ASCII file.

    Parameters
    ----------
    asc_file : file_like
        File-like object for an ESRI ASCII file.

    Yields
    ------
    str
        Header line.
    """
    pos = asc_file.tell()
    line = asc_file.readline()
    while len(line) > 0:
        if len(line.strip()) > 0:
            item = _parse_header_key_value(line)
            if item:
                yield item
            else:
                asc_file.seek(pos, 0)
                break
        pos = asc_file.tell()
        line = asc_file.readline()


def _parse_header_key_value(line: str) -> tuple[str, str] | None:
    """Parse a header line into a key-value pair.

    Parameters
    ----------
    line : str
        Header line.

    Returns
    -------
    (str, str)
        Header key-value pair

    Raises
    ------
    BadHeaderLineError
        There is something wrong with the header line.
    """
    match = _HEADER_KEY_REGEX_PATTERN.match(line)
    if match is None:
        return None
        # raise BadHeaderLineError(line)

    match = _HEADER_REGEX_PATTERN.match(line)
    if match is None:
        raise BadHeaderLineError(line)

    (key, value) = (match.group("key").lower(), match.group("value"))

    if key in _VALID_HEADER_KEYS:
        return (key, value)
    else:
        raise BadHeaderLineError(line)


def _header_is_valid(header: dict[str, str]) -> dict[str, int | float]:
    """Check if the ESRI ASCII header is valid.

    Parameters
    ----------
    header : dict
        Header as key-values pairs.

    Raises
    ------
    MissingRequiredKeyError
        The header is missing a required key.
    KeyTypeError
        The header has the key but its values is of the wrong type.
    """
    header_keys = set(header)
    required_keys = {"ncols", "nrows", "cellsize"}

    if not required_keys.issubset(header_keys):
        raise MissingRequiredKeyError(", ".join(required_keys - header_keys))

    for keys in [("xllcenter", "xllcorner"), ("yllcenter", "yllcorner")]:
        if len(set(keys) & header_keys) != 1:
            raise MissingRequiredKeyError("|".join(keys))

    validated_header = {}
    for key, requires in _HEADER_VALUE_TESTS.items():
        to_type, is_valid = requires

        if key not in header:
            continue

        try:
            validated_header[key] = to_type(header[key])
        except ValueError as exc:
            raise KeyTypeError(key, to_type) from exc

        if not is_valid(validated_header[key]):
            raise KeyValueError(key, "Bad value")

    return validated_header


def _read_asc_data(asc_file: TextIO) -> NDArray:
    """Read gridded data from an ESRI ASCII data file.

    Parameters
    ----------
    asc_file : file-like
        File-like object of the data file pointing to the start of the data.

    .. note::
        First row of the data is at the top of the raster grid, the second
        row is the second from the top, and so on.
    """
    return np.loadtxt(asc_file)



================================================
File: src/landlab/io/esri_ascii.py
================================================
#! /usr/bin/env python
"""Read/write data from an ESRI ASCII file into a RasterModelGrid.

ESRI ASCII functions
++++++++++++++++++++

.. autosummary::

    ~dump
    ~lazy_load
    ~lazy_loads
    ~load
    ~loads
    ~parse
"""
from __future__ import annotations

import io
from collections import OrderedDict
from collections.abc import Callable
from typing import Literal
from typing import NamedTuple
from typing import TextIO
from typing import overload

import numpy as np
from numpy.typing import ArrayLike
from numpy.typing import NDArray

from landlab.grid.raster import RasterModelGrid
from landlab.layers.eventlayers import _valid_keywords_or_raise


class EsriAsciiError(Exception):
    pass


class BadHeaderError(EsriAsciiError):
    def __init__(self, msg: str) -> None:
        self._msg = msg

    def __str__(self) -> str:
        return self._msg


def dump(
    grid: RasterModelGrid,
    stream: TextIO | None = None,
    at: Literal["node", "patch", "corner", "cell"] = "node",
    name: str | None = None,
) -> str | None:
    """Dump a grid field to ESRII ASCII format.

    Parameters
    ----------
    grid :
        A Landlab grid.
    stream :
        A ``file_like`` object to write to. If ``None``, return
        a string containing the serialized grid.
    at :
        Where the field to be written is located on the grid.
    name :
        The name of the field to be written. If ``None``, only the header
        information will be written.

    Returns
    -------
    :
        The grid field in ESRI ASCII format or ``None`` if a ``file_like``
        object was provided.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.io import esri_ascii

    >>> grid = RasterModelGrid((3, 4), xy_spacing=2.0)
    >>> print(esri_ascii.dump(grid, at="node"))
    NROWS 3
    NCOLS 4
    CELLSIZE 2.0
    XLLCENTER 0.0
    YLLCENTER 0.0
    NODATA_VALUE -9999

    >>> print(esri_ascii.dump(grid, at="cell"))
    NROWS 1
    NCOLS 2
    CELLSIZE 2.0
    XLLCENTER 2.0
    YLLCENTER 2.0
    NODATA_VALUE -9999
    """
    grid = _validate_grid(grid)

    shape = np.asarray(grid.shape)
    if at in ("corner", "patch"):
        shape -= 1
    elif at == "cell":
        shape -= 2

    shift = _get_lower_left_shift(at=at, ref="center")

    header = _Header(
        nrows=shape[0],
        ncols=shape[1],
        xllcenter=grid.xy_of_lower_left[0] - grid.dx * shift,
        yllcenter=grid.xy_of_lower_left[1] - grid.dx * shift,
        cellsize=grid.dx,
    )
    lines = [str(header)]

    if name:
        data = getattr(grid, f"at_{at}")[name]
        kwds = {"comments": ""}
        if data.dtype.kind in ("i", "u"):
            kwds["fmt"] = "%d"
        with io.StringIO() as fp:
            np.savetxt(fp, np.flipud(data.reshape(shape)), **kwds)
            lines.append(fp.getvalue())

    content = "".join(lines)
    if stream is None:
        return content
    else:
        stream.write(content)
        return None


def load(
    stream: TextIO,
    at: str = "node",
    name: str | None = None,
    out: RasterModelGrid | None = None,
) -> RasterModelGrid:
    """Parse a RasterModelGrid from a ESRI ASCII format stream.

    Parameters
    ----------
    stream : file_like
        A text stream in ESRI ASCII format.
    at : {'node', 'patch', 'corner', 'cell'}, optional
        Location on the grid where data are placed.
    name : str, optional
        Name of the newly-created field. If `name` is
        not provided, the grid will be created but the
        data not added as a field.
    out : RasterModelGrid, optional
        Place the data from the file onto an existing grid. If not
        provided, create a new grid.

    Returns
    -------
    :
        A newly-created ``RasterModelGrid`` with, optionaly, the data added
        as a field (if `name` was provided).
    """
    return loads(stream.read(), at=at, name=name, out=out)


def loads(
    s: str,
    at: str = "node",
    name: str | None = None,
    out: RasterModelGrid | None = None,
) -> RasterModelGrid:
    """Parse a RasterModelGrid from a ESRI ASCII formatted string.

    Parameters
    ----------
    s : str
        A string in ESRI ASCII format.
    at : {'node', 'patch', 'corner', 'cell'}, optional
        Location on the grid where data are placed.
    name : str, optional
        Name of the newly-created field. If `name` is
        not provided, the grid will be created but the
        data not added to the grid as a field.
    out : RasterModelGrid, optional
        Place the data from the file onto an existing grid. If not
        provided, create a new grid.

    Returns
    -------
    RasterModelGrid
        A newly-created ``RasterModelGrid`` with, optionaly, the data added
        as a field (if `name` was provided).

    Examples
    --------
    >>> from landlab.io import esri_ascii

    >>> contents = '''
    ... NROWS 1
    ... NCOLS 2
    ... XLLCORNER -2.0
    ... YLLCORNER 4.0
    ... CELLSIZE 2.0
    ... NODATA_VALUE -9999
    ... '''.lstrip()
    >>> grid = esri_ascii.loads(contents, at="cell")
    >>> grid.shape
    (3, 4)
    >>> grid.xy_of_lower_left
    (-3.0, 3.0)
    >>> grid.spacing
    (2.0, 2.0)

    >>> contents = '''
    ... NROWS 1
    ... NCOLS 2
    ... XLLCENTER -2.0
    ... YLLCENTER 4.0
    ... CELLSIZE 2.0
    ... NODATA_VALUE -9999
    ... 10 11
    ... '''.lstrip()
    >>> grid = esri_ascii.loads(contents, at="cell", name="foo")
    >>> grid.shape
    (3, 4)
    >>> grid.xy_of_lower_left
    (-4.0, 2.0)
    >>> grid.spacing
    (2.0, 2.0)
    >>> grid.at_cell["foo"]
    array([10., 11.])

    >>> contents = '''
    ... NROWS 3
    ... NCOLS 4
    ... XLLCENTER 0.0
    ... YLLCENTER 0.0
    ... CELLSIZE 1.0
    ... NODATA_VALUE -9999
    ... 1 2 3 4
    ... 5 6 7 8
    ... 9 10 11 12
    ... '''.lstrip()
    >>> grid = esri_ascii.loads(contents, at="node", name="foo")
    >>> contents = '''
    ... NROWS 1
    ... NCOLS 2
    ... XLLCENTER 1.0
    ... YLLCENTER 1.0
    ... CELLSIZE 1.0
    ... NODATA_VALUE -9999
    ... 10 20
    ... '''.lstrip()
    >>> grid = esri_ascii.loads(contents, at="cell", name="foo", out=grid)
    >>> grid.at_node["foo"].reshape(grid.shape)
    array([[ 9., 10., 11., 12.],
           [ 5.,  6.,  7.,  8.],
           [ 1.,  2.,  3.,  4.]])
    >>> grid.at_cell["foo"]
    array([10., 20.])
    """
    if name is None:
        info = parse(s, with_data=False)
    else:
        info, data = parse(s, with_data=True)
    header = _Header(**info)

    shape = np.asarray(header.shape)
    if at in ("corner", "patch"):
        shape += 1
    elif at == "cell":
        shape += 2

    shift = header.cell_size * _get_lower_left_shift(at=at, ref=header.lower_left_ref)
    xy_of_lower_left = np.asarray(header.lower_left) + shift

    if out is None:
        grid = RasterModelGrid(
            shape, xy_spacing=header.cell_size, xy_of_lower_left=xy_of_lower_left
        )
    else:
        grid = _validate_grid(
            out, shape, xy_spacing=header.cell_size, xy_of_lower_left=xy_of_lower_left
        )

    if name is not None:
        getattr(grid, f"at_{at}")[name] = data

    return grid


def _header_to_grid_args(info: dict[str, int | float], at: str):
    header = _Header(**info)

    shape = np.asarray(header.shape)
    if at in ("corner", "patch"):
        shape += 1
    elif at == "cell":
        shape += 2

    shift = header.cell_size * _get_lower_left_shift(at=at, ref=header.lower_left_ref)
    # xy_of_lower_left = np.asarray(header.lower_left) + shift

    return {
        "shape": tuple(shape),
        "xy_spacing": (header.cell_size, header.cell_size),
        "xy_of_lower_left": tuple(np.asarray(header.lower_left) + shift),
    }


class RasterGridArgs(NamedTuple):
    shape: tuple[int, int]
    xy_spacing: tuple[float, float]
    xy_of_lower_left: tuple[float, float]


@overload
def lazy_load(stream: TextIO, at: str = "node", name: None = ...) -> RasterGridArgs: ...


@overload
def lazy_load(
    stream: TextIO, at: str = "node", name: str = ...
) -> tuple[RasterGridArgs, NDArray]: ...


def lazy_load(
    stream: TextIO,
    at: str = "node",
    name: str | None = None,
) -> RasterGridArgs | tuple[RasterGridArgs, NDArray]:
    """Parse a RasterModelGrid from a ESRI ASCII format stream.

    Parameters
    ----------
    stream : file_like
        A text stream in ESRI ASCII format.
    at : {'node', 'patch', 'corner', 'cell'}, optional
        Location on the grid where data are placed.
    name : str, optional
        Name of the newly-created field. If `name` is
        not provided, the grid will be created but the
        data not added as a field.

    Returns
    -------
    RasterGridArgs
        The header metadata
    NDArray, optional
        The data as a numpy array.
    """
    return lazy_loads(stream.read(), at=at, name=name)


@overload
def lazy_loads(s: str, at: str = "node", name: None = ...) -> RasterGridArgs: ...


@overload
def lazy_loads(
    s: str, at: str = "node", name: str = ...
) -> tuple[RasterGridArgs, NDArray]: ...


def lazy_loads(
    s: str,
    at: str = "node",
    name: str | None = None,
    out: RasterModelGrid | None = None,
) -> RasterGridArgs | tuple[RasterGridArgs, NDArray]:
    """Parse a ESRI ASCII formatted string.

    Parameters
    ----------
    s : str
        A string in ESRI ASCII format.
    at : {'node', 'patch', 'corner', 'cell'}, optional
        Location on the grid where data are placed.
    name : str, optional
        Name of the newly-created field. If `name` is
        not provided, the grid will be created but the
        data not added to the grid as a field.
    out : RasterModelGrid, optional
        Place the data from the file onto an existing grid. If not
        provided, create a new grid.

    Returns
    -------
    RasterGridArgs
        The header metadata
    NDArray, optional
        The data as a numpy array.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.io import esri_ascii

    >>> contents = '''
    ... NROWS 1
    ... NCOLS 2
    ... XLLCORNER -2.0
    ... YLLCORNER 4.0
    ... CELLSIZE 2.0
    ... NODATA_VALUE -9999
    ... 10 20
    ... '''.lstrip()
    >>> args, data = esri_ascii.lazy_loads(contents, at="cell", name="foo")
    >>> args
    RasterGridArgs(shape=(3, 4), xy_spacing=(2.0, 2.0), xy_of_lower_left=(-3.0, 3.0))
    >>> data
    array([10., 20.])

    >>> grid = RasterModelGrid(*args)
    >>> grid.at_cell["foo"] = data

    >>> contents = '''
    ... NROWS 3
    ... NCOLS 4
    ... XLLCORNER -3.0
    ... YLLCORNER 3.0
    ... CELLSIZE 2.0
    ... NODATA_VALUE -9999
    ... 1 2 3 4
    ... 5 6 7 8
    ... 9 10 11 12
    ... '''.lstrip()
    >>> args, data = esri_ascii.lazy_loads(contents, at="node", name="foo", out=grid)
    >>> args
    RasterGridArgs(shape=(3, 4), xy_spacing=(2.0, 2.0), xy_of_lower_left=(-3.0, 3.0))
    >>> data
    array([ 9., 10., 11., 12.,  5.,  6.,  7.,  8.,  1.,  2.,  3.,  4.])

    >>> grid.at_cell["foo"]
    array([10., 20.])
    >>> grid.at_node["foo"]
    array([ 9., 10., 11., 12.,  5.,  6.,  7.,  8.,  1.,  2.,  3.,  4.])
    """
    if name is None:
        info = parse(s, with_data=False)
    else:
        info, data = parse(s, with_data=True)

    args = RasterGridArgs(**_header_to_grid_args(info, at=at))

    if name is not None:
        if out is not None:
            grid = _validate_grid(out, *args)
            getattr(grid, f"at_{at}")[name] = data
        return args, data
    else:
        return args


@overload
def parse(s: str, with_data: Literal[False] = ...) -> dict[str, int | float]: ...


@overload
def parse(
    s: str, with_data: Literal[True] = ...
) -> tuple[dict[str, int | float], NDArray]: ...


def parse(
    s: str, with_data: bool = False
) -> dict[str, int | float] | tuple[dict[str, int | float], NDArray]:
    """Parse a ESRI ASCII formatted string.

    Parameters
    ----------
    s : str
        String to parse.
    with_data : bool, optional
        Return the data as a numpy array, otherwise, just
        return the header.

    Returns
    -------
    dict or tuple of (dict, ndarray)
        The header metadata and, optionally, the data.

    Examples
    --------
    >>> from landlab.io import esri_ascii

    >>> contents = '''
    ... NROWS 2
    ... NCOLS 3
    ... XLLCORNER -2.0
    ... YLLCORNER 4.0
    ... CELLSIZE 2.0
    ... NODATA_VALUE -9999
    ... 10 20 30
    ... 40 50 60
    ... '''.lstrip()
    >>> list(esri_ascii.parse(contents).items())
    [('nrows', 2),
     ('ncols', 3),
     ('xllcorner', -2.0),
     ('yllcorner', 4.0),
     ('cellsize', 2.0),
     ('nodata_value', -9999.0)]

    >>> info, data = esri_ascii.parse(contents, with_data=True)
    >>> data
    array([40., 50., 60., 10., 20., 30.])
    """
    lines = s.splitlines()

    start_of_data: int | None = 0
    for lineno, line in enumerate(lines):
        if not _Header.is_header_line(line):
            start_of_data = lineno
            break
    else:
        start_of_data = None

    if start_of_data is None:
        header, body = lines, []
    else:
        header, body = lines[:start_of_data], lines[start_of_data:]

    if not header:
        raise EsriAsciiError("missing header")
    if with_data and not body:
        raise EsriAsciiError("missing data")

    info = OrderedDict(_Header.parse_header_line(line) for line in header)

    validated_info = _Header(**info)

    if with_data:
        data = np.loadtxt([" ".join(body)]).reshape(validated_info.shape)

        return info, np.flipud(data).reshape((-1,))
    else:
        return info


def _validate_grid(
    grid: RasterModelGrid,
    shape: ArrayLike | None = None,
    xy_spacing: float | tuple[float, float] | None = None,
    xy_of_lower_left: tuple[float, float] | None = None,
) -> RasterModelGrid:
    if not isinstance(grid, RasterModelGrid):
        raise EsriAsciiError(
            "Not a RasterModelGrid. Only RasterModelGrids can be expressed in"
            " ESRI ASCII format."
        )
    if grid.dx != grid.dy:
        raise EsriAsciiError(f"x and y spacing must be equal ({grid.dx} != {grid.dy}).")

    if shape is not None and not np.all(np.equal(grid.shape, shape)):
        raise EsriAsciiError(f"Grid shape mismatch ({grid.shape} != {shape}).")
    if xy_spacing is not None and not np.all(np.equal(grid.spacing, xy_spacing)):
        raise EsriAsciiError(f"Grid spacing mismatch ({grid.dx} != {xy_spacing}).")
    if xy_of_lower_left is not None and not np.all(
        np.equal(grid.xy_of_lower_left, xy_of_lower_left)
    ):
        raise EsriAsciiError(
            f"Grid lower-left mismatch ({grid.xy_of_lower_left} != {xy_of_lower_left})."
        )

    return grid


def _get_lower_left_shift(at="node", ref="center"):
    """Calculate the shift from the lower left of a grid to ESRI ASCII.

    Parameters
    ----------
    at : {'node', 'patch', 'corner', 'cell'}, optional
        Grid location where data are placed.
    ref : {'center', 'corner'}, optional
        Reference location with respect to the ESRI ASCII cell.

    Returns
    -------
    float
        The unit shift between the lower left of an ESRI ASCII field
        and a ``RasterModelGrid``.
    """
    if at == "node" or (at == "patch" and ref == "corner"):
        return 0.0
    elif (
        at == "corner"
        or (at == "patch" and ref == "center")
        or (at == "cell" and ref == "corner")
    ):
        return -0.5
    elif at == "cell" and ref == "center":
        return -1.0

    raise RuntimeError(f"unreachable code ({at!r}, {ref!r}")


class _Header:
    required_keys = frozenset(("ncols", "nrows", "cellsize"))
    optional_keys = frozenset(
        ("xllcorner", "xllcenter", "yllcorner", "yllcenter", "nodata_value")
    )

    def __init__(self, **kwds):
        _valid_keywords_or_raise(
            kwds, required=_Header.required_keys, optional=_Header.optional_keys
        )

        self._shape = self._validate_shape(kwds["nrows"], kwds["ncols"])
        self._cell_size = self._validate_cell_size(kwds["cellsize"])
        self._nodata_value = kwds.get("nodata_value", -9999)

        lower_left = {
            k: kwds[k]
            for k in ("xllcorner", "xllcenter", "yllcorner", "yllcenter")
            if k in kwds
        }

        self._lower_left, self._lower_left_ref = self._validate_lower_left(**lower_left)

    @staticmethod
    def parse_header_line(line: str) -> tuple[str, int | float]:
        """Parse a header line into a key/value pair."""
        try:
            key, value = line.split(maxsplit=1)
        except ValueError:
            raise BadHeaderError(
                f"header line must contain a key/value pair ({line!r})"
            ) from None
        else:
            key = key.lower()

        convert: dict[str, Callable[[str], int | float]] = {"nrows": int, "ncols": int}

        try:
            return key, convert.get(key, float)(value)
        except ValueError:
            raise BadHeaderError(
                f"unable to convert header value to a number ({line!r})"
            ) from None

    @staticmethod
    def is_header_line(line: str) -> bool:
        """Check if a string is a possible header line."""
        try:
            key, value = line.split(maxsplit=1)
        except ValueError:
            return False
        else:
            return key.lower() in (_Header.required_keys | _Header.optional_keys)

    @property
    def shape(self) -> tuple[int, int]:
        return self._shape

    @staticmethod
    def _validate_shape(n_rows: int, n_cols: int) -> tuple[int, int]:
        if not isinstance(n_rows, (int, np.integer)) or n_rows <= 0:
            raise BadHeaderError(f"n_rows must be a positive integer ({n_rows!r})")
        if not isinstance(n_cols, (int, np.integer)) or n_cols <= 0:
            raise BadHeaderError(f"n_cols must be a positive integer ({n_cols!r})")

        return n_rows, n_cols

    @property
    def lower_left(self) -> tuple[float, float]:
        return self._lower_left

    @property
    def lower_left_ref(self) -> str:
        return self._lower_left_ref

    @staticmethod
    def _validate_lower_left(cell_size=0.0, **kwds) -> tuple[tuple[float, float], str]:
        if set(kwds) == {"xllcorner", "yllcorner"}:
            lower_left = kwds["xllcorner"], kwds["yllcorner"]
            ref = "corner"
        elif set(kwds) == {"xllcenter", "yllcenter"}:
            lower_left = kwds["xllcenter"], kwds["yllcenter"]
            ref = "center"
        else:
            raise BadHeaderError(
                "header must contain one, and only one, of the pairs"
                " ('xllcenter', 'yllcenter') or ('xllcorner', 'yllcorner')"
                f" (got {', '.join(repr(k) for k in sorted(set(kwds)))})"
            )
        return lower_left, ref

    @property
    def cell_size(self) -> float:
        return self._cell_size

    @staticmethod
    def _validate_cell_size(cell_size: float) -> float:
        if cell_size <= 0.0:
            raise BadHeaderError(f"cell size must be greater than zero ({cell_size})")
        return float(cell_size)

    @property
    def nodata(self) -> int | float:
        return self._nodata_value

    def __str__(self) -> str:
        lines = (
            f"NROWS {self.shape[0]}",
            f"NCOLS {self.shape[1]}",
            f"CELLSIZE {self.cell_size}",
            f"XLL{self.lower_left_ref.upper()} {self.lower_left[0]}",
            f"YLL{self.lower_left_ref.upper()} {self.lower_left[1]}",
            f"NODATA_VALUE {self.nodata}",
        )
        return "\n".join(lines) + "\n"

    def __repr__(self) -> str:
        kwds = {
            "nrows": self.shape[0],
            "ncols": self.shape[1],
            "cellsize": self.cell_size,
            f"xll{self.lower_left_ref}": self.lower_left[0],
            f"yll{self.lower_left_ref}": self.lower_left[1],
            "nodata_value": self.nodata,
        }
        args = [f"{k}={v!r}" for k, v in kwds.items()]
        return f"_Header({', '.join(args)})"



================================================
File: src/landlab/io/legacy_vtk.py
================================================
import os
import pathlib
from enum import IntEnum
from enum import unique

import numpy as np


def dump(grid, stream=None, include="*", exclude=None, z_coord=0.0, at="node"):
    """Format a grid in VTK legacy format.

    Parameters
    ----------
    grid : ModelGrid
        A *Landlab* grid.
    stream : file_like, optional
        File-like object to write the formatted output. If not provided,
        return the formatted vtk as a string.
    include : str, or iterable of str, optional
        Glob-style pattern for field names to include.
    exclude : str, or iterable of str, optional
        Glob-style pattern for field names to exclude.
    z_coord : array_like or str, optional
        If the grid does not have a *z* coordinate, use this value. If
        a ``str``, use the corresponding field.
    at : 'node' or 'corner', optional
        Use either the grid's *node*s (and *patches*) or *corners* (and *cells*).

    Returns
    -------
    str or ``None``
        The grid formatted as legacy VTK or ``None`` if an output stream
        was provided.

    Examples
    --------
    >>> import os
    >>> import numpy as np
    >>> from landlab import HexModelGrid
    >>> import landlab.io.legacy_vtk as vtk

    >>> grid = HexModelGrid((3, 2))

    >>> topo = np.arange(grid.number_of_nodes)
    >>> grid.at_node["topographic__elevation"] = topo
    >>> grid.at_node["surface_water__depth"] = (7.0 - topo) / 10.0

    >>> lines = vtk.dump(grid, z_coord=topo).splitlines()
    >>> print(os.linesep.join(lines[:4]))
    # vtk DataFile Version 2.0
    Landlab output
    ASCII
    DATASET UNSTRUCTURED_GRID

    The x, y, and z coordinates of each grid node (VTK calls these
    "points")

    >>> print(os.linesep.join(lines[5:13]))
    POINTS 7 float
    0.5 0.0 0.0
    1.5 0.0 1.0
    0.0 0.866025 2.0
    1.0 0.866025 3.0
    2.0 0.866025 4.0
    0.5 1.732051 5.0
    1.5 1.732051 6.0

    Grid nodes that form each patch (VTK calls these "cells").

    >>> print(os.linesep.join(lines[14:21]))
    CELLS 6 24
    3 3 0 1
    3 3 2 0
    3 4 3 1
    3 5 2 3
    3 6 3 4
    3 6 5 3

    The type of each patch. A value of 5 is VTK code for triangle.

    >>> print(os.linesep.join(lines[22:29]))
    CELL_TYPES 6
    5
    5
    5
    5
    5
    5

    The data fields at grid nodes.

    >>> print(os.linesep.join(lines[30:51]))
    POINT_DATA 7
    <BLANKLINE>
    SCALARS surface_water__depth float 1
    LOOKUP_TABLE default
    0.7
    0.6
    0.5
    0.4
    0.3
    0.2
    0.1
    <BLANKLINE>
    SCALARS topographic__elevation float 1
    LOOKUP_TABLE default
    0.0
    1.0
    2.0
    3.0
    4.0
    5.0
    6.0

    To write the dual grid (i.e. corners and cells) use the ``at``
    keyword.

    >>> lines = vtk.dump(grid, at="corner").splitlines()
    >>> print(os.linesep.join(lines[5:12]))
    POINTS 6 float
    1.0 0.288675 0.0
    0.5 0.57735 0.0
    1.5 0.57735 0.0
    0.5 1.154701 0.0
    1.5 1.154701 0.0
    1.0 1.443376 0.0
    """
    content = _format_as_vtk(
        grid, include=include, exclude=exclude, z_coord=z_coord, at=at
    )
    if stream is None:
        return content
    else:
        stream.write(content)


def write_legacy_vtk(
    path, grid, z_at_node="topographic__elevation", fields=None, clobber=False
):
    """
    Write grid and field to a legacy VTK format file or file-like object.

    Parameters
    ----------
    path : file-like
        Path to file or a file-like object
    grid : Landlab grid object
        The grid for which to output data
    z_at_node : str or (n_nodes, ) ndarray
        Field name or array of values to use for z coordinate
    fields : list of str (optional)
        List of node fields to output; default is all node fields
    clobber : bool (optional)
        Ok to overwrite existing file (default False)

    Examples
    --------
    >>> import io
    >>> import os
    >>> import numpy as np
    >>> from landlab import HexModelGrid
    >>> from landlab.io.legacy_vtk import write_legacy_vtk

    >>> grid = HexModelGrid((3, 2))

    >>> topo = np.arange(grid.number_of_nodes)
    >>> grid.at_node["topographic__elevation"] = topo
    >>> grid.at_node["surface_water__depth"] = (7.0 - topo) / 10.0

    >>> vtk_file = write_legacy_vtk(io.StringIO(), grid)
    >>> lines = vtk_file.getvalue().splitlines()
    >>> print(lines[0])
    # vtk DataFile Version 2.0

    >>> print(os.linesep.join(lines[5:13]))
    POINTS 7 float
    0.5 0.0 0.0
    1.5 0.0 1.0
    0.0 0.866025 2.0
    1.0 0.866025 3.0
    2.0 0.866025 4.0
    0.5 1.732051 5.0
    1.5 1.732051 6.0

    >>> print(os.linesep.join(lines[14:21]))
    CELLS 6 24
    3 3 0 1
    3 3 2 0
    3 4 3 1
    3 5 2 3
    3 6 3 4
    3 6 5 3

    >>> print(os.linesep.join(lines[22:29]))
    CELL_TYPES 6
    5
    5
    5
    5
    5
    5

    >>> print(os.linesep.join(lines[30:51]))
    POINT_DATA 7
    <BLANKLINE>
    SCALARS surface_water__depth float 1
    LOOKUP_TABLE default
    0.7
    0.6
    0.5
    0.4
    0.3
    0.2
    0.1
    <BLANKLINE>
    SCALARS topographic__elevation float 1
    LOOKUP_TABLE default
    0.0
    1.0
    2.0
    3.0
    4.0
    5.0
    6.0
    """
    if isinstance(z_at_node, str):
        z_at_node = grid.at_node[z_at_node]

    if fields is None:
        fields = grid.at_node.keys()

    if isinstance(fields, str):
        fields = [fields]
    fields = [f"at_node:{field}" for field in fields]

    if isinstance(path, (str, pathlib.Path)):
        if os.path.exists(path) and not clobber:
            raise ValueError(f"file exists ({path})")

        with open(path, "w") as fp:
            dump(grid, stream=fp, include=fields, z_coord=z_at_node, at="node")

    else:
        dump(grid, stream=path, include=fields, z_coord=z_at_node, at="node")

    return path


def _format_as_vtk(grid, include="*", exclude=None, z_coord=0.0, at="node"):
    if at not in ("node", "corner"):
        raise ValueError(f"`at` keyword must be one of 'node' or 'corner' ({at})")

    if at == "node":
        point, cell = "node", "patch"
    else:
        point, cell = "corner", "cell"

    at_point = getattr(grid, f"at_{point}")
    at_cell = getattr(grid, f"at_{cell}")
    points_at_cell = getattr(grid, f"{point}s_at_{cell}")

    if isinstance(z_coord, str):
        z_coord = at_point[z_coord]

    try:
        coords_of_point = getattr(grid, f"coords_of_{point}")
    except AttributeError:
        coords_of_point = getattr(grid, f"xy_of_{point}")

    if coords_of_point.shape[1] == 2:
        coords_of_point = np.pad(getattr(grid, f"xy_of_{point}"), ((0, 0), (0, 1)))
        try:
            coords_of_point[:, -1] = z_coord
        except ValueError as e:
            e.add_note(
                f"The grid has {len(coords_of_point)} {at}s but the provided value"
                f" value for z_coord has size {np.shape(np.atleast_1d(z_coord))}."
            )
            raise

    content = [
        _format_vtk_header(),
        _format_vtk_points(coords_of_point),
        _format_vtk_cells(points_at_cell),
    ]

    fields = grid.fields(include=include, exclude=exclude)

    point_fields = {
        field.split(":")[1]: at_point[field.split(":")[1]]
        for field in sorted(fields)
        if field.startswith(f"at_{point}:")
    }
    if point_fields:
        content.append(_format_vtk_point_data(point_fields))

    cell_fields = {
        field.split(":")[1]: at_cell[field.split(":")[1]]
        for field in sorted(fields)
        if field.startswith(f"at_{cell}:")
    }
    if cell_fields:
        content.append(_format_vtk_cell_data(cell_fields))

    return (2 * "\n").join(content)


@unique
class CellType(IntEnum):
    TRIANGLE = 5
    QUAD = 9
    POLYGON = 7


VTK_CELL_TYPE = {
    3: CellType.TRIANGLE,
    4: CellType.QUAD,
}


def _format_vtk_header():
    return """\
# vtk DataFile Version 2.0
Landlab output
ASCII
DATASET UNSTRUCTURED_GRID"""


def _format_vtk_points(coords_of_points):
    return "\n".join(
        [f"POINTS {len(coords_of_points)} float"]
        + [" ".join(str(coord) for coord in coords) for coords in coords_of_points]
    )


def _format_vtk_cells(points_at_cell):
    cells = []
    types = []
    n_points = 0
    for cell in points_at_cell:
        points = [point for point in cell if point >= -1]
        if points:
            cells.append(f"{len(points)} " + " ".join(str(point) for point in points))
            types.append(format(VTK_CELL_TYPE.get(len(points), CellType.POLYGON)))
            n_points += len(points) + 1

    cells_section = "\n".join([f"CELLS {len(cells)} {n_points}"] + cells)

    types_section = "\n".join([f"CELL_TYPES {len(types)}"] + types)

    return (2 * "\n").join([cells_section, types_section])


def _format_vtk_point_data(point_data):
    content = []
    for name, value_at_point in point_data.items():
        content.append(_format_vtk_scalar_data(value_at_point, name=name))
        number_of_points = len(value_at_point)

    return (2 * "\n").join([f"POINT_DATA {number_of_points}"] + content)


def _format_vtk_cell_data(cell_data):
    content = []
    for name, value_at_cell in cell_data.items():
        content.append(_format_vtk_scalar_data(value_at_cell, name=name))
        number_of_cells = len(value_at_cell)

    return (2 * "\n").join([f"CELL_DATA {number_of_cells}"] + content)


def _format_vtk_scalar_data(values, name="data"):
    return "\n".join(
        [
            f"""\
SCALARS {name} float 1
LOOKUP_TABLE default"""
        ]
        + [str(float(value)) for value in values]
    )



================================================
File: src/landlab/io/native_landlab.py
================================================
#! /usr/bin/env python
"""Read data from a pickled Landlab grid file into a RasterModelGrid.

Read Landlab native
+++++++++++++++++++

.. autosummary::

    ~load_grid
    ~save_grid
"""

import os
import pickle

from landlab import ModelGrid


def save_grid(grid, path, clobber=False):
    """Save a grid and fields to a Landlab "native" format.

    This method uses pickle to save a grid as a pickle file.
    All fields will be saved, along with the grid.

    The recommended suffix for the save file is '.grid'. This will
    be added to your save if you don't include it.

    Caution: Pickling can be slow, and can produce very large files.
    Caution 2: Future updates to Landlab could potentially render old
    saves unloadable.

    Parameters
    ----------
    grid : object of subclass ModelGrid
        Grid object to save
    path : str
        Path to output file, either without suffix, or '.grid'
    clobber : bool (default False)
        Set to True to allow overwrites of existing files

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.io.native_landlab import save_grid
    >>> import tempfile
    >>> grid_out = RasterModelGrid((4, 5), xy_spacing=2.0)
    >>> with tempfile.TemporaryDirectory() as tmpdirname:
    ...     fname = os.path.join(tmpdirname, "testsavedgrid.grid")
    ...     save_grid(grid_out, fname, clobber=True)
    ...
    """
    if os.path.exists(path) and not clobber:
        raise ValueError("file exists")

    # test it's a grid
    assert issubclass(type(grid), ModelGrid)

    (base, ext) = os.path.splitext(path)
    if ext != ".grid":
        ext = ext + ".grid"
    path = base + ext

    with open(path, "wb") as file_like:
        pickle.dump(grid, file_like)


def load_grid(path):
    """Load a grid and its fields from a Landlab "native" format.

    This method uses pickle to load a saved grid.
    It assumes you saved using vmg.save() or save_grid, i.e., that the
    pickle file is a .grid file.

    Caution: Pickling can be slow, and can produce very large files.
    Caution 2: Future updates to Landlab could potentially render old
    saves unloadable.

    Parameters
    ----------
    path : str
        Path to output file, either without suffix, or '.grid'

    Examples
    --------
    >>> from landlab import VoronoiDelaunayGrid
    >>> from landlab.io.native_landlab import load_grid, save_grid
    >>> import numpy as np
    >>> import tempfile
    >>> x = np.random.rand(20)
    >>> y = np.random.rand(20)
    >>> grid_out = VoronoiDelaunayGrid(x, y)
    >>> with tempfile.TemporaryDirectory() as tmpdirname:
    ...     fname = os.path.join(tmpdirname, "testsavedgrid.grid")
    ...     save_grid(grid_out, fname, clobber=True)
    ...     grid_in = load_grid(fname)
    ...
    """
    (base, ext) = os.path.splitext(path)
    if ext != ".grid":
        ext = ext + ".grid"
    path = base + ext
    with open(path, "rb") as file_like:
        loaded_grid = pickle.load(file_like)
    assert issubclass(type(loaded_grid), ModelGrid)
    return loaded_grid



================================================
File: src/landlab/io/obj.py
================================================
#! /usr/bin/env python
"""Write (x,y,z) data from a Landlab grid + 1 field to a Wavefront OBJ file.

OBJ functions
+++++++++++++

.. autosummary::

    ~write_obj
"""
import os
import pathlib


def _write_obj_vertices(file_like, xyz_at_vertex):
    """Write node (x,y,z) coordinates as OBJ vertices.

    Parameters
    ----------
    file_like : file-like
        Opened file-like object to write vertices to.
    xyz_at_vertex : array-like, shape *(n_vertices, 3)*
        (x, y, z) values for each vertex.
    """
    for x, y, z in xyz_at_vertex:
        print(f"v {x} {y} {z}", file=file_like)


def _write_triangles_as_obj_faces(file_like, vertices_at_face):
    """Write triangular patches as OBJ faces.

    OBJ format uses vertex/UVtexture/normal; latter two left blank here.

    Parameters
    ----------
    file_like : file-like
        Opened file-like object to write faces to.
    vertices_at_face : array-like of int, shape *(n_faces, 3)*
        Vertex ids for each triangle.
    """
    for vertex_0, vertex_1, vertex_2 in vertices_at_face:
        print(f"f {vertex_0}// {vertex_1}// {vertex_2}//", file=file_like)


def _write_quads_as_obj_faces(file_, vertices_at_face):
    """Write quad patches as OBJ (triangle) faces.

    Subdivide each patch into two triangles using vertices 0-1-2 (upper left)
    and 2-3-0 (lower right).

    OBJ format uses vertex/UVtexture/normal; latter two left blank here.

    Parameters
    ----------
    file_like : file-like
        Opened file-like object to write faces to.
    vertices_at_face : array-like of int, shape *(n_faces, 4)*
        Vertex ids for each quadrilateral.
    """
    for vertex_0, vertex_1, vertex_2, vertex_3 in vertices_at_face:
        print(f"f {vertex_0}// {vertex_1}// {vertex_2}//", file=file_)
        print(f"f {vertex_2}// {vertex_3}// {vertex_0}//", file=file_)


def _patches_are_triangles(grid):
    """Returns True if patches have 3 nodes, False otherwise."""
    return grid.nodes_at_patch.shape[1] == 3


def _patches_are_quads(grid):
    """Returns True if patches have 4 nodes, False otherwise."""
    return grid.nodes_at_patch.shape[1] == 4


def write_obj(path, grid, field_for_z="topographic__elevation", clobber=False):
    """Write landlab grid and one field to Wavefront OBJ.

    Parameters
    ----------
    path : str, or file-like
        Path to output file.
    grid : Landlab grid object
        Landlab grid object that includes associated values.
    field_for_z : str, optional
        Name of a field to use for the *z*-values of the OBJ file.
    clobber : boolean, optional
        If *path* exists, clobber the existing file, otherwise raise an
        exception.

    Returns
    -------
    str or file-like
        The input path used to write the OBJ file.

    Examples
    --------
    >>> import io
    >>> from landlab import HexModelGrid, RasterModelGrid
    >>> from landlab.io.obj import write_obj

    >>> grid = HexModelGrid((3, 2), spacing=2.0)
    >>> z = grid.add_zeros("topographic__elevation", at="node")
    >>> z[3] = 1.0

    >>> obj_file = write_obj(io.StringIO(), grid)
    >>> print(obj_file.getvalue())
    # landlabgrid
    #
    g landlabgrid
    v 1.0 0.0 0.0
    v 3.0 0.0 0.0
    v 0.0 1.732051 0.0
    v 2.0 1.732051 1.0
    v 4.0 1.732051 0.0
    v 1.0 3.464102 0.0
    v 3.0 3.464102 0.0
    f 4// 1// 2//
    f 4// 3// 1//
    f 5// 4// 2//
    f 6// 3// 4//
    f 7// 4// 5//
    f 7// 6// 4//
    <BLANKLINE>
    """
    if not (_patches_are_triangles(grid) or _patches_are_quads(grid)):
        raise TypeError("grid faces must be triangles or quads")

    z_at_node = grid.at_node[field_for_z]

    if isinstance(path, (str, pathlib.Path)):
        if os.path.exists(path) and not clobber:
            raise ValueError(f"file exists ({path})")

        with open(path, "w") as fp:
            _write_obj_to_filelike(fp, grid, z_at_node)
    else:
        _write_obj_to_filelike(path, grid, z_at_node)

    return path


def _write_obj_to_filelike(file_like, grid, z_at_node):
    file_like.write("# landlabgrid\n")
    file_like.write("#\n")
    file_like.write("g landlabgrid\n")

    _write_obj_vertices(file_like, zip(grid.x_of_node, grid.y_of_node, z_at_node))
    if _patches_are_triangles(grid):
        _write_triangles_as_obj_faces(file_like, grid.nodes_at_patch + 1)
    elif _patches_are_quads(grid):
        _write_quads_as_obj_faces(file_like, grid.nodes_at_patch + 1)



================================================
File: src/landlab/io/shapefile.py
================================================
#!/usr/bin/env python3
"""Functions to read shapefiles and create a NetworkModelGrid."""
import pathlib

import numpy as np
import pandas as pd
import shapefile as ps

from landlab.graph.graph import NetworkGraph
from landlab.grid.network import NetworkModelGrid


def _read_shapefile(file, dbf):
    kwds = {}
    if dbf is not None:
        kwds["dbf"] = dbf

    if isinstance(file, (str, pathlib.Path)):
        sf = ps.Reader(str(file), **kwds)
    else:
        sf = ps.Reader(shp=file, **kwds)

    return sf


_NUMPY_DTYPE = {
    "integer": (int, float),
    "mixed": (float, complex),
    "mixed-integer": (int, complex),
    "mixed-integer-float": (float,),
    "floating": (float,),
    "complex": (complex,),
    "boolean": (bool,),
}


def _infer_data_type(array, dtype=None):
    """Infer the type of a numpy array.

    Infer the data type of a numpy array based on its values. This function
    is most useful when used on arrays that have *dtype=object* but all of
    its elements are of a standard data type.

    Parameters
    ----------
    array : array_like
        Input data to infer its data type.
    dtype : data-type, optional
        If not provided, infer data type from array elements; otherwise,
        try to cast to the provided data type.

    Returns
    -------
    out : ndarray
        Array interpretation of the input array with either the provided
        data type or one inferred from its elements.

    Examples
    --------
    >>> import numpy as np

    >>> _infer_data_type([1, 2, 3])
    array([1, 2, 3])
    >>> _infer_data_type([1, 2, 3], dtype=float)
    array([1.,  2.,  3.])
    >>> _infer_data_type(np.array([1.0, 2.0, 3.0], dtype=object))
    array([1.,  2.,  3.])
    >>> _infer_data_type([[1, 2, 3]])
    array([[1, 2, 3]])
    >>> _infer_data_type([None, 1, 2, 3])
    array([nan,   1.,   2.,   3.])
    """
    array = np.asarray(array, dtype=dtype)
    if dtype is None and not np.issubdtype(array.dtype, np.number):
        infered_dtype = pd.api.types.infer_dtype(array, skipna=True)
        for dtype in _NUMPY_DTYPE.get(infered_dtype, ()):
            try:
                _array = np.asarray(array.flatten(), dtype=dtype)
            except (TypeError, ValueError):
                pass
            else:
                array = _array.reshape(array.shape)
                break
    return array


def read_shapefile(
    file,
    dbf=None,
    store_polyline_vertices=True,
    points_shapefile=None,
    points_dbf=None,
    link_fields=None,
    node_fields=None,
    link_field_conversion=None,
    node_field_conversion=None,
    link_field_dtype=None,
    node_field_dtype=None,
    threshold=0.0,
):
    """Read shapefile and create a NetworkModelGrid.

    There are a number of assumptions that are required about the shapefile.

    * The shapefile must be a polyline shapefile.
    * All polylines must be their own object (e.g. no multi-part
      polylines).
    * Polyline endpoints match perfectly.

    You might notice that there is no ``write_shapefile`` function. If this is
    something you need for your work, please make a GitHub issue to start this
    process.

    Parameters
    ----------
    file: str or file-like
        File path or file-like of a valid polyline shapefile
    dbf: file-like, optional
        If file is file-like, the dbf must also be passed.
    store_polyline_vertices: bool, optional
        If True (default), store the vertices of the polylines in
        the at_link fields ``x_of_polyline`` and ``y_of_polyline``.
    points_shapefile: str or file-like
        File path or file-like of a valid point shapefile.
    points_dbf: file-like, optional
        If file is file-like, the dbf must also be passed.
    link_fields: list, optional
        List of polyline shapefile attributes to import as landlab at-link
        fields. Default is to import all.
    node_fields: list, optional
        List of point shapefile attributes to import as landlab at-node
        fields. Default is to import all.
    link_field_conversion: dict, optional
        Dictionary mapping polyline shapefile field names to desired at link
        field names. Default is no remapping.
    node_field_conversion: dict, optional
        Dictionary mapping node shapefile field names to desired at node field
        names. Default is no remapping.
    link_field_dtype: dict, optional
        Dictionary mapping node shapefile field names to desired dtype. Default
        is no change to dtype.
    node_field_dtype: dict, optional
        Dictionary mapping node shapefile field names to desired dtype. Default
        is no change to dtype.
    threshold: float, optional
        Maximum distance between a point in the point shapefile and a polyline
        junction in the polyline shapefile. Units are the same as in the
        shapefiles. Default is zero (requiring perfect overlap).

    Returns
    -------
    grid : NetworkModelGrid instance
        The network model grid will have nodes at the endpoints of the
        polylines, and links that connect these nodes. Any fields
        associated with the shapefile will be added as at-link fields. If a
        point shapefile is provided those values will be added as at-node
        fields.

    Examples
    --------
    First, we make a simple shapefile

    >>> from io import BytesIO
    >>> import os

    >>> import shapefile
    >>> shp = BytesIO()
    >>> shx = BytesIO()
    >>> dbf = BytesIO()
    >>> w = shapefile.Writer(shp=shp, shx=shx, dbf=dbf)
    >>> w.shapeType = shapefile.POLYLINE
    >>> w.field("spam", "N")
    >>> w.line([[[5, 5], [10, 10]]])
    >>> w.record(37)
    >>> w.line([[[5, 0], [5, 5]]])
    >>> w.record(100)
    >>> w.line([[[5, 5], [0, 10]]])
    >>> w.record(239)
    >>> w.close()

    Now create a NetworkModelGrid with read_shapefile:

    >>> from landlab.io.shapefile import read_shapefile
    >>> grid = read_shapefile(shp, dbf=dbf)
    >>> grid.nodes
    array([0, 1, 2, 3])
    >>> grid.x_of_node
    array([  5.,   5.,   0.,  10.])
    >>> grid.y_of_node
    array([  0.,   5.,  10.,  10.])
    >>> grid.nodes_at_link
    array([[0, 1],
           [2, 1],
           [1, 3]])
    >>> assert "spam" in grid.at_link
    >>> grid.at_link["spam"]
    array([100, 239, 37])

    Next lets also include a points file. First create both shapefiles.

    >>> shp = BytesIO()
    >>> shx = BytesIO()
    >>> dbf = BytesIO()
    >>> w = shapefile.Writer(shp=shp, shx=shx, dbf=dbf)
    >>> w.shapeType = shapefile.POLYLINE
    >>> w.field("spam", "N")
    >>> w.line([[[5, 5], [10, 10]]])
    >>> w.record(37)
    >>> w.line([[[5, 0], [5, 5]]])
    >>> w.record(100)
    >>> w.line([[[5, 5], [0, 10]]])
    >>> w.record(239)
    >>> w.close()

    >>> p_shp = BytesIO()
    >>> p_shx = BytesIO()
    >>> p_dbf = BytesIO()
    >>> p_w = shapefile.Writer(shp=p_shp, shx=p_shx, dbf=p_dbf)
    >>> p_w.shapeType = shapefile.POINT
    >>> p_w.field("eggs", "N")
    >>> p_w.point(5, 0)
    >>> p_w.record(2)
    >>> p_w.point(5, 5)
    >>> p_w.record(4)
    >>> p_w.point(0, 10)
    >>> p_w.record(8)
    >>> p_w.point(10, 10)
    >>> p_w.record(6)
    >>> p_w.close()

    Now read in both files together.

    >>> grid = read_shapefile(shp, dbf=dbf, points_shapefile=p_shp, points_dbf=p_dbf)
    >>> grid.nodes
    array([0, 1, 2, 3])
    >>> grid.x_of_node
    array([  5.,   5.,   0.,  10.])
    >>> grid.y_of_node
    array([  0.,   5.,  10.,  10.])
    >>> grid.nodes_at_link
    array([[0, 1],
           [2, 1],
           [1, 3]])
    >>> assert "spam" in grid.at_link
    >>> grid.at_link["spam"]
    array([100, 239, 37])
    >>> assert "eggs" in grid.at_node
    >>> grid.at_node["eggs"]
    array([2, 4, 8, 6])
    """
    if node_fields is not None:
        node_fields = set(node_fields)
    if link_fields is not None:
        link_fields = set(link_fields)

    if not points_shapefile and node_fields:
        raise ValueError("node_fields is provided without a points shapefile")

    sf = _read_shapefile(file, dbf)

    link_field_conversion = link_field_conversion or {}
    node_field_conversion = node_field_conversion or {}
    link_field_dtype = link_field_dtype or {}
    node_field_dtype = node_field_dtype or {}

    if sf.shapeTypeName != "POLYLINE":
        raise ValueError(
            "landlab.io.shapefile read requires a polyline "
            "type shapefile. The provided shapefile does "
            "not meet these requirements."
        )

    if points_shapefile:
        psf = _read_shapefile(points_shapefile, points_dbf)
        if psf.shapeTypeName != "POINT":
            raise ValueError(
                "landlab.io.shapefile read requires a point "
                "type shapefile. The provided shapefile does "
                "not meet these requirements."
            )

    # get record information, the first element is ('DeletionFlag', 'C', 1, 0)
    # which we will ignore.
    records = sf.fields[1:]

    # initialize data structures for node (x,y) tuples,
    # link (head_node_id, tail_node_id) tuples, and a dictionary of at-link
    # fields.
    # besides the at-link fields on the shapefile, we'll also store an array of
    # x and y of the full polyline segment'.

    node_xy = []
    links = []
    fields = {rec[0]: [] for rec in records}

    # store which link fields to retain
    if link_fields is None:
        link_fields = set(fields.keys())

    if store_polyline_vertices:
        link_fields.update(["x_of_polyline", "y_of_polyline"])
        fields["x_of_polyline"] = []
        fields["y_of_polyline"] = []

    if not link_fields.issubset(fields):
        raise ValueError(
            "requested link fields to retain are not contained in the shapefile."
        )

    record_order = [rec[0] for rec in records]

    # iterate through shapes and records
    shapeRecs = sf.shapeRecords()
    for sr in shapeRecs:
        # if not a multi-part polyline:
        if len(sr.shape.parts) == 1:
            # get all the points on the polyline and deconstruct into x and y
            points = sr.shape.points
            x, y = zip(*points)

            # construct the (x,y) tuples of the head and tail nodes of each
            # polyline. Note here, that head and tail just refer to starting and
            # ending, they will be re-oriented if necessary by landlab.

            head_node_xy = (x[0], y[0])
            tail_node_xy = (x[-1], y[-1])

            # we should expect that the head node and tail node of later links will
            # already be part of the model grid. So we check, and add the nodes,
            # if they don't already exist.

            if head_node_xy not in node_xy:
                node_xy.append(head_node_xy)

            if tail_node_xy not in node_xy:
                node_xy.append(tail_node_xy)

            # get the index of the head and tail node index.
            head_node__node_id = node_xy.index(head_node_xy)
            tail_node__node_id = node_xy.index(tail_node_xy)

            # append the head and tail node ids to the link array
            links.append((head_node__node_id, tail_node__node_id))

            for i in range(len(sr.record)):
                field_name = record_order[i]
                fields[field_name].append(sr.record[i])

            if store_polyline_vertices:
                fields["x_of_polyline"].append(x)
                fields["y_of_polyline"].append(y)

        else:
            raise ValueError(
                (
                    "landlab.io.shapefile currently does not support ",
                    "reading multipart polyline shapefiles.",
                )
            )

    # Create a Network Model Grid.
    x_of_node, y_of_node = zip(*node_xy)

    # We want to ensure that we maintain sorting, so start by creating an
    # unsorted network graph and sorting.
    # The sorting is important to ensure that the fields are assigned to
    # the correct links.
    graph = NetworkGraph((y_of_node, x_of_node), links=links, sort=False)
    sorted_nodes, sorted_links, sorted_patches = graph.sort()

    # use the sorting information to make a new network model grid.
    grid = NetworkModelGrid(
        (np.asarray(y_of_node)[sorted_nodes], np.asarray(x_of_node)[sorted_nodes]),
        np.vstack((graph.node_at_link_head, graph.node_at_link_tail)).T,
    )

    # add values to fields.
    for field_name in link_fields:
        mapped_field_name = link_field_conversion.get(field_name, field_name)

        values = _convert_array(
            fields[field_name], dtype=link_field_dtype.get(field_name, None)
        )
        grid.at_link[mapped_field_name] = np.take(values, sorted_links)

    # if a points shapefile is added, bring in and use.
    if points_shapefile:
        # get ready to store fields.
        psf_records = psf.fields[1:]
        psf_record_order = [rec[0] for rec in psf_records]
        psf_fields = {rec[0]: [] for rec in psf_records}

        # store which node fields to retain
        if node_fields is None:
            node_fields = set(psf_fields)

        if not node_fields.issubset(psf_fields):
            raise ValueError(
                "requested node fields to retain are not contained in the shapefile."
            )

        # we don't need to store node xy, just need to store which index each
        # node maps to on the new grid.
        psf_node_mapping = np.full(grid.x_of_node.shape, -1, dtype=int)

        # loop through each node
        psf_shapeRecs = psf.shapeRecords()
        for node_idx, sr in enumerate(psf_shapeRecs):
            # find the closest
            point_x = sr.shape.points[0][0]
            point_y = sr.shape.points[0][1]
            x_diff = grid.x_of_node - point_x
            y_diff = grid.y_of_node - point_y

            dist = np.sqrt(x_diff**2 + y_diff**2)

            # check that the distance is small.
            if np.min(dist) > threshold:
                raise ValueError(
                    "landlab.io.shapefile: a point in the points shapefile "
                    f"is {np.min(dist)} away from the closet polyline junction in the "
                    "polyline shapefile. This is larger than the threshold"
                    f"value of {threshold}. This may mean that the threshold"
                    "or that something is wrong with the points file."
                )

            ind = np.nonzero(dist == np.min(dist))[0]
            # verify that there is only one closest.

            if psf_node_mapping[ind[0]] >= 0:
                raise ValueError(
                    "landlab.io.shapefile requires that the points file "
                    "have a 1-1 mapping to the polylines file. More than one "
                    "at-node point provided maps to the node with Landlab ID "
                    f"{ind[0]}, (x,y). This point has coordinates of ({point_x}, {point_y})"
                )

            psf_node_mapping[ind[0]] = node_idx

            for rec_idx in range(len(sr.record)):
                field_name = psf_record_order[rec_idx]
                psf_fields[field_name].append(sr.record[rec_idx])

        if np.any(psf_node_mapping < 0):
            raise ValueError(
                "landlab.io.shapefile requires that the points file "
                "contain the same number of points as polyline junctions. "
                "The points file contains fewer points than polyline junctions."
            )

        # add values to nodes.
        for field_name in node_fields:
            mapped_field_name = node_field_conversion.get(field_name, field_name)

            grid.at_node[mapped_field_name] = _infer_data_type(
                np.take(psf_fields[field_name], psf_node_mapping),
                dtype=node_field_dtype.get(field_name, None),
            )

    return grid


def _convert_array(values, dtype=None):
    try:
        array = np.asarray(values, dtype=dtype)
    except ValueError:
        is_jagged_array = True
    else:
        is_jagged_array = False

    if is_jagged_array:
        array = np.array(
            [_infer_data_type(value, dtype=dtype) for value in values],
            dtype=object,
        )
    return array



================================================
File: src/landlab/io/netcdf/__init__.py
================================================
from .dump import to_netcdf
from .errors import NotRasterGridError
from .load import from_netcdf
from .read import read_netcdf
from .write import write_netcdf
from .write import write_raster_netcdf

__all__ = [
    "from_netcdf",
    "read_netcdf",
    "to_netcdf",
    "write_netcdf",
    "write_raster_netcdf",
    "NotRasterGridError",
]



================================================
File: src/landlab/io/netcdf/_constants.py
================================================
#!/usr/bin/env python
"""Constants used with the netcdf module."""


_DIMENSION_NAMES = ["ni", "nj", "nk"]
_AXES_NAMES = ["x", "y", "z"]

_NP_TO_NC_TYPE = {
    "float32": "f4",
    "float64": "f8",
    "int8": "i1",
    "int16": "i2",
    "int32": "i4",
    "int64": "i8",
    "uint8": "u1",
    "uint16": "u2",
    "uint32": "u4",
    "uint64": "u8",
    "bool": "i1",
}


_AXIS_DIMENSION_NAMES = ["nk", "nj", "ni"]
_AXIS_COORDINATE_NAMES = ["z", "y", "x"]

_DIMENSION_NAMES = set(_AXIS_DIMENSION_NAMES + ["nt"])
_COORDINATE_NAMES = set(_AXIS_COORDINATE_NAMES + ["t"])


_GRID_MAPPING_VARIABLES = [
    "crs_wkt",
    "earth_radius",
    "false_easting",
    "false_northing",
    "grid_mapping_name",
    "grid_north_pole_latitude",
    "grid_north_pole_longitude",
    "inverse_flattening",
    "latitude_of_projection_origin",
    "longitude_of_central_meridian",
    "longitude_of_prime_meridian",
    "longitude_of_projection_origin",
    "north_pole_grid_longitude",
    "perspective_point_height",
    "scale_factor_at_central_meridian",
    "scale_factor_at_projection_origin",
    "semi_major_axis",
    "semi_minor_axis",
    "standard_parallel",
    "straight_vertical_longitude_from_pole",
]



================================================
File: src/landlab/io/netcdf/dump.py
================================================
import pathlib

import numpy as np
import xarray as xr


def to_netcdf(
    grid, path, include="*", exclude=None, time=None, format="NETCDF4", mode="w"
):
    """Write landlab a grid to a netcdf file.

    Write the data and grid information for *grid* to *path* as NetCDF.
    If the *append* keyword argument in True, append the data to an existing
    file, if it exists. Otherwise, clobber an existing files.

    Parameters
    ----------
    grid : ModelGrid
        Landlab grid object that holds a grid and field values.
    path : str
        Path to which to save this grid.
    include : str or iterable of str, optional
        A list of unix-style glob patterns of field names to include. Fully
        qualified field names that match any of these patterns will be
        written to the output file. A fully qualified field name is one that
        that has a prefix that indicates what grid element is defined on
        (e.g. "at_node:topographic__elevation"). The default is to include
        all fields.
    exclude : str or iterable of str, optional
        Like the *include* keyword but, instead, fields matching these
        patterns will be excluded from the output file.
    format : {'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', 'NETCDF4'}
        Format of output netcdf file.
    attrs : dict
        Attributes to add to netcdf file.
    mode : {"w", "a"}, optional
        Write ("w") or append ("a") mode. If mode="w", any existing file at
        this location will be overwritten. If mode="a", existing variables
        will be overwritten.


    Parameters
    ----------
    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.io.netcdf import to_netcdf

    Create a uniform rectilinear grid with four rows and 3 columns, and add
    some data fields to it.

    >>> rmg = RasterModelGrid((4, 3))
    >>> rmg.at_node["topographic__elevation"] = np.arange(12.0)
    >>> rmg.at_node["uplift_rate"] = 2.0 * np.arange(12.0)

    Create a temporary directory to write the netcdf file into.

    >>> import tempfile, os
    >>> temp_dir = tempfile.mkdtemp()
    >>> os.chdir(temp_dir)

    Write the grid to a netcdf3 file but only include the *uplift_rate*
    data in the file.

    >>> to_netcdf(rmg, "test.nc", format="NETCDF3_64BIT", include="at_node:uplift_rate")

    Read the file back in and check its contents.

    >>> from scipy.io import netcdf_file
    >>> fp = netcdf_file("test.nc", "r")
    >>> "at_node:uplift_rate" in fp.variables
    True
    >>> "at_node:topographic__elevation" in fp.variables
    False
    >>> fp.variables["at_node:uplift_rate"][:].flatten().astype("=f8")
    array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,
            22.])

    >>> rmg.at_cell["air__temperature"] = np.arange(2.0)
    >>> to_netcdf(
    ...     rmg,
    ...     "test-cell.nc",
    ...     format="NETCDF3_64BIT",
    ...     include="at_cell:*",
    ...     # names="air__temperature", at="cell",
    ... )
    """
    path = pathlib.Path(path)
    if not path.is_file():
        mode = "w"

    if time is None and mode == "a":
        time = np.nan

    this_dataset = grid.as_dataset(include=include, exclude=exclude, time=time)

    if format != "NETCDF4":
        this_dataset["status_at_node"] = (
            ("node",),
            this_dataset["status_at_node"].values.astype(dtype=int),
        )

    if mode == "a":
        with xr.open_dataset(path) as that_dataset:
            if "time" not in that_dataset.sizes:
                _add_time_dimension_to_dataset(that_dataset, time=np.nan)

            new_vars = set(this_dataset.variables) - set(that_dataset.variables)
            for var in new_vars:
                that_dataset[var] = (
                    this_dataset[var].sizes,
                    np.full_like(this_dataset[var].values, np.nan),
                )

            for var in list(that_dataset.variables):
                if var.startswith("at_layer"):
                    del that_dataset[var]

            this_dataset = xr.concat(
                [that_dataset, this_dataset], dim="time", data_vars="minimal"
            )

            if np.isnan(this_dataset["time"][-1]):
                this_dataset["time"].values[-1] = this_dataset["time"][-2] + 1.0

    this_dataset.to_netcdf(path, format=format, mode="w", unlimited_dims=("time",))


def _add_time_dimension_to_dataset(dataset, time=0.0):
    """Add a time dimension to all variables except those at_layer."""
    names = {
        name
        for name in dataset.variables
        if name.startswith("at_") and not name.startswith("at_layer")
    }

    for name in names:
        dataset[name] = (
            ("time",) + tuple(dataset[name].sizes),
            dataset[name].values[None],
        )
    dataset["time"] = (("time",), [time])



================================================
File: src/landlab/io/netcdf/errors.py
================================================
#! /usr/bin/env
"""Exceptions to raise for the netcdf module."""


class Error(Exception):
    """Base class for errors in this package."""

    pass


class NotRasterGridError(Error):
    """Raise if grid is not uniform rectilinear.

    Raise this error if the grid defined in the netcdf file is not
    uniform rectilinear with constant spacing in all dimensions.
    """

    pass



================================================
File: src/landlab/io/netcdf/load.py
================================================
import fnmatch

import xarray as xr

from ...grid.hex import HexModelGrid
from ...grid.radial import RadialModelGrid
from ...grid.raster import RasterModelGrid


def from_netcdf(filename_or_obj, include="*", exclude=None):
    """Create a :class:`~.ModelGrid` from a netcdf file.

    Create a new :class:`~.ModelGrid` from the netcdf file, *nc_file*.
    If the netcdf file also contains data, add that data to the grid's fields.
    To create a new grid without any associated data from the netcdf file,
    use *include=None*.

    Parameters
    ----------
    filename_or_obj : str, Path, or file
        Strings and Path objects are interpreted as a path to a netCDF file
        or an OpenDAP URL and opened with python-netCDF4, unless the
        filename ends with .gz, in which case the file is gunzipped and
        opened with scipy.io.netcdf (only netCDF3 supported). Byte-strings
        or file-like objects are opened by scipy.io.netcdf (netCDF3)
        or h5py (netCDF4/HDF).
    include : str or iterable of str, optional
        A list of unix-style glob patterns of field names to include. Fully
        qualified field names that match any of these patterns will be
        written to the output file. A fully qualified field name is one that
        that has a prefix that indicates what grid element is defined on
        (e.g. "at_node:topographic__elevation"). The default is to include
        all fields.
    exclude : str or iterable of str, optional
        Like the *include* keyword but, instead, fields matching these
        patterns will be excluded from the output file.

    Returns
    -------
    :class:`~.ModelGrid`
        A newly-created :class:`~.ModelGrid`.
    """
    include = include or []
    if isinstance(include, str):
        include = [include]
    exclude = exclude or []
    if isinstance(exclude, str):
        exclude = [exclude]

    _grid_from_str = {
        "RasterModelGrid": RasterModelGrid,
        "HexModelGrid": HexModelGrid,
        "RadialModelGrid": RadialModelGrid,
        "uniform_rectilinear": RasterModelGrid,
        "triangular": HexModelGrid,
        "radial": RadialModelGrid,
    }

    with xr.open_dataset(filename_or_obj) as dataset:
        grid_type = dataset.attrs["grid_type"]

        try:
            from_dataset = _grid_from_str[grid_type].from_dataset
        except KeyError as exc:
            raise RuntimeError(f"grid type not recognized ({grid_type})") from exc
        else:
            grid = from_dataset(dataset)

        qualified_names = [name for name in dataset.variables if name.startswith("at_")]
        names = set()
        for pattern in include:
            names.update(fnmatch.filter(qualified_names, pattern))
        for pattern in exclude:
            names.difference_update(fnmatch.filter(qualified_names, pattern))

        for name in names:
            at_name, field_name = name.split(":")
            getattr(grid, at_name)[field_name] = dataset[name]

        grid.status_at_node = dataset["status_at_node"]

    return grid



================================================
File: src/landlab/io/netcdf/read.py
================================================
#! /usr/bin/env python
"""Read data from a NetCDF file into a RasterModelGrid.

Read netcdf
+++++++++++

.. autosummary::

    ~read_netcdf
"""
import contextlib

import numpy as np
import xarray as xr

from landlab.io import MismatchGridDataSizeError
from landlab.io import MismatchGridXYLowerLeft
from landlab.io import MismatchGridXYSpacing
from landlab.io.netcdf._constants import _AXIS_COORDINATE_NAMES
from landlab.io.netcdf._constants import _AXIS_DIMENSION_NAMES
from landlab.io.netcdf._constants import _COORDINATE_NAMES
from landlab.io.netcdf.errors import NotRasterGridError
from landlab.utils import add_halo


def _length_of_axis_dimension(root, axis_name):
    """Get the size of an axis by axis name.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF object.
    axis_name : str
        Name of the axis in the NetCDF file.

    Returns
    -------
    int
        Size of the dimension.
    """
    try:
        return len(root.dimensions[axis_name])
    except TypeError:
        return root.dimensions[axis_name]


def _read_netcdf_grid_shape(root):
    """Get the shape of a raster grid.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF object.

    Returns
    -------
    (rows, columns)
        Shape of the grid.
    """
    shape = []
    for axis_name in _AXIS_DIMENSION_NAMES:
        with contextlib.suppress(KeyError):
            shape.append(_length_of_axis_dimension(root, axis_name))
    return tuple(shape)


def _read_netcdf_coordinate_values(root):
    """Get arrays of coordinates for grid points.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.

    Returns
    -------
    tuple of ndarray
        Node coordinates for each dimension.
    """
    values = []
    for coordinate_name in _AXIS_COORDINATE_NAMES:
        with contextlib.suppress(KeyError):
            values.append(root.variables[coordinate_name][:].copy())
    return tuple(values)


def _read_netcdf_coordinate_units(root):
    """Get units for coodinate values.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.

    Returns
    -------
    tuple of str
        Units for each coordinate.
    """
    units = []
    for coordinate_name in _AXIS_COORDINATE_NAMES:
        with contextlib.suppress(KeyError):
            units.append(root.variables[coordinate_name].units)
    return tuple(units)


def _read_netcdf_structured_grid(root):
    """Get node coordinates for a structured grid.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.

    Returns
    -------
    tuple of ndarray
        Node coordinates for each dimension reshaped to match the shape
        of the grid.
    """
    shape = _read_netcdf_grid_shape(root)
    coordinates = _read_netcdf_coordinate_values(root)

    for coordinate in coordinates:
        coordinate.shape = shape

    return coordinates


def _read_netcdf_raster_structured_grid(root):
    """Get node coordinates for a structured grid written as a raster.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.

    Returns
    -------
    tuple of ndarray
        Node coordinates for each dimension reshaped to match the shape
        of the grid.
    """
    shape = _read_netcdf_grid_shape(root)
    coordinates = _read_netcdf_coordinate_values(root)

    if len(coordinates) != 2:
        assert ValueError("Rasters must have only two spatial coordinate dimensions")
    else:
        coordinates = np.meshgrid(coordinates[0], coordinates[1], indexing="ij")

    for coordinate in coordinates:
        coordinate.shape = shape

    return coordinates


def _read_netcdf_structured_data(root):
    """Get data values for a structured grid.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.

    Returns
    -------
    dict
        Data values, reshaped to match that of the grid. Keys are the
        variable names as read from the NetCDF file.
    """
    fields = {}
    grid_mapping_exists = False
    grid_mapping_dict = None
    for name, var in root.variables.items():
        # identify if a grid mapping variable exist and do not pass it as a field
        if name not in _COORDINATE_NAMES and hasattr(var, "grid_mapping"):
            grid_mapping = var.grid_mapping
            if isinstance(grid_mapping, bytes):
                grid_mapping = grid_mapping.decode("utf-8")
            grid_mapping_exists = True

    dont_use = list(_COORDINATE_NAMES)
    if grid_mapping_exists:
        dont_use.append(grid_mapping)
    for name, var in root.variables.items():
        if name not in dont_use:
            fields[name] = var.values.reshape((-1,))

    if grid_mapping_exists:
        grid_mapping_variable = root.variables[grid_mapping]
        grid_mapping_dict = {"name": grid_mapping}
        try:
            for att in grid_mapping_variable.ncattrs():
                grid_mapping_dict[att] = getattr(grid_mapping_variable, att)
        except AttributeError:  # if scipy is doing the reading
            for att in var._attributes:
                grid_mapping_dict[att] = getattr(grid_mapping_variable, att)
    return fields, grid_mapping_dict


def _get_raster_spacing(coords):
    """Get the row and column spacing of a raster grid.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF object.

    Returns
    -------
    (dy, dx)
        Spacing of grid rows and columns.
    """
    spacing = np.empty(len(coords), dtype=np.float64)

    for axis, coord in enumerate(coords):
        coord_spacing = np.diff(coord, axis=axis)
        if not np.all(coord_spacing == coord_spacing.flat[0]):
            raise NotRasterGridError()
        spacing[axis] = coord_spacing.flat[0]

    if not np.all(spacing == spacing[0]):
        raise NotRasterGridError()

    return spacing[0]


def read_netcdf(
    nc_file,
    grid=None,
    name=None,
    just_grid=False,
    halo=0,
    nodata_value=-9999.0,
):
    """Create a :class:`~.RasterModelGrid` from a netcdf file.

    Create a new :class:`~.RasterModelGrid` from the netcdf file, *nc_file*.
    If the netcdf file also contains data, add that data to the grid's fields.
    To create a new grid without any associated data from the netcdf file,
    set the *just_grid* keyword to ``True``.

    A halo can be added with the keyword *halo*.

    If you want the fields to be added to an existing grid, it can be passed
    to the keyword argument *grid*.

    Parameters
    ----------
    nc_file : str
        Name of a netcdf file.
    grid : *grid* , optional
        Adds data to an existing *grid* instead of creating a new one.
    name : str, optional
        Add only fields with NetCDF variable name to the grid. Default is to
        add all NetCDF varibles to the grid.
    just_grid : boolean, optional
        Create a new grid but don't add value data.
    halo : integer, optional
        Adds outer border of depth halo to the *grid*.
    nodata_value : float, optional
        Value that indicates an invalid value. Default is -9999.

    Returns
    -------
    :class:`~.RasterModelGrid`
        A newly-created :class:`~.RasterModelGrid`.

    Examples
    --------
    Import :func:`read_netcdf` and the path to an example netcdf file included
    with landlab.

    >>> from landlab.io.netcdf import read_netcdf

    Create a new grid from the netcdf file. The example grid is a uniform
    rectilinear grid with 4 rows and 3 columns of nodes with unit spacing.
    The data file also contains data defined at the nodes for the grid for
    a variable called, *surface__elevation*.

    >>> grid = read_netcdf("test-netcdf4.nc")  # doctest: +SKIP
    >>> grid.shape == (4, 3)  # doctest: +SKIP
    True
    >>> grid.dy, grid.dx  # doctest: +SKIP
    (1.0, 1.0)
    >>> list(grid.at_node.keys())  # doctest: +SKIP
    ['surface__elevation']
    >>> grid.at_node["surface__elevation"]  # doctest: +SKIP
    array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,
            11.])

    :func:`read_netcdf` will try to determine the format of the netcdf file.
    For example, the same call will also work for *netcdf3*-formatted files.

    >>> grid = read_netcdf("test-netcdf3-64bit.nc")  # doctest: +SKIP
    >>> grid.shape == (4, 3)  # doctest: +SKIP
    True
    >>> grid.dy, grid.dx  # doctest: +SKIP
    (1.0, 1.0)

    A more complicated example might add data with a halo to an existing grid.
    Note that the lower left corner must be specified correctly for the data
    and the grid to align correctly.

    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((6, 5), xy_of_lower_left=(-1.0, -1.0))  # doctest: +SKIP
    >>> grid = read_netcdf(
    ...     "test-netcdf4.nc",
    ...     grid=grid,
    ...     halo=1,
    ...     nodata_value=-1,
    ... )  # doctest: +SKIP
    >>> grid.at_node["surface__elevation"].reshape(grid.shape)  # doctest: +SKIP
    array([[ -1.,  -1.,  -1.,  -1.,  -1.],
           [ -1.,   0.,   1.,   2.,  -1.],
           [ -1.,   3.,   4.,   5.,  -1.],
           [ -1.,   6.,   7.,   8.,  -1.],
           [ -1.,   9.,  10.,  11.,  -1.],
           [ -1.,  -1.,  -1.,  -1.,  -1.]])
    """
    from landlab import RasterModelGrid

    dataset = xr.open_dataset(nc_file)

    if isinstance(name, str):
        names = {name}
    elif name is None:
        names = set(dataset.variables)
    else:
        names = set(name)

    # test if the input is a raster (x and y) are only 1-D instead of 2D.
    if len(dataset["x"].shape) == 1:
        y, x = np.meshgrid(dataset["y"], dataset["x"], indexing="ij")
    else:
        x = dataset["x"]
        y = dataset["y"]

    dx = np.diff(x, axis=1)
    dy = np.diff(y, axis=0)

    if np.all(dx == dx[0, 0]) and np.all(dy == dy[0, 0]):
        xy_spacing = (dx[0, 0], dy[0, 0])
    else:
        raise NotRasterGridError()

    shape = x.shape
    xy_of_lower_left = (
        x[0, 0] - halo * xy_spacing[0],
        y[0, 0] - halo * xy_spacing[1],
    )

    if grid is None:
        grid = RasterModelGrid(
            shape, xy_spacing=xy_spacing, xy_of_lower_left=xy_of_lower_left
        )
    else:
        if grid.shape != (shape[0] + 2 * halo, shape[1] + 2 * halo):
            raise MismatchGridDataSizeError(
                shape[0] + 2 * halo * shape[1] + 2 * halo,
                grid.number_of_node_rows * grid.number_of_node_columns,
            )
        if (grid.dx, grid.dy) != xy_spacing:
            raise MismatchGridXYSpacing((grid.dx, grid.dy), xy_spacing)

        if grid.xy_of_lower_left != xy_of_lower_left:
            raise MismatchGridXYLowerLeft(grid.xy_of_lower_left, xy_of_lower_left)

    if not just_grid:
        fields, grid_mapping_dict = _read_netcdf_structured_data(dataset)
        for field_name, values in fields.items():
            # add halo if necessary
            if halo > 0:
                values = add_halo(
                    values.reshape(shape), halo=halo, halo_value=nodata_value
                ).reshape((-1,))

            # add only the requested fields.
            if (name is None) or (field_name == name):
                add_field = True
            else:
                add_field = False

            if add_field:
                grid.add_field(field_name, values, at="node", clobber=True)

        if (name is not None) and (name not in grid.at_node):
            raise ValueError(f"Specified field {name} was not in provided NetCDF.")

    ignore = {"x", "y"}
    for name in names - ignore:
        values = dataset.variables[name].values
        if halo > 0:
            values = add_halo(
                values.reshape(shape), halo=halo, halo_value=nodata_value
            ).reshape((-1,))
        grid.add_field(name, values, at="node", clobber=True)

    return grid



================================================
File: src/landlab/io/netcdf/write.py
================================================
#! /usr/bin/env python
"""Write structured grids to NetCDF files.

Write netcdf
++++++++++++

.. autosummary::

    ~write_netcdf
"""
import pathlib

import numpy as np
import xarray as xr

from landlab.io.netcdf._constants import _AXIS_COORDINATE_NAMES
from landlab.io.netcdf._constants import _AXIS_DIMENSION_NAMES
from landlab.io.netcdf._constants import _NP_TO_NC_TYPE


def _set_netcdf_attributes(root, attrs):
    """Set attributes of a netcdf file.

    Set attributes of the netCDF Database object, *root*. Attributes are
    given as key/value pairs from *attrs*.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    attrs : dict
        Attributes as key-value pairs.
    """
    for key, val in attrs.items():
        setattr(root, key, val)


def _get_dimension_names(shape):
    """Get dimension names.

    Parameters
    ----------
    shape : tuple of int
        Shape of a structured grid.

    Returns
    -------
    tuple of str
        Dimension names for the NetCDF file.

    Examples
    --------
    >>> from landlab.io.netcdf.write import _get_dimension_names
    >>> _get_dimension_names((4,))
    ['ni']
    >>> _get_dimension_names((4, 5))
    ['nj', 'ni']
    >>> _get_dimension_names((4, 5, 6))
    ['nk', 'nj', 'ni']
    """
    names = _AXIS_DIMENSION_NAMES[-1 : -(len(shape) + 1) : -1]
    return names[::-1]


def _get_dimension_sizes(shape):
    """Get dimension sizes.

    Parameters
    ----------
    shape : tuple of int
        Shape of a structured grid.

    Returns
    -------
    dict
        Dimension sizes.

    Examples
    --------
    >>> from landlab.io.netcdf.write import _get_dimension_sizes
    >>> _get_dimension_sizes((4,))
    {'ni': 4}
    >>> sizes = _get_dimension_sizes((4, 5))
    >>> sizes["ni"], sizes["nj"]
    (5, 4)
    >>> sizes = _get_dimension_sizes((4, 5, 6))
    >>> sizes["ni"], sizes["nj"], sizes["nk"]
    (6, 5, 4)
    """
    names = _AXIS_DIMENSION_NAMES[-1 : -(len(shape) + 1) : -1]

    sizes = {}
    for axis, name in enumerate(names):
        sizes[name] = shape[-(axis + 1)]

    return sizes


def _get_axes_names(shape):
    """Get names of the axes.

    Parameters
    ----------
    shape : tuple of int
        Shape of a structured grid.

    Returns
    -------
    tuple of str
        Names of the axes for the NetCDF file.

    Examples
    --------
    >>> from landlab.io.netcdf.write import _get_axes_names
    >>> _get_axes_names((2,))
    ['x']
    >>> _get_axes_names((2, 3))
    ['y', 'x']
    >>> _get_axes_names((2, 3, 4))
    ['z', 'y', 'x']
    """
    names = _AXIS_COORDINATE_NAMES[-1 : -(len(shape) + 1) : -1]
    return names[::-1]


def _get_cell_bounds(shape, spacing=(1.0, 1.0), origin=(0.0, 0.0)):
    """Get bounds arrays for square cells.

    Parameters
    ----------
    shape : tuple of int
        Shape of the grid in cell corners.
    spacing : tuple of float
        Height and width of cells.
    origin : tuple of float
        Coordinates of lower-left corner of lower-left cell.

    Returns
    -------
    (y, x) : tuple of ndarray
        Tuple of the *y* and *x* coordinates of each cell corner (ordered
        counter-clockwise starting from lower-right. The shape of the returned
        arrays will be *(rows, cols, 4)*.

    Examples
    --------
    >>> from landlab.io.netcdf.write import _get_cell_bounds
    >>> bounds = _get_cell_bounds((3, 4))
    >>> bounds["y_bnds"]
    array([[[0.,  1.,  1.,  0.], [0.,  1.,  1.,  0.], [0.,  1.,  1.,  0.]],
           [[1.,  2.,  2.,  1.], [1.,  2.,  2.,  1.], [1.,  2.,  2.,  1.]]])
    >>> bounds["x_bnds"]
    array([[[1.,  1.,  0.,  0.], [2.,  2.,  1.,  1.], [3.,  3.,  2.,  2.]],
           [[1.,  1.,  0.,  0.], [2.,  2.,  1.,  1.], [3.,  3.,  2.,  2.]]])
    """
    rows = np.arange(shape[0]) * spacing[0] + origin[0]
    cols = np.arange(shape[1]) * spacing[1] + origin[1]

    corner_y, corner_x = np.meshgrid(rows, cols, indexing="ij")

    y_bnds = np.vstack(
        (
            corner_y[:-1, 1:].flat,
            corner_y[1:, 1:].flat,
            corner_y[1:, :-1].flat,
            corner_y[:-1, :-1].flat,
        )
    ).T
    x_bnds = np.vstack(
        (
            corner_x[:-1, 1:].flat,
            corner_x[1:, 1:].flat,
            corner_x[1:, :-1].flat,
            corner_x[:-1, :-1].flat,
        )
    ).T

    return {
        "y_bnds": y_bnds.reshape((shape[0] - 1, shape[1] - 1, 4)),
        "x_bnds": x_bnds.reshape((shape[0] - 1, shape[1] - 1, 4)),
    }


def _set_netcdf_cell_structured_dimensions(root, shape):
    """Set dimensions for a structured grid of cells.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    shape : tuple of int
        Shape of the cell grid (rows of cells, columns of cells).
    """
    if len(shape) < 1 or len(shape) > 3:
        raise ValueError("grid dimension must be 1, 2, or 3")

    dimensions = _get_dimension_sizes(shape)

    dims = root.dimensions

    if "nt" not in dims:
        root.createDimension("nt", None)

    for name, dim_size in dimensions.items():
        if name not in dims:
            root.createDimension(name, dim_size - 2)

    root.createDimension("nv", 4)


def _set_netcdf_structured_dimensions(root, shape):
    """Set dimensions for a structured grid.

    Add dimensions to *root* for a structured grid of size *shape*. The
    dimension names will be 'ni', 'nj', and 'nk'. 'ni' is the length of the
    fast dimension, followed by 'nj', and then 'nk'.

    For example, a grid with shape (3, 4, 5) will have dimensions ni=5,
    nj=4, and nk=3. Lower dimension grids simply drop the slowest dimension.
    Thus, a grid with shape (3, 4) has dimensions ni=4, and nj=3.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    shape : tuple of int
        Shape of the grid.
    """
    if len(shape) < 1 or len(shape) > 3:
        raise ValueError("grid dimension must be 1, 2, or 3")

    dimensions = _get_dimension_sizes(shape)

    dims = root.dimensions

    if "nt" not in dims:
        root.createDimension("nt", None)

    for name, dim_size in dimensions.items():
        if name not in dims:
            root.createDimension(name, dim_size)


def _set_netcdf_variables(root, fields, **kwds):
    """Set the field variables.

    First set the variables that define the grid and then the variables
    at the grid nodes and cells.
    """
    names = kwds.pop("names", None)

    _add_spatial_variables(root, fields, **kwds)
    _add_variables_at_points(root, fields, names=names)


def _set_netcdf_raster_variables(root, fields, **kwds):
    """Set the field variables for rasters.

    First set the variables that define the grid and then the variables
    at the grid nodes and cells.
    """
    names = kwds.pop("names", None)

    _add_raster_spatial_variables(root, fields, **kwds)
    _add_variables_at_points(root, fields, names=names)


def _set_netcdf_cell_variables(root, fields, **kwds):
    """Set the cell field variables.

    First set the variables that define the grid and then the variables
    at the grid nodes and cells.
    """
    names = kwds.pop("names", None)

    _add_cell_spatial_variables(root, fields, **kwds)
    _add_variables_at_cells(root, fields, names=names)


def _add_cell_spatial_variables(root, grid, **kwds):
    """Add the spatial variables that describe the cell grid."""
    long_name = kwds.get("long_name", {})

    cell_grid_shape = [dim - 1 for dim in grid.shape]
    spatial_variable_shape = _get_dimension_names(cell_grid_shape)

    bounds = _get_cell_bounds(
        cell_grid_shape,
        spacing=(grid.dy, grid.dx),
        origin=(grid.dy * 0.5, grid.dx * 0.5),
    )

    shape = spatial_variable_shape + ["nv"]
    for name, values in bounds.items():
        # var = root.createVariable(name, 'f8', shape)
        # var[:] = values

        try:
            var = root.variables[name]
        except KeyError:
            var = root.createVariable(name, "f8", shape)

        var[:] = values

        axis = grid.axis_name.index(name[0])

        var.units = str(grid.axis_units[axis])
        try:
            var.long_name = str(long_name[name])
        except KeyError:
            var.long_name = str(grid.axis_name[axis])


def _add_spatial_variables(root, grid, **kwds):
    """Add spatial variables to a NetCDF file.

    Add the variables to *root* that define the structured grid, *grid*.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    grid : RasterModelGrid
        A structured grid.
    long_name : dict, optional
        Long name for each spatial variable to add. Keys are grid field
        names, values are corresponding long names.
    """
    long_name = kwds.get("long_name", {})

    netcdf_vars = root.variables

    spatial_variable_names = _get_axes_names(grid.shape)
    spatial_variable_shape = _get_dimension_names(grid.shape)

    for axis, name in enumerate(spatial_variable_names):
        try:
            var = netcdf_vars[name]
        except KeyError:
            var = root.createVariable(name, "f8", spatial_variable_shape)

        coords = grid.node_axis_coordinates(axis=axis).view()
        coords.shape = var.shape
        var[:] = coords

        var.units = grid.axis_units[axis].encode("utf-8")
        try:
            var.long_name = long_name[name].encode("utf-8")
        except KeyError:
            var.long_name = grid.axis_name[axis].encode("utf-8")


def _add_raster_spatial_variables(root, grid, **kwds):
    """Add spatial variables to a NetCDF file for rasters.

    Add the variables to *root* that define the structured grid, *grid*.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    grid : RasterModelGrid
        A structured grid.
    long_name : dict, optional
        Long name for each spatial variable to add. Keys are grid field
        names, values are corresponding long names.
    """
    long_name = kwds.get("long_name", {})

    netcdf_vars = root.variables

    spatial_variable_names = _get_axes_names(grid.shape)
    spatial_variable_shape = _get_dimension_names(grid.shape)

    for axis, name in enumerate(spatial_variable_names):
        try:
            var = netcdf_vars[name]
        except KeyError:
            var = root.createVariable(name, "f8", [spatial_variable_shape[axis]])

        coords = grid.node_axis_coordinates(axis=axis).view().reshape(grid.shape)
        if axis == 1:
            coords = coords[1, :]
        elif axis == 0:
            coords = coords[:, 1]
        else:
            raise NotImplementedError("")
        coords.shape = var.shape

        var[:] = coords

        var.units = str(grid.axis_units[axis])
        try:
            var.long_name = str(long_name[name])
        except KeyError:
            var.long_name = str(grid.axis_name[axis])


def _add_variables_at_points(root, fields, names=None):
    if isinstance(names, str):
        names = [names]
    names = names or fields["node"].keys()

    netcdf_vars = root.variables

    spatial_variable_shape = _get_dimension_names(fields.shape)

    try:
        n_times = len(netcdf_vars["t"]) - 1
    except TypeError:
        n_times = len(netcdf_vars["t"][:]) - 1
    except KeyError:
        n_times = 0

    node_fields = fields["node"]
    for var_name in names:
        try:
            var = netcdf_vars[var_name]
        except KeyError:
            var = root.createVariable(
                var_name,
                _NP_TO_NC_TYPE[str(node_fields[var_name][0].dtype)],
                ["nt"] + spatial_variable_shape,
            )

        if node_fields[var_name].size > 1:
            data = node_fields[var_name].view()
            data.shape = var.shape[1:]
            try:
                var[n_times, :] = data
            except ValueError:
                raise
        else:
            var[n_times] = node_fields[var_name].flat[0]

        var.units = node_fields.units[var_name] or "?"
        var.long_name = var_name

        if hasattr(fields, "grid_mapping"):
            var.grid_mapping = fields.grid_mapping["name"]


def _add_variables_at_cells(root, fields, names=None):
    if isinstance(names, str):
        names = [names]
    names = names or fields["cell"].keys()

    netcdf_vars = root.variables

    cell_grid_shape = [dim - 1 for dim in fields.shape]

    spatial_variable_shape = _get_dimension_names(cell_grid_shape)

    try:
        n_times = len(netcdf_vars["t"]) - 1
    except KeyError:
        n_times = 0

    cell_fields = fields["cell"]
    for var_name in names:
        try:
            var = netcdf_vars[var_name]
        except KeyError:
            var = root.createVariable(
                var_name,
                _NP_TO_NC_TYPE[str(cell_fields[var_name].dtype)],
                ["nt"] + spatial_variable_shape,
            )

        if cell_fields[var_name].size > 1:
            data = cell_fields[var_name].view()
            data.shape = var.shape[1:]
            try:
                var[n_times, :] = data
            except ValueError:
                raise
        else:
            var[n_times] = cell_fields[var_name].flat[0]

        var.units = str(cell_fields.units[var_name] or "?")
        var.long_name = str(var_name)


def _add_time_variable(root, time, **kwds):
    """Add a time value to a NetCDF file.

    Append a new time value to the time variable of a NetCDF file. If there
    is not time variable, create one. The time variable is named, ``t``.

    Parameters
    ----------
    root : netcdf_file
        A NetCDF file.
    time : float
        The time.
    units : str, optional
        Time units.
    reference : str, optional
        Reference time.
    """
    units = kwds.get("units", "days")
    reference = kwds.get("reference", "00:00:00 UTC")

    netcdf_vars = root.variables

    try:
        time_var = netcdf_vars["t"]
    except KeyError:
        time_var = root.createVariable("t", "f8", ("nt",))
        time_var.units = " ".join([units, "since", reference])
        time_var.long_name = "time"

    try:
        n_times = len(time_var)
    except TypeError:
        n_times = len(time_var[:])
    if time is not None:
        time_var[n_times] = time
    else:
        time_var[n_times] = n_times


def _set_netcdf_grid_mapping_variable(root, grid_mapping):
    """Create grid mapping variable, if necessary."""
    name = grid_mapping.pop("name")
    var = root.createVariable(name, "S1", dimensions=())
    for attr in grid_mapping.keys():
        setattr(var, attr, grid_mapping[attr])


_VALID_NETCDF_FORMATS = {
    "NETCDF3_CLASSIC",
    "NETCDF3_64BIT",
    "NETCDF4_CLASSIC",
    "NETCDF4",
}


def _guess_at_location(fields, names):
    """Guess where the values should be located."""
    node_fields = set(fields["node"].keys())
    cell_fields = set(fields["cell"].keys())

    if names is None or len(names) == 0:
        if len(node_fields) > 0:
            at = "node"
        else:
            at = "cell"
    else:
        if node_fields.issuperset(names):
            at = "node"
        elif cell_fields.issuperset(names):
            at = "cell"
        else:
            at = None
    return at


def write_netcdf(
    path,
    grid,
    attrs=None,
    append=False,
    format="NETCDF3_64BIT",
    names=None,
    at=None,
    time=None,
    raster=False,
):
    """Write landlab fields to netcdf.

    Write the data and grid information for *grid* to *path* as NetCDF.
    If the *append* keyword argument in True, append the data to an existing
    file, if it exists. Otherwise, clobber an existing files.

    Parameters
    ----------
    path : str
        Path to output file.
    grid : RasterModelGrid
        Landlab RasterModelGrid object that holds a grid and associated values.
    append : boolean, optional
        Append data to an existing file, otherwise clobber the file.
    format : {'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', 'NETCDF4'}
        Format of output netcdf file.
    attrs : dict
        Attributes to add to netcdf file.
    names : iterable of str, optional
        Names of the fields to include in the netcdf file. If not provided,
        write all fields.
    at : {'node', 'cell'}, optional
        The location where values are defined.
    raster : bool, optional
        Indicate whether spatial dimensions are written as full value arrays
        (default) or just as coordinate dimensions.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.io.netcdf import write_netcdf

    Create a uniform rectilinear grid with four rows and 3 columns, and add
    some data fields to it.

    >>> rmg = RasterModelGrid((4, 3))
    >>> rmg.at_node["topographic__elevation"] = np.arange(12.0)
    >>> rmg.at_node["uplift_rate"] = 2.0 * np.arange(12.0)

    Create a temporary directory to write the netcdf file into.

    >>> import tempfile, os
    >>> temp_dir = tempfile.mkdtemp()
    >>> os.chdir(temp_dir)

    Write the grid to a netcdf3 file but only include the *uplift_rate*
    data in the file.

    >>> write_netcdf("test.nc", rmg, format="NETCDF3_64BIT", names="uplift_rate")

    Read the file back in and check its contents.

    >>> from scipy.io import netcdf_file
    >>> fp = netcdf_file("test.nc", "r")
    >>> "uplift_rate" in fp.variables
    True
    >>> "topographic__elevation" in fp.variables
    False
    >>> fp.variables["uplift_rate"][:].flatten().astype("=f8")
    array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,
            22.])

    >>> rmg.at_cell["air__temperature"] = np.arange(2.0)
    >>> write_netcdf(
    ...     "test-cell.nc",
    ...     rmg,
    ...     format="NETCDF3_64BIT",
    ...     names="air__temperature",
    ...     at="cell",
    ... )
    """
    path = pathlib.Path(path)
    if append and not path.exists():
        append = False

    if at not in (None, "cell", "node"):
        raise ValueError("value location not understood")

    if isinstance(names, str):
        names = (names,)

    at = at or _guess_at_location(grid, names) or "node"
    if names is None:
        names = grid[at].keys()

    if not set(grid[at].keys()).issuperset(names):
        raise ValueError("values must be on either cells or nodes, not both")

    attrs = attrs or {}

    dims = ("nt", "nj", "ni")
    shape = grid.shape
    if at == "cell":
        shape = shape[0] - 2, shape[1] - 2

    data = {}
    if append:
        with xr.open_dataset(path) as dataset:
            time_varying_names = [
                name for name in dataset.variables if "nt" in dataset[name].sizes
            ]
            for name in set(time_varying_names) & set(names):
                values = getattr(grid, "at_" + at)[name].reshape((1,) + shape)
                data[name] = (dims, np.concatenate([dataset[name].values, values]))

            if "t" not in dataset.variables:
                times = np.arange(len(dataset["nt"]) + 1)
            else:
                times = np.concatenate((dataset["t"].values, [0.0]))

        if time is None:
            times[-1] = times[-2] + 1.0
        else:
            times[-1] = time
        data["t"] = (("nt",), times)

    if at == "cell":
        data["x_bnds"] = (
            ("nj", "ni", "nv"),
            grid.x_of_corner[grid.corners_at_cell].reshape(shape + (4,)),
        )
        data["y_bnds"] = (
            ("nj", "ni", "nv"),
            grid.y_of_corner[grid.corners_at_cell].reshape(shape + (4,)),
        )
    else:
        if raster:
            data["x"] = (("ni"), grid.x_of_node.reshape(shape)[0, :])
            data["y"] = (("nj"), grid.y_of_node.reshape(shape)[:, 0])
        else:
            data["x"] = (("nj", "ni"), grid.x_of_node.reshape(shape))
            data["y"] = (("nj", "ni"), grid.y_of_node.reshape(shape))

    if not append:
        if time is not None:
            data["t"] = (("nt",), [time])
        for name in names:
            data[name] = (
                dims,
                getattr(grid, "at_" + at)[name].reshape((-1,) + shape),
            )

    dataset = xr.Dataset(data, attrs=attrs)

    dataset.to_netcdf(path, mode="w", format=format, unlimited_dims=("nt",))


def write_raster_netcdf(
    path,
    fields,
    attrs=None,
    append=False,
    time=None,
    format="NETCDF4",
    names=None,
    at=None,
):
    """Write Raster Model Grid landlab fields to netcdf.

    Write the data and grid information for *fields* to *path* as NetCDF.

    This method is for Raster Grids only and takes advantage of regular x and
    y spacing to save memory.

    Rather that writing x and y of node locations at all (nr x nc) locations,
    it writes a 1D array each for x and y.

    A more modern version of this might write x and y location as a netcdf
    coordinate. However, the original version of this function wrote x and y
    as data variables rather than coordinates.

    If the *append* keyword argument in True, append the data to an existing
    file, if it exists. Otherwise, clobber an existing files.

    Parameters
    ----------
    path : str
        Path to output file.
    fields : field-like
        Landlab field object that holds a grid and associated values. This must
        be a Raster type.
    append : boolean, optional
        Append data to an existing file, otherwise clobber the file.
    time : float, optional
        Add a time to the time variable.
    format : {'NETCDF4'}
        Format of output netcdf file.
    attrs : dict
        Attributes to add to netcdf file.
    names : iterable of str, optional
        Names of the fields to include in the netcdf file. If not provided,
        write all fields.
    at : {'node'}, optional
        The location where values are defined. Presently only implemented for
        type 'node'.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.io.netcdf import write_raster_netcdf

    Create a uniform rectilinear grid with four rows and 3 columns, and add
    some data fields to it.

    >>> rmg = RasterModelGrid((4, 3))
    >>> rmg.shape
    (4, 3)
    >>> rmg.at_node["topographic__elevation"] = np.arange(12.0)
    >>> rmg.at_node["uplift_rate"] = 2.0 * np.arange(12.0)

    Create a temporary directory to write the netcdf file into.

    >>> import tempfile, os
    >>> temp_dir = tempfile.mkdtemp()
    >>> os.chdir(temp_dir)

    Write the grid to a netcdf4 file but only include the *uplift_rate*
    data in the file.

    >>> write_raster_netcdf(
    ...     "test.nc",
    ...     rmg,
    ...     format="NETCDF3_64BIT",
    ...     names="uplift_rate",
    ... )

    Read the file back in and check its contents.

    >>> from scipy.io import netcdf_file
    >>> fp = netcdf_file("test.nc", "r")
    >>> "uplift_rate" in fp.variables
    True
    >>> "topographic__elevation" in fp.variables
    False
    >>> fp.variables["uplift_rate"][:].flatten().astype("=f8")
    array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,
            22.])
    >>> fp.variables["x"][:].astype("=f8")
    array([0.,  1.,  2.])
    >>> fp.variables["y"][:].astype("=f8")
    array([0.,  1.,  2.,  3.])

    Read now with read_netcdf

    >>> from landlab.io.netcdf import read_netcdf
    >>> grid = read_netcdf("test.nc")
    >>> grid.shape
    (4, 3)
    >>> grid.x_of_node
    array([0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.])
    >>> grid.y_of_node
    array([0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.,  3.,  3.,  3.])
    >>> grid.at_node["uplift_rate"]
    array([ 0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,
           22.])
    """
    return write_netcdf(
        path,
        fields,
        attrs=attrs,
        append=append,
        format=format,
        names=names,
        at=at,
        time=time,
        raster=True,
    )



================================================
File: src/landlab/layers/__init__.py
================================================
from .eventlayers import EventLayers
from .eventlayers import EventLayersMixIn
from .materiallayers import MaterialLayers
from .materiallayers import MaterialLayersMixIn

__all__ = ["EventLayers", "EventLayersMixIn", "MaterialLayers", "MaterialLayersMixIn"]



================================================
File: src/landlab/layers/eventlayers.py
================================================
import os

import numpy as np


def _deposit_or_erode(layers, n_layers, dz):
    """Update the array that contains layers with deposition or erosion.

    This function operates on the entire array that contain the layers (active,
    and allocated but not yet active). The number of active layers includes the
    layer that is currently being added. Thus the row with the index
    ``n_layers - 1`` is the layer that is currently being added as an active
    layer.

    Note that in EventLayers, layers represent an event, and not necessarily
    material.

    This means that if only erosion occurs, the array elements in the row with
    the index ``n_layers - 1`` will be set to zero and thickness will be
    removed from lower layers. Note that lower layers have smaller row indicies
    as the bottom of the layer stack has row index zero.

    If deposition occurs, the array elements in the row with index
    ``n_layers - 1`` will be set to the value of dz.

    Parameters
    ----------
    layers : ndarray of shape `(n_layers, n_nodes)`
        Array of layer thicknesses. This array is the datastructure that
        contains all allocated layers, active or inactive.
    n_layers : int
        Number of active layers.
    dz : ndarray of shape `(n_nodes, )`
        Thickness of the new layer. Negative thicknesses mean
        erode the top-most layers.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.layers.eventlayers import _deposit_or_erode

    First we create a numpy array allocated to contain layers. We fill it with
    -1. These -1.'s do not represent negative layer thickness. In EventLayers
    this array is created with np.empty, but that creates different numbers
    every time and doesn't work for testing.

    >>> allocated_layers_array = np.full((4, 3), 0.0)

    Next we add a layer with spatially variable thickness. We specify that the
    number of active layers (including the one being added) is 1.

    >>> dz = np.array([1.0, 2.0, 3.0])
    >>> _deposit_or_erode(allocated_layers_array, 1, dz)
    >>> allocated_layers_array
    array([[1.,  2.,  3.],
           [0.,  0.,  0.],
           [0.,  0.,  0.],
           [0.,  0.,  0.]])

    As you can see, this changes the value of the first row in the array. The
    remainder of the array represents space in the datatastructure that has
    been allocated to contain layers, but does not yet contain active layers.

    Next we add a layer of thickness 1. To do this, we now need to specify that
    the number of active layers is 2.

    >>> dz = np.array([1.0, 1.0, 1.0])
    >>> _deposit_or_erode(allocated_layers_array, 2, dz)
    >>> allocated_layers_array
    array([[1.,  2.,  3.],
           [1.,  1.,  1.],
           [0.,  0.,  0.],
           [0.,  0.,  0.]])

    Finally, we do some erosion. We specify that the number of active layers is
    3 and give a spatially variable field of erosion and deposition.

    >>> _deposit_or_erode(allocated_layers_array, 3, [1.0, -1.0, -2.0])
    >>> allocated_layers_array
    array([[1.,  2.,  2.],
           [1.,  0.,  0.],
           [1.,  0.,  0.],
           [0.,  0.,  0.]])

    >>> _deposit_or_erode(allocated_layers_array, 3, [1.0, -1.0, -2.0])
    >>> allocated_layers_array
    array([[1.,  1.,  0.],
           [1.,  0.,  0.],
           [2.,  0.,  0.],
           [0.,  0.,  0.]])
    """
    from .ext.eventlayers import deposit_or_erode

    layers = layers.reshape((layers.shape[0], -1))
    try:
        dz = dz.reshape((layers.shape[1],))
    except (AttributeError, ValueError):
        dz = np.broadcast_to(dz, (layers.shape[1],))
    finally:
        dz = np.asarray(dz, dtype=float)

    deposit_or_erode(layers, n_layers, dz)


def _get_surface_index(layers, n_layers, surface_index):
    """Get index within each stack of the layer at the topographic surface.

    Parameters
    ----------
    layers : ndarray of shape `(n_layers, n_nodes)`
        Array of layer thicknesses. This array is the datastructure that
        contains all allocated layers, active or inactive.
    n_layers : int
        Number of active layers.
    surface_index : ndarray of shape `(n_nodes, )`

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.layers.eventlayers import _deposit_or_erode, _get_surface_index

    >>> layers = np.full((5, 3), 1.0)
    >>> dz = np.array([-1.0, -2.0, -3.0])

    Note here, if you are very confused by the use of ``_deposit_or_erode``
    we recommend you read the docstring associated with that function.

    >>> _deposit_or_erode(layers, 5, dz)
    >>> layers
    array([[1.,  1.,  1.],
           [1.,  1.,  1.],
           [1.,  1.,  0.],
           [1.,  0.,  0.],
           [0.,  0.,  0.]])

    >>> surface_index = np.empty(3, dtype=int)
    >>> _get_surface_index(layers, 5, surface_index)
    >>> surface_index
    array([3, 2, 1])
    """
    from .ext.eventlayers import get_surface_index

    layers = layers.reshape((layers.shape[0], -1))

    get_surface_index(layers, n_layers, surface_index)


def _reduce_matrix(array, step, reducer):
    """Combine rows of a 2D matrix.

    Parameters
    ----------
    array : ndarray, shape (m, n)
        Matrix to reduce.
    step : int
        Number of rows in each block to reduce.
    reducer : ufunc
        Function to use for combining rows.

    Returns
    -------
    ndarray
        Matrix with rows combined.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.layers.eventlayers import _reduce_matrix
    >>> array = np.arange(12).reshape((4, 3))
    >>> array
    array([[ 0,  1,  2],
           [ 3,  4,  5],
           [ 6,  7,  8],
           [ 9, 10, 11]])
    >>> _reduce_matrix(array, 4, np.sum)
    array([[18, 22, 26]])
    >>> _reduce_matrix(array, 2, np.sum)
    array([[ 3,  5,  7],
           [15, 17, 19]])
    """
    return reducer(array.reshape((-1, step) + array.shape[1:]), axis=1).reshape(
        (-1,) + array.shape[1:]
    )


class _BlockSlice:
    """Slices that divide a matrix into equally sized blocks."""

    def __init__(self, *args):
        """_BlockSlice([start], stop, [step])"""
        if len(args) > 3:
            raise TypeError(
                f"_BlockSlice expected at most 3 arguments, got {len(args)}"
            )

        self._args = tuple(args)

        self._start = 0
        self._stop = None
        self._step = None

        if len(args) == 1:
            self._stop = args[0]
        elif len(args) == 2:
            self._start, self._stop = args
        elif len(args) == 3:
            self._start, self._stop, self._step = args
            self._step = min(self._stop - self._start, self._step)

        if self._stop is not None and self._stop < self._start:
            raise ValueError(
                "stop ({}) must be greater than start ({})".format(
                    self._stop, self._start
                )
            )

    def __repr__(self):
        return "_BlockSlice({})".format(", ".join([repr(arg) for arg in self._args]))

    @property
    def start(self):
        return self._start

    @property
    def stop(self):
        return self._stop

    @property
    def step(self):
        return self._step

    def indices(self, n_rows):
        """Row indices to blocks within a matrix.

        Parameters
        ----------
        n_rows : int
            The number of rows in the matrix.

        Returns
        -------
        (start, stop, step)
            Tuple of (int* that gives the row of the first block, row of the
            last block, and the number of rows in each block.

        Examples
        --------
        >>> from landlab.layers.eventlayers import _BlockSlice

        The default is one single block that encomapses all the rows.

        >>> _BlockSlice().indices(4)
        (0, 4, 4)

        >>> _BlockSlice(3).indices(4)
        (0, 3, 3)

        >>> _BlockSlice(1, 3).indices(4)
        (1, 3, 2)

        >>> _BlockSlice(1, 7, 2).indices(8)
        (1, 7, 2)
        """
        start, stop, step = self.start, self.stop, self.step
        if stop is None:
            stop = n_rows

        start, stop, _ = slice(start, stop).indices(n_rows)

        if step is None:
            step = stop - start

        if step != 0 and (stop - start) % step != 0:
            stop = (stop - start) // step * step + start

        return start, stop, step


def _valid_keywords_or_raise(kwds, required=(), optional=()):
    """Check for valid keyword arguments.

    Parameters
    ----------
    kwds : iterable of str
        Keywords to check for validity.
    required : iterable of str, optional
        Keywords that are required.
    optional : iterable of str, optional
        Keywords that are optional.

    Examples
    --------
    >>> from landlab.layers.eventlayers import _valid_keywords_or_raise
    >>> _valid_keywords_or_raise(["foo"], optional=["foo", "bar"])
    >>> _valid_keywords_or_raise(["foo"], required=["foo", "bar"])
    Traceback (most recent call last):
        ...
    TypeError: missing keyword arguments ('bar')
    >>> _valid_keywords_or_raise(["baz"], optional=["foo", "bar"])
    Traceback (most recent call last):
        ...
    TypeError: invalid keyword arguments ('baz' not in {'bar', 'foo'})
    """
    keys = set(kwds)
    required = set(required)
    optional = required | set(optional)

    unknown = keys - optional
    if unknown:
        raise TypeError(
            "invalid keyword arguments ({0} not in {{{1}}})".format(
                ", ".join(sorted(repr(name) for name in unknown)),
                ", ".join(sorted(repr(name) for name in optional)),
            )
        )

    missing = required - keys
    if missing:
        raise TypeError(
            "missing keyword arguments ({})".format(
                ", ".join(sorted(repr(name) for name in missing))
            )
        )


def resize_array(array, newsize, exact=False):
    """Increase the size of an array, leaving room to grow.

    Parameters
    ----------
    array : ndarray
        The array to resize.
    newsize : int
        Size of the zero-th dimension of the resized array.
    exact : bool, optional
        Should the new array have the exact size provided or
        at least that size.

    Returns
    -------
    ndarray
        Copy of the input array resized.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.layers.eventlayers import resize_array

    >>> x = np.arange(6)
    >>> bigger_x = resize_array(x, 10)
    >>> bigger_x.size
    17
    >>> np.all(x[:6] == bigger_x[:6])
    True
    >>> x is bigger_x
    False

    >>> x = np.arange(6).reshape((2, 3))
    >>> bigger_x = resize_array(x, 4)
    >>> bigger_x.shape == (10, 3)
    True

    >>> bigger_x = resize_array(x, 4, exact=True)
    >>> bigger_x.shape == (4, 3)
    True

    :meta private:
    """
    newsize = int(newsize)
    allocated = array.shape[0]

    if newsize <= allocated:
        return array

    if exact:
        new_allocated = newsize
    else:
        new_allocated = (newsize >> 3) + 6 + newsize

    larger_array = np.empty((new_allocated,) + array.shape[1:], dtype=array.dtype)
    larger_array[:allocated] = array

    return larger_array


def _allocate_layers_for(array, number_of_layers, number_of_stacks):
    """Allocate a layer matrix.

    Parameters
    ----------
    array : number or ndarray
        Array of layer properties to track.
    number_of_layers : int
        Number of layers to allocate.
    number_of_stacks : int
        Number of stacks to allocate.

    Returns
    -------
    ndarray of size `(number_of_layers, number_of_stacks, values_per_stack)`
        Newly allocated matrix for storing layer properties.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.layers.eventlayers import _allocate_layers_for

    >>> layers = _allocate_layers_for(3, 2, 4)
    >>> layers.shape == (2, 4)
    True
    >>> layers.dtype.kind == "i"
    True

    >>> layers = _allocate_layers_for(np.zeros(4), 2, 4)
    >>> layers.shape == (2, 4)
    True
    >>> layers.dtype.kind == "f"
    True

    >>> layers = _allocate_layers_for(np.zeros(2), 2, 4)
    >>> layers.shape == (2, 4, 2)
    True
    >>> layers.dtype.kind == "f"
    True
    """
    array = np.asarray(array)

    if array.ndim > 0 and len(array) != number_of_stacks:
        values_per_stack = array.shape
    else:
        values_per_stack = array.shape[1:]

    return np.empty(
        (number_of_layers, number_of_stacks) + values_per_stack, dtype=array.dtype
    )


class EventLayersMixIn:
    """MixIn that adds a EventLayers attribute to a ModelGrid."""

    @property
    def event_layers(self):
        """EventLayers for each cell."""
        try:
            self._event_layers
        except AttributeError:
            self._event_layers = EventLayers(self.number_of_cells)
        return self._event_layers

    @property
    def at_layer(self):
        """EventLayers for each cell."""
        return self.event_layers


class EventLayers:
    """Track EventLayers where each event is its own layer.

    EventLayers are meant to represent a layered object in which each layer
    represents a event. Thus they are likely the most appropriate tool to use
    if the user is interested in chronostratigraphy. If erosion occurs, a new
    layer with zero thickness is created. Thus, EventLayers may not be the most
    memory efficent layers datastructure.

    EventLayers exists in contrast to the MaterialLayers object which does not
    make a new layer if only erosion occurs and if the attributes of the new
    layer are equivalent to the attributes of the material at the surface of the
    layer stack.

    Parameters
    ----------
    number_of_stacks : int
        Number of layer stacks to track.

    Examples
    --------
    >>> from landlab.layers.eventlayers import EventLayers

    Create an empty layer stack with 5 stacks.

    >>> layers = EventLayers(5)
    >>> layers.number_of_stacks
    5
    >>> layers.number_of_layers
    0

    Add a layer with a uniform thickness.

    >>> layers.add(1.5)
    >>> layers.number_of_layers
    1
    >>> layers.dz
    array([[1.5,  1.5,  1.5,  1.5,  1.5]])

    Add a second layer with uneven thickness.

    >>> layers.add([1.0, 2.0, 0.5, 5.0, 0.0])
    >>> layers.dz
    array([[1.5,  1.5,  1.5,  1.5,  1.5],
           [1. ,  2. ,  0.5,  5. ,  0. ]])

    Adding a layer with negative thickness will remove
    existing layers for the top of the stack. Note that
    this will create a new layer with thickness zero
    that represents this 'event'. If instead your
    application would prefer that no new row is added to
    the layers datastructure, you may want to consider
    the MaterialLayers object.

    >>> layers.add(-1)
    >>> layers.dz
    array([[1.5,  1.5,  1. ,  1.5,  0.5],
           [0. ,  1. ,  0. ,  4. ,  0. ],
           [0. ,  0. ,  0. ,  0. ,  0. ]])

    Get the index value of the layer within each stack
    at the topographic surface.

    >>> layers.surface_index
    array([0, 1, 0, 1, 0])
    """

    def __init__(self, number_of_stacks, allocated=0):
        self._number_of_layers = 0
        self._number_of_stacks = number_of_stacks
        self._surface_index = np.zeros(number_of_stacks, dtype=int)
        self._attrs = {}

        dims = (self.number_of_layers, self.number_of_stacks)
        self._attrs["_dz"] = np.empty(dims, dtype=float)
        self._resize(allocated, exact=True)

    def __getitem__(self, name):
        return self._attrs[name][: self.number_of_layers]

    def __setitem__(self, name, values):
        dims = (self.allocated, self.number_of_stacks)
        values = np.asarray(values)
        if values.ndim == 1:
            values = np.expand_dims(values, 1)
        values = np.broadcast_to(values, (self.number_of_layers, self.number_of_stacks))
        self._attrs[name] = _allocate_layers_for(values.flatten()[0], *dims)
        self._attrs[name][: self.number_of_layers] = values

    def __iter__(self):
        return (name for name in self._attrs if not name.startswith("_"))

    def __str__(self):
        lines = [
            "number_of_layers: {number_of_layers}",
            "number_of_stacks: {number_of_stacks}",
            "tracking: {attrs}",
        ]
        return os.linesep.join(lines).format(
            number_of_layers=self.number_of_layers,
            number_of_stacks=self.number_of_stacks,
            attrs=", ".join(self.tracking) or "null",
        )

    def __repr__(self):
        return self.__class__.__name__ + "({number_of_stacks})".format(
            number_of_stacks=self.number_of_stacks
        )

    @property
    def tracking(self):
        """Layer properties being tracked.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers
        >>> layers = EventLayers(3)
        >>> layers.tracking
        []
        >>> layers.add(1.0, age=1.0)
        >>> layers.tracking
        ['age']
        """
        return [name for name in self._attrs if not name.startswith("_")]

    def _setup_layers(self, **kwds):
        dims = (self.allocated, self.number_of_stacks)
        for name, array in kwds.items():
            self._attrs[name] = _allocate_layers_for(array, *dims)

    @property
    def number_of_stacks(self):
        """Number of stacks."""
        return self._number_of_stacks

    @property
    def thickness(self):
        """Total thickness of the columns.

        The sum of all layer thicknesses for each stack as an array
        of shape `(number_of_stacks, )`.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Initially there are no layers so the total thickness is 0.

        >>> layers = EventLayers(3)
        >>> layers.thickness
        array([0.,  0.,  0.])

        After adding some layers, the stacks have varying thicknesses.

        >>> layers.add(15.0)
        >>> layers.add([1.0, -1.0, 2.0])
        >>> layers.thickness
        array([16.,  14.,  17.])
        """
        return np.sum(self.dz, axis=0)

    @property
    def z(self):
        """Thickness to top of each layer.

        Thickness from the bottom of each stack to the top of each layer
        as an array of shape `(number_of_layers, number_of_stacks)`.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Initially there are no layers so the elevation to the top
        is 0.

        >>> layers = EventLayers(3)
        >>> layers.z.shape == (0, 3)
        True

        After adding some layers, elevations are to the top of each layer.

        >>> layers.add(15.0)
        >>> layers.add([1.0, -1.0, 2.0])
        >>> layers.dz
        array([[15.,  14.,  15.],
               [ 1.,   0.,   2.]])
        >>> layers.z
        array([[15.,  14.,  15.],
               [16.,  14.,  17.]])
        """
        return np.cumsum(self.dz, axis=0)

    @property
    def dz(self):
        """Thickness of each layer.

        The thickness of each layer at each stack as an array of shape
        `(number_of_layers, number_of_stacks)`.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Initially there are no layers so there are not thicknesses.

        >>> layers = EventLayers(3)
        >>> layers.dz.shape == (0, 3)
        True

        Now add two layers, the first of uniform thickness and the
        second non-uniform and with some erosion.

        >>> layers.add(15.0)
        >>> layers.add([1.0, -1.0, 2.0])
        >>> layers.dz
        array([[15.,  14.,  15.],
               [ 1.,   0.,   2.]])
        """
        return self._attrs["_dz"][: self.number_of_layers]

    @property
    def number_of_layers(self):
        """Total number of layers.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        >>> layers = EventLayers(3)
        >>> layers.number_of_layers
        0

        >>> layers.add(15.0)
        >>> layers.add([1.0, -1.0, 2.0])
        >>> layers.number_of_layers
        2
        """
        return self._number_of_layers

    @property
    def allocated(self):
        """Total number of allocated layers.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        >>> layers = EventLayers(3)
        >>> layers.number_of_layers
        0
        >>> layers.allocated == 0
        True

        >>> layers.add(15.0)
        >>> layers.number_of_layers
        1
        >>> layers.allocated == 7
        True
        >>> for _ in range(layers.allocated):
        ...     layers.add(0.0)
        ...
        >>> layers.number_of_layers
        8
        >>> layers.allocated == 15
        True

        If you know how many layers you will ultimately have, you
        can allocated enough memory for them when you create your
        layer stacks.

        >>> layers = EventLayers(3, allocated=15)
        >>> layers.number_of_layers
        0
        >>> layers.allocated == 15
        True

        >>> layers.add(15.0)
        >>> layers.number_of_layers
        1
        >>> layers.allocated == 15
        True
        >>> for _ in range(layers.allocated):
        ...     layers.add(0.0)
        ...
        >>> layers.number_of_layers
        16
        >>> layers.allocated == 24
        True
        """
        return self._attrs["_dz"].shape[0]

    def add(self, dz, **kwds):
        """Add a layer to the stacks.

        Parameters
        ----------
        dz : float or array_like
            Thickness to add to each stack.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Create an empty layer stack with 3 stacks.

        >>> layers = EventLayers(3)
        >>> layers.number_of_layers
        0

        To add a layer of uniform thickness to every stack.

        >>> layers.add(1.5)
        >>> layers.number_of_layers
        1
        >>> layers.dz
        array([[1.5,  1.5,  1.5]])

        Add a second layer with uneven thickness.

        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.dz
        array([[1.5,  1.5,  1.5],
               [1. ,  2. ,  0.5]])

        Adding a layer with negative thickness will remove
        existing layers for the top of the stack.

        >>> layers.add(-1)
        >>> layers.dz
        array([[1.5,  1.5,  1. ],
               [0. ,  1. ,  0. ],
               [0. ,  0. ,  0. ]])

        Use keywords to track properties of each layer. For instance,
        here we create a new stack and add a layer with a particular
        *age*. You can access the layer properties as if the object
        were a dictionary.

        >>> layers = EventLayers(3)
        >>> layers.add(1.0, age=3.0)
        >>> layers.dz
        array([[1.,  1.,  1.]])
        >>> layers["age"]
        array([[3.,  3.,  3.]])
        >>> layers.add(2.0, age=6.0)
        >>> layers["age"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.]])

        Attributes for each layer will exist even if the the layer is
        associated with erosion.

        >>> layers.add([-2, -1, 1], age=8.0)
        >>> layers.dz
        array([[1.,  1.,  1.],
               [0.,  1.,  2.],
               [0.,  0.,  1.]])
        >>> layers["age"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.],
               [8.,  8.,  8.]])

        To get the values at the surface of the layer stack:

        >>> layers.get_surface_values("age")
        array([3.,  6.,  8.])
        """
        if self.number_of_layers == 0:
            self._setup_layers(**kwds)

        self._add_empty_layer()

        _deposit_or_erode(self._attrs["_dz"], self.number_of_layers, dz)
        _get_surface_index(
            self._attrs["_dz"], self.number_of_layers, self._surface_index
        )

        for name in kwds:
            try:
                self[name][-1] = kwds[name]
            except KeyError as exc:
                raise ValueError(
                    f"{name!r} is not being tracked. Error in adding."
                ) from exc

    def reduce(self, *args, **kwds):
        """reduce([start], stop, [step])
        Combine layers.

        Reduce adjacent layers into a single layer.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Create an empty layer stack with 3 stacks.

        >>> layers = EventLayers(3)
        >>> layers.number_of_layers
        0

        To add a layer of uniform thickness to every stack.

        >>> layers.add(1.5)
        >>> layers.number_of_layers
        1
        >>> layers.dz
        array([[1.5,  1.5,  1.5]])

        Add a second layer with uneven thickness.

        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.dz
        array([[1.5,  1.5,  1.5],
               [1. ,  2. ,  0.5]])

        Combine all of the layers into a single layer.

        >>> layers.reduce()
        >>> layers.dz
        array([[2.5,  3.5,  2. ]])

        Add two additional layers to the top. The bottom-most layer is row
        0, and the two new layers are rows 1 and 2.

        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.dz
        array([[2.5,  3.5,  2. ],
               [1. ,  2. ,  0.5],
               [1. ,  2. ,  0.5]])

        Combine the two new layers (layers 1 and 2) into a single layer.

        >>> layers.reduce(1, 3)
        >>> layers.dz
        array([[2.5,  3.5,  2. ],
               [2. ,  4. ,  1. ]])

        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.dz
        array([[2.5,  3.5,  2. ],
               [2. ,  4. ,  1. ],
               [1. ,  2. ,  0.5],
               [1. ,  2. ,  0.5]])

        Combine the middle two layers.

        >>> layers.reduce(1, 3)
        >>> layers.dz
        array([[2.5,  3.5,  2. ],
               [3. ,  6. ,  1.5],
               [1. ,  2. ,  0.5]])
        >>> layers.add([1.0, 1.0, 1.0])
        >>> layers.dz
        array([[2.5,  3.5,  2. ],
               [3. ,  6. ,  1.5],
               [1. ,  2. ,  0.5],
               [1. ,  1. ,  1. ]])

        Combine every two layers (layers 0 and 1 and combined, and layers
        1 and 2 are combined).

        >>> layers.reduce(0, 4, 2)
        >>> layers.dz
        array([[5.5,  9.5,  3.5],
               [2. ,  3. ,  1.5]])

        When layers are combined, thicknesses are summed but layer attributes
        can be combined in other ways (e.g. max, or mean)

        >>> layers = EventLayers(3)
        >>> layers.add([1, 1, 1], age=0.0)
        >>> layers.add([1, 2, 5], age=1.0)
        >>> layers.add([2, 2, 2], age=2.0)
        >>> layers.reduce(age=np.max)
        >>> layers["age"]
        array([[2.,  2.,  2.]])

        >>> layers.add([2, 2, 2], age=3.0)
        >>> layers.add([2, 2, 2], age=4.0)
        >>> layers.reduce(1, 3, age=np.mean)
        >>> layers["age"]
        array([[2. ,  2. ,  2. ],
               [3.5,  3.5,  3.5]])
        """
        _valid_keywords_or_raise(kwds, required=self.tracking, optional=self._attrs)

        start, stop, step = _BlockSlice(*args).indices(self._number_of_layers)

        if step <= 1:
            return

        n_blocks = (stop - start) // step
        n_removed = n_blocks * (step - 1)
        for name, array in self._attrs.items():
            middle = _reduce_matrix(array[start:stop, :], step, kwds.get(name, np.sum))
            top = array[stop : self._number_of_layers, :]

            array[start : start + n_blocks, :] = middle
            array[start + n_blocks : start + n_blocks + len(top)] = top

        self._number_of_layers -= n_removed
        self._surface_index[:] -= n_removed

    @property
    def surface_index(self):
        """Index to the top non-empty layer.

        Examples
        --------
        >>> from landlab.layers.eventlayers import EventLayers

        Create an empty layer stack with 5 stacks.

        >>> layers = EventLayers(3)
        >>> layers.surface_index
        array([0, 0, 0])

        Add a layer with a uniform thickness.

        >>> for _ in range(5):
        ...     layers.add(1.0)
        ...
        >>> layers.surface_index
        array([4, 4, 4])

        Add a layer with varying thickness. Negative thickness
        removes thickness from underlying layers, zero thickness adds a
        layer but doesn't change the surface index.

        >>> layers.add([-1.0, 0.0, 1.0])
        >>> layers.surface_index
        array([3, 4, 5])
        """
        return self._surface_index

    def get_surface_values(self, name):
        """Values of a field on the surface layer."""
        return self._attrs[name][self.surface_index, np.arange(self._number_of_stacks)]

    def _add_empty_layer(self):
        """Add a new empty layer to the stacks."""
        if self.number_of_layers >= self.allocated:
            self._resize(self.allocated + 1)

        self._number_of_layers += 1
        self._attrs["_dz"][self.number_of_layers - 1, :] = 0.0
        for name in self._attrs:
            self._attrs[name][self.number_of_layers - 1] = 0.0

    def _resize(self, newsize, exact=False):
        """Allocate more memory for the layers."""
        for name in self._attrs:
            self._attrs[name] = resize_array(self._attrs[name], newsize, exact=exact)



================================================
File: src/landlab/layers/materiallayers.py
================================================
import numpy as np

from landlab.layers.eventlayers import EventLayers
from landlab.layers.eventlayers import _deposit_or_erode
from landlab.layers.eventlayers import _get_surface_index


class MaterialLayersMixIn:
    """MixIn that adds a MaterialLayers attribute to a ModelGrid."""

    @property
    def material_layers(self):
        """MaterialLayers for each cell."""
        try:
            self._material_layers
        except AttributeError:
            self._material_layers = MaterialLayers(self.number_of_cells)
        return self._material_layers


class MaterialLayers(EventLayers):
    """Track MaterialLayers where each layer has some material in it.

    MaterialLayers are meant to represent a layered object in which each layer
    has some material in it. If erosion occurs, no new layer is created. These
    layers stand in contrast to the EventLayers for which each event is
    represented by a layer.

    MaterialLayers is likely a more memory efficent data structure than
    EventLayers as it does not record erosion as an array of zeros.

    Parameters
    ----------
    number_of_stacks : int
        Number of layer stacks to track.

    Examples
    --------
    >>> from landlab.layers.materiallayers import MaterialLayers

    Create an empty layer stack with 5 stacks.

    >>> layers = MaterialLayers(5)
    >>> layers.number_of_stacks
    5
    >>> layers.number_of_layers
    0

    Add a layer with a uniform thickness.

    >>> layers.add(1.5)
    >>> layers.number_of_layers
    1
    >>> layers.dz
    array([[1.5,  1.5,  1.5,  1.5,  1.5]])

    MaterialLayers will combine layers if they have the same attributes.
    Adding a second layer with uneven thickness. Will increment the
    first layers thickness. This stands in contrast with EventLayers
    which will track each addition as a separate entry in the layers
    datastructure.

    >>> layers.add([1.0, 2.0, 3.0, 5.0, 0.0])
    >>> layers.dz
    array([[2.5,  3.5,  4.5,  6.5,  1.5]])

    Adding a layer with negative thickness will remove
    material from the layers. Unlike EventLayers, it will not add a
    layer of zeros that represent an event with no deposition.

    >>> layers.add(-1)
    >>> layers.dz
    array([[1.5,  2.5,  3.5,  5.5,  0.5]])

    Get the index value of the layer within each stack
    at the topographic surface.

    >>> layers.surface_index
    array([0, 0, 0, 0, 0])

    See the example in the ``add`` method to learn how MaterialLayers
    behaves if material properties are also tracked.
    """

    def add(self, dz, **kwds):
        """Add a layer to the  MaterialLayers stacks.

        Parameters
        ----------
        dz : float or array_like
            Thickness to add to each stack.

        Examples
        --------
        >>> from landlab.layers.materiallayers import MaterialLayers

        Create an empty layer stack with 3 stacks.

        >>> layers = MaterialLayers(3)
        >>> layers.number_of_layers
        0

        To add a layer of uniform thickness to every stack.

        >>> layers.add(1.5)
        >>> layers.number_of_layers
        1
        >>> layers.dz
        array([[1.5,  1.5,  1.5]])

        Add a second layer with uneven thickness.

        >>> layers.add([1.0, 2.0, 0.5])
        >>> layers.dz
        array([[2.5,  3.5,  2. ]])

        Because the attributes of this layer and the previous layer
        are the same (e.g. they don't exist), MaterialLayer will combine
        them. This is the primary difference between MaterialLayers and
        EventLayers.

        Adding a layer with negative thickness will remove material from
        the top of the stack.

        >>> layers.add(-1)
        >>> layers.dz
        array([[1.5,  2.5,  1. ]])
        >>> layers.number_of_layers
        1

        Use keywords to track properties of each layer. For instance,
        here we create a new stack and add a layer with a particular
        *type* and a particular *size*. You can access the layer properties as
        if the object were a dictionary.

        >>> layers = MaterialLayers(3)
        >>> layers.add(1.0, type=3.0, size="sand")
        >>> layers.dz
        array([[1.,  1.,  1.]])
        >>> layers["type"]
        array([[3.,  3.,  3.]])

        As you can see, there is no rule that says you can't use a string as
        the value of an attribute.

        Adding a layer with the same attributes as the entire surface of the
        MaterialLayers will result in the layers being combined.

        >>> layers.add(1.0, type=3.0, size="sand")
        >>> layers.add([2, -1, 0], type=3.0, size="sand")
        >>> layers.dz
        array([[4.,  1.,  2.]])

        Adding material with different attributes results in the creation of
        a new layer.

        >>> layers.add(2.0, type=6.0, size="sand")
        >>> layers.dz
        array([[4.,  1.,  2.],
               [2.,  2.,  2.]])
        >>> layers["type"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.]])
        >>> np.all(
        ...     layers["size"] == [["sand", "sand", "sand"], ["sand", "sand", "sand"]]
        ... )
        True

        Attributes for each layer will exist even if part the the layer is
        associated with erosion.

        >>> layers.add([-2, -1, 1], type=8.0, size="gravel")
        >>> layers.dz
        array([[4.,  1.,  2.],
               [0.,  1.,  2.],
               [0.,  0.,  1.]])
        >>> layers["type"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.],
               [8.,  8.,  8.]])

        To get the values at the surface of the layer stack:

        >>> layers.get_surface_values("type")
        array([3.,  6.,  8.])

        Removing enough material such that an entire layer's
        thickness is no longer present, results in that layer
        no longer being tracked. This is another difference
        between MaterialLayers and EventLayers.

        >>> layers.add([0.0, 0.0, -1.0])
        >>> layers.dz
        array([[4.,  1.,  2.],
               [0.,  1.,  2.]])
        >>> layers["type"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.]])
        >>> np.all(
        ...     layers["size"] == [["sand", "sand", "sand"], ["sand", "sand", "sand"]]
        ... )
        True
        >>> layers.number_of_layers
        2

        If attributes (like age and size in this example) are tracked, a layer
        will be combined with the surface layer only if all attributes are the
        same across the entire layer. Right now, the surface values vary.

        >>> layers.get_surface_values("type")
        array([3.,  6.,  6.])
        >>> np.all(layers.get_surface_values("size") == ["sand", "sand", "sand"])
        True

        Since the surface has different types, adding material will create a
        new layer.

        >>> layers.add(3.0, type=6.0, size="sand")
        >>> layers.dz
        array([[4.,  1.,  2.],
               [0.,  1.,  2.],
               [3.,  3.,  3.]])
        >>> layers["type"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.],
               [6.,  6.,  6.]])
        >>> layers.number_of_layers
        3

        But now, the entire surface has the qualities of type = 6. and size =
        'sand', so layers will be combined. This even works if the thickness of
        the new layer includes both erosion and deposition.

        >>> layers.add([-3.5, 0.0, 2.0], type=6.0, size="sand")
        >>> layers.dz
        array([[3.5,  1. ,  2. ],
               [0. ,  1. ,  2. ],
               [0. ,  3. ,  5. ]])
        >>> layers["type"]
        array([[3.,  3.,  3.],
               [6.,  6.,  6.],
               [6.,  6.,  6.]])
        >>> layers.number_of_layers
        3
        """
        dz = np.asarray(dz)

        if self.number_of_layers == 0:
            self._setup_layers(**kwds)

        compatible = self.number_of_layers > 0 and self.is_compatible(dz, **kwds)

        if not compatible:
            self._add_empty_layer()

        _deposit_or_erode(self._attrs["_dz"], self.number_of_layers, dz)
        _get_surface_index(
            self._attrs["_dz"], self.number_of_layers, self._surface_index
        )

        self._remove_empty_layers()

        if not compatible:
            for name in kwds:
                self[name][-1] = kwds[name]

    def _remove_empty_layers(self):
        number_of_filled_layers = self.surface_index.max() + 1
        if number_of_filled_layers < self.number_of_layers:
            self._number_of_layers = number_of_filled_layers

    def is_compatible(self, dz, **kwds):
        """Check if a new layer is compatible with the existing top layer.

        Parameters
        ----------
        dz : float or array_like
            Thickness to add to each stack.

        Returns
        -------
        bool
            ``True`` if the new layer is compatible, otherwise ``False``.
        """
        where_deposition = dz > 0.0

        if np.any(where_deposition):
            if not_tracked := set(kwds) - set(self):
                raise ValueError(
                    "Error adding layer."
                    f" {', '.join(sorted(repr(t) for t in not_tracked))}"
                    " is not being tracked. Currently tracking:"
                    f" {', '.join(sorted(repr(t) for t in set(self)))}"
                )
            for name in kwds:
                is_compatible = self[name][self.surface_index] == kwds[name]

                if not np.all(is_compatible[where_deposition]):
                    return False
        return True



================================================
File: src/landlab/layers/ext/__init__.py
================================================



================================================
File: src/landlab/layers/ext/eventlayers.pyx
================================================
cimport cython

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def deposit_or_erode(
    cython.floating [:, :] layers,
    long n_layers,
    const cython.floating [:] dz,
):
    cdef int n_stacks = layers.shape[1]
    cdef int top_ind = n_layers - 1
    cdef int col
    cdef int layer
    cdef double removed
    cdef double amount_to_remove

    with nogil:
        for col in range(n_stacks):
            if dz[col] >= 0.:
                layers[top_ind, col] += dz[col]
            else:
                amount_to_remove = - dz[col]
                removed = 0.
                for layer in range(top_ind, -1, -1):
                    removed += layers[layer, col]
                    layers[layer, col] = 0.
                    if removed > amount_to_remove:
                        layers[layer, col] = removed - amount_to_remove
                        break


@cython.boundscheck(False)
@cython.wraparound(False)
def get_surface_index(
    const cython.floating [:, :] layers,
    long n_layers,
    id_t [:] surface_index,
):
    cdef int n_stacks = layers.shape[1]
    cdef int top_ind = n_layers
    cdef int col
    cdef int layer

    with nogil:
        for col in range(n_stacks):
            for layer in range(top_ind - 1, -1, -1):
                if layers[layer, col] > 0:
                    surface_index[col] = layer
                    break



================================================
File: src/landlab/plot/__init__.py
================================================
from .graph import plot_graph
from .imshow import imshow_grid
from .imshow import imshow_grid_at_node
from .imshowhs import imshowhs_grid
from .imshowhs import imshowhs_grid_at_node
from .layers import plot_layers
from .network_sediment_transporter import plot_network_and_parcels

__all__ = [
    "imshow_grid",
    "imshowhs_grid",
    "imshow_grid_at_node",
    "imshowhs_grid_at_node",
    "plot_network_and_parcels",
    "plot_layers",
    "plot_graph",
]



================================================
File: src/landlab/plot/colors.py
================================================
"""colors.py.

Created on Mon Jan 18 13:28:17 2016

@author: gtucker
"""

from matplotlib.colors import LinearSegmentedColormap


def water_colormap():
    """Return matplotlib colormap with 'water' theme."""
    cdict = {
        "red": ((0.0, 0.0, 169.0 / 255.0), (1.0, 38.0 / 255.0, 1.0)),
        "green": ((0.0, 0.0, 222.0 / 255.0), (1.0, 39.0 / 255.0, 1.0)),
        "blue": ((0.0, 0.0, 242.0 / 255.0), (1.0, 23.0 / 255.0, 1.0)),
    }
    return LinearSegmentedColormap("landlab_water", cdict)


def earth_colormap():
    """Return matplotlib colormap with 'earth' theme."""
    cdict = {
        "red": ((0.0, 0.0, 252.0 / 255.0), (1.0, 33.0 / 255.0, 1.0)),
        "green": ((0.0, 0.0, 237.0 / 255.0), (1.0, 38.0 / 255.0, 1.0)),
        "blue": ((0.0, 0.0, 179.0 / 255.0), (1.0, 24.0 / 255.0, 1.0)),
    }
    return LinearSegmentedColormap("landlab_earth", cdict)


def colormap(name):
    """Return named Landlab colormap as a matplotlib colormap.

    Parameters
    ----------
    name : str
        Name of colormap

    Currently available maps are:
        'water': black to light blue
        'earth': dark olive to light sand color
    """
    colormap_fns = {"water": water_colormap(), "earth": earth_colormap()}
    try:
        return colormap_fns[name]
    except KeyError:
        print('Warning: colormap "' + name + '" does not exist')
        return None



================================================
File: src/landlab/plot/drainage_plot.py
================================================
"""Plot drainage network."""

import matplotlib.pylab as plt
import numpy as np

from landlab.plot.imshow import imshow_grid

# KRB, FEB 2017.


def drainage_plot(
    mg,
    surface="topographic__elevation",
    receivers=None,
    proportions=None,
    surf_cmap="gray",
    quiver_cmap="viridis",
    title="Drainage Plot",
):
    if isinstance(surface, str):
        colorbar_label = surface
    else:
        colorbar_label = "topographic_elevation"
    imshow_grid(mg, surface, cmap=surf_cmap, colorbar_label=colorbar_label)

    if receivers is None:
        receivers = mg.at_node["flow__receiver_node"]
        if proportions is None and "flow__receiver_proportions" in mg.at_node:
            proportions = mg.at_node["flow__receiver_proportions"]
    else:
        receivers = np.asarray(receivers)

    if receivers.ndim == 1:
        receivers = np.expand_dims(receivers, axis=1)

    nreceievers = receivers.shape[-1]

    propColor = plt.colormaps[quiver_cmap]
    for j in range(nreceievers):
        rec = receivers[:, j]
        is_bad = rec == -1

        xdist = -0.8 * (mg.x_of_node - mg.x_of_node[rec])
        ydist = -0.8 * (mg.y_of_node - mg.y_of_node[rec])

        if proportions is None:
            proportions = np.ones_like(receivers, dtype=float)
        if proportions.ndim == 1:
            proportions = np.expand_dims(proportions, axis=1)

        is_bad[proportions[:, j] == 0.0] = True

        xdist[is_bad] = np.nan
        ydist[is_bad] = np.nan

        prop = proportions[:, j] * 256.0
        lu = np.floor(prop)
        colors = propColor(lu.astype(int))

        shape = (mg.number_of_nodes, 1)

        plt.quiver(
            mg.x_of_node.reshape(shape),
            mg.y_of_node.reshape(shape),
            xdist.reshape(shape),
            ydist.reshape(shape),
            color=colors,
            angles="xy",
            scale_units="xy",
            scale=1,
            zorder=3,
        )

    # Plot different types of nodes:
    (o,) = plt.plot(
        mg.x_of_node[mg.status_at_node == mg.BC_NODE_IS_CORE],
        mg.y_of_node[mg.status_at_node == mg.BC_NODE_IS_CORE],
        "b.",
        label="Core Nodes",
        zorder=4,
    )
    (fg,) = plt.plot(
        mg.x_of_node[mg.status_at_node == mg.BC_NODE_IS_FIXED_VALUE],
        mg.y_of_node[mg.status_at_node == mg.BC_NODE_IS_FIXED_VALUE],
        "c.",
        label="Fixed Gradient Nodes",
        zorder=5,
    )
    (fv,) = plt.plot(
        mg.x_of_node[mg.status_at_node == mg.BC_NODE_IS_FIXED_GRADIENT],
        mg.y_of_node[mg.status_at_node == mg.BC_NODE_IS_FIXED_GRADIENT],
        "g.",
        label="Fixed Value Nodes",
        zorder=6,
    )
    (c,) = plt.plot(
        mg.x_of_node[mg.status_at_node == mg.BC_NODE_IS_CLOSED],
        mg.y_of_node[mg.status_at_node == mg.BC_NODE_IS_CLOSED],
        "r.",
        label="Closed Nodes",
        zorder=7,
    )

    node_id = np.arange(mg.number_of_nodes)
    flow_to_self = receivers[:, 0] == node_id

    (fts,) = plt.plot(
        mg.x_of_node[flow_to_self],
        mg.y_of_node[flow_to_self],
        "kx",
        markersize=6,
        label="Flows To Self",
        zorder=8,
    )

    ax = plt.gca()

    ax.legend(
        labels=[
            "Core Nodes",
            "Fixed Gradient Nodes",
            "Fixed Value Nodes",
            "Closed Nodes",
            "Flows To Self",
        ],
        handles=[o, fg, fv, c, fts],
        numpoints=1,
        loc="center left",
        bbox_to_anchor=(1.7, 0.5),
    )
    sm = plt.cm.ScalarMappable(cmap=propColor, norm=plt.Normalize(vmin=0, vmax=1))
    sm._A = []
    cx = plt.colorbar(sm, ax=ax)
    cx.set_label("Proportion of Flow")
    plt.title(title)



================================================
File: src/landlab/plot/event_handler.py
================================================
#! /usr/bin/env python
"""Functions to interact with figures that plot Landlab grid data."""

from pprint import pprint


def query_grid_on_button_press(event, grid):
    """Print and returns node information using an imshow plot.

    This function is triggered when a mouse button is pressed on the matplotlib
    figure connected by event. Coordinates of grid and its node attributes are
    queried only when the event location is within the axes of the figure.
    The node whose attributes are queried is the node at the center of the
    cell that contains the event coordinates.

    This function only works with raster model grids.

    Parameters
    ----------
    event : matplotlib event
        Event associated with a figure canvas using mpl_connect().
    grid : RasterModelGrid
        Grid containing the attributes to print.

    Returns
    -------
    query_results :
        Dictionary containing grid query results.
    """
    from ..grid.raster import RasterModelGrid

    if not isinstance(grid, RasterModelGrid):
        raise TypeError("Only raster grids can be queried.")

    if all([event.xdata, event.ydata]):
        x_pressed = int(round(event.xdata / grid.dx))
        y_pressed = int(round(event.ydata / grid.dy))

        query_results = {
            "grid location": {"x_coord": event.xdata, "y_coord": event.ydata},
            "node": {
                "ID": grid.grid_coords_to_node_id(y_pressed, x_pressed),
                "column": x_pressed,
                "row": y_pressed,
            },
        }

        print("\nGrid query results:\n")
        pprint(query_results, width=1)

    return query_results



================================================
File: src/landlab/plot/graph.py
================================================
import matplotlib.pyplot as plt
import numpy as np


def plot_nodes(graph, color="r", with_id=True, markersize=4):
    for node in range(len(graph.x_of_node)):
        x, y = graph.x_of_node[node], graph.y_of_node[node]
        plt.plot(
            graph.x_of_node[node],
            graph.y_of_node[node],
            "o",
            color=color,
            markersize=markersize,
        )
        if with_id:
            plt.text(x, y, node, color=color, size=16)


def plot_links(
    graph, color="b", linestyle="solid", with_id=True, as_arrow=True, linewidth=None
):
    if as_arrow:
        head_width = 0.1
    else:
        head_width = 0.0
    for link, nodes in enumerate(graph.nodes_at_link):
        x, y = graph.x_of_node[nodes[0]], graph.y_of_node[nodes[0]]
        dx, dy = graph.x_of_node[nodes[1]] - x, graph.y_of_node[nodes[1]] - y
        plt.arrow(
            x,
            y,
            dx,
            dy,
            head_width=head_width,
            linewidth=linewidth,
            length_includes_head=True,
            color=color,
            linestyle=linestyle,
        )
        if with_id:
            plt.text(x + dx * 0.5, y + dy * 0.5, link, size=16, color=color)


def plot_patches(graph, color="g", with_id=False):
    from matplotlib.patches import Polygon

    for patch, nodes in enumerate(graph.nodes_at_patch):
        nodes = nodes[nodes >= 0]
        x, y = np.mean(graph.x_of_node[nodes]), np.mean(graph.y_of_node[nodes])
        plt.gca().add_patch(
            Polygon(graph.xy_of_node[nodes], ec=color, fc=None, alpha=0.5)
        )
        if with_id:
            plt.text(
                x,
                y,
                patch,
                color=color,
                size=16,
                horizontalalignment="center",
                verticalalignment="center",
            )


def plot_graph(graph, at="node,link,patch", with_id=True, axes=None):
    """Plot elements of a graph.

    Parameters
    ----------
    graph : graph-like
        A landlab graph-like object.
    at : str or iterable of str
        Comma-separated list of elements to plot.
    with_id : str, iterable of str or bool
        Indicate which elements should be plotted with their corresponding id.
        Either a comma-separated list of grid elements or ``True`` to include
        ids for all elements of ``False`` for no elements.
    axes : , optional
        Add the plot to an existing matplotlib ``Axes``, otherwise, create a new one.

    Returns
    -------
    ``Axes``
        The ``Axes`` containing the plot.
    """
    EVERYWHERE = {"node", "link", "patch", "corner", "face", "cell"}

    if isinstance(with_id, bool):
        with_id = EVERYWHERE if with_id else set()
    else:
        with_id = _parse_locations_as_set(with_id)
    locs = _parse_locations_as_set(at)

    ax = plt.axes() if axes is None else axes

    ax.set_xlim([min(graph.x_of_node) - 0.5, max(graph.x_of_node) + 0.5])
    ax.set_ylim([min(graph.y_of_node) - 0.5, max(graph.y_of_node) + 0.5])

    if "node" in locs:
        plot_nodes(graph, with_id="node" in with_id, markersize=4)
    if "link" in locs:
        plot_links(graph, with_id="link" in with_id, linewidth=None, as_arrow=True)
    if "patch" in locs:
        plot_patches(graph, with_id="patch" in with_id)

    if "corner" in locs:
        plot_nodes(graph.dual, color="c", with_id="corner" in with_id)
    if "face" in locs:
        plot_links(graph.dual, linestyle="dotted", color="k", with_id="face" in with_id)
    if "cell" in locs and graph.number_of_cells > 0:
        plot_patches(graph.dual, color="m", with_id="cell" in with_id)

    ax.set_xlabel("x")
    ax.set_ylabel("y")
    ax.set_aspect(1.0)

    return ax


def _parse_locations_as_set(locations):
    """Parse grid element locations as a set.

    Parameters
    ----------
    locations : str or iterable of str
        Grid locations.

    Returns
    -------
    set
        Grid locations as strings.

    Raises
    ------
    ValueError
        If any of the locations are invalid.
    """
    EVERYWHERE = {"node", "link", "patch", "corner", "face", "cell"}

    if isinstance(locations, str):
        as_set = set(locations.split(","))
    else:
        as_set = set(locations)

    as_set = {item.strip() for item in as_set}

    unknown = sorted(as_set - EVERYWHERE)
    if unknown:
        unknown = [repr(item) for item in unknown]
        raise ValueError(
            f"unknown location{'s' if len(unknown) > 1 else ''} ({', '.join(unknown)})"
        )

    return as_set



================================================
File: src/landlab/plot/imshow.py
================================================
#! /usr/bin/env python
"""Methods to plot data defined on Landlab grids.

Plotting functions
++++++++++++++++++

.. autosummary::

    ~imshow_grid
    ~imshow_grid_at_cell
    ~imshow_grid_at_node
"""
from warnings import warn

import numpy as np

from ..field import FieldError
from .event_handler import query_grid_on_button_press

try:
    import matplotlib.pyplot as plt
    from matplotlib.collections import LineCollection
    from matplotlib.collections import PatchCollection
    from matplotlib.patches import Polygon
except ImportError:
    import warnings

    warnings.warn("matplotlib not found", ImportWarning, stacklevel=2)


class ModelGridPlotterMixIn:
    """MixIn that provides plotting functionality.

    Inhert from this class to provide a ModelDataFields object with the
    method function, ``imshow``, that plots a data field.
    """

    def imshow(self, *args, **kwds):
        """Plot a data field.

        This is a wrapper for `plot.imshow_grid`, and can take the same
        keywords. See that function for full documentation.

        Parameters
        ----------
        values : str, or array-like
            Name of a field or an array of values to plot.

        See Also
        --------
        landlab.plot.imshow_grid

        LLCATS: GINF
        """
        if len(args) == 1:
            values = args[0]
        elif len(args) == 2:
            at, values = args
            warn(f"use grid.imshow(values, at={at!r})", DeprecationWarning)
            if at != kwds.get("at", at):
                raise ValueError(f"multiple locations provided ({at}, {kwds['at']})")
            kwds["at"] = at
        else:
            raise TypeError(f"imshow expected 1 or 2 arguments, got {len(args)}")

        imshow_grid(self, values, **kwds)


def imshow_grid_at_node(grid, values, **kwds):
    """Prepare a map view of data over all nodes in the grid.
    Data is plotted as cells shaded with the value at the node at its center.
    Outer edges of perimeter cells are extrapolated. Closed elements are
    colored uniformly (default black, overridden with kwd 'color_for_closed');
    other open boundary nodes get their actual values.

    *values* can be a field name, a regular array, or a masked array. If a
    masked array is provided, masked entries will be treated as if they were
    Landlab BC_NODE_IS_CLOSED. Used together with the color_at_closed=None
    keyword (i.e., "transparent"), this can allow for construction of overlay
    layers in a figure (e.g., only defining values in a river network, and
    overlaying it on another landscape).

    Use matplotlib functions like xlim, ylim to modify your plot after calling
    :func:`imshow_grid`, as desired.

    Node coordinates are printed when a mouse button is pressed on a cell in
    the plot.

    This function happily works with both regular and irregular grids.

    Parameters
    ----------
    grid : ModelGrid
        Grid containing the field to plot, or describing the geometry of the
        provided array.
    values : array_like, masked_array, or str
        Node values, or a field name as a string from which to draw the data.
    plot_name : str, optional
        String to put as the plot title.
    var_name : str, optional
        Variable name, to use as a colorbar label.
    var_units : str, optional
        Units for the variable being plotted, for the colorbar.
    grid_units : tuple of str, optional
        Units for y, and x dimensions. If None, component will look to the
        grid property `axis_units` for this information. If no units are
        specified there, no entry is made.
    symmetric_cbar : bool
        Make the colormap symetric about 0.
    cmap : str
        Name of a colormap
    limits : tuple of float
        Minimum and maximum of the colorbar.
    vmin, vmax: floats
        Alternatives to limits.
    allow_colorbar : bool
        If True, include the colorbar.
    colorbar_label : str or None
        The string with which to label the colorbar.
    norm : matplotlib.colors.Normalize
        The normalizing object which scales data, typically into the interval
        [0, 1]. Ignore in most cases.
    shrink : float
        Fraction by which to shrink the colorbar.
    color_for_closed : str or None
        Color to use for closed nodes (default 'black'). If None, closed
        (or masked) nodes will be transparent.
    color_for_background : color str or other color declaration, or None
        Color to use for closed elements (default None). If None, the
        background will be transparent, and appear white.
    show_elements : bool
        If True, and grid is a Voronoi, the faces will be plotted in black
        along with just the colour of the cell, defining the cell outlines
        (defaults False).
    output : None, string, or bool
        If None (or False), the image is sent to the imaging buffer to await
        an explicit call to show() or savefig() from outside this function.
        If a string, the string should be the path to a save location, and the
        filename (with file extension). The function will then call
        plt.savefig([string]) itself. If True, the function will call
        plt.show() itself once plotting is complete.
    """
    if isinstance(values, str):
        values_at_node = grid.at_node[values]
    else:
        values_at_node = values.reshape((-1,))

    if values_at_node.size != grid.number_of_nodes:
        raise ValueError("number of values does not match number of nodes")

    values_at_node = np.ma.masked_where(
        grid.status_at_node == grid.BC_NODE_IS_CLOSED, values_at_node
    )

    _imshow_grid_values(grid, values_at_node, **kwds)

    if isinstance(values, str):
        plt.title(values)

    plt.gcf().canvas.mpl_connect(
        "button_press_event", lambda event: query_grid_on_button_press(event, grid)
    )


def imshow_grid_at_cell(grid, values, **kwds):
    """Map view of grid data over all grid cells.

    Prepares a map view of data over all cells in the grid.
    Method can take any of the same ``**kwds`` as :func:`imshow_grid_at_node`.

    Parameters
    ----------
    grid : ModelGrid
        Grid containing the field to plot, or describing the geometry of the
        provided array.
    values : array_like, masked_array, or str
        Values at the cells on the grid. Alternatively, can be a field name
        (string) from which to draw the data from the grid.
    plot_name : str, optional
        String to put as the plot title.
    var_name : str, optional
        Variable name, to use as a colorbar label.
    var_units : str, optional
        Units for the variable being plotted, for the colorbar.
    grid_units : tuple of str, optional
        Units for y, and x dimensions. If None, component will look to the
        gri property `axis_units` for this information. If no units are
        specified there, no entry is made.
    symmetric_cbar : bool
        Make the colormap symetric about 0.
    cmap : str
        Name of a colormap
    limits : tuple of float
        Minimum and maximum of the colorbar.
    vmin, vmax: floats
        Alternatives to limits.
    allow_colorbar : bool
        If True, include the colorbar.
    colorbar_label : str or None
        The string with which to label the colorbar.
    norm : matplotlib.colors.Normalize
        The normalizing object which scales data, typically into the interval
        [0, 1]. Ignore in most cases.
    shrink : float
        Fraction by which to shrink the colorbar.
    color_for_closed : str or None
        Color to use for closed elements (default 'black'). If None, closed
        (or masked) elements will be transparent.
    color_for_background : color str or other color declaration, or None
        Color to use for closed elements (default None). If None, the
        background will be transparent, and appear white.
    show_elements : bool
        If True, and grid is a Voronoi, the faces will be plotted in black
        along with just the colour of the cell, defining the cell outlines
        (defaults False).
    output : None, string, or bool
        If None (or False), the image is sent to the imaging buffer to await
        an explicit call to show() or savefig() from outside this function.
        If a string, the string should be the path to a save location, and the
        filename (with file extension). The function will then call
        plt.savefig([string]) itself. If True, the function will call
        plt.show() itself once plotting is complete.

    Raises
    ------
    ValueError
        If input grid is not uniform rectilinear.
    """
    kwds.setdefault("color_for_closed", None)

    if isinstance(values, str):
        try:
            values_at_cell = grid.at_cell[values]
        except FieldError:
            values_at_cell = grid.at_node[values]
    else:
        values_at_cell = values

    if values_at_cell.size == grid.number_of_nodes:
        values_at_cell = values_at_cell[grid.node_at_cell]

    if values_at_cell.size != grid.number_of_cells:
        raise ValueError(
            "number of values must match number of cells or " "number of nodes"
        )

    values_at_node = np.ma.masked_array(grid.empty(at="node"))
    values_at_node.mask = True
    values_at_node[grid.node_at_cell] = values_at_cell
    values_at_node.mask[grid.node_at_cell] = False

    myimage = _imshow_grid_values(grid, values_at_node, **kwds)

    if isinstance(values, str):
        plt.title(values)

    return myimage


def _imshow_grid_values(
    grid,
    values,
    plot_name=None,
    var_name=None,
    var_units=None,
    grid_units=(None, None),
    symmetric_cbar=False,
    cmap="pink",
    limits=None,
    colorbar_label=None,
    allow_colorbar=True,
    vmin=None,
    vmax=None,
    norm=None,
    shrink=1.0,
    color_for_closed="black",
    color_for_background=None,
    show_elements=False,
    output=None,
    alpha=1.0,
):
    from ..grid.raster import RasterModelGrid

    if isinstance(cmap, str):
        cmap = plt.colormaps[cmap]

    if color_for_closed is not None:
        cmap.set_bad(color=color_for_closed)
    else:
        cmap.set_bad(alpha=0.0)

    if isinstance(grid, RasterModelGrid):
        values = values.reshape(grid.shape)

        if values.ndim != 2:
            raise ValueError("values must have ndim == 2")

        y = (
            np.arange(values.shape[0] + 1) * grid.dy
            - grid.dy * 0.5
            + grid.xy_of_lower_left[1]
        )
        x = (
            np.arange(values.shape[1] + 1) * grid.dx
            - grid.dx * 0.5
            + grid.xy_of_lower_left[0]
        )

        kwds = {"cmap": cmap}
        (kwds["vmin"], kwds["vmax"]) = (values.min(), values.max())
        if (limits is None) and ((vmin is None) and (vmax is None)):
            if symmetric_cbar:
                (var_min, var_max) = (values.min(), values.max())
                limit = max(abs(var_min), abs(var_max))
                (kwds["vmin"], kwds["vmax"]) = (-limit, limit)
        elif limits is not None:
            (kwds["vmin"], kwds["vmax"]) = (limits[0], limits[1])
        else:
            if vmin is not None:
                kwds["vmin"] = vmin
            if vmax is not None:
                kwds["vmax"] = vmax
        kwds["alpha"] = alpha

        myimage = plt.pcolormesh(x, y, values, **kwds)
        myimage.set_rasterized(True)
        myimage.axes.set_aspect("equal")
        plt.autoscale(tight=True)

        if allow_colorbar:
            cb = plt.colorbar(norm=norm, shrink=shrink)
            if colorbar_label:
                cb.set_label(colorbar_label)
    else:
        import matplotlib.cm as cmx
        import matplotlib.colors as colors

        values = values.reshape(-1)

        if limits is not None:
            (vmin, vmax) = (limits[0], limits[1])
        else:
            if vmin is None:
                vmin = values.min()
            if vmax is None:
                vmax = values.max()
            if symmetric_cbar:
                vmin, vmax = -max(abs(vmin), abs(vmax)), max(abs(vmin), abs(vmax))

        cNorm = colors.Normalize(vmin, vmax)
        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)
        colorVal = scalarMap.to_rgba(values, alpha=alpha)[grid.node_at_cell]

        patches = []

        for corners in grid.corners_at_cell:
            valid_corners = corners[corners != grid.BAD_INDEX]
            closed_loop_corners = np.concatenate([valid_corners, [valid_corners[0]]])

            x = grid.x_of_corner[closed_loop_corners]
            y = grid.y_of_corner[closed_loop_corners]
            xy = np.vstack((x, y)).T
            patches.append(Polygon(xy, closed=True, fill=True))

        patchcollection = PatchCollection(
            patches, facecolor=colorVal, edgecolor=colorVal
        )

        ax = plt.gca()
        ax.add_collection(patchcollection)

        if show_elements:
            x = grid.x_of_corner[grid.corners_at_face]
            y = grid.y_of_corner[grid.corners_at_face]

            segs = np.dstack((x, y))
            line_segments = LineCollection(segs)
            line_segments.set_color("black")
            ax.add_collection(line_segments)

        ax.set_aspect("equal")
        ax.set_rasterized(True)

        plt.xlim((np.min(grid.x_of_node), np.max(grid.x_of_node)))
        plt.ylim((np.min(grid.y_of_node), np.max(grid.y_of_node)))

        scalarMap.set_array(values)
        if allow_colorbar:
            cb = plt.colorbar(scalarMap, shrink=shrink, ax=ax)
            if colorbar_label:
                cb.set_label(colorbar_label)

    if grid_units[1] is None and grid_units[0] is None:
        grid_units = grid.axis_units
        if grid_units[1] == "-" and grid_units[0] == "-":
            plt.xlabel("X")
            plt.ylabel("Y")
        else:
            plt.xlabel("X (%s)" % grid_units[1])
            plt.ylabel("Y (%s)" % grid_units[0])
    else:
        plt.xlabel("X (%s)" % grid_units[1])
        plt.ylabel("Y (%s)" % grid_units[0])

    if plot_name is not None:
        plt.title("%s" % (plot_name))

    if var_name is not None or var_units is not None:
        if var_name is not None:
            assert type(var_name) is str
            if var_units is not None:
                assert type(var_units) is str
                colorbar_label = var_name + " (" + var_units + ")"
            else:
                colorbar_label = var_name
        else:
            assert type(var_units) is str
            colorbar_label = "(" + var_units + ")"
        assert type(colorbar_label) is str
        assert allow_colorbar
        cb.set_label(colorbar_label)

    if color_for_background is not None:
        plt.gca().set_facecolor(color_for_background)

    if output is not None:
        if type(output) is str:
            plt.savefig(output)
            plt.clf()
        elif output:
            plt.show()


def imshow_grid(grid, values, **kwds):
    """Prepare a map view of data over all nodes or cells in the grid.

    Data is plotted as colored cells. If at='node', the surrounding cell is
    shaded with the value at the node at its center. If at='cell', the cell
    is shaded with its own value. Outer edges of perimeter cells are
    extrapolated. Closed elements are colored uniformly (default black,
    overridden with kwd 'color_for_closed'); other open boundary nodes get
    their actual values.

    *values* can be a field name, a regular array, or a masked array. If a
    masked array is provided, masked entries will be treated as if they were
    Landlab BC_NODE_IS_CLOSED. Used together with the color_for_closed=None
    keyword (i.e., "transparent"), this can allow for construction of overlay
    layers in a figure (e.g., only defining values in a river network, and
    overlaying it on another landscape).

    Use matplotlib functions like xlim, ylim to modify your plot after calling
    :func:`imshow_grid`, as desired.

    This function happily works with both regular and irregular grids.

    Parameters
    ----------
    grid : ModelGrid
        Grid containing the field to plot, or describing the geometry of the
        provided array.
    values : array_like, masked_array, or str
        Node or cell values, or a field name as a string from which to draw
        the data.
    at : str, {'node', 'cell'}
        Tells plotter where values are defined.
    plot_name : str, optional
        String to put as the plot title.
    var_name : str, optional
        Variable name, to use as a colorbar label.
    var_units : str, optional
        Units for the variable being plotted, for the colorbar.
    grid_units : tuple of str, optional
        Units for y, and x dimensions. If None, component will look to the
        gri property `axis_units` for this information. If no units are
        specified there, no entry is made.
    symmetric_cbar : bool
        Make the colormap symetric about 0.
    cmap : str
        Name of a colormap
    alpha : array-like or scalar or None, optional
        Set the transparency.
    limits : tuple of float
        Minimum and maximum of the colorbar.
    vmin, vmax: floats
        Alternatives to limits.
    allow_colorbar : bool
        If True, include the colorbar.
    colorbar_label : str or None
        The string with which to label the colorbar.
    norm : matplotlib.colors.Normalize
        The normalizing object which scales data, typically into the interval
        [0, 1]. Ignore in most cases.
    shrink : float
        Fraction by which to shrink the colorbar.
    color_for_closed : str or None
        Color to use for closed elements (default 'black'). If None, closed
        (or masked) elements will be transparent.
    color_for_background : color str or other color declaration, or None
        Color to use for closed elements (default None). If None, the
        background will be transparent, and appear white.
    show_elements : bool
        If True, and grid is a Voronoi, the faces will be plotted in black
        along with just the colour of the cell, defining the cell outlines
        (defaults False).
    output : None, string, or bool
        If None (or False), the image is sent to the imaging buffer to await
        an explicit call to show() or savefig() from outside this function.
        If a string, the string should be the path to a save location, and the
        filename (with file extension). The function will then call
        plt.savefig([string]) itself. If True, the function will call
        plt.show() itself once plotting is complete.
    """
    if "values_at" in kwds:
        warn(
            "the 'values_at' keyword is deprecated, use the 'at' keyword instead",
            DeprecationWarning,
        )
        kwds.setdefault("at", kwds.pop("values_at"))
    values_at = kwds.pop("at", None)

    if values_at is None:
        values_at = _guess_location(grid, values)

    if values_at is None:
        raise TypeError("unable to determine location of values, use 'at' keyword")
    elif values_at not in {"node", "cell"}:
        raise TypeError(
            f"value location, {values_at!r}, is not supported (must be one of 'node', 'cell')"
        )

    if isinstance(values, str):
        values = grid.field_values(values, at=values_at)

    if values_at == "node":
        imshow_grid_at_node(grid, values, **kwds)
    elif values_at == "cell":
        imshow_grid_at_cell(grid, values, **kwds)


def _guess_location(
    grid, values, search_order=("node", "cell", "link", "patch", "corner", "face")
):
    """Make an educated guess as to where a field is located on a grid."""
    if isinstance(values, str):
        return _guess_location_from_name(grid, values)
    else:
        return _guess_location_from_size(grid, values)


def _guess_location_from_name(
    grid, name, search_order=("node", "cell", "link", "patch", "corner", "face")
):
    """Given a name, make an educated guess as to where a field is located on a grid.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    name : str
        Name of a field.

    Returns
    -------
    str or None
        Grid element where the field is likely defined.
    """
    for location in search_order:
        if grid.has_field(name, at=location):
            return location
    return None


def _guess_location_from_size(
    grid, values, search_order=("node", "cell", "link", "patch", "corner", "face")
):
    """Given an array, make an educated guess as to where a field is located on a grid.

    Parameters
    ----------
    grid : ModelGrid
        A landlab ModelGrid.
    values : array-like
        An array of values.

    Returns
    -------
    str or None
        Grid element where the field is likely defined.
    """
    for location in search_order:
        if values.size == grid.number_of_elements(location):
            return location
    return None



================================================
File: src/landlab/plot/imshowhs.py
================================================
"""Methods to plot data defined on Landlab grids.

Plotting functions
++++++++++++++++++

.. autosummary::

    ~imshowhs_grid
    ~imshowhs_grid_at_node
"""

import warnings

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LightSource
from matplotlib.colors import to_rgba
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

from .event_handler import query_grid_on_button_press


def imshowhs_grid(grid, values, **kwds):
    """Prepare a map view of data over all nodes in the grid using a hillshade
    topography map in the background.

    Data are plotted as cells shaded with the value at the node at its center.
    Outer edges of perimeter cells are extrapolated. Closed elements are
    colored uniformly (with the color being controlled by the *color_for_closed*
    keyword); other open boundary nodes get their actual values.

    *values* can be a field name, a regular array, or a masked array. If a
    masked array is provided, masked entries are treated as if they were
    *landlab* :py:attr:`~.NodeStatus.CLOSED` nodes. If closed nodes are also set to
    be transparent (i.e. ``color_for_closed=None``), this can allow for the
    construction of overlying layers in a figure (e.g., only defining values in a
    river network, and then overlaying it on another landscape).

    Use matplotlib functions like ``xlim``, ``ylim`` to modify your plot after calling
    :func:`imshowhs_grid`, as desired.

    Node coordinates are printed when a mouse button is pressed on a cell in
    the plot.

    .. note::

        For now, this function only works with :class:`~.RasterModelGrid`.

    Parameters
    ----------
    grid : ModelGrid
        Grid containing the field to plot, or describing the geometry of the
        provided array.
    values : array_like, masked_array, or str
        Node values, or a field name as a string from which to draw the data.
    plot_name : str, optional
        String to put as the plot title.
    var_name : str, optional
        Variable name, to use as a colorbar label.
    var_name_two : str, optional
        Variable name of second layer, to use as a colorbar label.
    var_units : str, optional
        Units for the variable being plotted, for the colorbar.
    grid_units : tuple of str, optional
        Units for *y*, and *x* dimensions. If ``None``, component will look to the
        grid property :py:attr:`~.ModelGrid.axis_units` for this information. If no units are
        specified there, no entry is made.
    symmetric_cbar : bool
        Make the colormap symmetric about 0.
    cmap : str
        Name of a colormap
    limits : tuple of float
        Minimum and maximum of the colorbar.
    vmin, vmax: floats
        Alternatives to limits.
    norm : matplotlib.colors.Normalize
        The normalizing object which scales data, typically into the interval
        [0, 1]. Ignore in most cases.
    ticks_km : bool, optional
        Display ticks in km instead of m
    allow_colorbar : bool
        If ``True``, include the colorbar.
    shrink : float
        Fraction by which to shrink the colorbar.
    color_for_closed : str or None
        Color to use for closed nodes (default ``None``). If ``None``,
        (or masked) nodes will be transparent.
    color_for_background : color str or other color declaration, or None
        Color to use for closed elements (default ``None``). If ``None``, the
        background will be transparent, and appear white.
    output : None, string, or bool
        If ``None`` (or ``False``), the image is sent to the imaging buffer to await
        an explicit call to ``show()`` or ``savefig()`` from outside this function.
        If a ``str``, the string should be the path to a save location, and the
        filename (with file extension). The function will then call
        ``plt.savefig([string])`` itself. If ``True``, the function will call
        ``plt.show()`` itself once plotting is complete.
    fontweight_xlabel : str, optional
        Weight of *x* label. The default is 'bold'.
    fontweight_ylabel : str, optional
        Weight of *y* label. The default is 'bold'.
    plot_type : {"DEM", "Hillshade", "Drape1", "Drape2"}, optional
        The type of plot that will be plotted.

        * 'DEM': Display a digital elevation map underlain by a shaded relief,
          based on the same DEM ('topographic__elevation')
        * 'Hillshade': Display the shaded relief, of the provided DEM
          ('topographic__elevation')
        * 'Drape1': Display any kind of provided layer on top of a shaded
          relief provided in the 'topographic__elevation' field
        * 'Drape2': Display two layers on top of a shaded relief provided in
          the 'topographic__elevation' field

        The default is "DEM".
    drape1 : array_like, masked_array
        Node values to plot on top of a hillshade map. The default is ``None``.
    drape2 : array_like, masked_array
        Node values to plot on top of drape1 and a hillshade map. The default is ``None``.
    cmap2 : str
        Name of a colormap for drape 2. The default is ``None``.
    vertical_exa : float, optional
        Vertical exaggeration of hillshade map. The default is ``None``.
    azdeg : float, optional
        Azimuth of the light source. The default is 315.
    altdeg : float, optional
        Elevation of the light source. The default is 65.
    thres_drape1 : float, optional
        Threshold below which drape1 is made transparent. The default is ``None``.
    alpha : float (0-1), optional
        Transparency of DEM/Drape1 . The default is ``None``.
    thres_drape2 : float, optional
        Threshold below which drape2 is made transparent. The default is ``None``.
    alpha2 : float (0-1), optional
        Transparency of Drape2 . The default is ``None``.
    add_double_colorbar : bool, optional
        Add a double colorbar when two drapes are plotted. The default is ``False``.
    plt_contour : bool, optional
        Add contour lines to elevation plot. The default is ``False``.
    contour_nb : int, optional
        Number of contour lines. The default is 50.
    default_fontsize : float, optional
        Default font size for plot labels. The default is 10.
    cbar_height : percentage, optional
        Height of colorbar as a percentage of the figure. The default is *5%*.
    cbar_width : percentage, optional
        Width of colorbar in percentage of figure. The default is *30%*.
    cbar_or : str, optional
        Orientation of colorbar. The default is "horizontal".
    cbar_loc : str, optional
        Location of colorbar. The default is "lower right".
    bbox_to_anchor : vector, optional
        Bounding box to anchor. The default is ``(0, 0, 1, 1)``.
    cbar_ticks_position : str, optional
        location of colorbar ticks (below or on top of the colorbar). The default
        is "top".
    cbar_ticks_position2 : str, optional
        location of colorbar ticks for colorbar of Drape2 (below or on top of the
        colorbar). The default is "bottom".
    colorbar_label_y : float, optional
        location of colorbar label with respect to the colorbar in y direction.
        The default is -40.
    colorbar_label_x : float , optional
        location of colorbar label with respect to the colorbar in x direction.
        The default is 0.5.
    cbar_tick_size : float, optional
        Colorbar tick size. The default is 10.
    cbar_label_color : str, optional
        Colorbar tick color. The default is 'black'.
    cbar_label_fontweight : str, optional
        Colorbar font weight. The default is 'bold'.
    add_label_bbox : bool, optional
        Add a bbox surrounding the colorbar label. The default is ``False``.
    y_label_offSet_var_1 : float, optional
        Offset of ylabel on colorbar of first variable in plot with two
        overlaying plots. The default is 3.0.
    y_label_offSet_var_2 : float, optional
        Offset of ylabel on colorbar of first variable in plot with two
        overlaying plots. The default is -1.25.

    Returns
    -------
    ax
        Axis of the plot if *output* keyword is ``True``.
    """
    if "values_at" in kwds:
        warnings.warn(
            f"the 'values_at' keyword is deprecated, use `at={kwds['values_at']!r}` instead",
            DeprecationWarning,
            stacklevel=2,
        )
    values_at = kwds.pop("values_at", "node")
    values_at = kwds.pop("at", values_at)

    if isinstance(values, str):
        values = grid.field_values(values, at=values_at)
        # values = grid.field_values(values_at, values)

    if values_at == "node":
        ax = imshowhs_grid_at_node(grid, values, **kwds)
    elif values_at in {"link", "patch", "corner", "face", "cell"}:
        raise NotImplementedError(
            "For now, only values at nodes can be displayed using the in the "
            "imshowhs functions"
        )
    else:
        raise TypeError(f"{values_at}: value location not understood")

    return ax


def imshowhs_grid_at_node(grid, values, **kwds):
    """Prepare a map view of data over all nodes in the grid using a hillshade
    topography map in the background.

    Data are plotted as cells shaded with the value at the node at its center.
    Outer edges of perimeter cells are extrapolated. Closed elements are
    colored uniformly (with the color being controlled by the *color_for_closed*
    keyword); other open boundary nodes get their actual values.

    *values* can be a field name, a regular array, or a masked array. If a
    masked array is provided, masked entries are treated as if they were
    *landlab* :py:attr:`~.NodeStatus.CLOSED` nodes. If closed nodes are also set to
    be transparent (i.e. ``color_for_closed=None``), this can allow for the
    construction of overlying layers in a figure (e.g., only defining values in a
    river network, and then overlaying it on another landscape).

    Use matplotlib functions like ``xlim``, ``ylim`` to modify your plot after calling
    :func:`imshowhs_grid`, as desired.

    Node coordinates are printed when a mouse button is pressed on a cell in
    the plot.

    .. note::

        For now, this function only works with :class:`~.RasterModelGrid`.

    Parameters
    ----------
    grid : ModelGrid
        Grid containing the field to plot, or describing the geometry of the
        provided array.
    values : array_like, masked_array, or str
        Node values, or a field name as a string from which to draw the data.
    plot_name : str, optional
        String to put as the plot title.
    var_name : str, optional
        Variable name, to use as a colorbar label.
    var_name_two : str, optional
        Variable name of second layer, to use as a colorbar label.
    var_units : str, optional
        Units for the variable being plotted, for the colorbar.
    grid_units : tuple of str, optional
        Units for *y*, and *x* dimensions. If ``None``, component will look to the
        grid property :py:attr:`~.ModelGrid.axis_units` for this information. If no units are
        specified there, no entry is made.
    symmetric_cbar : bool
        Make the colormap symmetric about 0.
    cmap : str
        Name of a colormap
    limits : tuple of float
        Minimum and maximum of the colorbar.
    vmin, vmax: floats
        Alternatives to limits.
    norm : matplotlib.colors.Normalize
        The normalizing object which scales data, typically into the interval
        [0, 1]. Ignore in most cases.
    ticks_km : bool, optional
        Display ticks in km instead of m
    allow_colorbar : bool
        If ``True``, include the colorbar.
    shrink : float
        Fraction by which to shrink the colorbar.
    color_for_closed : str or None
        Color to use for closed nodes (default ``None``). If ``None``,
        (or masked) nodes will be transparent.
    color_for_background : color str or other color declaration, or None
        Color to use for closed elements (default ``None``). If ``None``, the
        background will be transparent, and appear white.
    output : None, string, or bool
        If ``None`` (or ``False``), the image is sent to the imaging buffer to await
        an explicit call to ``show()`` or ``savefig()`` from outside this function.
        If a ``str``, the string should be the path to a save location, and the
        filename (with file extension). The function will then call
        ``plt.savefig([string])`` itself. If ``True``, the function will call
        ``plt.show()`` itself once plotting is complete.
    fontweight_xlabel : str, optional
        Weight of *x* label. The default is 'bold'.
    fontweight_ylabel : str, optional
        Weight of *y* label. The default is 'bold'.
    plot_type : {"DEM", "Hillshade", "Drape1", "Drape2"}, optional
        The type of plot that will be plotted.

        * 'DEM' (the default): Display a digital elevation map underlain by a
          shaded relief, based on the same DEM ('topographic__elevation')
        * 'Hillshade': Display the shaded relief, of the provided DEM
          ('topographic__elevation')
        * 'Drape1': Display any kind of provided layer on top of a shaded
          relief provided in the 'topographic__elevation' field
        * 'Drape2': Display two layers on top of a shaded relief provided in
          the 'topographic__elevation' field

        The default is "DEM".
    drape1 : array_like, masked_array
        Node values to plot on top of a hillshade map. The default is ``None``.
    drape2 : array_like, masked_array
        Node values to plot on top of drape1 and a hillshade map. The default is ``None``.
    cmap2 : str
        Name of a colormap for drape 2. The default is ``None``.
    vertical_exa : float, optional
        Vertical exaggeration of hillshade map. The default is ``None``.
    azdeg : float, optional
        Azimuth of the light source. The default is 315.
    altdeg : float, optional
        Elevation of the light source. The default is 65.
    thres_drape1 : float, optional
        Threshold below which drape1 is made transparent. The default is ``None``.
    alpha : float (0-1), optional
        Transparency of DEM/Drape1 . The default is ``None``.
    thres_drape2 : float, optional
        Threshold below which drape2 is made transparent. The default is ``None``.
    alpha2 : float (0-1), optional
        Transparency of Drape2 . The default is ``None``.
    add_double_colorbar : bool, optional
        Add a double colorbar when two drapes are plotted. The default is ``False``.
    plt_contour : bool, optional
        Add contour lines to elevation plot. The default is ``False``.
    contour_nb : int, optional
        Number of contour lines. The default is 50.
    default_fontsize : float, optional
        Default font size for plot labels. The default is 10.
    cbar_height : percentage, optional
        Height of colorbar as a percentage of the figure. The default is *5%*.
    cbar_width : percentage, optional
        Width of colorbar in percentage of figure. The default is *30%*.
    cbar_or : str, optional
        Orientation of colorbar. The default is "horizontal".
    cbar_loc : str, optional
        Location of colorbar. The default is "lower right".
    bbox_to_anchor : vector, optional
        Bounding box to anchor. The default is ``(0, 0, 1, 1)``.
    cbar_ticks_position : str, optional
        Location of colorbar ticks (below or on top of the colorbar). The default
        is "top".
    cbar_ticks_position2 : str, optional
        Location of colorbar ticks for colorbar of *Drape2* (below or on top of the
        colorbar). The default is "bottom".
    colorbar_label_y : float, optional
        Location of colorbar label with respect to the colorbar in *y* direction.
        The default is -40.
    colorbar_label_x : float , optional
        Location of colorbar label with respect to the colorbar in x direction.
        The default is 0.5.
    cbar_tick_size : float, optional
        Colorbar tick size. The default is 10.
    cbar_label_color : str, optional
        Colorbar tick color. The default is 'black'.
    cbar_label_fontweight : str, optional
        Colorbar font weight. The default is 'bold'.
    add_label_bbox : bool, optional
        Add a bbox surrounding the colorbar label. The default is ``False``.
    y_label_offSet_var_1 : float, optional
        Offset of *ylabel* on colorbar of first variable in plot with two overlaying
        plots. The default is 3.0.
    y_label_offSet_var_2 : float, optional
        Offset of *ylabel* on colorbar of first variable in plot with two overlaying
        plots. The default is -1.25.

    Returns
    -------
    ax
        Axis of the plot if *output* keyword is ``True``.
    """
    if isinstance(values, str):
        values_at_node = grid.at_node[values]
    else:
        values_at_node = values.reshape((-1,))

    if values_at_node.size != grid.number_of_nodes:
        raise ValueError("number of values does not match number of nodes")

    values_at_node = np.ma.masked_where(
        grid.status_at_node == grid.BC_NODE_IS_CLOSED, values_at_node
    )

    ax = _imshowhs_grid_values(grid, values_at_node, **kwds)

    if isinstance(values, str):
        plt.title(values)

    plt.gcf().canvas.mpl_connect(
        "button_press_event", lambda event: query_grid_on_button_press(event, grid)
    )
    # plt.show()
    return ax


def _imshowhs_grid_values(
    grid,
    values,
    plot_name=None,
    var_name=None,
    var_name_two=None,
    var_units=None,
    fontweight_xlabel="bold",
    fontweight_ylabel="bold",
    grid_units=(None, None),
    symmetric_cbar=False,
    cmap="pink",
    limits=None,
    allow_colorbar=True,
    vmin=None,
    vmax=None,
    norm=None,
    ticks_km=False,
    shrink=1.0,
    color_for_closed=None,
    color_for_background=None,
    output=None,
    plot_type="DEM",
    drape1=None,
    drape2=None,
    cmap2=None,
    vertical_exa=None,
    azdeg=315,
    altdeg=65,
    thres_drape1=None,
    alpha=None,
    thres_drape2=None,
    alpha2=None,
    add_double_colorbar=False,
    plt_contour=False,
    contour_nb=50,
    default_fontsize=10,
    cbar_height="5%",
    cbar_width="30%",
    cbar_or="horizontal",
    cbar_loc="lower right",
    bbox_to_anchor=(0, 0, 1, 1),
    cbar_ticks_position="top",
    cbar_ticks_position2="bottom",
    colorbar_label_y=-40,
    colorbar_label_x=0.5,
    cbar_tick_size=10,
    cbar_label_color="black",
    cbar_tick_color="black",
    cbar_label_fontweight="bold",
    add_label_bbox=False,
    y_label_offSet_var_1=3,
    y_label_offSet_var_2=-1.25,
):
    from ..grid.raster import RasterModelGrid

    if not isinstance(grid, RasterModelGrid):
        raise NotImplementedError(
            "For now, only RasterModelGrids are supported in the imshowhs functions"
        )

    plot_type_options = ["DEM", "Hillshade", "Drape1", "Drape2"]
    if plot_type not in plot_type_options:
        raise ValueError(
            f"plot_type should be one of the following: {', '.join(plot_type_options)}"
        )
    if plot_type == "Drape1" and drape1 is None:
        raise ValueError(
            "if plot_type is Drape1, 'drape1' input argument cannot be None. "
            "Provide at least one array with the size of the number of grid "
            "nodes as drape1='field_to_be_plotted'"
        )
    if plot_type == "Drape2" and (drape1 is None or drape2 is None):
        raise ValueError(
            "if plot_type is Drape2, 'drape1' and 'drape2' input arguments cannot be None. "
            "Provide an array for both with the size of the number of grid nodes as "
            "drape1='field1_to_be_plotted' and drape2='field2_to_be_plotted'"
        )

    # Poperties of bounding box of colorbar label, if used:
    if add_label_bbox:
        bbox_prop = {
            "boxstyle": "round",
            "pad": 0.1,
            "facecolor": "white",
            "alpha": 0.7,
            "edgecolor": "white",
        }
    else:
        bbox_prop = None

    if isinstance(cmap, str):
        cmap = plt.colormaps[cmap]

    if color_for_closed is not None:
        cmap.set_bad(color=color_for_closed)
    else:
        cmap.set_bad(alpha=0.0)

    values.shape = grid.shape

    if isinstance(grid, RasterModelGrid):
        # somethingToPlot is a flag indicating if any pixels should be plotted.
        somethingToPlot = True

        if values.ndim != 2:
            raise ValueError("values must have ndim == 2")

        y = (
            np.arange(values.shape[0] + 1) * grid.dy
            - grid.dy * 0.5
            + grid.xy_of_lower_left[1]
        )
        x = (
            np.arange(values.shape[1] + 1) * grid.dx
            - grid.dx * 0.5
            + grid.xy_of_lower_left[0]
        )

        ls = LightSource(azdeg=azdeg, altdeg=altdeg)
        if cmap is None:
            cmap = plt.colormaps["terrain"]

        dx = x[1] - x[0]
        dy = y[1] - y[0]

        if vertical_exa is not None:
            ve = vertical_exa
        else:
            ve = 3
        extent = np.array([x[0], x[-1], y[-1], y[0]])
        if ticks_km:
            extent /= 1e3

        ax1 = plt.gca()
        if alpha is None:
            alpha = 1
        if alpha2 is None:
            alpha2 = 1
        blend_modes = ["hsv", "overlay", "soft"]
        if plot_type == "DEM":
            kwds = {"cmap": cmap}
            (kwds["vmin"], kwds["vmax"]) = (values.min(), values.max())
            if (limits is None) and ((vmin is None) and (vmax is None)):
                if symmetric_cbar:
                    (var_min, var_max) = (values.min(), values.max())
                    limit = max(abs(var_min), abs(var_max))
                    (kwds["vmin"], kwds["vmax"]) = (-limit, limit)
            elif limits is not None:
                (kwds["vmin"], kwds["vmax"]) = (limits[0], limits[1])
            else:
                if vmin is not None:
                    kwds["vmin"] = vmin
                if vmax is not None:
                    kwds["vmax"] = vmax

            val = values.data
            rgb = ls.shade(
                val,
                cmap=cmap,
                blend_mode=blend_modes[0],
                vert_exag=ve,
                dx=dx,
                dy=dy,
                fraction=0.4,
            )
            if color_for_closed is not None:
                rgb[:, :, :][values.mask] = to_rgba(color_for_closed)

            ima = ax1.imshow(rgb, extent=extent, **kwds)

        elif plot_type == "Hillshade":
            cmap_gray = plt.colormaps["gray"]
            if color_for_closed is not None:
                cmap_gray.set_bad(color=color_for_closed)
            else:
                cmap_gray.set_bad(alpha=0.0)
            hs_values = ls.hillshade(values.data, vert_exag=ve, dx=dx, dy=dy)
            if color_for_closed is not None:
                hs_values = np.ma.masked_where(values.mask, hs_values)
            ima = plt.imshow(
                hs_values,
                cmap=cmap_gray,
                extent=extent,
            )

            allow_colorbar = False

        elif plot_type == "Drape1" or plot_type == "Drape2":
            # Process values from first drape
            if isinstance(drape1, str):
                values_at_node_drape1 = grid.at_node[drape1]
            else:
                values_at_node_drape1 = drape1.reshape((-1,))

            if values_at_node_drape1.size != grid.number_of_nodes:
                raise ValueError("number of values does not match number of nodes")

            values_at_node_drape1 = np.ma.masked_where(
                grid.status_at_node == grid.BC_NODE_IS_CLOSED, values_at_node_drape1
            )

            # Add mask if thres_drape1 is given
            if thres_drape1 is not None:
                # check if any value exceeds threshold
                if not np.any(values_at_node_drape1 > thres_drape1):
                    somethingToPlot = False

                values_at_node_drape1 = np.ma.masked_where(
                    values_at_node_drape1 < thres_drape1, values_at_node_drape1
                )

            if isinstance(grid, RasterModelGrid):
                shape = grid.shape
            else:
                shape = (-1,)
            val1 = values_at_node_drape1.reshape(shape)

            kwds = {"cmap": cmap}
            (kwds["vmin"], kwds["vmax"]) = (val1.min(), val1.max())
            if (limits is None) and ((vmin is None) and (vmax is None)):
                if symmetric_cbar:
                    (var_min, var_max) = (val1.min(), val1.max())
                    limit = max(abs(var_min), abs(var_max))
                    (kwds["vmin"], kwds["vmax"]) = (-limit, limit)
            elif limits is not None:
                (kwds["vmin"], kwds["vmax"]) = (limits[0], limits[1])
            else:
                if vmin is not None:
                    kwds["vmin"] = vmin
                if vmax is not None:
                    kwds["vmax"] = vmax

            cmap_gray = plt.colormaps["gray"]
            if color_for_closed is not None:
                cmap_gray.set_bad(color=color_for_closed)
            else:
                cmap_gray.set_bad(alpha=0.0)

            hs_values = ls.hillshade(values.data, vert_exag=ve, dx=dx, dy=dy)
            if color_for_closed is not None:
                hs_values = np.ma.masked_where(values.mask, hs_values)
            ima = plt.imshow(
                hs_values,
                cmap=cmap_gray,
                extent=extent,
            )
            ima = ax1.imshow(val1, extent=extent, alpha=alpha, **kwds)
            if plt_contour:
                plt.contour(
                    x[0:-1] * 1e-3,
                    y[0:-1] * 1e-3,
                    val1,
                    contour_nb,
                    colors="black",
                    linewidths=0.2,
                )
        if somethingToPlot:
            # To cartezian  coordinates   (not if other layers has to be plotted on top!)
            if plot_type != "Drape2":
                ax1.invert_yaxis()
            plt.xticks(fontsize=default_fontsize)
            plt.yticks(fontsize=default_fontsize)

            # if Drape2, default behavior is to add colorbar of first layer if
            # add_double_colorbar == False
            if allow_colorbar and (
                plot_type == "DEM"
                or plot_type == "Drape1"
                or (plot_type == "Drape2" and not add_double_colorbar)
            ):
                cb_or = cbar_or
                cb_ticks_position = cbar_ticks_position

                axins1 = inset_axes(
                    ax1,
                    width=cbar_width,  # width = 50% of parent_bbox width
                    height=cbar_height,  # height : 5%
                    loc=cbar_loc,
                    bbox_transform=ax1.transAxes,
                    borderpad=0,
                    bbox_to_anchor=bbox_to_anchor,
                )

                maxV = kwds["vmax"]
                minV = kwds["vmin"]
                cb_length = maxV - minV
                if maxV <= 10:
                    cb = plt.colorbar(
                        ima,
                        ax=ax1,
                        cax=axins1,
                        orientation=cb_or,
                        ticks=[
                            np.round(minV + 0.2 * cb_length, 1),
                            np.round(minV + 0.8 * cb_length, 1),
                        ],
                    )
                elif maxV <= 100:
                    cb = plt.colorbar(
                        ima,
                        ax=ax1,
                        cax=axins1,
                        orientation=cb_or,
                        ticks=[
                            np.round(minV + 0.2 * cb_length, 0),
                            np.round(minV + 0.8 * cb_length, 0),
                        ],
                    )
                else:
                    cb = plt.colorbar(
                        ima,
                        ax=ax1,
                        cax=axins1,
                        orientation=cb_or,
                        ticks=[
                            np.round(0.1 * (minV + 0.2 * cb_length)) * 10,
                            np.round(0.1 * (minV + 0.8 * cb_length)) * 10,
                        ],
                    )
                axins1.xaxis.set_ticks_position(cb_ticks_position)
                cb.ax.tick_params(
                    labelsize=cbar_tick_size,
                    color=cbar_tick_color,
                    labelcolor=cbar_tick_color,
                )

                # if colorbar_label:
                #     cb.set_label(colorbar_label, rotation=270)
                #     # ax1.xaxis.set_label_coords(0,2.5)

            if plot_type == "Drape2":
                # Process values from first drape

                if isinstance(drape2, str):
                    values_at_node_drape2 = grid.at_node[drape2]
                else:
                    values_at_node_drape2 = drape2.reshape((-1,))

                if values_at_node_drape2.size != grid.number_of_nodes:
                    raise ValueError("number of values does not match number of nodes")

                values_at_node_drape2 = np.ma.masked_where(
                    grid.status_at_node == grid.BC_NODE_IS_CLOSED, values_at_node_drape2
                )

                # Add mask if thres_drape1 is given
                if thres_drape2 is not None:
                    values_at_node_drape2 = np.ma.masked_where(
                        values_at_node_drape2 < thres_drape2, values_at_node_drape2
                    )

                if isinstance(grid, RasterModelGrid):
                    shape = grid.shape
                else:
                    shape = (-1,)
                val2 = values_at_node_drape2.reshape(shape)

                if cmap2 is None:
                    cmap2 = plt.colormaps["terrain"]
                kwds = {"cmap": cmap2}
                (kwds["vmin"], kwds["vmax"]) = (val2.min(), val2.max())
                if (limits is None) and ((vmin is None) and (vmax is None)):
                    if symmetric_cbar:
                        (var_min, var_max) = (val2.min(), val2.max())
                        limit = max(abs(var_min), abs(var_max))
                        (kwds["vmin"], kwds["vmax"]) = (-limit, limit)
                elif limits is not None:
                    (kwds["vmin"], kwds["vmax"]) = (limits[0], limits[1])
                else:
                    if vmin is not None:
                        kwds["vmin"] = vmin
                    if vmax is not None:
                        kwds["vmax"] = vmax

                ima2 = ax1.imshow(val2, extent=extent, alpha=alpha2, **kwds)
                ax1.invert_yaxis()

                # Add colorbars
                if add_double_colorbar:
                    axins1 = inset_axes(
                        ax1,
                        width=cbar_width,  # width = 50% of parent_bbox width
                        height=cbar_height,  # height : 5%
                        loc=cbar_loc,
                        bbox_to_anchor=(-0.005, 0.25, 1, 1),
                        bbox_transform=ax1.transAxes,
                        borderpad=0,
                    )

                    cb_or = cbar_or
                    cb_ticks_position = cbar_ticks_position
                    maxV = np.max(val1)
                    minV = np.min(val1)
                    cb_length = maxV - minV
                    if maxV <= 10:
                        cb = plt.colorbar(
                            ima,
                            ax=ax1,
                            cax=axins1,
                            orientation=cb_or,
                            ticks=[
                                np.round(minV + 0.2 * cb_length, 1),
                                np.round(minV + 0.8 * cb_length, 1),
                            ],
                        )
                    elif maxV <= 100:
                        cb = plt.colorbar(
                            ima,
                            ax=ax1,
                            cax=axins1,
                            orientation=cb_or,
                            ticks=[
                                np.round(minV + 0.2 * cb_length, 0),
                                np.round(minV + 0.8 * cb_length, 0),
                            ],
                        )
                    else:
                        cb = plt.colorbar(
                            ima,
                            ax=ax1,
                            cax=axins1,
                            orientation=cb_or,
                            ticks=[
                                np.round(0.1 * (minV + 0.2 * cb_length)) * 10,
                                np.round(0.1 * (minV + 0.8 * cb_length)) * 10,
                            ],
                        )
                    cb.ax.tick_params(
                        labelsize=cbar_tick_size,
                        color=cbar_tick_color,
                        labelcolor=cbar_tick_color,
                    )
                    axins1.xaxis.set_ticks_position(cb_ticks_position)

                    axins1.set_xlabel(
                        var_name,
                        usetex=True,
                        fontsize=default_fontsize,
                        rotation=0,
                        color=cbar_label_color,
                        fontweight=cbar_label_fontweight,
                        bbox=bbox_prop,
                    )
                    axins1.xaxis.set_label_coords(0.5, y_label_offSet_var_1)

                    axins2 = inset_axes(
                        ax1,
                        width=cbar_width,  # width = 50% of parent_bbox width
                        height=cbar_height,  # height : 5%
                        loc=cbar_loc,
                        bbox_to_anchor=(-0.005, 0.15, 1, 1),
                        bbox_transform=ax1.transAxes,
                        borderpad=0,
                    )
                    cb_or = cbar_or
                    cb_ticks_position = cbar_ticks_position2
                    maxV = np.max(val2)
                    minV = np.min(val2)
                    cb_length = maxV - minV
                    if maxV <= 10:
                        cb = plt.colorbar(
                            ima2,
                            ax=ax1,
                            cax=axins2,
                            orientation=cb_or,
                            ticks=[
                                np.round(minV + 0.2 * cb_length, 1),
                                np.round(minV + 0.8 * cb_length, 1),
                            ],
                        )
                    elif maxV <= 100:
                        cb = plt.colorbar(
                            ima2,
                            ax=ax1,
                            cax=axins2,
                            orientation=cb_or,
                            ticks=[
                                np.round(minV + 0.2 * cb_length, 0),
                                np.round(minV + 0.8 * cb_length, 0),
                            ],
                        )
                    else:
                        cb = plt.colorbar(
                            ima2,
                            ax=ax1,
                            cax=axins2,
                            orientation=cb_or,
                            ticks=[
                                np.round(0.1 * (minV + 0.2 * cb_length)) * 10,
                                np.round(0.1 * (minV + 0.8 * cb_length)) * 10,
                            ],
                        )
                    cb.ax.tick_params(
                        labelsize=cbar_tick_size,
                        color=cbar_tick_color,
                        labelcolor=cbar_tick_color,
                    )

                    axins2.xaxis.set_ticks_position(cb_ticks_position)
                    axins2.set_xlabel(
                        var_name_two,
                        usetex=True,
                        fontsize=default_fontsize,
                        rotation=0,
                        color=cbar_label_color,
                        fontweight=cbar_label_fontweight,
                        bbox=bbox_prop,
                    )
                    axins2.xaxis.set_label_coords(0.5, y_label_offSet_var_2)
        # If nothing to plot
        else:
            ax1.invert_yaxis()
    if grid_units[1] is None and grid_units[0] is None:
        grid_units = grid.axis_units
        if grid_units[1] == "-" and grid_units[0] == "-":
            ax1.set_xlabel(
                "Easting", fontweight=fontweight_xlabel, fontsize=default_fontsize
            )
            ax1.set_ylabel(
                "Northing", fontweight=fontweight_ylabel, fontsize=default_fontsize
            )
        else:
            ax1.set_xlabel(
                "Easting, %s" % grid_units[1],
                fontweight=fontweight_xlabel,
                fontsize=default_fontsize,
            )
            ax1.set_ylabel(
                "Northing, %s" % grid_units[1],
                fontweight=fontweight_ylabel,
                fontsize=default_fontsize,
            )
    else:
        ax1.set_xlabel(
            "Easting, %s" % grid_units[1],
            fontweight=fontweight_xlabel,
            fontsize=default_fontsize,
        )
        ax1.set_ylabel(
            "Northing, %s" % grid_units[1],
            fontweight=fontweight_ylabel,
            fontsize=default_fontsize,
        )

    if plot_name is not None:
        plt.title(f"{plot_name}")

    if (
        somethingToPlot
        and (var_name is not None or var_units is not None)
        and plot_type != "Drape2"
    ):
        if var_name is not None:
            assert type(var_name) is str
            if var_units is not None:
                assert type(var_units) is str
                colorbar_label = var_name + " (" + var_units + ")"
            else:
                colorbar_label = var_name
        else:
            assert type(var_units) is str
            colorbar_label = "(" + var_units + ")"
        assert type(colorbar_label) is str
        if allow_colorbar:
            cb.set_label(
                colorbar_label,
                fontsize=default_fontsize,
                labelpad=colorbar_label_y,
                color=cbar_label_color,
                x=colorbar_label_x,
                fontweight=cbar_label_fontweight,
                bbox=bbox_prop,
            )

    if color_for_background is not None:
        plt.gca().set_facecolor(color_for_background)

    if output is not None:
        if isinstance(output, str):
            plt.savefig(output)
            plt.clf()
        elif output:
            plt.show()

    return ax1



================================================
File: src/landlab/plot/layers.py
================================================
from functools import partial
from itertools import tee

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Patch
from scipy.interpolate import interp1d


def pairwise(iterable):
    "s -> (s0,s1), (s1,s2), (s2, s3), ..."
    a, b = tee(iterable)
    next(b, None)
    return zip(a, b)


def plot_layers(
    elevation_at_layer,
    x=None,
    sea_level=0.0,
    color_water=(0.8, 1.0, 1.0),
    color_bedrock=(0.8, 0.8, 0.8),
    color_layer=None,
    layer_line_width=0.5,
    layer_line_color="k",
    title=None,
    x_label="Distance",
    y_label="Elevation",
    legend_location="lower left",
):
    """Plot a stack of sediment layers as a cross section.

    Create a plot of the elevation sediment layers, including surfaces for
    sea level and bedrock.

    Parameters
    ----------
    elevation_at_layer : array-like of shape *(n_layers, n_stacks)*
        Elevation to each layer along the profile. Layers are provided
        row-by-row, with the bottom-most layer being the first row.
    x : array-like, optional
        Distance to each stack along the cross-section. If not provided,
        stack number will be used.
    sea_level : float, optional
        Elevation of sea level.
    color_water : tuple of float, optional
        Tuple of *(red, green, blue)* values for water.
    color_bedrock : tuple of float, optional
        Tuple of *(red, green, blue)* values for bedrock.
    color_layer : string, optional
        Colormap to use to color in the layers.
    layer_line_width : float, optional
        Width of line used to plot layer surfaces.
    layer_line_color : string, optional
        Color of the line used to plot layer surfaces.
    title : string, optional
        Text to be used for the graph's title. The default is to not
        include a title.
    x_label : string, optional
        Text to be used for the x (horizontal) axis label.
    y_label : string, optional
        Text to be used for the y (vertical) axis label.
    legend_location : string, optional
        Where to put the legend.
    """
    elevation_at_layer = np.asarray(elevation_at_layer)
    elevation_at_layer = np.expand_dims(
        elevation_at_layer,
        axis=tuple(np.arange(2 - elevation_at_layer.ndim)),
    )

    if len(elevation_at_layer) == 0:
        raise ValueError(
            f"no layers to plot (elevation_at_layer.shape is {np.shape(elevation_at_layer)}"
        )

    if x is None:
        x = np.arange(elevation_at_layer.shape[1])

    top_surface = elevation_at_layer[-1]
    bottom_surface = elevation_at_layer[0]

    if len(elevation_at_layer) > 0:
        _plot_layers(
            x,
            elevation_at_layer,  # [layers_to_plot],
            color=color_layer,
            lc=layer_line_color,
            lw=layer_line_width,
        )
    _plot_water(x, top_surface, sea_level=sea_level, fc=color_water)
    _plot_bedrock(x, bottom_surface, fc=color_bedrock)
    _plot_surface(x, top_surface, sea_level=sea_level)

    legend_location and _plot_legend(
        legend_location, color_water=color_water, color_bedrock=color_bedrock
    )

    plt.xlabel(x_label)
    plt.ylabel(y_label)
    title and plt.title(title)

    plt.show()


def _plot_water(x, y, sea_level=0.0, fc=(0.8, 1.0, 1.0)):
    x_water, y_water = _insert_shorelines(x, y, sea_level=sea_level)
    if fc is not None:
        plt.fill_between(x_water, y_water, sea_level, where=y_water <= sea_level, fc=fc)

    water_surface = np.full_like(x_water, sea_level, dtype=float)
    water_surface[y_water > sea_level] = np.nan
    plt.plot(x_water, water_surface, color="b")


def _plot_bedrock(x, y, fc=(0.8, 0.8, 0.8)):
    if fc is not None:
        plt.fill_between(
            x,
            y,
            np.full_like(y, y.min()),
            color=fc,
        )
    plt.plot(x, y, color="k")


def _plot_surface(x, y, sea_level=0.0):
    under_water = y <= sea_level
    plt.plot(x[~under_water], y[~under_water], color="g")
    plt.plot(x[under_water], y[under_water], color="b")


def _plot_layers(x, layers, color=None, lc="k", lw=0.5):
    if color is not None:
        cmap = plt.colormaps[color] if isinstance(color, str) else color

        for layer, (lower, upper) in enumerate(pairwise(layers)):
            plt.fill_between(
                x,
                lower,
                upper,
                fc=cmap(layer * 256 // len(layers)),
            )
    plt.plot(
        x,
        layers.T,
        color=lc,
        linewidth=lw,
    )


def _plot_legend(legend_location, color_water=None, color_bedrock=None):
    legend_item = partial(Patch, edgecolor="k", linewidth=0.5)
    items = [
        ("Ocean", color_water),
        ("Bedrock", color_bedrock),
    ]
    legend = [legend_item(label=label, fc=color) for label, color in items if color]
    legend and plt.legend(handles=legend, loc=legend_location)


def _insert_shorelines(x, y, sea_level=0.0):
    """Insert shorelines into x-y arrays.

    Examples
    --------
    >>> from landlab.plot.layers import _insert_shorelines
    >>> _insert_shorelines([0, 1, 2], [2, 1, -1])
    (array([0. ,  1. ,  1.5,  2. ]), array([ 2.,  1.,  0., -1.]))
    """
    x, y = np.asarray(x, dtype=float), np.asarray(y, dtype=float)

    y_relative_to_sea_level = y - sea_level
    shorelines = _search_zero_crossings(y_relative_to_sea_level)
    x_of_shoreline = _interp_zero_crossings(x, y_relative_to_sea_level, shorelines)

    return (
        np.insert(x, shorelines + 1, x_of_shoreline),
        np.insert(y, shorelines + 1, sea_level),
    )


def _search_zero_crossings(y):
    """Search an array for changes in sign between elements.

    Parameters
    ----------
    y : array-like
        Input array to check for sign changes.

    Returns
    -------
    int
        Indices into *y* where a sign has changed.

    Examples
    --------
    >>> from landlab.plot.layers import _search_zero_crossings

    The returned index is to the element before the zero-crossing.

    >>> list(_search_zero_crossings([2, 1, -1]))
    [1]
    >>> list(_search_zero_crossings([-2, -2, 1, 2]))
    [1]
    >>> list(_search_zero_crossings([-2, -2, 1, 2, -1]))
    [1, 3]

    These are not zero-crossings.

    >>> len(_search_zero_crossings([2, 0, 0, -2])) == 0
    True
    >>> len(_search_zero_crossings([2, 0, 1])) == 0
    True
    >>> len(_search_zero_crossings([2, 3, 4])) == 0
    True
    >>> len(_search_zero_crossings([0, 0, 0])) == 0
    True
    """
    sign = np.sign(y)

    # zeros = sign == 0
    # if not np.all(zeros):
    #     while np.any(zeros):
    #         sign[zeros] = np.roll(sign, 1)[zeros]
    #         zeros = sign == 0

    # return np.where(sign[1:] != sign[:-1])[0]
    return np.where(sign[1:] * sign[:-1] < 0)[0]


def _interp_zero_crossings(x, y, shorelines):
    """Interpolate between adjacent elements to find x-locations of zero-crossings.

    Parameters
    ----------
    x : array-like
        Distances.
    y : array-like
        Elevations.
    shorelines : array-like of int
        Indices to shoreline elements.

    Returns
    -------
    array of float
        Distances to interpolated shorelines.

    Examples
    --------
    >>> from landlab.plot.layers import _interp_zero_crossings
    >>> _interp_zero_crossings([0, 1, 2], [1, -1, -1], [0])
    array([0.5])
    >>> _interp_zero_crossings([0, 1, 2, 3], [1, -1, -1, 4], [0, 2])
    array([0.5, 2.2])
    """
    x_of_shoreline = []
    for shoreline in shorelines:
        coast = slice(shoreline, shoreline + 2)

        # for scipy<1.10 interp1d requires x and y to have at least two elements,
        # which is not the case if theshoreline is the last element.
        x_of_shoreline.append(
            interp1d(np.broadcast_to(y[coast], 2), np.broadcast_to(x[coast], 2))(0.0)
        )

    return np.asarray(x_of_shoreline)



================================================
File: src/landlab/plot/video_out.py
================================================
#! /usr/bin/env python

"""Create mp4 animation of Landlab output.

This component allows creation of mp4 animations of output from Landlab.
It does so by stitching together output from the conventional Landlab
static plotting routines from plot/imshow.py.

It is compatible with all Landlab grids, though cannot handle an evolving grid
as yet.

Initialize the video object vid at the start of your code, then simply call
vid.add_frame(grid, data) each time you want to add a frame. At the end of
the model run, call vid.produce_video().

CAUTION: This component may prove *very* memory-intensive. It is recommended
that the total number of frames included in the output multiplied by the
number of pixels (nodes) in the image not exceed XXXXXXXXX.

Due to some issues with codecs in matplotlib, at the moment on .gif output
movies are recommended. If this irritates you, you can modify your own
PYTHONPATH to allow .mp4 compilation (try a google search for the warning
raised by this method for some hints). These (known) issues are apparently
likely to resolve themselves in a future release of matplotlib.
"""
import matplotlib.animation as animation
import matplotlib.pyplot as plt
import numpy as np

from landlab.plot import imshow


class VideoPlotter:
    """Create animations of landlab output.

    Create Landlab movies.

    Parameters
    ----------
    grid : RasterModelGrid
        A RasterModelGrid.
    data_centering : {'node', 'cell'}, optional
        Where data are centered.
    start : float, optional
        Model time at which filming starts.
    stop : float, optional
        Model time at which filming stops.
    step : float, optional
        Model time frequency at which frames are made.
    """

    def __init__(self, grid, data_centering="node", start=None, stop=None, step=None):
        """Create Landlab movies.

        Parameters
        ----------
        grid : RasterModelGrid
            A RasterModelGrid.
        data_centering : {'node', 'cell'}, optional
            Where data are centered.
        start : float, optional
            Model time at which filming starts.
        stop : float, optional
            Model time at which filming stops.
        step : float, optional
            Model time frequency at which frames are made.
        """
        self.initialize(grid, data_centering, start, stop, step)

    def initialize(self, grid, data_centering, start, stop, step):
        """Set up the plotter.

        A copy of the grid is required.

        *data_centering* controls the type of data the video will be plotting.

        It can be set to: `"node"` (default) or `"cell"`.

        *start*, *stop,* and *step* control when a frame is added. They are
        absolute times in the model run. All are optional.

        Parameters
        ----------
        grid : RasterModelGrid
            A RasterModelGrid.
        data_centering : {'node', 'cell'}, optional
            Where data are centered.
        start : float
            Model time at which filming starts.
        stop : float
            Model time at which filming stops.
        step : float
            Model time frequency at which frames are made.
        """
        options_for_data_centering = ["node", "cell"]

        if data_centering not in options_for_data_centering:
            raise ValueError("data_centering not valid")

        self.grid = grid
        # self.image_list = []
        self.data_list = []

        # this controls the intervals at which to plot
        self.last_remainder = float("inf")
        self.last_t = float("-inf")
        if start is None:
            start = float("-inf")
        if stop is None:
            stop = float("inf")
        self.step_control_tuple = (start, stop, step)

        # initialize the plots for the vid
        if data_centering == "node":
            self.centering = "n"
            self.plotfunc = imshow.imshow_grid_at_node
        elif data_centering == "cell":
            self.centering = "c"
            self.plotfunc = imshow.imshow_cell_grid

        self.randomized_name = "my_animation_" + str(int(np.random.random() * 10000))
        self.fig = plt.figure(self.randomized_name)  # randomized name

    def add_frame(self, grid, data, elapsed_t, **kwds):
        """Add a frame to the video.

        data can be either the data to plot (nnodes, or appropriately lengthed
        numpy array), or a string for grid field access.

        kwds can be any of the usual plotting keywords, e.g., cmap.
        """
        if isinstance(data, str):
            if self.centering == "n":
                data_in = grid.at_node[data]
            elif self.centering == "c":
                data_in = grid.at_cell[data]
        else:
            data_in = data

        self.kwds = kwds

        if self.last_t < elapsed_t:
            try:
                normalized_elapsed_t = elapsed_t - self.start_t
            except AttributeError:
                self.start_t = elapsed_t
                normalized_elapsed_t = 0.0
        else:  # time has apparently gone "backwards"; reset the module
            # ...note a *forward* jump in time wouldn't register
            self.clear_module()
            self.start_t = elapsed_t
            normalized_elapsed_t = 0.0

        # we're between start & stop
        if self.step_control_tuple[0] <= elapsed_t < self.step_control_tuple[1]:
            if not self.step_control_tuple[2]:  # no step provided
                print("Adding frame to video at elapsed time %f" % elapsed_t)
                self.data_list.append(data_in.copy())
            else:
                excess_fraction = normalized_elapsed_t % self.step_control_tuple[2]
                # Problems with rounding errors make this double check
                # necessary
                if excess_fraction < self.last_remainder or np.allclose(
                    excess_fraction, self.step_control_tuple[2]
                ):
                    print("Adding frame to video at elapsed time %f" % elapsed_t)
                    self.data_list.append(data_in.copy())
                self.last_remainder = excess_fraction
        self.last_t = elapsed_t

    def produce_video(
        self,
        interval=200,
        repeat_delay=2000,
        filename="video_output.gif",
        override_min_max=None,
    ):
        """Finalize and save the video of the data.

        Parameters
        ----------
        interval : int, optional
            Interval between frames in milliseconds.
        repeat_delay : int, optional
            Repeat delay before restart in milliseconds.
        filename : str, optional
            Name of the file to save in the present working directory. At
            present, only *.gifs* will implement reliably without
            tweaking Python's PATHs.
        override_min_max : tuple of float
            Minimum and maximum for the scale on the plot as (*min*, *max*).
        """
        print("Assembling video output, may take a while...")
        plt.figure(self.randomized_name)
        # find the limits for the plot:
        if not override_min_max:
            self.min_limit = np.amin(self.data_list[0])
            self.max_limit = np.amax(self.data_list[0])

            if len(self.data_list) <= 1:
                raise ValueError("Animation must have at least one frame.")

            # assumes there is more than one frame in the loop
            for i in self.data_list[1:]:
                self.min_limit = min((self.min_limit, np.amin(i)))
                self.max_limit = max((self.max_limit, np.amax(i)))
        else:
            self.min_limit = override_min_max[0]
            self.max_limit = override_min_max[1]

        self.fig.colorbar(
            self.plotfunc(
                self.grid,
                self.data_list[0],
                limits=(self.min_limit, self.max_limit),
                allow_colorbar=False,
                **self.kwds,
            )
        )

        ani = animation.FuncAnimation(
            self.fig,
            _make_image,
            frames=self._yield_image,
            interval=interval,
            blit=True,
            repeat_delay=repeat_delay,
        )
        ani.save(filename, fps=1000.0 / interval)
        plt.close()

    def _yield_image(self):
        """Helper function designed to generate image_list items for plotting,
        rather than storing them all."""

        for i in self.data_list:
            # yield self.grid.node_vector_to_raster(i)
            yield (
                i,
                self.plotfunc,
                (self.min_limit, self.max_limit),
                self.grid,
                self.kwds,
            )

    def clear_module(self):
        """Clear internally held data.

        Wipe all internally held data that would cause trouble if module
        were to be rerun without being reinstantiated.
        """
        self.data_list = []


def _make_image(yielded_tuple):
    yielded_raster_data = yielded_tuple[0]
    plotfunc = yielded_tuple[1]
    limits_in = yielded_tuple[2]
    grid = yielded_tuple[3]
    kwds = yielded_tuple[4]
    im = plotfunc(
        grid, yielded_raster_data, limits=limits_in, allow_colorbar=False, **kwds
    )
    return im



================================================
File: src/landlab/plot/network_sediment_transporter/__init__.py
================================================
"""
Created on Tue Jun 18 14:22:27 2019

@author: pfeif
"""

from .plot_network_and_parcels import plot_network_and_parcels

__all__ = ["plot_network_and_parcels"]



================================================
File: src/landlab/plot/network_sediment_transporter/locate_parcel_xy.py
================================================
"""
Created on Fri Oct 24 16:28:00 2019

This code converts location in a link to an X, Y


@author: Jon Czuba, Katy Barnhart
"""

import numpy as np


def locate_parcel_xy(grid, parcels, parcel_time_index, parcel_number):
    # determine the location of that parcel in its link
    parcel_loc = parcels.dataset.location_in_link[
        parcel_number, parcel_time_index
    ].values

    # parcels that end their timestep off network have the starting link id
    # recorded, and np.nan as the distance.

    if not np.isnan(parcel_loc):
        # get link id
        parcel_link = int(
            parcels.dataset.element_id[parcel_number, parcel_time_index].values
        )

        # DANGER DANGER: This code assumes the verticies of links are ordered
        # from upstream to downstream. This should be the case for delineated
        # river networks, so this line should not be necessary. A quick
        # work-around is the following, but ideally verticies should be flipped in GIS.
        # parcel_loc = 0.9999 - parcel_loc

        # get the X, Y vertices of the squiggly line for that link (loaded by
        # import_shapefile.py)

        # I am not sure these next 2 lines are necessary here, but I don't know
        # how to do this differently and/or better.
        if "x_of_polyline" in grid.at_link:
            link_x = grid["link"]["x_of_polyline"][parcel_link]
            link_y = grid["link"]["y_of_polyline"][parcel_link]
        else:
            flow_dir = grid.at_link["flow__link_direction"][parcel_link]
            head_node = grid.node_at_link_head[parcel_link]
            tail_node = grid.node_at_link_tail[parcel_link]
            if flow_dir == -1:
                link_x = [grid.x_of_node[head_node], grid.x_of_node[tail_node]]
                link_y = [grid.y_of_node[head_node], grid.y_of_node[tail_node]]
            elif flow_dir == 1:
                # 1 = with direction of from tail to head.
                link_x = [grid.x_of_node[tail_node], grid.x_of_node[head_node]]
                link_y = [grid.y_of_node[tail_node], grid.y_of_node[head_node]]
            else:
                raise ValueError(
                    "trying to plot on an inactive link. this should not happen."
                )
            # eventually need to use x_of_node, y_of_node, and nodes_at_link,
            # but the upstream to downstream ordering also matters.

        # cumulative distance between squiggly-line link vertices [0 to link length]
        link_dist = np.concatenate(
            [[0], np.cumsum(np.sqrt(np.diff(link_x) ** 2 + np.diff(link_y) ** 2))]
        )

        # cumulative relative distance between squiggly-line link verticies [0 to 1]
        # divide cumulative distance by max distance to get vector of distances between
        # 0 and 1
        link_rel_dist = link_dist / np.max(link_dist)

        # # determine which two points on squiggly line bound parcel location in that link
        # upper_loc_idx = np.argmax(link_rel_dist - parcel_loc > 0)
        #
        # to_interp_link_loc = link_rel_dist[upper_loc_idx - 1 : upper_loc_idx + 1]
        # to_interp_link_x = link_x[upper_loc_idx - 1 : upper_loc_idx + 1]
        # to_interp_link_y = link_y[upper_loc_idx - 1 : upper_loc_idx + 1]
        #
        # # check values are increasing
        # np.all(np.diff(to_interp_link_loc) > 0)

        # interpolate the X,Y coordinates from the parcel location
        parcel_x = np.interp(
            parcel_loc, link_rel_dist, link_x
        )  # , left=np.nan, right=np.nan)
        parcel_y = np.interp(parcel_loc, link_rel_dist, link_y)
        # assert np.isnan(parcel_x) == False

        # save data to a single variable. better would be to save this info as
        # an element of parcels.dataset.X and ...Y
        XY = [parcel_x, parcel_y]

        # parcels.dataset["X"] = parcel_x
        # parcels.dataset["Y"] = parcel_y

    else:
        # if that parcel is no longer in the system do not try to compute X,Y and
        # instead return NaN
        XY = [np.nan, np.nan]

    # return the X,Y values
    return XY



================================================
File: src/landlab/plot/network_sediment_transporter/plot_network_and_parcels.py
================================================
"""Plot outputs of the NetworkSedimentTransporter.

This code plots:

*  the network, with option to color each link according to a link attribute.
*  the parcels, with option to color and size each parcel according to
   parcel attributes.

Authors: Katy Barnhart, Jon Czuba, Allison Pfeiffer
"""

import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.collections import LineCollection
from matplotlib.colors import Normalize

from landlab.plot.network_sediment_transporter.locate_parcel_xy import locate_parcel_xy
from landlab.utils.return_array import return_array_at_link


def plot_network_and_parcels(
    grid,
    parcels,
    parcel_time_index=None,
    map_buffer=0.1,
    parcel_filter=None,
    network_color=None,
    link_attribute=None,
    link_attribute_title=None,
    network_cmap="cividis",
    network_norm=None,
    network_linewidth=None,
    parcel_color=None,
    parcel_color_attribute=None,
    parcel_color_attribute_title=None,
    parcel_color_cmap="plasma",
    parcel_color_norm=None,
    parcel_size=None,
    parcel_size_attribute=None,
    parcel_size_attribute_title=None,
    parcel_size_norm=None,
    parcel_size_min=5,
    parcel_size_max=40,
    parcel_alpha=0.5,
    fig=None,
    output=None,
    **kwargs,
):
    """Plot a river network and parcels on the river network.

    Intended to display the results of the :class:`~.NetworkSedimentTransporter`
    component.

    The river network (an instance of :class:`~.NetworkModelGrid`) is plotted either as
    straight links between grid nodes, or (if the network was created using a
    shapefile to set network topology) as sinuous lines representing the actual
    link geometry.

    The parcels (an instance of :class:`~.DataRecord`) are represented as dot markers
    along the links, with the marker location set by parcel attribute
    `location_at_link`. The default is to plot the parcel locations at the
    last timestep in :class`~.DataRecord`, though any time index may be specified.

    Use of this plotting tool is described in detail in a landlab tutorial.

    Parameters
    ----------
    grid : NetworkModelGrid
        Instance of NetworkModelGrid.
    parcels : DataRecord
        Instance of Landlab DataRecord, with the same attribute requirements as
        :class:`~.NetworkSedimentTransporter`.
    parcel_time_index : int, optional
        Parcel time index to plot. Default is last timestep in parcels
        :class:`~.DataRecord`.
    map_buffer : float, optional
        Increase the plot extent by at least this much. Note, because of axis
        equal, may be more.
    parcel_filter : array_like of bool, shape (number_of_parcels, ), optional
        Filter to plot only a selection of the parcels.

    Other Parameters
    ----------------
    network_color : str, optional
        Uniform color for network links.
    link_attribute : array_like or str, optional
        Value (as either an array or the name of an *at-link* field) used to set
        link color. Categorical options not supported. Must be continuous.
    link_attribute_title : str, optional
        String to use as the title, if `link_attribute` is a string, it is
        used as the default.
    network_cmap : str, optional
        Name of colormap for network.
    network_norm : matplotlib.colors.Normalize, optional
        Default is linear between minimum and maximum of `link_attribute`.
    network_linewidth : float, optional
        Width of network lines.
    parcel_color : str, optional
        Constant color used for parcel markers.
    parcel_color_attribute : str, optional
        Parcel attribute name, categorical options not supported. Must be continuous.
    parcel_color_attribute_title : str, optional
        String to use as the legend title. If `parcel_color_attribute` is a
        string, it is used as the default.
    parcel_color_cmap : str, optional
        Name of colormap for variable parcel color.
    parcel_color_norm : matplotlib.colors.Normalize, optional
        Default is linear between minimum and maximum of `parcel_color_attribute`.
    parcel_size : float, optional
        Marker size in points.
    parcel_size_attribute: str, optional
        Parcel attribute name, categorical options not supported. Must be continuous.
    parcel_size_attribute_title : str, optional
        String to use as the title, if `parcel_size_attribute` is a string, it is
        used as the default.
    parcel_size_norm : matplotlib.colors.Normalize, optional
        Default is linear between minimum and maximum of `parcel_size_attribute`.
    parcel_size_min : float, optional
        Specify the smallest size of the dot markers plotted, in
        units of points (default 5). Use with `parcel_size_max`. They will be
        aligned with the limits of `parcel_size_norm`.
    parcel_size_max : float, optional
        Specify the largest size of the dot markers plotted, in
        units of points (default 40). Use with `parcel_size_min`. They will be
        aligned with the limits of `parcel_size_norm`.
    parcel_alpha : float, optional
        Specify parcel marker transparency between 0.0 and 1.0.
    fig :  matplotlib.figure.Figure, optional
        Default is to create a new figure object.
    output : bool, str, optional
        If not provided (or ``False``), the image is sent to the imaging buffer to await
        an explicit call to :func:`~matplotlib.pyplot.show` or
        :func:`~matplotlib.pyplot.savefig` from outside this function.
        If a string, `output` should be the path to a file (with file extension) to
        save the figure to. The function will then call
        :func:`~matplotlib.pyplot.savefig` itself. If ``True``, the function will call
        :func:`~matplotlib.pyplot.show` itself once plotting is complete.
    **kwargs :
        Anything else to pass to figure creation.
    """
    # part 0 checking and default setting.

    # only network color/linewidth provided OR link attribute.
    if (link_attribute is not None) and (network_color is not None):
        raise ValueError(
            "Only one of link_attribute and network_color can be provided."
        )

    if link_attribute is None:
        network_color = network_color or "c"
        network_linewidth = network_linewidth or 0.5
        legend_link = False
    else:
        legend_link = True
        if link_attribute_title is None:
            if isinstance(link_attribute, str):
                link_attribute_title = link_attribute
            else:
                link_attribute_title = ""

    # only parcel color OR parcel_color_attribute.
    if (parcel_color_attribute is not None) and (parcel_color is not None):
        raise ValueError(
            "Only one of parcel_color_attribute and parcel_color can be provided."
        )

    if parcel_color_attribute is None:
        parcel_color = parcel_color or "k"
        legend_parcel_color = False
    else:
        legend_parcel_color = True
        if parcel_color_attribute_title is None:
            parcel_color_attribute_title = parcel_color_attribute

    # only parcel size or parcel_size_attribute
    if (parcel_size_attribute is not None) and (parcel_size is not None):
        raise ValueError(
            "Only one of parcel_size_attribute and parcel_size can be provided."
        )

    if parcel_size_attribute is None:
        parcel_size = parcel_size or 1.0
        legend_parcel_size = False
    else:
        legend_parcel_size = True

        if parcel_size_attribute_title is None:
            parcel_size_attribute_title = parcel_size_attribute

    # parcel time:
    # cant use standard value or default because a value of 0 is valid.
    if parcel_time_index is None:
        parcel_time_index = -1

    # Figure out whether the legend will have one, two, or three
    # parts (linewidth, parcel size, parcel color)
    n_legends = legend_link + legend_parcel_size + legend_parcel_color

    # set up figure, label and legend gridspecs.
    if fig is None:
        fresh_fig = True
        fig = plt.figure(**kwargs)
    else:
        # we'll be adding this plot to existing axes
        fresh_fig = False

    spec = gridspec.GridSpec(
        ncols=1,
        nrows=3,
        left=0,
        right=1,
        top=1,
        bottom=0,
        figure=fig,
        height_ratios=[1, 0.1, 0.2],
    )

    if fresh_fig:
        ax = fig.add_subplot(spec[0, 0])
    else:
        plt.figure(fig)
        ax = plt.gca()
        ax.set_subplotspec(spec[0, 0])

    if n_legends > 0:
        label_spec = spec[1, 0].subgridspec(
            ncols=2 * n_legends - 1,
            nrows=1,
            wspace=0.1,
            hspace=1,
            width_ratios=[1] + (n_legends - 1) * [0.2, 1],
        )
        legend_spec = spec[2, 0].subgridspec(
            ncols=2 * n_legends - 1,
            nrows=1,
            wspace=0.1,
            hspace=1,
            width_ratios=[1] + (n_legends - 1) * [0.2, 1],
        )
        legend_idx = 0

    # SET UP LINESEGMENTS FOR NETWORK. If polylines exist use, otherwise use
    # endpoints. Also get the ranges so a buffer can be placed around the
    # network.

    if "x_of_polyline" in grid.at_link:
        xy_of_polylines = _get_xy_of_polylines(
            grid.at_link["x_of_polyline"], grid.at_link["y_of_polyline"]
        )
    else:
        xy_of_polylines = grid.xy_of_node[grid.nodes_at_link]

    xlim, ylim = _calc_xy_limits(xy_of_polylines, buffer_frac=map_buffer)

    # Add Linesegments and Configure.

    # if there is a link attribute.
    if link_attribute is not None:
        line_segments = LineCollection(
            xy_of_polylines,
            cmap=network_cmap,
            norm=network_norm,
            linewidth=network_linewidth,
            zorder=1,
        )
        line_segments.set_array(return_array_at_link(grid, link_attribute))
        ax.add_collection(line_segments)

        # create label
        lax = fig.add_subplot(label_spec[0, legend_idx])
        lax.text(
            0.5,
            0.0,
            "Line Color",
            transform=lax.transAxes,
            color="k",
            ha="center",
            va="top",
            size=plt.rcParams["font.size"] + 2,
        )
        lax.axis("off")

        # add legend.
        lax = fig.add_subplot(legend_spec[0, legend_idx])
        legend_idx += 2
        fig.colorbar(
            line_segments, cax=lax, orientation="horizontal", label=link_attribute_title
        )

    # if link values are constant.
    else:
        line_segments = LineCollection(
            xy_of_polylines, colors=network_color, linewidth=network_linewidth, zorder=1
        )
        ax.add_collection(line_segments)

    # Part 2: Add Parcels.
    X = np.empty(len(parcels.dataset.element_id))
    Y = np.empty(len(parcels.dataset.element_id))

    # Locate parcel XY for each parcel at a particular time
    # some aspects of this may be possible to speed up, but at minimum
    # locate_parcel_xy must be called for each link (since calculating location)
    # along link requires interpoloation.
    # if this occurs we must also ensure the parcel order is maintained b/c of
    # color and shape formatting.

    for parcel_idx in range(parcels.dataset.item_id.size):
        XY = locate_parcel_xy(grid, parcels, parcel_time_index, parcel_idx)
        X[parcel_idx] = XY[0]
        Y[parcel_idx] = XY[1]

    # plot X,Y point on delineated network and color/size point according to a
    # certain attribute of the parcel or the link in which the parcel resides

    # if a parcel color attribute is provided.
    if parcel_color_attribute is not None:
        # if this is true, then instead of none we need to get the right
        # values from the parcels and scale/normalize them correctly. At present
        # plan to support only continuous values. Can be extended to strs as
        # categorical.
        if parcel_color_attribute in parcels.dataset:
            if "time" in parcels.dataset[parcel_color_attribute].sizes:
                parcel_color = parcels.dataset[parcel_color_attribute].values[
                    :, parcel_time_index
                ]
            else:
                parcel_color = parcels.dataset[parcel_color_attribute].values
        else:
            raise ValueError(
                f"Parcel color attribute {parcel_color_attribute} not present in "
                "parcels."
            )

        if parcel_filter is not None:
            parcel_color = parcel_color[parcel_filter]

    if parcel_size_attribute is not None:
        # if this is true, then instead of none we need to get the right
        # values from the parcels and scale/normalize them correctly. At present
        # plan to support only continuous values. Can be extended to strs as
        # categorical.
        if parcel_size_attribute in parcels.dataset:
            if "time" in parcels.dataset[parcel_size_attribute].sizes:
                parcel_size_values = parcels.dataset[parcel_size_attribute].values[
                    :, parcel_time_index
                ]
            else:
                parcel_size_values = parcels.dataset[parcel_size_attribute].values

            if parcel_size_norm is None:
                parcel_size_norm = Normalize(
                    vmin=parcel_size_values.min(), vmax=parcel_size_values.max()
                )

            parcel_size = parcel_size_min + (
                parcel_size_max - parcel_size_min
            ) * parcel_size_norm(parcel_size_values)
        else:
            raise ValueError(
                f"Parcel size attribute {parcel_size_attribute} not present in "
                "parcels."
            )

        if parcel_filter is not None:
            parcel_size = parcel_size[parcel_filter]

    # add scatter, filter x and y if necessary.
    if parcel_filter is not None:
        X = X[parcel_filter]
        Y = Y[parcel_filter]

    scatter = ax.scatter(
        X,
        Y,
        s=parcel_size,
        c=parcel_color,
        alpha=parcel_alpha,
        cmap=parcel_color_cmap,
        norm=parcel_color_norm,
        zorder=2,
    )

    # create legends.
    if legend_parcel_color:
        lax = fig.add_subplot(label_spec[0, legend_idx])
        lax.text(
            0.5,
            0.0,
            "Parcel Color",
            transform=lax.transAxes,
            color="k",
            ha="center",
            va="top",
            size=plt.rcParams["font.size"] + 2,
        )
        lax.axis("off")

        lax = fig.add_subplot(legend_spec[0, legend_idx])
        legend_idx += 2
        fig.colorbar(
            scatter,
            cax=lax,
            orientation="horizontal",
            label=parcel_color_attribute_title,
        )

    if legend_parcel_size:
        lax = fig.add_subplot(label_spec[0, legend_idx])
        lax.text(
            0.5,
            0.0,
            "Parcel Size",
            transform=lax.transAxes,
            color="k",
            ha="center",
            va="top",
            size=plt.rcParams["font.size"] + 2,
        )
        lax.axis("off")

        lax = fig.add_subplot(legend_spec[0, legend_idx])
        handles, _ = scatter.legend_elements(prop="sizes", alpha=0.6)

        if len(handles) - 1 == 0:
            han = handles
            lab = [parcel_size_values.min()]
        else:
            han = handles[:: len(handles) - 1]
            lab = [parcel_size_values.min(), parcel_size_values.max()]

        lax.legend(
            han,
            lab,
            title=parcel_size_attribute_title,
            loc="center",
            frameon=False,
        )

        plt.axis("off")

    # Set the plot limits
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)

    # make axes equal
    ax.axis("equal")

    if isinstance(output, str):
        plt.savefig(output, bbox_inches="tight")
        plt.clf()
    elif output:
        plt.show()


def _get_xy_of_polylines(x_of_polylines, y_of_polylines):
    """Zip together x and y coordinate arrays.

    Parameters
    ----------
    x_of_polylines : ndarray
        x coordinates of a series of polyline segments.
    y_of_polylines : ndarray
        y coordinates of a series of polyline segments.

    Returns
    -------
    ndarray
        An ndarray of zipped polyline coordinates.

    Examples
    --------
    >>> x = [[0, 1, 2], [3, 4], [4, 3, 2, 1]]
    >>> y = [[5, 7, 6], [9, 8], [4, 5, 6, 7]]
    >>> xy_of_polylines = _get_xy_of_polylines(x, y)
    >>> len(xy_of_polylines)
    3
    >>> xy_of_polylines[0]
    array([[0, 5],
           [1, 7],
           [2, 6]])
    >>> xy_of_polylines[1]
    array([[3, 9],
           [4, 8]])
    >>> xy_of_polylines[2]
    array([[4, 4],
           [3, 5],
           [2, 6],
           [1, 7]])
    """
    return [np.stack(xy, axis=1) for xy in zip(x_of_polylines, y_of_polylines)]


def _calc_xy_limits(xy_of_segment, buffer_frac=0.0):
    """Calculate xy limits with an optional buffer.

    Parameters
    ----------
    xy_of_segment : iterable of ndarray
        xy coordinates of each segment.
    buffer_frac : float, optional
        Size of buffer as a fraction of the size of the bounding
        box of all the segments. A value of zero mean the limits
        will be 'tight'.

    Returns
    -------
    x_limits, y_limits
        x and y limits.

    Examples
    --------
    >>> xy_of_segments = ([[0, 1], [1, 2]], [[4, 5], [2, 3], [6, 6]], [[2, 9]])
    >>> _calc_xy_limits(xy_of_segments)
    ((0.0, 6.0), (1.0, 9.0))
    >>> _calc_xy_limits(xy_of_segments, buffer_frac=0.5)
    ((-3.0, 9.0), (-3.0, 13.0))
    """
    segments = np.concatenate(xy_of_segment)

    x_limits = _calc_limits(segments[:, 0], buffer_frac=buffer_frac)
    y_limits = _calc_limits(segments[:, 1], buffer_frac=buffer_frac)

    return x_limits, y_limits


def _calc_limits(values, buffer_frac=0.0):
    """Calculate min and max limits with a buffer on each end.

    Parameters
    ----------
    values : iterable
        Values to find limits of.
    buffer_frac : float, optional
        Size of buffer, as a fraction of peak-to-peak, to add to the
        upper and lower limit.

    Returns
    -------
    limits : tuple
        Lower and upper limits.

    Examples
    --------
    >>> _calc_limits([1, 3, 5, 4, 2])
    (1.0, 5.0)
    >>> _calc_limits([1, 3, 5, 4, 2], buffer_frac=0.25)
    (0.0, 6.0)
    """
    values = np.asarray(values)
    min_value, max_value = values.min(), values.max()
    buffer_width = buffer_frac * (max_value - min_value)
    return min_value - buffer_width, max_value + buffer_width



================================================
File: src/landlab/utils/__init__.py
================================================
#! /usr/bin/env

from .add_halo import add_halo
from .count_repeats import count_repeated_values
from .matrix import get_core_node_at_node
from .matrix import get_core_node_matrix
from .return_array import return_array_at_link
from .return_array import return_array_at_node
from .source_tracking_algorithm import convert_arc_flow_directions_to_landlab_node_ids
from .source_tracking_algorithm import find_unique_upstream_hsd_ids_and_fractions
from .source_tracking_algorithm import track_source
from .stable_priority_queue import StablePriorityQueue
from .watershed import get_watershed_mask
from .watershed import get_watershed_masks
from .watershed import get_watershed_masks_with_area_threshold
from .watershed import get_watershed_nodes
from .watershed import get_watershed_outlet
from .window_statistic import calculate_window_statistic

__all__ = [
    "add_halo",
    "count_repeated_values",
    "track_source",
    "convert_arc_flow_directions_to_landlab_node_ids",
    "find_unique_upstream_hsd_ids_and_fractions",
    "get_watershed_mask",
    "get_watershed_masks_with_area_threshold",
    "get_watershed_nodes",
    "get_watershed_outlet",
    "get_watershed_masks",
    "StablePriorityQueue",
    "return_array_at_node",
    "return_array_at_link",
    "get_core_node_at_node",
    "get_core_node_matrix",
    "calculate_window_statistic",
]



================================================
File: src/landlab/utils/_matrix.pyx
================================================
cimport cython

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


@cython.boundscheck(False)
@cython.wraparound(False)
def get_matrix_diagonal_elements_with_coef(
    const id_t [:, :] core_nodes_at_c2c_link,
    const id_t [:, :] core_nodes_at_c2fv_link,
    const id_t [:, :] core_nodes_at_fv2c_link,
    const cython.floating [:] coef_at_c2c_link,
    const cython.floating [:] coef_at_c2fv_link,
    const cython.floating [:] coef_at_fv2c_link,
    cython.floating [:] data,
):
    cdef int tail, head
    cdef int link
    cdef int n_links
    cdef double coef

    n_links = len(core_nodes_at_c2c_link)
    for link in range(n_links):
        tail = core_nodes_at_c2c_link[link, 0]
        head = core_nodes_at_c2c_link[link, 1]
        coef = coef_at_c2c_link[link]
        data[tail] -= coef
        data[head] -= coef

    n_links = len(core_nodes_at_c2fv_link)
    for link in range(n_links):
        tail = core_nodes_at_c2fv_link[link, 0]
        data[tail] -= coef_at_c2fv_link[link]

    n_links = len(core_nodes_at_fv2c_link)
    for link in range(n_links):
        head = core_nodes_at_fv2c_link[link, 1]
        data[head] -= coef_at_fv2c_link[link]


@cython.boundscheck(False)
@cython.wraparound(False)
def get_matrix_diagonal_elements(
    const id_t [:, :] core_nodes_at_c2c_link,
    const id_t [:, :] core_nodes_at_c2fv_link,
    const id_t [:, :] core_nodes_at_fv2c_link,
    cython.floating [:] data,
):
    cdef int tail, head
    cdef int link
    cdef int n_links

    n_links = len(core_nodes_at_c2c_link)
    for link in range(n_links):
        tail = core_nodes_at_c2c_link[link, 0]
        head = core_nodes_at_c2c_link[link, 1]
        data[tail] -= 1.0
        data[head] -= 1.0

    n_links = len(core_nodes_at_c2fv_link)
    for link in range(n_links):
        tail = core_nodes_at_c2fv_link[link, 0]
        data[tail] -= 1.0

    n_links = len(core_nodes_at_fv2c_link)
    for link in range(n_links):
        head = core_nodes_at_fv2c_link[link, 1]
        data[head] -= 1.0


@cython.boundscheck(False)
@cython.wraparound(False)
def fill_right_hand_side(
    const id_t [:, :] nodes_at_c2fv_link,
    const id_t [:, :] nodes_at_fv2c_link,
    const id_t [:] core_node_at_node,
    const cython.floating [:] value_at_node,
    cython.floating [:] out,
):
    cdef int tail, head

    for tail, head in nodes_at_c2fv_link:
        out[core_node_at_node[tail]] -= value_at_node[head]

    for tail, head in nodes_at_fv2c_link:
        out[core_node_at_node[head]] -= value_at_node[tail]



================================================
File: src/landlab/utils/add_halo.py
================================================
import numpy as np


def add_halo(data, halo=1, halo_value=None):
    """Add a halo of no data value to data.

    Parameters
    ----------
    data : array-like
        Array to add the halo to.
    halo : int, optional
        The size of the halo.
    halo_value : float, optional
        Value to fill the halo with. If not provided, the new data will is not
        initialized.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils import add_halo
    >>> data = np.array([[1, 2, 3], [4, 5, 6]])
    >>> add_halo(data, halo_value=9)
    array([[9, 9, 9, 9, 9], [9, 1, 2, 3, 9], [9, 4, 5, 6, 9], [9, 9, 9, 9, 9]])
    """
    if halo < 0:
        raise ValueError("halo must be greater than or equal to zero")
    elif halo == 0:
        return data.copy()

    data_with_halo = np.empty([dim + 2 * halo for dim in data.shape], dtype=data.dtype)
    data_with_halo[halo:-halo, halo:-halo] = data
    if halo_value is not None:
        data_with_halo[:halo, :] = halo_value
        data_with_halo[-halo:, :] = halo_value
        data_with_halo[:, :halo] = halo_value
        data_with_halo[:, -halo:] = halo_value

    return data_with_halo



================================================
File: src/landlab/utils/count_repeats.py
================================================
#! /usr/bin/env python
"""Count repeated values in an array."""

import numpy as np


def count_repeated_values(values):
    """Count how many times in an array values repeat and where they appear.

    Return a list of length *n* that gives the values and indices of repeated
    values. The first element of the list will be the values and indices of
    all values that appear once or the first time repeated values appear. The
    next element, values that repeat twice or more, and so on. Thus, the
    length of the returned list will be the maximum number that any value is
    repeated in *x*.

    Parameters
    ----------
    values : array_like
        Input array to count repeated values.

    Returns
    -------
    list of tuple
        List of tuples of (*repeated_values*, *indices*).

    Examples
    --------

    For an array that contains no repeated values, this function just returns
    a copy of *x*, and the indices to each element.

    >>> import numpy as np
    >>> from landlab.utils.count_repeats import count_repeated_values
    >>> counts = count_repeated_values(np.array([20, 30, 40], dtype=int))
    >>> len(counts)
    1
    >>> counts[0]
    (array([20, 30, 40]), array([0, 1, 2]))

    If *x* contains a repeated value, the first element contains all unique
    values along with their indices. For repeated values, return indices to
    their first occurance. The second element contains values and indices to
    values occuring two or more times.

    >>> counts = count_repeated_values(np.array([20, 30, 40, 30, 30], dtype=int))
    >>> len(counts)
    3
    >>> counts[0]
    (array([20, 30, 40]), array([0, 1, 2]))
    >>> counts[1]
    (array([30]), array([3]))
    >>> counts[2]
    (array([30]), array([4]))

    The input array remains unchanged.

    >>> x = np.array([20, 30, 30, 40], dtype=int)
    >>> counts = count_repeated_values(x)
    >>> x
    array([20, 30, 30, 40])
    """
    counts = []

    (unique_values, unique_inds) = np.unique(values, return_index=True)
    x_inds = np.arange(len(values), dtype=int)
    while len(unique_values) > 0:
        counts.append((unique_values, x_inds[unique_inds]))
        values = np.delete(values, unique_inds)
        x_inds = np.delete(x_inds, unique_inds)
        (unique_values, unique_inds) = np.unique(values, return_index=True)

    return counts



================================================
File: src/landlab/utils/decorators.py
================================================
"""General decorators for the landlab library.

General Landlab decorators
++++++++++++++++++++++++++

.. autosummary::

    ~use_field_name_or_array
    ~make_return_array_immutable
    ~deprecated
"""

import inspect
import os
import textwrap
import warnings
from functools import wraps

import numpy as np

from landlab import FieldError


class cache_result_in_object:
    def __init__(self, cache_as=None):
        self._attr = cache_as

    def __call__(self, func):
        name = self._attr or "_" + func.__name__

        @wraps(func)
        def _wrapped(obj):
            if not hasattr(obj, name):
                setattr(obj, name, func(obj))
            return getattr(obj, name)

        return _wrapped


class store_result_in_grid:
    def __init__(self, name=None):
        self._attr = name

    def __call__(self, func):
        @wraps(func)
        def _wrapped(grid):
            name = self._attr or "_" + func.__name__
            try:
                getattr(grid, name)
            except AttributeError:
                setattr(grid, name, func(grid))
            return getattr(grid, name)

        return _wrapped


class store_result_in_dataset:
    def __init__(self, dataset=None, name=None):
        self._dataset = dataset
        self._attr = name

    def __call__(self, func):
        @wraps(func)
        def _wrapped(grid):
            name = self._attr or func.__name__
            if self._dataset:
                ds = getattr(grid, self._dataset)
            else:
                ds = grid

            if name not in ds:
                setattr(grid, self._dataset, ds.update({"name": func(grid)}))

            return getattr(grid, self._dataset)[name].values

        return _wrapped


def read_only_array(func):
    """Decorate a function so that its return array is read-only.

    Parameters
    ----------
    func : function
        A function that returns a numpy array.

    Returns
    -------
    func
        A wrapped function that returns a read-only numpy array.
    """

    @wraps(func)
    def _wrapped(self, *args, **kwds):
        """Make the returned array read-only."""
        array = func(self, *args, **kwds)
        array.flags.writeable = False
        return array

    return _wrapped


def add_signature_to_doc(func):
    """Add a function signature to the first line of a docstring.

    Add the signature of a function to the first line of its docstring.
    This is useful for functions that are decorated in such a way
    that its signature changes.

    Parameters
    ----------
    func : function
        Function to add signature to.

    Returns
    -------
    str
        The new docstring with the function signature on the first line.

    Examples
    --------
    >>> from landlab.utils.decorators import add_signature_to_doc

    >>> def foo(arg1, kwd=None):
    ...     '''Do something.'''
    ...     pass
    ...
    >>> print(add_signature_to_doc(foo))
    foo(arg1, kwd=None)
    <BLANKLINE>
    Do something.
    """
    return """{name}{argspec}

{body}""".format(
        name=func.__name__,
        argspec=str(inspect.signature(func)),
        body=inspect.getdoc(func),
    )


class use_field_name_or_array:
    """Decorate a function so that it accepts a field name or array.

    Parameters
    ----------
    func : function
        A function that accepts a grid and array as arguments.
    at_element : str
        The element type that the field is defined on ('node', 'cell',
        etc.)

    Returns
    -------
    func
        A wrapped function that accepts a grid and either a field name or
        a numpy array.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((4, 5), xy_spacing=(1, 2))

    >>> def my_func(grid, vals):
    ...     return grid.area_of_cell * vals
    ...
    >>> my_func(grid, np.arange(grid.number_of_cells))
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    Decorate the function so that the second argument can be array-like or
    the name of a field contained withing the grid. The decorator takes a
    single argument that is the name (as a `str`) of the grid element that
    the values are defined on ("node", "cell", etc.).

    >>> from landlab.utils.decorators import use_field_name_or_array
    >>> @use_field_name_or_array("cell")
    ... def my_func(grid, vals):
    ...     return grid.area_of_cell * vals
    ...

    The array of values now can be list or anything that can be converted to
    a numpy array.

    >>> my_func(grid, [0, 1, 2, 3, 4, 5])
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    The array of values doesn't have to be flat.

    >>> vals = np.array([[0, 1, 2], [3, 4, 5]])
    >>> my_func(grid, vals)
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    The array of values can be a field name.

    >>> _ = grid.add_field("elevation", [0, 1, 2, 3, 4, 5], at="cell")
    >>> my_func(grid, "elevation")
    array([  0.,   2.,   4.,   6.,   8.,  10.])
    """

    def __init__(self, at_element):
        """Initialize the decorator.

        Parameters
        ----------
        at_element : str
            The element type that the field is defined on ('node', 'cell',
            etc.)
        """
        self._at = at_element

    def __call__(self, func):
        """Wrap the function."""

        func.__doc__ = add_signature_to_doc(func)

        @wraps(func)
        def _wrapped(grid, vals, *args, **kwds):
            """Convert the second argument to an array."""
            if isinstance(vals, str):
                if vals in grid[self._at]:
                    vals = grid[self._at][vals]
                else:
                    raise FieldError(vals)
            else:
                vals = np.asarray(vals).reshape(-1)

            return func(grid, vals, *args, **kwds)

        return _wrapped


class use_field_name_array_or_value:
    """Decorate a function so that it accepts a field name, array, or value.

    Parameters
    ----------
    func : function
        A function that accepts a grid and array as arguments.
    at_element : str
        The element type that the field is defined on ('node', 'cell',
        etc.)

    Returns
    -------
    func
        A wrapped function that accepts a grid and either a field name,
        a numpy array, or a value as arguments.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> grid = RasterModelGrid((4, 5), xy_spacing=(1, 2))

    >>> def my_func(grid, vals):
    ...     return grid.area_of_cell * vals
    ...
    >>> my_func(grid, np.arange(grid.number_of_cells))
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    Decorate the function so that the second argument can be array-like,
    the name of a field contained withing the grid, or a value (float, int,
    etc.). The decorator takes a single argument that is the name (as a `str`)
    of the grid element that the values are defined on ("node", "cell", etc.).

    >>> from landlab.utils.decorators import use_field_name_array_or_value
    >>> @use_field_name_array_or_value("cell")
    ... def my_func(grid, vals):
    ...     return grid.area_of_cell * vals
    ...

    The array of values now can be list or anything that can be converted to
    a numpy array.

    >>> my_func(grid, [0, 1, 2, 3, 4, 5])
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    The array of values doesn't have to be flat.

    >>> vals = np.array([[0, 1, 2], [3, 4, 5]])
    >>> my_func(grid, vals)
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    The array of values can be a field name.

    >>> _ = grid.add_field("elevation", [0, 1, 2, 3, 4, 5], at="cell")
    >>> my_func(grid, "elevation")
    array([  0.,   2.,   4.,   6.,   8.,  10.])

    The array of values can be a value (float, int, etc.).

    >>> my_func(grid, 4.0)
    array([8.,  8.,  8.,  8.,  8.,  8.])
    """

    def __init__(self, at_element):
        """Initialize the decorator.

        Parameters
        ----------
        at_element : str
            The element type that the field is defined on ('node', 'cell',
            etc.)
        """
        self._at = at_element

    def __call__(self, func):
        """Wrap the function."""

        func.__doc__ = add_signature_to_doc(func)

        @wraps(func)
        def _wrapped(grid, vals, *args, **kwds):
            """Convert the second argument to an array."""
            if isinstance(vals, str):
                if vals in grid[self._at]:
                    vals = grid[self._at][vals]
                else:
                    raise FieldError(vals)
            else:
                expected_size = grid.size(self._at)
                vals = np.asarray(vals).ravel()
                if vals.size == 1:
                    vals = np.broadcast_to(vals, (expected_size,))

                if vals.size != expected_size:
                    raise ValueError(
                        "Array passed to function decorated with "
                        "use_field_name_array_or_value is not "
                        "the size of fields at " + self._at
                    )
            return func(grid, vals, *args, **kwds)

        return _wrapped


def make_return_array_immutable(func):
    """Decorate a function so that its return array is read-only.

    Parameters
    ----------
    func : function
        A function that returns a numpy array.

    Returns
    -------
    func
        A wrapped function that returns a read-only view of an array.
    """

    @wraps(func)
    def _wrapped(self, *args, **kwds):
        """Make the returned array read-only."""
        array = func(self, *args, **kwds)
        immutable_array = array.view()
        immutable_array.flags.writeable = False
        return immutable_array

    return _wrapped


def deprecated(use, version):
    """Mark a function as deprecated.

    Parameters
    ----------
    use : str
        Name of replacement function to use.
    version : str
        Version number when function was marked as deprecated.

    Returns
    -------
    func
        A wrapped function that issues a deprecation warning.
    """

    def real_decorator(func):
        warning_str = """
.. note:: This method is deprecated as of Landlab version {ver}.

    Use :func:`{use}` instead.

""".format(
            ver=version, use=use
        )

        doc_lines = (func.__doc__ or "").split(os.linesep)

        for _lineno, line in enumerate(doc_lines):
            if len(line.rstrip()) == 0:
                break

        head = doc_lines[:_lineno]
        body = doc_lines[_lineno:]

        head = textwrap.dedent(os.linesep.join(head))
        body = textwrap.dedent(os.linesep.join(body))

        func.__doc__ = os.linesep.join([head, warning_str, body])

        @wraps(func)
        def _wrapped(*args, **kwargs):
            if func.__name__.startswith("_"):
                pass
            else:
                warnings.warn(
                    message="Call to deprecated function {name}.".format(
                        name=func.__name__
                    ),
                    category=DeprecationWarning,
                    stacklevel=2,
                )
            return func(*args, **kwargs)

        _wrapped.__dict__.update(func.__dict__)

        return _wrapped

    return real_decorator



================================================
File: src/landlab/utils/depth_dependent_roughness.py
================================================
"""Creates a field of Manning's n value, where each value is dependent on the
water depth at a given node (e.g. Jain et al., 2005, Mugler et al., 2011 and
Rengers et al., 2016). This "effectively creates separate values of Manning's n
for hillslopes and channels" (Rengers et al., 2016).

This component creates -or- overwrites a field on the grid called
'mannings_n' where each node is assigned a Manning's n value based on the
minimum Manning's n value for the landscape, the local water depths, an index
(or threshold) water depth above which all Manning's n values are considered
constant, and a vegetation drag coefficent (for more on vegetation drag and
the impact on surface roughness, see Wu et al., 1999 in the Journal of
Hydraulic Engineering.)

This can be used iteratively inside a driver loop, to update Manning's n values
as water depths change in another component (e.g. OverlandFlow)

.. codeauthor:: Jordan Adams

Examples
--------
>>> import numpy as np
>>> from landlab import RasterModelGrid
>>> grid = RasterModelGrid((5, 5))
>>> grid.at_node["surface_water__depth"] = [
...     [5.0, 5.0, 5.0, 5.0, 5.0],
...     [4.0, 4.0, 4.0, 4.0, 4.0],
...     [3.0, 3.0, 3.0, 3.0, 3.0],
...     [2.0, 2.0, 2.0, 2.0, 2.0],
...     [1.0, 1.0, 1.0, 1.0, 1.0],
... ]
>>> depth_dependent_mannings_n(grid, index_flow_depth=2.0)
>>> grid.at_node["mannings_n"]
array([0.06      ,  0.06      ,  0.06      ,  0.06      ,  0.06      ,
       0.06      ,  0.06      ,  0.06      ,  0.06      ,  0.06      ,
       0.06      ,  0.06      ,  0.06      ,  0.06      ,  0.06      ,
       0.06      ,  0.06      ,  0.06      ,  0.06      ,  0.06      ,
       0.07559526,  0.07559526,  0.07559526,  0.07559526,  0.07559526])
"""

import contextlib

import numpy as np

from landlab import FieldError


def depth_dependent_mannings_n(
    grid,
    water_depths="surface_water__depth",
    min_mannings_n=0.06,
    index_flow_depth=0.003,
    veg_drag_exponent=(-1.0 / 3.0),
):
    """Method to create or overwrite a Manning's n field
    (grid.at_node['mannings_n']) with spatially variable n values based on
    water depths.

    Parameters
    ----------
    grid : A Landlab RasterModelGrid instance
        A Landlab grid - only works with RasterModelGrid instances as of
        1/31/17.
    water_depths : array or Landlab field of floats
        Array of values, with length of number of nodes, water depths
        at all grid node locations. (m)
    min_mannings_n : float
        This is the minimum Manning's n coefficient for a given landscape,
        following Chow, 1959. (s m^(-1./3.))
    index_flow_depth : float
        The flow depth above which it is assumed that Manning's n is
        constant. (m)
    veg_drag_exponent :
        An exponent related to vegetation drag effects, which increases
        effective Manning's n at low flow conditions.
    """

    # Looks for a field called 'mannings_n' attached to the grid instance. If
    # one is found, a FieldError is thrown but ignored. This method
    # REWRITES over the existing Manning's n fields after the calculation.
    with contextlib.suppress(FieldError):
        grid.add_zeros("mannings_n", at="node")

    # Identifies locations where water depth is lower than the value supplied
    # through keyword index_flow_depth.
    (locs_less,) = np.where(grid.at_node["surface_water__depth"] <= index_flow_depth)

    # Identifies locations where water depth is greater than the value
    # supplied through keyword index_flow_depth.
    (locs_more,) = np.where(grid.at_node["surface_water__depth"] > index_flow_depth)

    # At all locations lower than the index flow depth (assumed to be shallow
    # flow on hillslopes), a new Manning's n value is calculated to that
    # incorporates effects of vegetation drag. These Manning's n values will
    # be greater than the supplied Manning's n (keyword: min_mannings_n)
    grid.at_node["mannings_n"][locs_less] = (
        min_mannings_n
        * (grid.at_node["surface_water__depth"][locs_less] / index_flow_depth)
        ** veg_drag_exponent
    )

    # Resets the field with the new Manning's n values.
    grid.at_node["mannings_n"][locs_more] = min_mannings_n



================================================
File: src/landlab/utils/distance_to_divide.py
================================================
#! /usr/bin/env python
"""Functions to calculate flow distance from divide."""
import numpy as np

from landlab import FieldError
from landlab import RasterModelGrid


def calculate_distance_to_divide(
    grid, longest_path=True, add_to_grid=False, clobber=False
):
    """Calculate the along flow distance from drainage divide to point.

    This utility calculates the along flow distance based on the results of
    running flow accumulation on the grid. It will use the connectivity
    used by the FlowAccumulator (e.g. D4, D8, Dinf).

    Parameters
    ----------
    grid : ModelGrid
    longest_path : bool, optional
        Take the longest (or shortest) path to a drainage divide. Default is
        true.
    add_to_grid : boolean, optional
        Flag to indicate if the stream length field should be added to the
        grid. Default is False. The field name used is ``distance_to_divide``.
    clobber : boolean, optional
        Flag to indicate if adding the field to the grid should not clobber an
        existing field with the same name. Default is False.

    Returns
    -------
    distance_to_divide : float ndarray
        The distance that has to be covered from an imaginary flow, located in
        each node of the grid, to reach the watershed's outlet.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.distance_to_divide import calculate_distance_to_divide
    >>> mg = RasterModelGrid((5, 4))
    >>> mg.at_node["topographic__elevation"] = [
    ...     [0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 10.0, 10.0, 0.0],
    ...     [0.0, 20.0, 20.0, 0.0],
    ...     [0.0, 30.0, 30.0, 0.0],
    ...     [0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> mg.set_closed_boundaries_at_grid_edges(
    ...     bottom_is_closed=False,
    ...     left_is_closed=True,
    ...     right_is_closed=True,
    ...     top_is_closed=True,
    ... )
    >>> fr = FlowAccumulator(mg, flow_director="D8")
    >>> fr.run_one_step()
    >>> distance_to_divide = calculate_distance_to_divide(
    ...     mg,
    ...     add_to_grid=True,
    ...     clobber=True,
    ... )
    >>> mg.at_node["distance_to_divide"]
    array([0.,  3.,  3.,  0.,
           0.,  2.,  2.,  0.,
           0.,  1.,  1.,  0.,
           0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.])

    Now, let's change to MFD the flow_director method, which routes flow to
    multiple nodes.

    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.distance_to_divide import calculate_distance_to_divide
    >>> mg = RasterModelGrid((5, 4), xy_spacing=(1, 1))
    >>> mg.at_node["topographic__elevation"] = [
    ...     [0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 10.0, 10.0, 0.0],
    ...     [0.0, 20.0, 20.0, 0.0],
    ...     [0.0, 30.0, 30.0, 0.0],
    ...     [0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> mg.set_closed_boundaries_at_grid_edges(
    ...     bottom_is_closed=False,
    ...     left_is_closed=True,
    ...     right_is_closed=True,
    ...     top_is_closed=True,
    ... )
    >>> fr = FlowAccumulator(mg, flow_director="MFD")
    >>> fr.run_one_step()
    >>> distance_to_divide = calculate_distance_to_divide(
    ...     mg,
    ...     add_to_grid=True,
    ...     clobber=True,
    ... )
    >>> mg.at_node["distance_to_divide"]
    array([0.,  3.,  3.,  0.,
           0.,  2.,  2.,  0.,
           0.,  1.,  1.,  0.,
           0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.])

    The distance_to_divide utility can also work on irregular grids. For the
    example we will use a Hexagonal Model Grid, a special type of Voroni Grid
    that has regularly spaced hexagonal cells.

    >>> from landlab import HexModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.distance_to_divide import calculate_distance_to_divide
    >>> dx = 1
    >>> hmg = HexModelGrid((5, 3), dx)
    >>> _ = hmg.add_field(
    ...     "topographic__elevation",
    ...     hmg.node_x + np.round(hmg.node_y),
    ...     at="node",
    ... )
    >>> hmg.status_at_node[hmg.boundary_nodes] = hmg.BC_NODE_IS_CLOSED
    >>> hmg.status_at_node[0] = hmg.BC_NODE_IS_FIXED_VALUE
    >>> fr = FlowAccumulator(hmg, flow_director="D4")
    >>> fr.run_one_step()
    >>> distance_to_divide = calculate_distance_to_divide(
    ...     hmg,
    ...     add_to_grid=True,
    ...     clobber=True,
    ... )
    >>> hmg.at_node["distance_to_divide"]
    array([3.,  0.,  0.,
        0.,  2.,  1.,  0.,
      0.,  1.,  1.,  0.,  0.,
        0.,   0.,  0.,  0.,
           0.,  0.,  0.])
    """
    # check that flow__receiver nodes exists
    if "flow__receiver_node" not in grid.at_node:
        raise FieldError(
            "A 'flow__receiver_node' field is required at the "
            "nodes of the input grid."
        )

    if "flow__upstream_node_order" not in grid.at_node:
        raise FieldError(
            "A 'flow__upstream_node_order' field is required at the "
            "nodes of the input grid."
        )

    if "drainage_area" not in grid.at_node:
        raise FieldError(
            "A 'flow__upstream_node_order' field is required at the "
            "nodes of the input grid."
        )

    # get the reciever nodes, depending on if this is to-one, or to-multiple,
    # we'll need to get a different at-node field.
    if grid.at_node["flow__receiver_node"].size != grid.size("node"):
        to_one = False
    else:
        to_one = True

    flow__receiver_node = grid.at_node["flow__receiver_node"]
    drainage_area = grid.at_node["drainage_area"]

    # get the upstream node order
    flow__upstream_node_order = grid.at_node["flow__upstream_node_order"]

    # get downstream flow link lengths, result depends on type of grid.
    if isinstance(grid, RasterModelGrid):
        flow_link_lengths = grid.length_of_d8[
            grid.at_node["flow__link_to_receiver_node"]
        ]
    else:
        flow_link_lengths = grid.length_of_link[
            grid.at_node["flow__link_to_receiver_node"]
        ]

    # create an array that representes the distance to the divide.
    distance_to_divide = np.zeros(grid.nodes.size)

    if not longest_path:
        distance_to_divide[:] = 2 * grid.size("node") * np.max(flow_link_lengths)

    # iterate through the flow__upstream_node_order backwards.
    for node in reversed(flow__upstream_node_order):
        # if drainage are is equal to node cell area, set distance to zeros
        # this should handle the drainage divide cells as boundary cells have
        # their area set to zero.
        if drainage_area[node] == grid.cell_area_at_node[node]:
            distance_to_divide[node] = 0

        # get flow recievers
        reciever = flow__receiver_node[node]

        if to_one:
            # if not processing an outlet node.
            if reciever != node:
                if longest_path:
                    cond = (
                        distance_to_divide[reciever]
                        < distance_to_divide[node] + flow_link_lengths[node]
                    )
                else:
                    cond = (
                        distance_to_divide[reciever]
                        > distance_to_divide[node] + flow_link_lengths[node]
                    )

                if cond:
                    distance_to_divide[reciever] = (
                        distance_to_divide[node] + flow_link_lengths[node]
                    )

        else:
            # non-existant links are coded with -1
            useable_receivers = np.where(reciever != grid.BAD_INDEX)[0]

            for idx in range(len(useable_receivers)):
                r = reciever[useable_receivers][idx]
                fll = flow_link_lengths[node][useable_receivers][idx]

                # if not processing an outlet node.
                if r != node:
                    if longest_path:
                        cond = distance_to_divide[r] < distance_to_divide[node] + fll
                    else:
                        cond = distance_to_divide[r] > distance_to_divide[node] + fll

                    if cond:
                        distance_to_divide[r] = distance_to_divide[node] + fll

    # store on the grid
    if add_to_grid:
        grid.add_field(
            "distance_to_divide", distance_to_divide, at="node", clobber=clobber
        )

    return distance_to_divide



================================================
File: src/landlab/utils/fault_facet_finder.py
================================================
#! /usr/bin/env python

"""This class is designed to provide functions to allow the automated
identification of planar facet surfaces above fault traces.

Module is SLOW (e.g., minutes+ per full analysis of a "large" data set).
It is only intended for model post-analysis or DEM analysis. Do not loop
this class!! This is part of the NSF funded project investigating fault
scarp degradation, Tucker, Hobley, McCoy.
"""


import sys

import numpy as np
from pylab import figure
from pylab import plot
from pylab import show

from landlab.plot import imshow as gridshow


def cmp(a, b):
    return (a > b) - (a < b)


class find_facets:
    """Note that this class assumes the grid does not change during the model
    run. Changes to data stored in the grid should (?) update automatically.

    If *fault_azimuth* is supplied, it should be -pi/2 < az <= pi/2
    (i.e., we don't consider fault dip, even if it's known).
    """

    def __init__(self, grid, elev_field="topographic__elevation", fault_azimuth=None):
        """Note that this class assumes the grid does not change during the
        model run. Changes to data stored in the grid should (?) update
        automatically.

        If *fault_azimuth* is supplied, it should be -pi/2 < az <= pi/2
        (i.e., we don't consider fault dip, even if it's known).
        """
        if not np.isclose(grid.dx, grid.dy):
            raise ValueError("row and column spacing must be the same")

        self.grid = grid
        self.elevs = self.grid.at_node[elev_field]
        self.az = fault_azimuth

    def analyse_fault_trace(self, fault_trace_node_ids):
        """This method takes the grid and an array listing the (contiguous)
        node ids of cells that contain a single fault segment trace of
        interest.

        It sets and returns the azimuth of the fault trace, az,
        -pi/2 < az <= pi/2.
        (i.e., smallest angle between north and the trace).
        """
        self.ft_trace_node_ids = fault_trace_node_ids
        x = self.grid.node_x[fault_trace_node_ids]
        y = self.grid.node_y[fault_trace_node_ids]
        (grad, offset) = np.polyfit(x, y, 1)
        angle = np.arctan(grad)
        if grad >= 0.0:
            self.az = np.pi / 2.0 - angle
        else:
            self.az = -np.pi / 2.0 - angle

        return self.az

    def set_slopes_aspects(self):
        self.slopes = self.grid.calc_slopes_of_nodes(elevs=self.elevs)
        self.aspect = self.grid.calc_aspect_of_node(elevs=self.elevs)
        print("Calculated and stored slopes and aspects...")

    def define_aspect_node_subset(self, angle_tolerance=5.0):
        """This method sets and returns a list of all nodes in the landscape
        which have an aspect within 5 degrees of perpendicular to the fault
        trace.

        It assumes self.az, the angle between north and the fault trace, has
        already been set, and also that self.slopes and self.aspect are also
        set.
        The returned boolean array is num_core_nodes long.
        *angle_tolerance* is the angle in degrees that the aspect must be within
        from the fault trace angle.
        NB: this version is too discriminating on the aspect restriction,
        presumably because we use only a single ft angle for what's really
        a 2d trace. Need to work with local aspect.
        """
        perp_to_az = np.pi / 2.0 + self.az
        five_degrees = np.pi / 180.0 * angle_tolerance  # note the silly naming
        perp_plus_five = (perp_to_az + five_degrees) % (2.0 * np.pi)
        perp_minus_five = (perp_to_az - five_degrees) % (2.0 * np.pi)
        other_dip_plus_five = (perp_to_az + np.pi + five_degrees) % (2.0 * np.pi)
        other_dip_minus_five = (perp_to_az + np.pi - five_degrees) % (2.0 * np.pi)

        # need to be careful near the 2pi->0 discontinuity...
        greater_condition = np.greater(self.aspect, perp_minus_five)
        lesser_condition = np.less(self.aspect, perp_plus_five)
        if (perp_to_az - five_degrees) < 0.0:
            condition_first_dip = np.logical_or(greater_condition, lesser_condition)
        else:
            condition_first_dip = np.logical_and(greater_condition, lesser_condition)
        greater_condition_2 = np.greater(self.aspect, other_dip_minus_five)
        lesser_condition_2 = np.less(self.aspect, other_dip_plus_five)
        if (perp_to_az + np.pi + five_degrees) // (
            2.0 * np.pi
        ):  # top condition exceeds 2pi
            condition_opposite_dip = np.logical_or(
                greater_condition_2, lesser_condition_2
            )
        else:
            condition_opposite_dip = np.logical_and(
                greater_condition_2, lesser_condition_2
            )

        self.aspect_close_nodes = np.logical_or(
            condition_first_dip, condition_opposite_dip
        )
        print("Calculated and stored nodes with aspects compatible with fault trace...")
        return self.aspect_close_nodes

    def define_aspect_node_subset_local(
        self, dist_tolerance=4.0, angle_tolerance=15.0, dip_dir="E"
    ):
        """ """
        grid = self.grid
        try:
            print("using subset")
            # remember, steep_nodes is already core_nodes.size long
            subset = np.where(self.steep_nodes)[0]
        except NameError:
            print("using all nodes")
            subset = np.arange(grid.core_nodes.size)
        closest_ft_node = np.empty(subset.size, dtype=int)
        angle_to_ft = np.empty_like(closest_ft_node, dtype=float)
        new_angle_to_ft = np.empty_like(closest_ft_node, dtype=float)
        distance_to_ft = np.empty_like(closest_ft_node, dtype=float)
        distance_to_ft.fill(sys.float_info.max)
        new_distance_to_ft = np.empty_like(closest_ft_node, dtype=float)
        for i in self.ft_trace_node_ids:
            grid.calc_distances_of_nodes_to_point(
                (grid.node_x[i], grid.node_y[i]),
                node_subset=grid.core_nodes[subset],
                get_az="angles",
                out_distance=new_distance_to_ft,
                out_azimuth=new_angle_to_ft,
            )
            closer_nodes = new_distance_to_ft < distance_to_ft
            distance_to_ft[closer_nodes] = new_distance_to_ft[closer_nodes]
            angle_to_ft[closer_nodes] = new_angle_to_ft[closer_nodes]
            closest_ft_node[closer_nodes] = i
        self.closest_ft_node = -np.ones(grid.core_nodes.size)
        self.distance_to_ft = -np.ones(grid.core_nodes.size)
        self.angle_to_ft = -np.ones(grid.core_nodes.size)
        self.closest_ft_node[subset] = closest_ft_node
        self.distance_to_ft[subset] = distance_to_ft
        # angle_to_ft is actually the angle_from_ft! So we need to adjust.
        # a second problem is that pts downslope (opposite az) can also be on the line.
        # solution - take a dip_dir input...
        angle_to_ft = (angle_to_ft + np.pi) % (2.0 * np.pi)
        self.angle_to_ft[subset] = angle_to_ft
        # gridshow.imshow_grid_at_node(self.grid, self.distance_to_ft)
        # show()
        # gridshow.imshow_grid_at_node(self.grid, self.angle_to_ft)
        # show()
        # the relevant condition is now that the local aspect and angle to fault
        # are the same...
        # We need to bias the five degrees against distant points, as it's easier
        # to have similar angles in the far field. Rule should be in px - the
        # two angles should be within *angle_tol* px of each other at the ft
        # trace.
        divergence_at_ft = distance_to_ft * np.tan(
            (angle_to_ft - self.aspect[subset]) % np.pi
        )
        # might be *too* forgiving for close-in nodes
        condition = np.less(np.fabs(divergence_at_ft), grid.dx * dist_tolerance)
        # ...so add another tester; must be w/i 15 degrees of each other:
        diff_angles = np.min(
            [
                np.fabs(angle_to_ft - self.aspect[subset]),
                np.fabs(np.fabs(angle_to_ft - self.aspect[subset]) - 2.0 * np.pi),
            ],
            axis=0,
        )
        self.diff_angles = np.empty(grid.core_nodes.size, dtype=float)
        self.diff_angles.fill(sys.float_info.max)
        self.diff_angles[subset] = diff_angles
        # gridshow.imshow_grid_at_node(self.grid, self.angle_to_ft)
        # show()
        figure(6)
        gridshow.imshow_grid_at_node(
            self.grid, np.where(self.diff_angles < 100000.0, self.diff_angles, -1.0)
        )
        condition2 = np.less(diff_angles, angle_tolerance * np.pi / 180.0)
        condition = np.logical_and(condition, condition2)
        core_nodes_size_condition = np.zeros(grid.core_nodes.size, dtype=bool)
        core_nodes_size_condition[subset] = condition
        # gridshow.imshow_grid_at_node(self.grid, core_nodes_size_condition)
        # show()
        # core_nodes_size_condition = np.zeros(grid.core_nodes.size, dtype=bool)
        # core_nodes_size_condition[subset] = condition2
        # gridshow.imshow_grid_at_node(self.grid, core_nodes_size_condition)
        # show()
        self.aspect_close_nodes = core_nodes_size_condition
        print("Calculated and stored nodes with aspects compatible with fault trace...")
        return self.aspect_close_nodes

    def define_steep_nodes(self, threshold_in_degrees=5.0):
        """This method sets and returns a list of all nodes in the landscape
        which are "steep" and could be part of a facet. The critical hillslope
        angle is set by *threshold_in_degrees*, and defaults to 5.

        This assumes you have already called define_aspect_node_subset,
        in which self.slope is set. The returned boolean array is
        num_core_nodes long.
        """
        threshold_in_rads = threshold_in_degrees * np.pi / 180.0
        self.steep_nodes = np.greater(self.slopes, threshold_in_rads)
        print("Calculated and stored nodes with slopes exceeding slope threshold...")
        # gridshow.imshow_grid_at_node(self.grid, self.steep_nodes)
        # show()
        return self.steep_nodes

    def show_possible_nodes(self):
        """Once the subsets by aspect and slope have been set, call this
        function to see both the whole elevation map, and the subset of nodes
        that will be searched."""
        possible_core_nodes = np.logical_and(self.steep_nodes, self.aspect_close_nodes)
        figure(1)
        gridshow.imshow_grid_at_node(self.grid, self.elevs)
        figure(2)
        gridshow.imshow_grid_at_node(self.grid, self.slopes)
        figure(3)
        gridshow.imshow_grid_at_node(self.grid, self.aspect)
        figure(4)
        gridshow.imshow_grid_at_node(self.grid, possible_core_nodes)
        show()

    def find_coherent_facet_patches(self, tolerance=3.0, threshold_num_px=12):
        """This method searches the (already determined) possible pixels for
        patches with coherent slope angles, within a *tolerance* (in degrees).
        A patch is only recorded if it consists of at least *threshold_num_px*.

        The method records and returns:

        *  a ragged array of lists, where each list is the pixels comprising
           each facet patch, and
        *  a (num_patches, 2) array recording the mean slope and and its stdev
           for each patch.
        """
        self.possible_core_nodes = np.where(
            np.logical_and(self.steep_nodes, self.aspect_close_nodes)
        )[0]
        consistent_slope_patches = []
        for i in self.possible_core_nodes:
            nodes_in_patch = np.array([i])
            patch_size = 1
            mean_slope = self.slopes[nodes_in_patch]
            while 1:
                possible_neighbors = np.union1d(
                    self.grid.active_adjacent_nodes_at_node[nodes_in_patch].flat,
                    self.possible_core_nodes,
                )
                neighbor_slopes = self.slopes[possible_neighbors]
                low_tol_condition = np.greater(neighbor_slopes, mean_slope - tolerance)
                high_tol_condition = np.less(neighbor_slopes, mean_slope + tolerance)
                total_condition = np.logical_and(low_tol_condition, high_tol_condition)
                nodes_in_patch = possible_neighbors[total_condition]
                new_patch_size = nodes_in_patch.size
                if patch_size == new_patch_size:
                    break
                else:
                    patch_size = new_patch_size
                    mean_slope = np.mean(neighbor_slopes[total_condition])
            if new_patch_size > threshold_num_px:
                consistent_slope_patches.append(nodes_in_patch)
        # May also need a uniqueness test: a px should only appear in one list.
        # (i.e., all patches containing a given px should all be identical)
        self.consistent_slope_patches = consistent_slope_patches
        return consistent_slope_patches

    def find_slope_lines(self, tolerance=1.0):
        """This method attempts to find slope-consistent line profiles up
        facets, perpendicular to the fault.

        Assumes you used define_aspect_node_subset_local().
        """
        grid = self.grid
        self.possible_core_nodes = np.where(
            np.logical_and(self.steep_nodes, self.aspect_close_nodes)
        )[0]
        pcn = self.possible_core_nodes
        unique_starting_pts = np.unique(self.closest_ft_node[pcn])  # in real node nos
        # set up places to store the profile data:
        profile_ft_node_id = []
        profile_ft_node_x = []
        profile_ft_node_y = []
        profile_ft_node_z = []
        profile_ft_node_dist = []
        profile_x_facet_pts = []
        profile_z_facet_pts = []
        profile_S_facet_pts = []
        for count, i in enumerate(unique_starting_pts):
            print(f"Running {count} of {unique_starting_pts.size}")
            # set the local angle of the ft trace:
            ft_pt_distances_to_node = self.grid.calc_distances_of_nodes_to_point(
                (grid.node_x[i], grid.node_y[i]), node_subset=self.ft_trace_node_ids
            )
            close_ft_nodes = np.less(ft_pt_distances_to_node, 5.0 * grid.dx)
            x = grid.node_x[self.ft_trace_node_ids[close_ft_nodes]]
            y = grid.node_y[self.ft_trace_node_ids[close_ft_nodes]]
            (grad, offset) = np.polyfit(x, y, 1)
            condition = np.equal(self.closest_ft_node[pcn], i)
            nodes_possible = pcn[condition]
            print(f"{nodes_possible.size} nodes")
            if nodes_possible.size > 10.0:
                # their_az = self.angle_to_ft[nodes_possible]
                # their_diff_angles = self.diff_angles[nodes_possible]
                their_elevs = self.elevs[grid.core_nodes][nodes_possible]
                # their_distances = self.distance_to_ft[nodes_possible]
                # need to make new distances so we remove the ambiguity of angle
                # around the ft point (i.e., dists from a far-field pt on the ft normal)
                # now make a multiplier to make sure the reference point for
                # new distances is far from the actual pts:
                multiplier = 10.0 * np.ptp(grid.node_y[grid.core_nodes[nodes_possible]])
                # derive the position:
                x_ref = grid.node_x[i] + cmp(
                    grid.node_x[i],
                    np.mean(grid.node_x[grid.core_nodes[nodes_possible]]),
                ) * multiplier * abs(grad)
                y_ref = (
                    grid.node_y[i]
                    + cmp(
                        grid.node_y[i],
                        np.mean(grid.node_y[grid.core_nodes[nodes_possible]]),
                    )
                    * multiplier
                )
                # get new absolute distances
                dist_to_ft = self.grid.calc_distances_of_nodes_to_point(
                    (x_ref, y_ref), node_subset=np.array([i])
                )
                dists_along_profile = (
                    self.grid.calc_distances_of_nodes_to_point(
                        (x_ref, y_ref), node_subset=grid.core_nodes[nodes_possible]
                    )
                    - dist_to_ft
                )
                # note the ft is now the origin, but pts might be back-to-front
                # (consistently, though) sort the distances. Remove any pts that
                # aren't in a "cluster".  We assume there will be one big "bunched"
                # plane, then a load of outliers
                dist_order = np.argsort(dists_along_profile)
                dist_diffs = np.diff(dists_along_profile[dist_order])
                print("dists along profile sorted: ", dists_along_profile[dist_order])
                print("dist diffs: ", dist_diffs)
                # max_diff = 3.*np.median(dist_diffs) #######this might need
                # attention if there's a heavy tail on the distances
                if grad < 1:
                    mod = np.sqrt(1.0 + grad**2.0)
                else:
                    mod = np.sqrt(1.0 + (1.0 / grad) ** 2.0)
                max_diff = 1.9 * mod * grid.dx
                locs_of_large_diffs = np.where(dist_diffs > max_diff)[0]
                # there should only be 1 place on the line where there's a cluster,
                # i.e., a large pts_betw_of_max_diffs.
                # This is what we're seeking.
                # ...this can be empty quite easily
                pts_betw_large_diffs = np.diff(locs_of_large_diffs)
                # need to be careful here in case the where call gives an empty
                # array
                if locs_of_large_diffs.size > 1:
                    biggest_interval_loc = np.argmax(pts_betw_large_diffs)
                elif locs_of_large_diffs.size == 1:
                    # one side or the other must be bigger:
                    if 2.0 * locs_of_large_diffs[0] < dists_along_profile.size - 1:
                        locs_of_large_diffs = np.array(
                            [locs_of_large_diffs[0], (dists_along_profile.size - 1)]
                        )
                    else:
                        locs_of_large_diffs = np.array([0, locs_of_large_diffs[0]])
                    biggest_interval_loc = np.array([0])
                    # here we assume that the single large diff must be further
                    # from the ft than the plane
                else:
                    locs_of_large_diffs = np.array([0, (dists_along_profile.size - 1)])
                    biggest_interval_loc = np.array([0])
                    # ...all the pts in the line are one cluster
                # apply a test to ensure we only save "big" patches; a
                # threshold of 10 pts on the line
                try:
                    patch_size = pts_betw_large_diffs[biggest_interval_loc]
                except IndexError:  # pts_betw_large_diffs is empty
                    patch_size = locs_of_large_diffs[1] - locs_of_large_diffs[0]
                if patch_size > 10.0:
                    start_pt_of_cluster = locs_of_large_diffs[biggest_interval_loc] + 1
                    end_pt_of_cluster = (
                        locs_of_large_diffs[biggest_interval_loc + 1] + 1
                    )  # both referring to the sorted list
                    # both +1s are to account for required frame of ref changes -
                    # indices refer to where the big gaps start, not where they ends
                    # so:
                    dists_to_sorted_pts = dists_along_profile[dist_order][
                        start_pt_of_cluster:end_pt_of_cluster
                    ]
                    elevs_of_sorted_pts = their_elevs[dist_order][
                        start_pt_of_cluster:end_pt_of_cluster
                    ]
                    slopes_of_sorted_pts = self.slopes[nodes_possible][dist_order][
                        start_pt_of_cluster:end_pt_of_cluster
                    ]
                    profile_ft_node_id.append(i.copy())
                    profile_ft_node_x.append(grid.node_x[i].copy())
                    profile_ft_node_y.append(grid.node_y[i].copy())
                    profile_ft_node_z.append(self.elevs[i].copy())
                    profile_ft_node_dist.append(dist_to_ft.copy())
                    profile_x_facet_pts.append(dists_to_sorted_pts.copy())
                    profile_z_facet_pts.append(elevs_of_sorted_pts.copy())
                    profile_S_facet_pts.append(slopes_of_sorted_pts.copy())
                    figure(5)
                    plot(dists_to_sorted_pts, elevs_of_sorted_pts)
                    # dirty, but effective code!

        self.profile_ft_node_id = profile_ft_node_id
        self.profile_ft_node_x = profile_ft_node_x
        self.profile_ft_node_y = profile_ft_node_y
        self.profile_ft_node_z = profile_ft_node_z
        self.profile_ft_node_dist = profile_ft_node_dist
        self.profile_x_facet_pts = profile_x_facet_pts
        self.profile_z_facet_pts = profile_z_facet_pts
        self.profile_S_facet_pts = profile_S_facet_pts

    def fit_slopes_to_facet_lines(
        self, polynomial_degree=4, curvature_threshold=0.0004
    ):
        """Fits (linear) lines of best fit to extracted profiles, already
        stored as class properties."""
        avg_slopes_linear = []
        avg_slopes_poly = []
        curv_of_flattest_part_list = []
        slope_min_curv = []
        rsqd_list = []
        big_slope_small_curv = []
        elev_at_bssc = []
        for i in range(len(self.profile_x_facet_pts)):
            x = self.profile_x_facet_pts[i]
            z = self.profile_z_facet_pts[i]
            (grad, offset) = np.polyfit(x, z, 1)
            coeffs, residuals = np.polyfit(x, z, polynomial_degree, full=True)[:2]
            rsqd = 1.0 - residuals / (z.size * z.var())
            # differentiate the coeffs to get slope:
            diff_multiplier = np.arange(polynomial_degree + 1)[::-1]
            curv_multiplier = np.arange(polynomial_degree)[::-1]
            z_equ = np.poly1d(coeffs)
            S_equ = np.poly1d((coeffs * diff_multiplier)[:-1])
            curv_equ = np.poly1d(
                ((coeffs * diff_multiplier)[:-1] * curv_multiplier)[:-1]
            )
            S_at_each_pt = S_equ(x)
            curv_at_each_pt = curv_equ(x)
            avg_slopes_linear.append(abs(grad))
            avg_slopes_poly.append(np.amax(np.fabs(S_at_each_pt)))
            loc_of_flattest_part = np.argmin(np.fabs(curv_at_each_pt[2:-2])) + 2
            curv_of_flattest_part = curv_at_each_pt[loc_of_flattest_part]
            S_at_min_curve_untested = abs(S_at_each_pt[loc_of_flattest_part])
            small_curves = np.less(np.fabs(curv_at_each_pt[2:-2]), curvature_threshold)
            try:
                big_slope_small_curv.append(np.amax(S_at_each_pt[small_curves]))
                elev_at_bssc.append(z[np.argmax(S_at_each_pt[small_curves])])
            except ValueError:
                big_slope_small_curv.append(np.nan)
                elev_at_bssc.append(np.nan)
            slope_min_curv.append(S_at_min_curve_untested)
            curv_of_flattest_part_list.append(curv_of_flattest_part)
            rsqd_list.append(rsqd)
            # figure(8)
            # synthetic_z = grad*x + offset
            synthetic_z = z_equ(x)
            plot(x, z, "x")
            plot(x, synthetic_z, "-")
        self.avg_slopes_linear = np.array(avg_slopes_linear)
        self.avg_slopes_poly = np.array(avg_slopes_poly)
        self.curv_of_flattest_part = np.array(curv_of_flattest_part_list)
        self.slope_min_curv = np.array(slope_min_curv)
        self.big_slope_small_curv = np.array(big_slope_small_curv)
        self.elev_at_bssc = np.array(elev_at_bssc)
        self.rsqd = np.array(rsqd_list)



================================================
File: src/landlab/utils/flow__distance.py
================================================
#! /usr/bin/env python
"""Functions to calculate flow distance."""
import numpy as np

from landlab import FieldError
from landlab import RasterModelGrid


def calculate_flow__distance(grid, add_to_grid=False, clobber=False):
    """Calculate the along flow distance from node to outlet.

    This utility calculates the along flow distance based on the results of
    running flow accumulation on the grid. It will use the connectivity
    used by the FlowAccumulator (e.g. D4, D8, Dinf).

    Parameters
    ----------
    grid : ModelGrid
    add_to_grid : boolean, optional
        Flag to indicate if the stream length field should be added to the
        grid. Default is False. The field name used is ``flow__distance``.
    clobber : boolean, optional
        Flag to indicate if adding the field to the grid should not clobber an
        existing field with the same name. Default is False.

    Returns
    -------
    flow__distance : float ndarray
        The distance that has to be covered from an imaginary flow, located in
        each node of the grid, to reach the watershed's outlet.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.flow__distance import calculate_flow__distance
    >>> mg = RasterModelGrid((5, 4), xy_spacing=(1, 1))
    >>> mg.at_node["topographic__elevation"] = [
    ...     [0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 21.0, 10.0, 0.0],
    ...     [0.0, 31.0, 20.0, 0.0],
    ...     [0.0, 32.0, 30.0, 0.0],
    ...     [0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> mg.set_closed_boundaries_at_grid_edges(
    ...     bottom_is_closed=True,
    ...     left_is_closed=True,
    ...     right_is_closed=True,
    ...     top_is_closed=True,
    ... )
    >>> fr = FlowAccumulator(mg, flow_director="D8")
    >>> fr.run_one_step()
    >>> flow__distance = calculate_flow__distance(mg, add_to_grid=True, clobber=True)
    >>> mg.at_node["flow__distance"]
    array([0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  1.        ,  0.        ,  0.        ,
           0.        ,  1.41421356,  1.        ,  0.        ,
           0.        ,  2.41421356,  2.        ,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ])

    Now, let's change to D4 the flow_director method, which does not
    consider diagonal links bewtween nodes.

    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.flow__distance import calculate_flow__distance
    >>> mg = RasterModelGrid((5, 4), xy_spacing=(1, 1))
    >>> mg.at_node["topographic__elevation"] = [
    ...     [0.0, 0.0, 0.0, 0.0],
    ...     [0.0, 21.0, 10.0, 0.0],
    ...     [0.0, 31.0, 20.0, 0.0],
    ...     [0.0, 32.0, 30.0, 0.0],
    ...     [0.0, 0.0, 0.0, 0.0],
    ... ]
    >>> mg.set_closed_boundaries_at_grid_edges(
    ...     bottom_is_closed=True,
    ...     left_is_closed=True,
    ...     right_is_closed=True,
    ...     top_is_closed=True,
    ... )
    >>> fr = FlowAccumulator(mg, flow_director="D4")
    >>> fr.run_one_step()
    >>> flow__distance = calculate_flow__distance(mg, add_to_grid=True, clobber=True)
    >>> mg.at_node["flow__distance"]
    array([0.,  0.,  0.,  0.,
           0.,  1.,  0.,  0.,
           0.,  2.,  1.,  0.,
           0.,  3.,  2.,  0.,
           0.,  0.,  0.,  0.])

    The flow__distance utility can also work on irregular grids. For the example we
    will use a Hexagonal Model Grid, a special type of Voroni Grid that has
    regularly spaced hexagonal cells.

    >>> from landlab import HexModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils.flow__distance import calculate_flow__distance
    >>> dx = 1
    >>> hmg = HexModelGrid((5, 3), spacing=dx)
    >>> _ = hmg.add_field(
    ...     "topographic__elevation",
    ...     hmg.node_x + np.round(hmg.node_y),
    ...     at="node",
    ... )
    >>> hmg.status_at_node[hmg.boundary_nodes] = hmg.BC_NODE_IS_CLOSED
    >>> hmg.status_at_node[0] = hmg.BC_NODE_IS_FIXED_VALUE
    >>> fr = FlowAccumulator(hmg, flow_director="D4")
    >>> fr.run_one_step()
    >>> flow__distance = calculate_flow__distance(hmg, add_to_grid=True, clobber=True)
    >>> hmg.at_node["flow__distance"]
    array([0.,  0.,  0.,
           0.,  1.,  2.,  0.,
           0.,  2.,  2.,  3.,  0.,
           0.,  3.,  3.,  0.,
           0.,  0.,  0.])
    """
    # check that flow__receiver nodes exists
    if "flow__receiver_node" not in grid.at_node:
        raise FieldError(
            "A 'flow__receiver_node' field is required at the "
            "nodes of the input grid."
        )
    if "flow__upstream_node_order" not in grid.at_node:
        raise FieldError(
            "A 'flow__upstream_node_order' field is required at the "
            "nodes of the input grid."
        )

    # get the reciever nodes, depending on if this is to-one, or to-multiple,
    # we'll need to get a different at-node field.
    if grid.at_node["flow__receiver_node"].size != grid.size("node"):
        to_one = False
    else:
        to_one = True
    flow__receiver_node = grid.at_node["flow__receiver_node"]

    # get the upstream node order
    flow__upstream_node_order = grid.at_node["flow__upstream_node_order"]

    # get downstream flow link lengths, result depends on type of grid.
    if isinstance(grid, RasterModelGrid):
        flow_link_lengths = grid.length_of_d8[
            grid.at_node["flow__link_to_receiver_node"]
        ]
    else:
        flow_link_lengths = grid.length_of_link[
            grid.at_node["flow__link_to_receiver_node"]
        ]

    # create an array that representes the outlet lengths.
    flow__distance = np.zeros(grid.nodes.size)

    # iterate through the flow__upstream_node_order, this will already have
    # identified the locations of the outlet nodes and have
    for node in flow__upstream_node_order:
        # get flow recievers
        reciever = flow__receiver_node[node]

        # assess if this is a to one (D8/D4) or to multiple (Dinf, MFD)
        # flow directing method.
        if to_one:
            potential_outlet = reciever
        else:
            # if this is an outlet, the first element of the recievers will be
            # the nodes ID.
            potential_outlet = reciever[0]

        # assess if this is an outlet or not.
        if potential_outlet == node:
            not_outlet = False
        else:
            not_outlet = True

        # if not an outlet
        if not_outlet:
            # deal with the two cases of route to one and route to multiple.
            if to_one:
                # get the stream length of the downstream node
                downstream_stream_length = flow__distance[reciever]

                # get the stream segment length from this node to its downstream
                # neigbor
                stream_increment_length = flow_link_lengths[node]

            else:
                # non-existant links are coded with -1
                useable_receivers = np.where(reciever != grid.BAD_INDEX)[0]

                # we will have the stream flow to the downstream node with the
                # shortest distance to the outlet.
                # in the event of a tie, we will choose the shorter link length.

                # get the flow distances of the downstream nodes
                potential_downstream_stream_lengths = flow__distance[
                    flow__receiver_node[node]
                ][useable_receivers]

                # get the stream segment lengths from this node to its downstream
                # neighbor
                potential_stream_increment_lengths = flow_link_lengths[node][
                    useable_receivers
                ]

                # get the lowest downstream stream length.
                downstream_stream_length = np.min(potential_downstream_stream_lengths)

                # determine which of the stream increments flowed to this
                # downstream neighbor.
                which_link = np.where(
                    potential_downstream_stream_lengths == downstream_stream_length
                )[0]

                # and choose the smallest of these links.
                stream_increment_length = np.min(
                    potential_stream_increment_lengths[which_link]
                )

            # set the total stream length of this node
            flow__distance[node] = downstream_stream_length + stream_increment_length

    # store on the grid
    if add_to_grid:
        grid.add_field("flow__distance", flow__distance, at="node", clobber=clobber)

    return flow__distance



================================================
File: src/landlab/utils/jaggedarray.py
================================================
"""The JaggedArray class to store arrays of variable-length arrays.

Examples
--------

Create a JaggedArray that stores link IDs for the links attached to the
nodes of a 3x3 grid.

>>> from landlab.utils.jaggedarray import JaggedArray
>>> links_at_node = JaggedArray(
...     [
...         [0, 6],
...         [1, 7, 0],
...         [8, 1],
...         [2, 9, 6],
...         [3, 10, 2, 7],
...         [11, 3, 8],
...         [4, 7],
...         [5, 10, 4],
...         [5, 11],
...     ]
... )

Make up some data that provides values at each of the links.

>>> value_at_link = np.arange(12, dtype=float)

Create another JaggedArray. Here we store the values at each of the links
attached to nodes of the grid.

>>> values_at_node = JaggedArray.empty_like(links_at_node, dtype=float)
>>> values_at_node.array[:] = value_at_link[links_at_node.array]

Now operate on the link values for each node.

>>> values_at_node.foreach_row(sum)
array([  6.,   8.,   9.,  17.,  22.,  22.,  11.,  19.,  16.])
>>> values_at_node.foreach_row(min)
array([0.,  0.,  1.,  2.,  2.,  3.,  4.,  4.,  5.])
>>> values_at_node.foreach_row(np.ptp)
array([6.,  7.,  7.,  7.,  8.,  8.,  3.,  6.,  6.])
"""

import numpy as np


def flatten_jagged_array(jagged, dtype=None):
    """Flatten a list of lists.

    Parameters
    ----------
    jagged : array_like of array_like
        An array of arrays of unequal length.

    Returns
    -------
    (data, offset) : (ndarray, ndarray of int)
        A tuple the data, as a flat numpy array, and offsets into that array
        for every item of the original list.

    Examples
    --------
    >>> from landlab.utils.jaggedarray import flatten_jagged_array
    >>> data, offset = flatten_jagged_array([[1, 2], [], [3, 4, 5]], dtype=int)
    >>> data
    array([1, 2, 3, 4, 5])
    >>> offset
    array([0, 2, 2, 5])
    """
    data = np.concatenate(jagged).astype(dtype=dtype)
    # if len(jagged) > 1:
    #     data = np.concatenate(jagged).astype(dtype=dtype)
    # else:
    #     data = np.array(jagged[0]).astype(dtype=dtype)
    items_per_block = np.array([len(block) for block in jagged], dtype=int)

    offset = np.empty(len(items_per_block) + 1, dtype=int)
    offset[0] = 0
    offset[1:] = np.cumsum(items_per_block)

    return data, offset


def unravel(data, offset, out=None, pad=None):
    """Unravel a jagged array.

    Parameters
    ----------
    data : ndarray
        Flattened-array of the data.
    offset : ndarray of int
        Offsets to the start of rows of the jagged array.
    out : ndarray
        Buffer into which to place the unravelled data.
    pad : number
        Value to use to pad rows of the jagged array.

    Returns
    -------
    ndarray
        Matrix that holds the unravelled jagged array.
    """
    from .ext.jaggedarray import unravel

    n_cols = np.diff(offset).max()
    if out is None:
        if pad is None:
            out = np.empty((len(offset) - 1, n_cols), dtype=data.dtype)
        else:
            out = np.full((len(offset) - 1, n_cols), pad, dtype=data.dtype)
    else:
        if pad is not None:
            out.fill(pad)

    unravel(data, offset, out)

    return out


class JaggedArray:
    """A container for an array of variable-length arrays.

    JaggedArray([row0, row1, ...])
    JaggedArray(values, values_per_row)

    Examples
    --------
    Create a JaggedArray with an array of arrays.

    >>> from landlab.utils.jaggedarray import JaggedArray
    >>> x = JaggedArray([[0, 1, 2], [3, 4]])
    >>> x.array
    array([0, 1, 2, 3, 4])

    Create a JaggedArray as a 1D array and a list or row lengths.

    >>> x = JaggedArray([0, 1, 2, 3, 4], (3, 2))
    >>> x.array
    array([0, 1, 2, 3, 4])
    """

    def __init__(self, *args):
        """JaggedArray([row0, row1, ...]) JaggedArray(values, values_per_row)

        Examples
        --------
        Create a JaggedArray with an array of arrays.

        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.array
        array([0, 1, 2, 3, 4])

        >>> x = JaggedArray([[0, 1, 2]])
        >>> x.array
        array([0, 1, 2])
        >>> x.offset
        array([0, 3])

        Create a JaggedArray as a 1D array and a list or row lengths.

        >>> x = JaggedArray([0, 1, 2, 3, 4], (3, 2))
        >>> x.array
        array([0, 1, 2, 3, 4])
        """
        if len(args) == 1:
            values, values_per_row = (
                np.concatenate(args[0]),
                [len(row) for row in args[0]],
            )
            # if len(args[0]) > 1:
            #     values, values_per_row = (np.concatenate(args[0]),
            #                               [len(row) for row in args[0]])
            # else:
            #     values, values_per_row = (np.array(args[0]), [len(args[0])])
        else:
            values, values_per_row = (np.array(args[0]), args[1])

        self._values = values
        self._number_of_rows = len(values_per_row)
        self._offsets = JaggedArray._offsets_from_values_per_row(values_per_row)
        self._offsets.flags["WRITEABLE"] = False

    @property
    def array(self):
        """The jagged array as a 1D array.

        Returns
        -------
        array :
            A view of the underlying 1D array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.array
        array([0, 1, 2, 3, 4])

        >>> x.array[0] = 1
        >>> x.array
        array([1, 1, 2, 3, 4])
        """
        return self._values

    @property
    def offset(self):
        """The offsets to rows of a 1D array.

        Returns
        -------
        array :
            Offsets into the underlying 1D array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.offset
        array([0, 3, 5])

        From the offsets you can get values for rows of the jagged array.

        >>> x.array[x.offset[0] : x.offset[1]]
        array([0, 1, 2])

        Once the array is created, you can't change the offsets.

        >>> x.offset[0] = 1
        Traceback (most recent call last):
        ValueError: assignment destination is read-only
        """
        return self._offsets

    @property
    def size(self):
        """Number of array elements.

        Returns
        -------
        int :
            Number of values in the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.size
        5
        """
        return len(self._values)

    @property
    def number_of_rows(self):
        """Number of array rows.

        Returns
        -------
        int :
            Number of rows in the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.number_of_rows
        2
        """
        return self._number_of_rows

    @staticmethod
    def _offsets_from_values_per_row(values_per_row):
        """Get offsets into the base array from array lengths.

        Parameters
        ----------
        values_per_row : array of int
            The number of values in each row of the JaggedArray.

        Returns
        -------
        ndarray
            An array of offsets.
        """
        offset = np.empty(len(values_per_row) + 1, dtype=int)
        np.cumsum(values_per_row, out=offset[1:])
        offset[0] = 0
        return offset

    @staticmethod
    def empty_like(jagged, dtype=None):
        """Create a new JaggedArray that is like another one.

        Parameters
        ----------
        jagged : JaggedArray
            A JaggedArray to copy.
        dtype : np.dtype
            The data type of the new JaggedArray.

        Returns
        -------
        JaggedArray
            A new JaggedArray.
        """
        return JaggedArray(
            np.empty_like(jagged.array, dtype=dtype), np.diff(jagged.offset)
        )

    def length_of_row(self, row):
        """Number of values in a given row.

        Parameters
        ----------
        row : int
            Index to a row.

        Returns
        -------
        int :
            Number of values in the row.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.length_of_row(0)
        3
        >>> x.length_of_row(1)
        2
        """
        return self._offsets[row + 1] - self._offsets[row]

    def row(self, row):
        """Get the values of a row as an array.

        Parameters
        ----------
        row : int
            Index to a row.

        Returns
        -------
        array :
            Values in the row as a slice of the underlying array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.row(0)
        array([0, 1, 2])
        >>> x.row(1)
        array([3, 4])

        >>> y = x.row(0)
        >>> y[0] = 1
        >>> x.row(0)
        array([1, 1, 2])
        """
        return self._values[self._offsets[row] : self._offsets[row + 1]]

    def __iter__(self):
        """Iterate over the rows of the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> for row in x:
        ...     row
        ...
        array([0, 1, 2])
        array([3, 4])
        """
        for row_number in range(self._number_of_rows):
            yield self.row(row_number)

    def foreach_row(self, func, out=None):
        """Apply an operator row-by-row.

        Examples
        --------
        >>> from landlab.utils.jaggedarray import JaggedArray
        >>> x = JaggedArray([[0, 1, 2], [3, 4]])
        >>> x.foreach_row(sum)
        array([3, 7])

        >>> out = np.empty(2, dtype=int)
        >>> x.foreach_row(sum, out=out) is out
        True
        >>> out
        array([3, 7])
        """
        if out is None:
            out = np.empty(self.number_of_rows, dtype=self._values.dtype)

        for row_number, row in enumerate(self):
            out[row_number] = func(row)

        return out



================================================
File: src/landlab/utils/jaggedarray_ma.py
================================================
"""Store arrays of variable-length arrays implemented with masked arrays.

Implements a MaskedJaggedArray class using numpy masked arrays.

Examples
--------

Create a MaskedJaggedArray that stores link IDs for the links attached to the
nodes of a 3x3 grid.

>>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
>>> links_at_node = MaskedJaggedArray(
...     [
...         [0, 6],
...         [1, 7, 0],
...         [8, 1],
...         [2, 9, 6],
...         [3, 10, 2, 7],
...         [11, 3, 8],
...         [4, 7],
...         [5, 10, 4],
...         [5, 11],
...     ]
... )

Make up some data that provides values at each of the links.

>>> value_at_link = np.arange(12, dtype=float)

Create another MaskedJaggedArray. Here we store the values at each of the links
attached to nodes of the grid.

>>> values_at_node = MaskedJaggedArray.empty_like(links_at_node, dtype=float)
>>> values_at_node.array = value_at_link[links_at_node.array]

Now operate on the link values for each node.

>>> values_at_node.foreach_row(np.sum)
array([ 6.,   8.,   9.,  17.,  22.,  22.,  11.,  19.,  16.])
>>> values_at_node.foreach_row(np.min)
array([0.,  0.,  1.,  2.,  2.,  3.,  4.,  4.,  5.])
>>> values_at_node.foreach_row(np.max)
array([ 6.,  7.,  8.,  9.,  10.,  11.,  7.,  10.,  11.])

Note: `np.ptp` doesn't work on masked arrays but since `max` and `min` seem
to, you can create a new `ptp` that returns the expected values.

>>> ptp = lambda x, axis=None: np.max(x, axis=axis) - np.min(x, axis=axis)
>>> values_at_node.foreach_row(ptp)
array([6.,  7.,  7.,  7.,  8.,  8.,  3.,  6.,  6.])

Or access the underlying masked array directly,

>>> values_at_node.masked_array.ptp(axis=1).data
array([6.,  7.,  7.,  7.,  8.,  8.,  3.,  6.,  6.])
"""

import numpy as np


class MaskedJaggedArray:
    """A container for an array of variable-length arrays.

    MaskedJaggedArray([row0, row1, ...])
    MaskedJaggedArray(values, values_per_row)

    Examples
    --------
    Create a MaskedJaggedArray with an array of arrays.

    >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
    >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
    >>> x.array
    array([0, 1, 2, 3, 4])

    Create a MaskedJaggedArray as a 1D array and a list or row lengths.

    >>> x = MaskedJaggedArray([0, 1, 2, 3, 4], (3, 2))
    >>> x.array
    array([0, 1, 2, 3, 4])
    """

    def __init__(self, *args):
        """MaskedJaggedArray([row0, row1, ...]) MaskedJaggedArray(values,
        values_per_row)

        Examples
        --------
        Create a MaskedJaggedArray with an array of arrays.

        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.array
        array([0, 1, 2, 3, 4])

        Create a MaskedJaggedArray as a 1D array and a list or row lengths.

        >>> x = MaskedJaggedArray([0, 1, 2, 3, 4], (3, 2))
        >>> x.array
        array([0, 1, 2, 3, 4])
        """
        if len(args) == 1:
            if isinstance(args[0], np.ma.core.MaskedArray):
                mat = args[0]
            else:
                mat = MaskedJaggedArray.ma_from_list_of_lists(args[0])
        else:
            mat = MaskedJaggedArray.ma_from_flat_array(args[0], args[1])

        self._values = mat
        self._number_of_rows = mat.shape[0]

    @staticmethod
    def ma_from_list_of_lists(rows, dtype=None):
        """Create a masked array from a list of lists.

        Parameters
        ----------
        rows : array_like or array_like
            Rows of the jagged array.
        dtype : np.dtype, optional
            The data type of the new masked array.

        Returns
        -------
        np.masked_array
            A new masked array.
        """
        values_per_row = [len(row) for row in rows]
        mat = np.ma.masked_all((len(rows), max(values_per_row)), dtype=dtype or int)
        for row_number, row in enumerate(rows):
            mat[row_number, : len(row)] = row

        return mat

    @staticmethod
    def ma_from_flat_array(array, values_per_row):
        """Create a masked array from a flat array.

        Parameters
        ----------
        array : array_like
            Values of the jagged array.
        values_per_row : array_like of int
            Number of values in each row of the jagged array.

        Returns
        -------
        np.masked_array
            A new masked array.
        """
        array = np.array(array)
        mat = np.ma.masked_all(
            (len(values_per_row), max(values_per_row)), dtype=array.dtype
        )
        offset = 0
        for row_number in range(mat.shape[0]):
            n_valid = values_per_row[row_number]
            mat[row_number, :n_valid] = array[offset : offset + n_valid]
            offset += n_valid

        return mat

    @property
    def array(self):
        """The jagged array as a 1D array.

        Returns
        -------
        array :
            A view of the underlying 1D array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.array
        array([0, 1, 2, 3, 4])

        >>> x.array = np.array([1, 1, 2, 3, 4])
        >>> x.array
        array([1, 1, 2, 3, 4])
        """
        return self._values.compressed()

    @property
    def masked_array(self):
        """The jagged array as a masked array.

        Returns
        -------
        np.masked_array :
            The underlying masked array.
        """
        return self._values

    @array.setter
    def array(self, array):
        """Set the data of the jagged array from a 1D array.

        Parameters
        ----------
        array : array_like
            The new values of the array.
        """
        self._values[~self._values.mask] = array

    @property
    def size(self):
        """Number of array elements.

        Returns
        -------
        int :
            Number of values in the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.size
        5
        """
        return self.array.size

    @property
    def number_of_rows(self):
        """Number of array rows.

        Returns
        -------
        int :
            Number of rows in the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.number_of_rows == 2
        True
        """
        return self._number_of_rows

    @staticmethod
    def _offsets_from_values_per_row(values_per_row):
        """Get offsets into the base array from array lengths.

        Parameters
        ----------
        values_per_row : array of int
            The number of values in each row of the MaskedJaggedArray.

        Returns
        -------
        ndarray
            An array of offsets.
        """
        offset = np.empty(len(values_per_row) + 1, dtype=int)
        np.cumsum(values_per_row, out=offset[1:])
        offset[0] = 0
        return offset

    @staticmethod
    def empty_like(jagged, dtype=None):
        """Create a new MaskedJaggedArray that is like another one.

        Parameters
        ----------
        jagged : MaskedJaggedArray
            A MaskedJaggedArray to copy.
        dtype : np.dtype
            The data type of the new MaskedJaggedArray.

        Returns
        -------
        MaskedJaggedArray
            A new MaskedJaggedArray.
        """
        return MaskedJaggedArray(np.ma.empty_like(jagged.masked_array, dtype=dtype))

    def length_of_row(self, row):
        """Number of values in a given row.

        Parameters
        ----------
        row : int
            Index to a row.

        Returns
        -------
        int :
            Number of values in the row.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.length_of_row(0)
        3
        >>> x.length_of_row(1)
        2
        """
        return len(self.row(row))

    def row(self, row):
        """Get the values of a row as an array.

        Parameters
        ----------
        row : int
            Index to a row.

        Returns
        -------
        array :
            Values in the row as a slice of the underlying array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.row(0)
        array([0, 1, 2])
        >>> x.row(1)
        array([3, 4])
        """
        return self._values[row].compressed()

    def __iter__(self):
        """Iterate over the rows of the array.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> for row in x:
        ...     row
        ...
        array([0, 1, 2])
        array([3, 4])
        """
        for row in self._values:
            yield row.compressed()

    def foreach_row(self, func, out=None):
        """Apply an operator row-by-row.

        Examples
        --------
        >>> from landlab.utils.jaggedarray_ma import MaskedJaggedArray
        >>> x = MaskedJaggedArray([[0, 1, 2], [3, 4]])
        >>> x.foreach_row(np.sum)
        array([3, 7])

        >>> out = np.empty(2, dtype=int)
        >>> x.foreach_row(np.sum, out=out) is out
        True
        >>> out
        array([3, 7])
        """
        if out is None:
            return func(self._values, axis=1).compressed()
        else:
            return func(self._values, axis=1, out=out)



================================================
File: src/landlab/utils/matrix.py
================================================
#!/usr/bin/env python3
"""Functions to set up a finite-volume solution matrix for a landlab grid."""

import numpy as np
from scipy.sparse import csc_matrix

from ._matrix import fill_right_hand_side
from ._matrix import get_matrix_diagonal_elements
from ._matrix import get_matrix_diagonal_elements_with_coef


def get_core_node_at_node(grid):
    """Get node ids as numbered by core nodes.

    Get the core node ID for each node of a grid. If a node is not a core
    node, then use -1.

    Parameters
    ----------
    grid : ModelGrid
        A ModelGrid.

    Returns
    -------
    ndarray of int
        Ids of each of the grid's core nodes.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.utils import get_core_node_at_node

    >>> grid = RasterModelGrid((4, 5))
    >>> get_core_node_at_node(grid)
    array([-1, -1, -1, -1, -1,
           -1,  0,  1,  2, -1,
           -1,  3,  4,  5, -1,
           -1, -1, -1, -1, -1])

    >>> grid.status_at_node[13] = grid.BC_NODE_IS_FIXED_VALUE
    >>> grid.status_at_node[2] = grid.BC_NODE_IS_CLOSED
    >>> get_core_node_at_node(grid)
    array([-1, -1, -1, -1, -1,
           -1,  0,  1,  2, -1,
           -1,  3,  4, -1, -1,
           -1, -1, -1, -1, -1])
    """
    core_node_at_node = -np.ones(grid.number_of_nodes, dtype=int)
    core_node_at_node[grid.core_nodes] = np.arange(grid.number_of_core_nodes, dtype=int)
    return core_node_at_node


def get_matrix_entries(grid, coef_at_link=None):
    """Get entries of a sparse matrix.

    Parameters
    ----------
    grid : RasterModelGrid, HexModelGrid
        A landlab grid.
    coef_at_link : ndarray
        Coefficients at links used to construct the matrix.

    Returns
    -------
    tuple of (data, (row_ind, col_inds))
        Values of matrix elements along with their corresponding row and column
        index.
    """
    core2core = grid.link_with_node_status(
        status_at_tail=grid.BC_NODE_IS_CORE, status_at_head=grid.BC_NODE_IS_CORE
    )
    fv2core = grid.link_with_node_status(
        status_at_tail=grid.BC_NODE_IS_FIXED_VALUE, status_at_head=grid.BC_NODE_IS_CORE
    )
    core2fv = grid.link_with_node_status(
        status_at_tail=grid.BC_NODE_IS_CORE, status_at_head=grid.BC_NODE_IS_FIXED_VALUE
    )

    core_node_at_node = get_core_node_at_node(grid)

    nodes_at_c2fv_link = grid.nodes_at_link[core2fv]
    nodes_at_fv2c_link = grid.nodes_at_link[fv2core]

    core_nodes_at_c2c_link = core_node_at_node[grid.nodes_at_link[core2core]]
    core_nodes_at_c2fv_link = core_node_at_node[nodes_at_c2fv_link]
    core_nodes_at_fv2c_link = core_node_at_node[nodes_at_fv2c_link]

    n_core_nodes = grid.number_of_core_nodes

    values = np.zeros(n_core_nodes + 2 * len(core2core), dtype=float)
    row_inds = np.empty(n_core_nodes + 2 * len(core2core), dtype=int)
    col_inds = np.empty(n_core_nodes + 2 * len(core2core), dtype=int)

    diagonal_values = values[:n_core_nodes]
    diagonal_rows = row_inds[:n_core_nodes]
    diagonal_cols = col_inds[:n_core_nodes]

    upper_values = values[n_core_nodes : n_core_nodes + len(core2core)]
    upper_rows = row_inds[n_core_nodes : n_core_nodes + len(core2core)]
    upper_cols = col_inds[n_core_nodes : n_core_nodes + len(core2core)]

    lower_values = values[n_core_nodes + len(core2core) :]
    lower_rows = row_inds[n_core_nodes + len(core2core) :]
    lower_cols = col_inds[n_core_nodes + len(core2core) :]

    if coef_at_link is None:
        get_matrix_diagonal_elements(
            core_nodes_at_c2c_link,
            core_nodes_at_c2fv_link,
            core_nodes_at_fv2c_link,
            diagonal_values,
        )
        upper_values.fill(1.0)
    else:
        get_matrix_diagonal_elements_with_coef(
            core_nodes_at_c2c_link,
            core_nodes_at_c2fv_link,
            core_nodes_at_fv2c_link,
            coef_at_link[core2core],
            coef_at_link[core2fv],
            coef_at_link[fv2core],
            diagonal_values,
        )
        upper_values[:] = coef_at_link[core2core]

    diagonal_rows[:] = np.arange(n_core_nodes)
    diagonal_cols[:] = diagonal_rows

    upper_rows[:] = core_nodes_at_c2c_link[:, 0]
    upper_cols[:] = core_nodes_at_c2c_link[:, 1]

    lower_values[:] = upper_values
    lower_rows[:] = upper_cols
    lower_cols[:] = upper_rows

    return values, (row_inds, col_inds)


def get_core_node_matrix(grid, value_at_node, coef_at_link=None):
    """A matrix for core nodes and a right-hand side vector.

    Construct and return a matrix for the core nodes, plus a right-hand side vector
    containing values based on the input array `value_at_node`. Optionally,
    `coef_at_link` provides coefficients for each link (default is 1.0).

    Parameters
    ----------
    grid : RasterModelGrid, HexModelGrid
        A landlab grid.
    value_at_node : ndarray
        Values defined at nodes used to construct the right-hand side vector.
    coef_at_link : ndarray, optional
        Coefficents at links used to construct the matrix. If not provided,
        use 1.0.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.utils import get_core_node_matrix

    >>> grid = RasterModelGrid((4, 5))
    >>> grid.status_at_node[13] = grid.BC_NODE_IS_FIXED_VALUE
    >>> grid.status_at_node[2] = grid.BC_NODE_IS_CLOSED

    >>> vals = np.arange(
    ...     grid.number_of_nodes, dtype=np.double
    ... )  # made-up state variable array

    >>> mat, rhs = get_core_node_matrix(grid, vals)
    >>> mat.toarray()
    array([[-4.,  1.,  0.,  1.,  0.],
           [ 1., -3.,  1.,  0.,  1.],
           [ 0.,  1., -4.,  0.,  0.],
           [ 1.,  0.,  0., -4.,  1.],
           [ 0.,  1.,  0.,  1., -4.]])
    >>> rhs
    array([[ -6.],
           [  0.],
           [-25.],
           [-26.],
           [-30.]])

    >>> coefs = np.arange(grid.number_of_links, dtype=np.double)  # coefficient array
    >>> mat, rhs = get_core_node_matrix(grid, vals, coef_at_link=coefs)
    >>> mat.toarray()
    array([[-38.,  10.,   0.,  14.,   0.],
           [ 10., -36.,  11.,   0.,  15.],
           [  0.,  11., -46.,   0.,   0.],
           [ 14.,   0.,   0., -74.,  19.],
           [  0.,  15.,   0.,  19., -78.]])
    >>> rhs
    array([[ -6.],
           [  0.],
           [-25.],
           [-26.],
           [-30.]])
    """
    value_at_node = np.broadcast_to(value_at_node, grid.number_of_nodes)
    if coef_at_link is not None:
        coef_at_link = np.broadcast_to(coef_at_link, grid.number_of_links)

    (values, (row_inds, col_inds)) = get_matrix_entries(grid, coef_at_link=coef_at_link)

    mat = csc_matrix(
        (values, (row_inds, col_inds)),
        shape=(grid.number_of_core_nodes, grid.number_of_core_nodes),
    )

    fv2core = grid.link_with_node_status(
        status_at_tail=grid.BC_NODE_IS_FIXED_VALUE, status_at_head=grid.BC_NODE_IS_CORE
    )
    core2fv = grid.link_with_node_status(
        status_at_tail=grid.BC_NODE_IS_CORE, status_at_head=grid.BC_NODE_IS_FIXED_VALUE
    )

    core_node_at_node = get_core_node_at_node(grid)
    nodes_at_c2fv_link = grid.nodes_at_link[core2fv]
    nodes_at_fv2c_link = grid.nodes_at_link[fv2core]

    rhs = np.zeros(grid.number_of_core_nodes, dtype=float)
    fill_right_hand_side(
        nodes_at_c2fv_link, nodes_at_fv2c_link, core_node_at_node, value_at_node, rhs
    )

    return mat, rhs.reshape((-1, 1))



================================================
File: src/landlab/utils/return_array.py
================================================
#! /usr/bin/env python
"""Return array with same shape as grid elements."""
from landlab.utils.decorators import use_field_name_array_or_value


@use_field_name_array_or_value("node")
def return_array_at_node(grid, value):
    """Function to return an array stored at node or of shape `(n_nodes,)`.

    This function exists to take advantage of the use_field_name_array_or_value
    decorator which permits providing the surface as a field name or array.

    Parameters
    ----------
    grid : ModelGrid
    value : field name, ndarray of shape `(n_nodes, )`, or single value.

    Returns
    -------
    array : ndarray of shape `(n_nodes, )`
    """
    return value


@use_field_name_array_or_value("link")
def return_array_at_link(grid, value):
    """Function to return an array stored at node or of shape `(n_nodes,)`.

    This function exists to take advantage of the use_field_name_array_or_value
    decorator which permits providing the surface as a field name or array.

    Parameters
    ----------
    grid : ModelGrid
    value : field name, ndarray of shape `(n_nodes, )`, or single value.

    Returns
    -------
    array : ndarray of shape `(n_nodes, )`
    """
    return value



================================================
File: src/landlab/utils/source_tracking_algorithm.py
================================================
#! /usr/bin/env python
"""
Source Tracking Algorithm
+++++++++++++++++++++++++
.. autosummary::

    ~convert_arc_flow_directions_to_landlab_node_ids
    ~track_source
    ~find_unique_upstream_hsd_ids_and_fractions

Authors: Sai Nudurupati & Erkan Istanbulluoglu

Ref 1: 'The Landlab LandslideProbability Component User Manual' @
https://github.com/RondaStrauch/pub_strauch_etal_esurf/blob/master/LandslideComponentUsersManual.pdf

+----------+-------------------------------------------------------------------+
| Notation | Definition                                                        |
+==========+===================================================================+
| MD       | Modeling Domain - Raster grid that is being analyzed/worked upon. |
+----------+-------------------------------------------------------------------+
+ HSD      | Hydrologic Source Domain - Grid that is at least as coarse as MD. |
|          | For more info, refer Ref 1                                        |
+----------+-------------------------------------------------------------------+

"""
import copy
from collections import Counter

import numpy as np


def convert_arc_flow_directions_to_landlab_node_ids(grid, flow_dir_arc):
    """Convert Arc flow_directions to RasterModelGrid node ids.

    This function receives flow directions (D8) from ESRI ArcGIS and converts
    them to Landlab's RasterModelGrid node id. ESRI ArcGIS D8 flow directions
    are either of the eight valid output directions relating to the eight
    adjacent cells into which flow could travel. The valid output directions
    are powers of 2 starting from 2^0 (1) in the Eastern neighbor going
    clockwise to 2^7 (128) at Northeastern neighbor. For more information
    refer 'https://pro.arcgis.com/en/pro-app/tool-reference/spatial-analyst/
    how-flow-direction-works.htm'

    Parameters
    ----------
    grid: RasterModelGrid
        A grid.
    flow_dir_arc: ndarray of int, shape (n_nodes, )
        flow directions derived from ESRII ArcGIS.

    Returns
    -------
    receiver_nodes: ndarray of int, shape (n_nodes, )
        downstream node at each node. Note that this array gives the
        receiver nodes only for the core nodes. For non-core
        nodes, a zero is used.
    """
    r_arc_raw = np.log2(flow_dir_arc)
    r_arc_raw = r_arc_raw.astype("int")
    neigh_ = grid.adjacent_nodes_at_node
    diag_ = grid.diagonals_at_node
    neigh_ = np.fliplr(neigh_)
    diag_ = np.fliplr(diag_)
    a_n = np.hsplit(neigh_, 4)
    a_d = np.hsplit(diag_, 4)
    neighbors = np.hstack(
        (a_n[-1], a_d[0], a_n[0], a_d[1], a_n[1], a_d[2], a_n[2], a_d[3])
    )
    # Now neighbors has node ids of neighboring nodes in cw order starting at
    # right, hence the order of neighbors = [r, br, b, bl, l, tl, t, tr]
    receiver_nodes = np.zeros(grid.number_of_nodes, dtype=int)
    receiver_nodes[grid.core_nodes] = np.choose(
        r_arc_raw[grid.core_nodes], np.transpose(neighbors[grid.core_nodes])
    )
    return receiver_nodes


# %%
# Source Routing Algorithm
# Note 1: This algorithm works on core nodes only because core nodes
# have neighbors that are real values and not -1s.
# Note 2: Nodes in the following comments in this section refer to core nodes.
def track_source(grid, hsd_ids, flow_directions=None):
    """Track all contributing upstream core nodes for each core node.

    This algorithm traverses the grid based on information of flow directions
    at nodes and at every node identifies all the nodes upstream of a given
    node. The algorithm creates a dictionary with an entry for each node;
    a node's entry in the dictionary will contain a list with the node_ids
    of all upstream nodes. Thus this method permits identification of the
    source area contributing to each and every node in the model grid. This
    function is different from a standard flow accumulation routine in that
    it not only calculates the amount of flow at each node, but records the
    IDs of all upstream nodes. However, similar to a standard
    flow accumulation routine, it produces an at_node array of the amount
    of flow passing through the node. It also differs from a standard
    flow accumulation routing in that it permits the mapping of flow inputs
    from a coarser grid to to a finer model grid.

    In its present implementation, the algorithm has not been optimized
    for efficient time use. Its methods are brute force and it should be
    expected to be time intensive. It is not recommended to be run frequently
    in a modeling exercise. Due to its intensive nature, this algorithm may
    fail with large watersheds (a present, the development team has not
    derived a maximum stable watershed size).

    This function was initially developed to find contributing area of a
    30 m grid (MD), where the quantitative data that we were interested in was
    available in significantly coarser resolution (called Hydrologic Source
    Domain (HSD)). Therefore, we started working with re-sampled HSD,
    that is at the same resolution as MD, and represents exactly the same
    landscape. Alternatively, one can use the node ids of MD
    (grid.nodes.flatten()) as input for hsd_ids.

    For more information, refer Ref 1.

    Parameters
    ----------
    grid: RasterModelGrid
        A grid.
    hsd_ids: ndarray of int, shape (n_nodes, )
        array that maps the nodes of the grid to, possibly coarser,
        Hydrologic Source Domain (HSD) grid ids.
    flow_directions: ndarray of int, shape (n_nodes, ), optional.
        downstream node at each node. Alternatively, this data can be
        provided as a nodal field 'flow__receiver_node' on the grid.

    Returns
    -------
    (hsd_upstr, flow_accum): (dictionary, ndarray of shape (n_nodes))
        'hsd_upstr' maps each grid node to corresponding
        contributing upstream hsd_ids. hsd_upstr.keys() will return
        node_ids of the grid. hsd_upstr.values() will return lists of
        all upstream contributing hsd_ids, including repitions of hsd_ids,
        at corresponding node_ids.
        'flow_accum' is an array of the number of upstream contributing
        nodes at each node.
    """
    if flow_directions is None:
        if grid.at_node["flow__receiver_node"].size != grid.size("node"):
            raise NotImplementedError(
                "A route-to-multiple flow director has been "
                "run on this grid. The landlab development team has not "
                "verified that the source tracking utility is compatible with "
                "route-to-multiple methods. Please open a GitHub Issue "
                "to start this process."
            )

        r = grid.at_node["flow__receiver_node"]
    else:
        r = flow_directions
    z = grid.at_node["topographic__elevation"]
    core_nodes = grid.core_nodes
    core_elev = z[core_nodes]
    # Sort all nodes in the descending order of elevation
    sor_z = core_nodes[np.argsort(core_elev, kind="stable")[::-1]]
    # Create a list to record all nodes that have been visited
    # To store nodes that have already been counted
    alr_counted = []
    flow_accum = np.zeros(grid.number_of_nodes, dtype=int)
    hsd_upstr = {}
    # Loop through all nodes
    for i in sor_z:
        # Check 1: Check if this node has been visited earlier. If yes,
        # then skip to next node
        if i in alr_counted:
            continue
        # Check 2: If the visited node is a sink
        if r[i] == i:
            hsd_upstr.update({i: [hsd_ids[i]]})
            flow_accum[i] += 1.0
            alr_counted.append(i)
            continue
        # Check 3: Now, if the node is not a sink and hasn't been visited, it
        # belongs to a stream segment. Hence, all the nodes in the stream will
        # have to betraversed.
        # stream_buffer is a list that will hold the upstream contributing
        # node information for that particular segment until reaching outlet.
        stream_buffer = []
        j = i
        switch_i = True
        a = 0.0
        # Loop below will traverse the segment of the stream until an outlet
        # is reached.
        while True:
            # Following if loop is to execute the contents once the first node
            # in the segment is visited.
            if not switch_i:
                j = r[j]
                if j not in core_nodes:
                    break
            # If this node is being visited for the first time,
            # this 'if statement' will executed.
            if flow_accum[j] == 0.0:
                a += 1.0
                alr_counted.append(j)
                stream_buffer.append(hsd_ids[j])
            # Update number of upstream nodes.
            flow_accum[j] += a
            # If the node is being visited for the first time, the dictionary
            # 'hsd_upstr' will be updated.
            if j in hsd_upstr:
                hsd_upstr[j] += copy.copy(stream_buffer)
            # If the node has been already visited, then the upstream segment
            # that was not accounted for in the main stem, would be added to
            # all downstream nodes, one by one, until the outlet is reached.
            else:
                hsd_upstr.update({j: copy.copy(stream_buffer)})
            # If the outlet is reached, the 'while' loop will be exited.
            if r[j] == j:
                break
            # This will be executed only for the first node of the
            # stream segment.
            if switch_i:
                switch_i = False
    return (hsd_upstr, flow_accum)


# %%
# Algorithm to calculate coefficients of each upstream HSD ID
def find_unique_upstream_hsd_ids_and_fractions(hsd_upstr):
    """Finds unique entries in hsd_upstr.values()

    This function operates on hsd_upstr.values(), that are lists of hsd_ids.
    Two new Python dictionaries, 'unique_ids' and 'fractions' are created.

    unique_ids.keys() = hsd_upstr.keys()
    unique_ids.values()[i] = list of unique entries in hsd_upstr.values()[i]

    fractions.keys() = hsd_upstr.keys()
    fractions.values()[i] = (number of entries of each unique_id.values()[i]/
    length of hsd_upstr.values()[i]) for each unique_id.values()[i] in the
    same order.

    Note that 'hsd_upstr' is the output of track_source(). You can use
    an alternative input. In that case, please refer to the documentation
    of track_source() or refer source_tracking_algorithm_user_manual for
    more information.

    Parameters
    ----------
    hsd_upstr: dictionary
        'hsd_upstr' maps each MD grid node to corresponding
        contributing upstream HSD ids.

    Returns
    -------
    (unique_ids, fractions): (dictionary, dictionary)
        Tuple of data. 'unique_ids' maps each MD node with all upstream HSD
        ids without repitition. 'fractions' maps each MD node with the
        fractions of contributions of the corresponding upstream HSD ids in
        the same order as uniques_ids[node_id].
    """
    unique_ids = {}  # Holds unique upstream HSD ids
    C = {}  # Holds corresponding total numbers
    fractions = {}  # Holds corresponding fractions of contribution
    for ke in hsd_upstr.keys():
        cnt = Counter()
        for num in hsd_upstr[ke]:
            cnt[num] += 1
        unique_ids.update({ke: cnt.keys()})
        buf = []
        for k in cnt.keys():
            buf.append(cnt[k])
        C.update({ke: buf})
        e = [s / float(sum(buf)) for s in buf]
        fractions.update({ke: e})
    return (unique_ids, fractions)



================================================
File: src/landlab/utils/stable_priority_queue.py
================================================
#!/usr/env/python

import heapq
import itertools
from collections import deque

import numpy as np


class StablePriorityQueue:
    """Implements a stable priority queue, that tracks insertion order; i.e.,
    this is used to break ties.

    See https://docs.python.org/2/library/heapq.html#priority-queue-implementation-notes
    & https://www.sciencedirect.com/science/article/pii/S0098300413001337

    Examples
    --------
    >>> q = StablePriorityQueue()
    >>> q.add_task("b", priority=2)
    >>> q.add_task("a", priority=1)
    >>> q.add_task(0, priority=0)
    >>> q.add_task("c", priority=2)
    >>> q.remove_task(0)
    >>> q.pop_task()
    'a'
    >>> q.peek_at_task()
    'b'
    >>> np.all(q.tasks_currently_in_queue() == np.array(["b", "c"]))
    True
    >>> q.pop_task()
    'b'
    >>> np.all(q.tasks_ever_in_queue() == np.array(["b", "a", "0", "c"]))
    True

    If only ints or floats are loaded into the array, the _in_queue methods
    return arrays with the corresponding data types:

    >>> q = StablePriorityQueue()
    >>> q.add_task(2, priority=2)
    >>> q.add_task(1, priority=1)
    >>> np.issubdtype(q.tasks_currently_in_queue().dtype, np.integer)
    True
    >>> q = StablePriorityQueue()
    >>> q.add_task(np.pi)
    >>> np.issubdtype(q.tasks_currently_in_queue().dtype, np.floating)
    True

    Popping from (or peeking at) an empty queue will throw a KeyError:

    >>> q = StablePriorityQueue()
    >>> try:
    ...     q.pop_task()
    ... except KeyError:
    ...     print("No tasks left")
    ...
    No tasks left
    """

    def __init__(self):
        self._pq = []  # list of entries as a heap
        self._entry_finder = {}  # mapping of tasks to entries
        self._REMOVED = float("inf")  # placeholder for a removed task
        self._counter = itertools.count()  # unique sequence count
        self._tasks_ever_in_queue = deque([])
        # last one tracks all nodes that have ever been added

    def add_task(self, task, priority=0):
        """Add a new task or update the priority of an existing task."""
        if task == self._REMOVED:
            raise ValueError("StablePriorityQueue cannot accept tasks equal to INF!")
        if task in self._entry_finder:
            self.remove_task(task)
        count = next(self._counter)
        entry = [priority, count, task]
        self._entry_finder[task] = entry
        heapq.heappush(self._pq, entry)
        self._tasks_ever_in_queue.append(task)

    def remove_task(self, task):
        """Mark an existing task as _REMOVED.

        Raise KeyError if not found.
        """
        entry = self._entry_finder.pop(task)
        entry[-1] = self._REMOVED

    def pop_task(self):
        """Remove and return the lowest priority task.

        Raise KeyError if empty.
        """
        while self._pq:
            priority, count, task = heapq.heappop(self._pq)
            if task is not self._REMOVED:
                del self._entry_finder[task]
                return task
        raise KeyError("pop from an empty priority queue")

    def peek_at_task(self):
        """Return the lowest priority task without removal.

        Raise KeyError if empty.
        """
        while self._pq:
            priority, count, task = self._pq[0]
            if task is not self._REMOVED:
                return task
        raise KeyError("peeked at an empty priority queue")

    def tasks_currently_in_queue(self):
        """Return array of nodes currently in the queue."""
        mynodes = [
            task for (priority, count, task) in self._pq if task is not self._REMOVED
        ]
        return np.array(mynodes)

    def tasks_ever_in_queue(self):
        """Return array of all nodes ever added to this queue object.

        Repeats are permitted.
        """
        return np.array(self._tasks_ever_in_queue)



================================================
File: src/landlab/utils/structured_grid.py
================================================
#! /usr/bin/env python
"""Utility functions for structured grid of elements with four neighbors."""

import contextlib
import itertools

import numpy as np

from ..core.utils import as_id_array
from ..grid.base import BAD_INDEX_VALUE
from ..grid.nodestatus import NodeStatus


def node_count(shape):
    """Total number of nodes.

    The total number of nodes in a structured grid with dimensions given
    by the tuple, *shape*. Where *shape* is the number of node rows and
    node columns.

    >>> from landlab.utils.structured_grid import node_count
    >>> node_count((3, 4))
    12
    """
    assert len(shape) == 2
    return shape[0] * shape[1]


def interior_node_count(shape):
    """Number of interior nodes.

    Return the count of the number of interior nodes of a structured grid
    of dimensions, *shape*.

    >>> from landlab.utils.structured_grid import node_count, interior_node_count
    >>> node_count((2, 4))
    8
    >>> interior_node_count((2, 4))
    0
    >>> interior_node_count((1, 4))
    0
    >>> interior_node_count((3, 4))
    2
    """
    assert len(shape) == 2
    if np.min(shape) > 2:
        return (shape[0] - 2) * (shape[1] - 2)
    else:
        return 0


def cell_count(shape):
    """Total number of cells.

    The total number of cells in a structured grid with dimensions, *shape*.
    Where *shape* is a tuple that gives the dimensions of the grid as number
    of rows of nodes followed by number of columns of nodes.

    >>> from landlab.utils.structured_grid import cell_count
    >>> cell_count((3, 4))
    2
    >>> cell_count((1, 4))
    0
    """
    assert len(shape) == 2
    if np.min(shape) > 2:
        return (shape[0] - 2) * (shape[1] - 2)
    else:
        return 0


def active_cell_count(shape):
    """Number of active cells.

    Number of active cells. By default, all cells are active so this is
    the same as cell_count. (active = core+open boundary)
    """
    return cell_count(shape)


def core_cell_count(shape):
    """Number of core cells.

    Number of core cells. By default, all cells are core so this is the
    same as cell_count.
    """
    return cell_count(shape)


def active_link_count(shape):
    """Number of active links.

    Number of active links in a structured grid with dimensions, *shape*.
    A link is active if it connects to at least one active node.

    >>> from landlab.utils.structured_grid import link_count, active_link_count
    >>> link_count((3, 2))
    7
    >>> active_link_count((3, 2))
    0
    >>> active_link_count((3, 4))
    7
    """
    assert len(shape) == 2
    if np.min(shape) > 2:
        return 2 * shape[0] * shape[1] - 3 * (shape[0] + shape[1]) + 4
    else:
        return 0


def link_count(shape):
    """Total number of links.

    Total (active and inactive) number of links in a structured grid with
    dimensions, *shape*. This is the number of to-links and from-links, not
    the total of the two.

    >>> from landlab.utils.structured_grid import link_count
    >>> link_count((3, 2))
    7
    """
    assert len(shape) == 2
    return shape[1] * (shape[0] - 1) + shape[0] * (shape[1] - 1)


def vertical_link_count(shape):
    """Number of vertical links."""
    assert len(shape) == 2
    return (shape[0] - 1) * shape[1]


def horizontal_link_count(shape):
    """Number of horizontal links."""
    assert len(shape) == 2
    return shape[0] * (shape[1] - 1)


def perimeter_node_count(shape):
    """Number of perimeter nodes.

    Number of nodes that are on the perimeter of a structured grid with
    dimensions, *shape*, and thus boundary nodes.

    Examples
    --------
    >>> from landlab.utils.structured_grid import perimeter_node_count
    >>> perimeter_node_count((3, 4))
    10
    """
    assert len(shape) == 2
    return 2 * (shape[0] - 2) + 2 * (shape[1] - 2) + 4


def interior_cell_count(shape):
    """Number of interior cells.

    Number of interior cells. Since cells are only defined on interior
    nodes, this is the same as cell_count.
    """
    return cell_count(shape)


def face_count(shape):
    """Total number of faces.

    Total number of faces in a structured grid with dimensions, *shape*. Each
    cell has four faces, and shared faces only count once.

    Examples
    --------
    >>> from landlab.utils.structured_grid import face_count
    >>> face_count((3, 4))
    7
    """
    assert len(shape) == 2
    if np.min(shape) > 2:
        return (shape[0] - 1) * (shape[1] - 2) + (shape[0] - 2) * (shape[1] - 1)
    else:
        return 0


def active_face_count(shape):
    """Number of active faces.

    Total number of active faces in a structured grid with dimensions,
    *shape*. Each cell has four faces, and shared faces only count once.
    An active face is one that has a corresponing active link.

    >>> from landlab.utils.structured_grid import active_face_count
    >>> active_face_count((3, 4))
    7
    """
    return face_count(shape)


def top_index_iter(shape):
    """Iterator for the top boundary indices of a structured grid."""
    return range(shape[1] * (shape[0] - 1), shape[0] * shape[1])


def bottom_index_iter(shape):
    """Iterator for the bottom boundary indices of a structured grid."""
    return range(0, shape[1])


def left_index_iter(shape):
    """Iterator for the left boundary indices of a structured grid."""
    return range(0, shape[0] * shape[1], shape[1])


def right_index_iter(shape):
    """Iterator for the right boundary indices of a structured grid."""
    return range(shape[1] - 1, shape[0] * shape[1], shape[1])


def left_right_iter(shape, *args):
    """Iterator for the left and right boundary indices of a structured grid.

    This iterates over the indices in order rather than iterating all of
    the left boundary and then all of the right boundary.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils.structured_grid import left_right_iter
    >>> np.fromiter(left_right_iter((4, 3)), dtype=int)
    array([ 0,  2,  3,  5,  6,  8,  9, 11])
    >>> np.fromiter(left_right_iter((4, 3), 2), dtype=int)
    array([0, 2, 3, 5])
    >>> np.fromiter(left_right_iter((4, 3), 2, 4), dtype=int)
    array([ 6,  8,  9, 11])
    >>> np.fromiter(left_right_iter((4, 3), 1, 4, 2), dtype=int)
    array([ 3,  5,  9, 11])
    """
    if len(args) == 0:
        iter_rows = range(0, shape[0], 1)
    elif len(args) == 1:
        iter_rows = range(0, args[0], 1)
    elif len(args) == 2:
        iter_rows = range(args[0], args[1], 1)
    elif len(args) == 3:
        iter_rows = range(args[0], args[1], args[2])

    for row in iter_rows:
        yield row * shape[1]
        yield row * shape[1] + shape[1] - 1


def bottom_top_iter(shape):
    """Iterator for bottom then top indices of a structured grid.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils.structured_grid import bottom_top_iter
    >>> np.fromiter(bottom_top_iter((4, 3)), dtype=int)
    array([ 0,  1,  2,  9, 10, 11])
    """
    return itertools.chain(bottom_index_iter(shape), top_index_iter(shape))


def perimeter_iter(shape):
    """Iterator for perimeter nodes.

    Iterates over all of the perimeter node indices of a structured grid in
    order.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils.structured_grid import perimeter_iter
    >>> np.fromiter(perimeter_iter((4, 3)), dtype=int)
    array([ 0,  1,  2,  3,  5,  6,  8,  9, 10, 11])
    """
    return itertools.chain(
        bottom_index_iter(shape),
        left_right_iter(shape, 1, shape[0] - 1),
        top_index_iter(shape),
    )


def perimeter_nodes(shape):
    """Array of perimeter nodes.

    An array of the indices of the perimeter nodes of a structured grid.

    Examples
    --------
    >>> from landlab.utils.structured_grid import perimeter_nodes
    >>> perimeter_nodes((3, 4))
    array([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11])
    """
    return np.fromiter(perimeter_iter(shape), dtype=int)


def corners(shape):
    """Array of the indices of the grid corner nodes."""
    return np.array(
        [0, shape[1] - 1, shape[1] * (shape[0] - 1), shape[1] * shape[0] - 1]
    )


def bottom_edge_node_ids(shape):
    """Array of nodes on the bottom edge."""
    return np.fromiter(bottom_index_iter(shape), dtype=int)


def top_edge_node_ids(shape):
    """Array of nodes on the top edge."""
    return np.fromiter(top_index_iter(shape), dtype=int)


def left_edge_node_ids(shape):
    """Array of nodes on the left edge."""
    return np.fromiter(left_index_iter(shape), dtype=int)


def right_edge_node_ids(shape):
    """Array of nodes on the right edge."""
    return np.fromiter(right_index_iter(shape), dtype=int)


def interior_iter(shape):
    """Iterator for the interior nodes of a structured grid.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils.structured_grid import interior_iter
    >>> np.fromiter(interior_iter((4, 3)), dtype=int)
    array([4, 7])
    """
    interiors = []
    interiors_per_row = shape[1] - 2
    for row in range(shape[1] + 1, shape[1] * (shape[0] - 1), shape[1]):
        interiors.append(range(row, row + interiors_per_row))
    return itertools.chain(*interiors)


def interior_nodes(shape):
    """Array of interior nodes."""
    return np.fromiter(interior_iter(shape), dtype=int)


def node_coords(shape, *args):
    """Get node x and y coordinates.

    Get x, y coordinates for nodes in a structured grid with dimensions,
    *shape*. Use the optional argument *spacing* to give the spacing in each
    dimension, and *origin* the start of the coordinates in each dimension.

    Parameters
    ----------
    shape : tuple of int
        Number of node rows and columns.
    spacing : tuple, optional
        Row and column spacing.
    origin : tuple, optional
        Coordinate of lower-left node.

    Examples
    --------
    >>> from landlab.utils.structured_grid import node_coords
    >>> (cols, rows) = node_coords((3, 2))
    >>> rows
    array([0.,  0.,  1.,  1.,  2.,  2.])
    >>> cols
    array([0.,  1.,  0.,  1.,  0.,  1.])
    """
    try:
        spacing = args[0]
    except IndexError:
        spacing = np.ones(len(shape), dtype=float)
    else:
        assert len(spacing) == len(shape)

    try:
        origin = args[1]
    except IndexError:
        origin = np.zeros(len(shape), dtype=float)
    else:
        assert len(origin) == len(origin)

    node_count_ = np.prod(shape)

    row_y = np.arange(shape[0]) * spacing[0] + origin[0]
    col_x = np.arange(shape[1]) * spacing[1] + origin[1]

    (node_x, node_y) = np.meshgrid(col_x, row_y)

    node_x.shape = (node_count_,)
    node_y.shape = (node_count_,)

    return (node_x, node_y)


def node_at_cell(shape):
    """Array of nodes at cells.

    Indices of the nodes belonging to each cell.

    Examples
    --------
    >>> from landlab.utils.structured_grid import node_at_cell
    >>> node_at_cell((4, 3))
    array([4, 7])
    """
    node_ids = np.arange(node_count(shape))
    node_ids.shape = shape

    cell_node = node_ids[1:-1, 1:-1].copy()
    cell_node.shape = ((shape[0] - 2) * (shape[1] - 2),)

    return cell_node


def node_index_at_link_ends(shape):
    """Array of nodes at each end of links."""
    node_ids = np.arange(np.prod(shape))
    node_ids.shape = shape

    return (node_at_link_tail(node_ids), node_at_link_head(node_ids))


def inlink_index_at_node(shape):
    """Array of links entering nodes."""
    return inlinks(shape)


def outlink_index_at_node(shape):
    """Array of links leaving nodes."""
    return outlinks(shape)


def node_at_link_head(node_ids):
    """Array of nodes at the end of links."""
    vertical_links = node_ids[1:, :]
    horizontal_links = node_ids[:, 1:]
    return np.concatenate((vertical_links.flat, horizontal_links.flat))


def node_at_link_tail(node_ids):
    """Array of nodes at the start of links."""
    vertical_links = node_ids[:-1, :]
    horizontal_links = node_ids[:, :-1]
    return np.concatenate((vertical_links.flat, horizontal_links.flat))


def face_at_link(shape, actives=None, inactive_link_index=BAD_INDEX_VALUE):
    """Array of faces associated with links.

    Returns an array that maps link ids to face ids. For inactive links,
    which do not have associated faces, set their ids to
    *inactive_link_index*. Use the *actives* keyword to specify an array that
    contains the ids of all active links in the grid. The default assumes
    that only the perimeter nodes are inactive.

    Examples
    --------
    >>> from landlab.utils.structured_grid import face_at_link
    >>> faces = face_at_link((3, 4), inactive_link_index=-1)
    >>> faces
    array([-1,  0,  1, -1, -1,  2,  3,
           -1, -1, -1, -1,  4,  5,  6, -1, -1, -1])
    """
    if actives is None:
        actives = active_links(shape)

    num_links = link_count(shape)

    link_faces = np.empty(num_links, dtype=int)
    link_faces.fill(inactive_link_index)
    link_faces[actives] = np.arange(len(actives))

    return link_faces


def status_at_node(shape, boundary_status=NodeStatus.FIXED_VALUE):
    """Array of the statuses of nodes.

    The statuses of the nodes in a structured grid with dimensions,
    *shape*. Use the *boundary_status* keyword to specify the status of
    the top, bottom, left and right boundary nodes.
    """
    status = np.empty(np.prod(shape), dtype=np.int8)

    status[interior_nodes(shape)] = NodeStatus.CORE
    status[perimeter_nodes(shape)] = boundary_status

    return status


def active_links(shape, node_status_array=None, link_nodes=None):
    """Link IDs for active links of a structured quad grid.

    Return the link IDs for links that are *active* in a structured grid of
    quadrilaterals. Use the *node_status_array* keyword to specify the status
    for each of the grid's nodes. If not given, each of the perimeter nodes is
    assumed to be `NodeStatus.FIXED_VALUE`.

    Use the *link_nodes* keyword to provide, as a tuple of arrays, that give
    the *from-node* and the *to-node* for each for each link in the grid.

    Parameters
    ----------
    shape : tuple
        Shape of grid as number of node rows and columns.
    node_status_array : array_like, optional
        Status of each grid node.
    link_nodes : array_like, optional

    Examples
    --------
    Because, by default, the perimeter nodes are `NodeStatus.FIXED_VALUE` nodes,
    only links attached to the interior nodes are *active*.

    >>> from landlab.utils.structured_grid import active_links
    >>> from landlab.grid.nodestatus import NodeStatus
    >>> active_links((3, 4))
    array([ 1,  2,  5,  6, 11, 12, 13])

    If all the perimeter nodes `NodeStatus.CLOSED` nodes, the only active link
    is between the two core nodes.

    >>> node_status = np.ones(3 * 4) * NodeStatus.CLOSED
    >>> node_status[5:7] = NodeStatus.CORE
    >>> active_links((3, 4), node_status_array=node_status)
    array([12])

    You can also provide a list of all the *from_nodes* and *to_nodes* for
    the grid. The following describes a grid with only a single link (between
    nodes 5 and 6).

    >>> active_links((3, 4), link_nodes=(np.array([5]), np.array([6])))
    array([0])
    """
    if node_status_array is None:
        node_status_array = status_at_node(shape)

    if link_nodes is None:
        (link_from_node, link_to_node) = node_index_at_link_ends(shape)
    else:
        (link_from_node, link_to_node) = link_nodes

    from_node_status = node_status_array[link_from_node]
    to_node_status = node_status_array[link_to_node]

    active_links_ = (
        (from_node_status == NodeStatus.CORE) & ~(to_node_status == NodeStatus.CLOSED)
    ) | ((to_node_status == NodeStatus.CORE) & ~(from_node_status == NodeStatus.CLOSED))

    (active_links_,) = np.where(active_links_)

    return as_id_array(active_links_)


def active_face_index(shape):
    """Array of face indices."""
    return np.arange(active_face_count(shape))


def inlinks(shape):
    """Array of links entering nodes."""
    links = np.vstack((south_links(shape), west_links(shape)))
    links.shape = (2, node_count(shape))
    return links


def outlinks(shape):
    """Array of links leaving nodes."""
    links = np.vstack((north_links(shape), east_links(shape)))
    links.shape = (2, node_count(shape))
    return links


def active_inlinks(shape, node_status=None):
    """Array of active links entering nodes."""
    links = np.vstack(
        (active_south_links(shape, node_status), active_west_links(shape, node_status))
    )
    links.shape = (2, node_count(shape))
    return links


def active_inlinks2(shape, node_status=None):
    """Array of active links entering nodes.

    Finds and returns the link IDs of active links coming in to each node
    (that is, active links for which the node is the link head).

    Parameters
    ----------
    shape : 2-element tuple of ints
        Number of rows and columns in the grid
    node_status (optional) : numpy array of bool (x # of nodes)
        False where node is a closed boundary; True elsewhere

    Returns
    -------
    2d numpy array of int (2 x number of grid nodes)
        Link ID of incoming links to each node

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_inlinks2
    >>> active_inlinks2((3, 4))
    array([[-1, -1, -1, -1, -1,  4,  5, -1, -1, 11, 12, -1],
           [-1, -1, -1, -1, -1,  7,  8,  9, -1, -1, -1, -1]])

    Notes
    -----
    There are at most two inlinks for each node. The first row in the returned
    array gives the ID of the vertical incoming link from below (south), or -1
    if there is none. The second row gives the link ID of the horizontal link
    coming in from the left (or -1).
    """
    links = np.vstack(
        (
            active_south_links2(shape, node_status),
            active_west_links2(shape, node_status),
        )
    )
    links.shape = (2, node_count(shape))
    return links


def active_outlinks(shape, node_status=None):
    """Array of active links leaving nodes."""
    links = np.vstack(
        (active_north_links(shape, node_status), active_east_links(shape, node_status))
    )
    links.shape = (2, node_count(shape))
    return links


def active_outlinks2(shape, node_status=None):
    """Array of active links leaving nodes.

    Finds and returns the link IDs of active links going out of each node
    (that is, active links for which the node is the link tail).

    Parameters
    ----------
    shape : 2-element tuple of ints
        Number of rows and columns in the grid
    node_status (optional) : numpy array of bool (x # of nodes)
        False where node is a closed boundary; True elsewhere

    Returns
    -------
    2d numpy array of int (2 x number of grid nodes)
        Link ID of outgoing links from each node

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_outlinks2
    >>> active_outlinks2((3, 4))
    array([[-1,  4,  5, -1, -1, 11, 12, -1, -1, -1, -1, -1],
           [-1, -1, -1, -1,  7,  8,  9, -1, -1, -1, -1, -1]])

    Notes
    -----
    There are at most two outlinks for each node. The first row in the returned
    array gives the ID of the vertical outgoing link to above (north), or -1
    if there is none. The second row gives the link ID of the horizontal link
    going out to the right (east) (or -1).
    """
    links = np.vstack(
        (
            active_north_links2(shape, node_status),
            active_east_links2(shape, node_status),
        )
    )
    links.shape = (2, node_count(shape))
    return links


def vertical_link_ids(shape):
    """Array of links oriented vertically."""
    link_ids = np.empty((shape[0] - 1, shape[1]), dtype=int)
    num_links_per_row = (2 * shape[1]) - 1
    for r in range(shape[0] - 1):
        link_ids[r, :] = (shape[1] - 1) + (r * num_links_per_row) + np.arange(shape[1])
    return link_ids


def horizontal_link_ids(shape):
    """Array of links oriented horizontally."""
    link_ids = np.empty((shape[0], shape[1] - 1), dtype=int)
    num_links_per_row = (2 * shape[1]) - 1
    for r in range(shape[0]):
        link_ids[r, :] = (r * num_links_per_row) + np.arange(shape[1] - 1)
    return link_ids


def vertical_active_link_count(shape, node_status=None):
    """Number of active links oriented vertically."""
    if node_status is not None:
        is_inactive = node_status == 0
        is_inactive.shape = shape

        inactive_outlinks = is_inactive[:-1, 1:-1]
        inactive_inlinks = is_inactive[1:, 1:-1]
        inactive_links = inactive_outlinks | inactive_inlinks

        return (shape[0] - 1) * (shape[1] - 2) - np.sum(inactive_links.flat)
    else:
        return (shape[0] - 1) * (shape[1] - 2)


def horizontal_active_link_count(shape, node_status=None):
    """Number of active links oriented horizontally."""
    if node_status is not None:
        is_inactive = node_status == 0
        is_inactive.shape = shape

        inactive_outlinks = is_inactive[1:-1, :-1]
        inactive_inlinks = is_inactive[1:-1, 1:]
        inactive_links = inactive_outlinks | inactive_inlinks

        return (shape[0] - 2) * (shape[1] - 1) - np.sum(inactive_links.flat)
    else:
        return (shape[0] - 2) * (shape[1] - 1)


def vertical_inactive_link_mask(shape, node_status):
    """Array mask of vertical links that are inactive.

    Creates and returns a boolean 2D array dimensioned as the number of
    vertical links in the grid, not including the left and right boundaries.

    Parameters
    ----------
    shape : 2-element tuple of ints
        Number of rows and columns in the grid
    node_status : numpy array of bool (x # of nodes)
        False where node is a closed boundary; True elsewhere

    Returns
    -------
    (NR-1,NC-2) array of bool (NR=# of rows, NC=# of columns)
        Flags indicating whether the corresponding vertical link is inactive

    Examples
    --------
    >>> import numpy as np
    >>> from landlab.utils.structured_grid import vertical_inactive_link_mask
    >>> ns = np.ones(12, dtype=bool)  # case of no closed boundary nodes
    >>> vertical_inactive_link_mask((3, 4), ns)
    array([[False, False],
           [False, False]])
    >>> ns[2] = False  # node 2 is a closed boundary
    >>> vertical_inactive_link_mask((3, 4), ns)
    array([[False,  True],
           [False, False]])
    >>> ns[9] = False  # node 9 is also a closed boundary
    >>> vertical_inactive_link_mask((3, 4), ns)
    array([[False,  True],
           [ True, False]])
    """
    # Create a 2D boolean matrix indicating whether NODES are closed boundaries
    # GT thinks this should be False, not 0
    is_closed_node = node_status == 0
    is_closed_node.shape = shape

    inactive_outlinks = is_closed_node[:-1, 1:-1]  # middle cols, all but top row
    # middle cols, all but bottom row
    inactive_inlinks = is_closed_node[1:, 1:-1]
    # if either node is closed, the link is inactive
    return inactive_outlinks | inactive_inlinks


def horizontal_inactive_link_mask(shape, node_status):
    """Array mask of horizontal links that are inactive."""
    is_inactive = node_status == 0
    is_inactive.shape = shape

    inactive_outlinks = is_inactive[1:-1, :-1]
    inactive_inlinks = is_inactive[1:-1, 1:]
    return inactive_outlinks | inactive_inlinks


# def vertical_active_link_ids(shape):
#    link_ids = np.arange(vertical_active_link_count(shape), dtype=int)
#    link_ids.shape = (shape[0] - 1, shape[1] - 2)
#    return link_ids


def vertical_active_link_ids(shape, node_status=None):
    """Array of active links oriented vertically."""
    if node_status is None:
        link_ids = np.arange(vertical_active_link_count(shape), dtype=int)
        # link_ids.shape = (shape[0] - 1, shape[1] - 2)
        # return link_ids
    else:
        inactive_links = vertical_inactive_link_mask(shape, node_status)
        inactive_links.shape = (inactive_links.size,)
        active_link_count_ = inactive_links.size - np.sum(inactive_links)

        link_ids = np.empty(inactive_links.size)
        link_ids[inactive_links] = -1
        link_ids[~inactive_links] = np.arange(active_link_count_, dtype=int)

    link_ids.shape = (shape[0] - 1, shape[1] - 2)
    return link_ids


def vertical_active_link_ids2(shape, node_status=None):
    """Array of active links oriented vertically.

    Returns the link IDs of vertical active links as an (R-1) x (C-2) array.

    Parameters
    ----------
    shape : 2-element tuple of int
        number of rows and columns in grid
    node_status (optional) : 1d numpy array (x number of nodes) of bool
        False where node is a closed boundary, True otherwise

    Returns
    -------
    2d numpy array of int
        Link IDs of vertical active links, not including vertical links on the
        left and right grid edges. If a vertical link is inactive, its ID is
        given as -1.

    Examples
    --------
    >>> from landlab.utils.structured_grid import vertical_active_link_ids2
    >>> vertical_active_link_ids2((3, 4))
    array([[ 4,  5],
           [11, 12]])
    >>> ns = np.ones(12, dtype=bool)
    >>> ns[1] = False
    >>> ns[10] = False
    >>> vertical_active_link_ids2((3, 4), ns)
    array([[-1,  5],
           [11, -1]])

    Notes
    -----
    Same as vertical_active_link_ids() but returns "link IDs" for active links
    rather than "active link IDs" for active links. Designed to ultimately
    replace the original vertical_active_link_ids().
    """
    link_ids = np.empty((shape[0] - 1, shape[1] - 2), dtype=int)
    num_links_per_row = (2 * shape[1]) - 1
    for r in range(shape[0] - 1):
        link_ids[r, :] = shape[1] + (r * num_links_per_row) + np.arange(shape[1] - 2)

    if node_status is not None:
        inactive_links = vertical_inactive_link_mask(shape, node_status)
        link_ids[inactive_links] = -1

    return link_ids


def horizontal_active_link_ids(shape, node_status=None):
    """Array of active links oriented horizontally."""
    if node_status is None:
        link_id_offset = vertical_active_link_count(shape)
        link_ids = np.arange(
            link_id_offset,
            link_id_offset + horizontal_active_link_count(shape),
            dtype=int,
        )
    else:
        link_id_offset = vertical_active_link_count(shape, node_status=node_status)
        inactive_links = horizontal_inactive_link_mask(shape, node_status)
        inactive_links.shape = (inactive_links.size,)
        active_link_count_ = inactive_links.size - np.sum(inactive_links)

        link_ids = np.empty(inactive_links.size)
        link_ids[inactive_links] = -1
        link_ids[~inactive_links] = np.arange(
            link_id_offset, link_id_offset + active_link_count_, dtype=int
        )
    link_ids.shape = (shape[0] - 2, shape[1] - 1)
    return link_ids


def horizontal_active_link_ids2(shape, node_status=None):
    """Array of active links oriented horizontally.

    Returns the link IDs of horizontal active links as an (R-2) x (C-1) array.

    Parameters
    ----------
    shape : 2-element tuple of int
        number of rows and columns in grid
    node_status (optional) : 1d numpy array (x number of nodes) of bool
        False where node is a closed boundary, True otherwise

    Returns
    -------
    2d numpy array of int
        Link IDs of horizontal active links, not including horizontal links on
        top and bottom grid edges. If a horizontal link is inactive, its ID is
        given as -1.

    Examples
    --------
    >>> from landlab.utils.structured_grid import horizontal_active_link_ids2
    >>> horizontal_active_link_ids2((3, 4))
    array([[7, 8, 9]])
    >>> ns = np.ones(12, dtype=bool)
    >>> ns[4] = False
    >>> ns[7] = False
    >>> horizontal_active_link_ids2((3, 4), ns)
    array([[-1,  8, -1]])

    Notes
    -----
    Same as horizontal_active_link_ids() but returns "link IDs" for active
    links rather than "active link IDs" for active links. Designed to
    ultimately replace the original horizontal_active_link_ids().
    """
    link_ids = np.empty((shape[0] - 2, shape[1] - 1), dtype=int)
    num_links_per_row = (2 * shape[1]) - 1
    for r in range(shape[0] - 2):
        link_ids[r, :] = ((r + 1) * num_links_per_row) + np.arange(shape[1] - 1)
    if node_status is not None:
        inactive_links = horizontal_inactive_link_mask(shape, node_status)
        link_ids[inactive_links] = -1

    return link_ids


def west_links(shape):
    """Array of links pointing to the west.

    Examples
    --------
    >>> from landlab.utils.structured_grid import west_links
    >>> west_links((3, 4))
    array([[-1,  0,  1,  2],
           [-1,  7,  8,  9],
           [-1, 14, 15, 16]])
    """
    link_ids = horizontal_link_ids(shape)
    link_ids.shape = (shape[0], shape[1] - 1)
    return np.hstack((-np.ones((shape[0], 1), dtype=int), link_ids))


def north_links(shape):
    """Array of links pointing to the north.

    Examples
    --------
    >>> from landlab.utils.structured_grid import north_links
    >>> north_links((3, 4))
    array([[ 3,  4,  5,  6],
           [10, 11, 12, 13],
           [-1, -1, -1, -1]])
    """
    link_ids = vertical_link_ids(shape)
    link_ids.shape = (shape[0] - 1, shape[1])
    return np.vstack((link_ids, -np.ones((1, shape[1]), dtype=int)))


def south_links(shape):
    """Array of links pointing to the the south.

    Examples
    --------
    >>> from landlab.utils.structured_grid import south_links
    >>> south_links((3, 4))
    array([[-1, -1, -1, -1],
           [ 3,  4,  5,  6],
           [10, 11, 12, 13]])
    """
    link_ids = vertical_link_ids(shape)
    link_ids.shape = (shape[0] - 1, shape[1])
    return np.vstack((-np.ones((1, shape[1]), dtype=int), link_ids))


def east_links(shape):
    """Array of links pointing to the the east.

    Examples
    --------
    >>> from landlab.utils.structured_grid import east_links
    >>> east_links((3, 4))
    array([[ 0,  1,  2, -1],
           [ 7,  8,  9, -1],
           [14, 15, 16, -1]])
    """
    link_ids = horizontal_link_ids(shape)
    link_ids.shape = (shape[0], shape[1] - 1)
    return np.hstack((link_ids, -np.ones((shape[0], 1), dtype=int)))


def active_north_links(shape, node_status=None):
    """Array of active links pointing to the the north."""
    active_north_links_ = np.empty(shape, dtype=int)
    with contextlib.suppress(ValueError):
        links = vertical_active_link_ids(shape, node_status=node_status)
    links.shape = (shape[0] - 1, shape[1] - 2)
    active_north_links_[:-1, 1:-1] = links
    active_north_links_[:, (0, -1)] = -1
    active_north_links_[-1, :] = -1

    return active_north_links_


def active_north_links2(shape, node_status=None):
    """Array of active links pointing to the the north.

    >>> from landlab.utils.structured_grid import active_north_links2
    >>> active_north_links2((3, 4))
    array([[-1,  4,  5, -1],
           [-1, 11, 12, -1],
           [-1, -1, -1, -1]])
    """
    active_north_links_ = np.empty(shape, dtype=int)
    with contextlib.suppress(ValueError):
        links = vertical_active_link_ids2(shape, node_status=node_status)
    links.shape = (shape[0] - 1, shape[1] - 2)
    active_north_links_[:-1, 1:-1] = links
    active_north_links_[:, (0, -1)] = -1
    active_north_links_[-1, :] = -1

    return active_north_links_


def active_south_links(shape, node_status=None):
    """Array of active links pointing to the the south."""
    active_south_links_ = np.empty(shape, dtype=int)
    links = vertical_active_link_ids(shape, node_status=node_status)
    links.shape = (shape[0] - 1, shape[1] - 2)
    active_south_links_[1:, 1:-1] = links
    active_south_links_[:, (0, -1)] = -1
    active_south_links_[0, :] = -1

    return active_south_links_


def active_south_links2(shape, node_status=None):
    """Array of active links pointing to the the south.

    Finds and returns link IDs of active links that enter each node from the
    south (bottom), or -1 where no such active link exists.

    Parameters
    ----------
    shape : 2-element tuple of int
        number of rows and columns in grid
    node_status (optional) : 1d numpy array of bool
        False where node is a closed boundary, True otherwise

    Returns
    -------
    2d numpy array of int
        Link ID of active link connecting to a node from the south, or -1

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_south_links2
    >>> active_south_links2((3, 4))
    array([[-1, -1, -1, -1],
           [-1,  4,  5, -1],
           [-1, 11, 12, -1]])

    Notes
    -----
    Like active_south_links, but returns link IDs.
    """
    active_south_links_ = -np.ones(shape, dtype=int)
    links = vertical_active_link_ids2(shape, node_status=node_status)
    active_south_links_[1:, 1:-1] = links

    return active_south_links_


def active_west_links(shape, node_status=None):
    """Array of active links pointing to the the west.

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_west_links
    >>> active_west_links((3, 4))
    array([[-1, -1, -1, -1],
           [-1,  4,  5,  6],
           [-1, -1, -1, -1]])
    """
    active_west_links_ = np.empty(shape, dtype=int)
    with contextlib.suppress(ValueError):
        active_west_links_[1:-1, 1:] = horizontal_active_link_ids(
            shape, node_status=node_status
        )
    active_west_links_[(0, -1), :] = -1
    active_west_links_[:, 0] = -1

    return active_west_links_


def active_west_links2(shape, node_status=None):
    """Array of active links pointing to the the west.

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_west_links2
    >>> active_west_links2((3, 4))
    array([[-1, -1, -1, -1],
           [-1,  7,  8,  9],
           [-1, -1, -1, -1]])
    """
    active_west_links_ = -np.ones(shape, dtype=int)
    active_west_links_[1:-1, 1:] = horizontal_active_link_ids2(
        shape, node_status=node_status
    )

    return active_west_links_


def active_east_links(shape, node_status=None):
    """Array of active links pointing to the the east.

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_east_links
    >>> active_east_links((3, 4))
    array([[-1, -1, -1, -1],
           [ 4,  5,  6, -1],
           [-1, -1, -1, -1]])
    """
    active_east_links_ = np.empty(shape, dtype=int)
    active_east_links_.fill(-999)
    with contextlib.suppress(ValueError):
        active_east_links_[1:-1, :-1] = horizontal_active_link_ids(
            shape, node_status=node_status
        )
    active_east_links_[(0, -1), :] = -1
    active_east_links_[:, -1] = -1

    return active_east_links_


def active_east_links2(shape, node_status=None):
    """Array of active links pointing to the the east.

    Examples
    --------
    >>> from landlab.utils.structured_grid import active_east_links2
    >>> active_east_links2((3, 4))
    array([[-1, -1, -1, -1],
           [ 7,  8,  9, -1],
           [-1, -1, -1, -1]])
    """
    active_east_links_ = -np.ones(shape, dtype=int)
    active_east_links_[1:-1, :-1] = horizontal_active_link_ids2(
        shape, node_status=node_status
    )

    return active_east_links_


def outlink_count_per_node(shape):
    """Number of links leaving each node."""
    link_count_ = np.empty(shape, dtype=int)
    link_count_[:-1, :-1] = 2
    link_count_[-1, :-1] = 1
    link_count_[:-1, -1] = 1
    link_count_[-1, -1] = 0
    return np.ravel(link_count_)


def inlink_count_per_node(shape):
    """Number of links entering each node."""
    link_count_ = np.empty(shape, dtype=int)
    link_count_[1:, 1:] = 2
    link_count_[0, 1:] = 1
    link_count_[1:, 0] = 1
    link_count_[0, 0] = 0
    return np.ravel(link_count_)


def active_outlink_count_per_node(shape):
    """Number of active links leaving each node."""
    link_count_ = np.empty(shape, dtype=int)
    link_count_[1:-1, 1:-1] = 2
    link_count_[0, :] = 1
    link_count_[-1, :] = 0
    link_count_[:, 0] = 1
    link_count_[:, -1] = 0

    link_count_[0, 0] = 0
    link_count_[-1, 0] = 0

    return np.ravel(link_count_)


def active_inlink_count_per_node(shape):
    """Number of active links entering each node."""
    link_count_ = np.empty(shape, dtype=int)
    link_count_[1:-1, 1:-1] = 2
    link_count_[0, :] = 0
    link_count_[-1, :] = 1
    link_count_[:, 0] = 0
    link_count_[:, -1] = 1

    link_count_[0, -1] = 0
    link_count_[-1, -1] = 0

    return np.ravel(link_count_)


def setup_outlink_matrix(shape, return_count=True):
    """Create a matrix of links leaving each node."""
    links = outlinks(shape)
    if return_count:
        return (links, outlink_count_per_node(shape))
    else:
        return links


def setup_inlink_matrix(shape, return_count=True):
    """Create a matrix of links entering each node."""
    links = inlinks(shape)
    if return_count:
        return (links, inlink_count_per_node(shape))
    else:
        return links


def setup_active_outlink_matrix(shape, node_status=None, return_count=True):
    """Create a matrix of active links leaving each node."""
    links = active_outlinks(shape, node_status=node_status)
    if return_count:
        return links, active_outlink_count_per_node(shape)
    else:
        return links


def setup_active_outlink_matrix2(shape, node_status=None, return_count=True):
    """Create a matrix of active links leaving each node.

    Return the link IDs of the active links that leave each node of a grid. The
    shape of the returned array is (2, *N*) where *N* is the number of nodes in
    the grid. The first row contains the link ID exiting the node to the
    top, and the second row the link exiting the node to the right.

    Use the *return_count* keyword to, in addition to the link IDs, return the
    number of active links attached to each grid node.

    Use the *node_status_array* keyword to specify the status for each of the
    grid's nodes. If not given, each of the perimeter nodes is assumed to be
    `NodeStatus.FIXED_VALUE`.

    Parameters
    ----------
    shape : tuple
        Shape of the structured grid
    node_status : array_like, optional
        Status of each node in the grid.
    return_count : boolean, optional
        If `True`, also return an array of active link counts per node.

    Returns
    -------
    links : (2, N) ndarray
        Active link IDs for each node.
    count : ndarray
        Number of active links per node.

    Examples
    --------
    Get the active link IDs for a grid of 3 nodes by 4 nodes. The first row
    lists links entering nodes from the bottom, and the second links entering
    from the left.

    >>> from landlab.utils.structured_grid import setup_active_outlink_matrix2
    >>> setup_active_outlink_matrix2((3, 4), return_count=False)
    array([[-1,  4,  5, -1, -1, 11, 12, -1, -1, -1, -1, -1],
           [-1, -1, -1, -1,  7,  8,  9, -1, -1, -1, -1, -1]])
    >>> _, count = setup_active_outlink_matrix2((3, 4))
    >>> count
    array([0, 1, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0])
    """
    links = active_outlinks2(shape, node_status=node_status)
    if return_count:
        return links, active_outlink_count_per_node(shape)
    else:
        return links


def setup_active_inlink_matrix(shape, node_status=None, return_count=True):
    """Create a matrix of active links entering each node.

    Return the IDs of the active links that enter each node of a grid. The
    shape of the returned array is (2, *N*) where *N* is the number of nodes
    in the grid. The first row contains the link ID entering the node from the
    bottom, and the second row the link entering the node from the left.

    Use the *return_count* keyword to, in addition to the link IDs, return
    the number of active links attached to each grid node.

    Use the *node_status_array* keyword to specify the status for each of
    the grid's nodes. If not given, each of the perimeter nodes is assumed
    to be `NodeStatus.FIXED_VALUE`.

    Parameters
    ----------
    shape : tuple
        Shape of the structured grid
    node_status : array_like, optional
        Status of each node in the grid.
    return_count : boolean, optional
        If `True`, also return an array of active link counts per node.

    Returns
    -------
    links : (2, N) ndarray
        Active link IDs for each node.
    count : ndarray
        Number of active links per node.

    Examples
    --------
    Get the active link IDs for a grid of 3 nodes by 4 nodes. The first row
    list links entering nodes from the bottom, and the second links entering
    from the left.

    >>> from landlab.utils.structured_grid import setup_active_inlink_matrix
    >>> setup_active_inlink_matrix((3, 4), return_count=False)
    array([[-1, -1, -1, -1, -1,  0,  1, -1, -1,  2,  3, -1],
           [-1, -1, -1, -1, -1,  4,  5,  6, -1, -1, -1, -1]])
    >>> _, count = setup_active_inlink_matrix((3, 4))
    >>> count
    array([0, 0, 0, 0, 0, 2, 2, 1, 0, 1, 1, 0])
    """
    links = active_inlinks(shape, node_status=node_status)
    if return_count:
        return links, active_inlink_count_per_node(shape)
    else:
        return links


def setup_active_inlink_matrix2(shape, node_status=None, return_count=True):
    """Create a matrix of active links entering each node.

    Return the link IDs of the active links that enter each node of a grid. The
    shape of the returned array is (2, *N*) where *N* is the number of nodes in
    the grid. The first row contains the link ID entering the node from the
    bottom, and the second row the link entering the node from the left.

    Use the *return_count* keyword to, in addition to the link IDs, return the
    number of active links attached to each grid node.

    Use the *node_status_array* keyword to specify the status for each of the
    grid's nodes. If not given, each of the perimeter nodes is assumed to be
    `NodeStatus.FIXED_VALUE`.

    Parameters
    ----------
    shape : tuple
        Shape of the structured grid
    node_status : array_like, optional
        Status of each node in the grid.
    return_count : boolean, optional
        If `True`, also return an array of active link counts per node.

    Returns
    -------
    links : (2, N) ndarray
        Active link IDs for each node.
    count : ndarray
        Number of active links per node.

    Examples
    --------
    Get the active link IDs for a grid of 3 nodes by 4 nodes. The first row
    lists links entering nodes from the bottom, and the second links entering
    from the left.

    >>> from landlab.utils.structured_grid import setup_active_inlink_matrix2
    >>> setup_active_inlink_matrix2((3, 4), return_count=False)
    array([[-1, -1, -1, -1, -1,  4,  5, -1, -1, 11, 12, -1],
           [-1, -1, -1, -1, -1,  7,  8,  9, -1, -1, -1, -1]])
    >>> _, count = setup_active_inlink_matrix2((3, 4))
    >>> count
    array([0, 0, 0, 0, 0, 2, 2, 1, 0, 1, 1, 0])
    """
    links = active_inlinks2(shape, node_status=node_status)
    if return_count:
        return links, active_inlink_count_per_node(shape)
    else:
        return links


def node_index_with_halo(shape, halo_indices=BAD_INDEX_VALUE):
    """Array of links with a halo of no-data values.

    Examples
    --------
    >>> from landlab.utils.structured_grid import node_index_with_halo
    >>> node_index_with_halo((2, 3), halo_indices=-1)
    array([[-1, -1, -1, -1, -1],
           [-1,  0,  1,  2, -1],
           [-1,  3,  4,  5, -1],
           [-1, -1, -1, -1, -1]])
    """
    shape_with_halo = np.array(shape) + 2

    ids = np.empty(shape_with_halo, dtype=int)

    (interiors, boundaries) = (
        interior_nodes(shape_with_halo),
        perimeter_nodes(shape_with_halo),
    )

    ids.flat[interiors] = range(interior_node_count(shape_with_halo))
    ids.flat[boundaries] = halo_indices

    return ids


def cell_index_with_halo(shape, halo_indices=BAD_INDEX_VALUE, inactive_indices=None):
    """Array of cells with a halo of no-data values.

    Examples
    --------
    >>> from landlab.utils.structured_grid import cell_index_with_halo
    >>> cell_index_with_halo((2, 3), halo_indices=-1)
    array([[-1, -1, -1, -1, -1],
           [-1,  0,  1,  2, -1],
           [-1,  3,  4,  5, -1],
           [-1, -1, -1, -1, -1]])

    >>> cell_index_with_halo((2, 3), halo_indices=-1, inactive_indices=-1)
    array([[-1, -1, -1, -1, -1],
           [-1, -1, -1, -1, -1],
           [-1, -1, -1, -1, -1],
           [-1, -1, -1, -1, -1]])
    """
    ids = node_index_with_halo(shape, halo_indices=halo_indices)
    if inactive_indices is not None:
        ids[:, (1, -2)] = inactive_indices
        ids[(1, -2), :] = inactive_indices

    return ids


def _neighbor_node_ids(ids_with_halo):
    """Matrix of four neighbor nodes for each node."""
    shape = (ids_with_halo.shape[0] - 2, ids_with_halo.shape[1] - 2)
    kwds = {
        "strides": ids_with_halo.strides,
        "buffer": ids_with_halo,
        "dtype": ids_with_halo.dtype,
        "offset": ids_with_halo.itemsize * (ids_with_halo.shape[1]),
    }

    # kwds["offset"] = ids_with_halo.itemsize * (ids_with_halo.shape[1])
    west_ids = np.ndarray(shape, **kwds)

    kwds["offset"] = ids_with_halo.itemsize * (ids_with_halo.shape[1] + 2)
    east_ids = np.ndarray(shape, **kwds)

    kwds["offset"] = ids_with_halo.itemsize
    south_ids = np.ndarray(shape, **kwds)

    kwds["offset"] = ids_with_halo.itemsize * (ids_with_halo.shape[1] * 2 + 1)
    north_ids = np.ndarray(shape, **kwds)

    return np.vstack((east_ids.flat, north_ids.flat, west_ids.flat, south_ids.flat))


def _centered_node_ids(ids_with_halo):
    """Array of nodes taken from a matrix of nodes with a halo."""
    shape = (ids_with_halo.shape[0] - 2, ids_with_halo.shape[1] - 2)
    kwds = {
        "strides": ids_with_halo.strides,
        "buffer": ids_with_halo,
        "dtype": ids_with_halo.dtype,
        "offset": ids_with_halo.itemsize * (ids_with_halo.shape[1] + 1),
    }

    return np.ndarray(shape, **kwds)


def neighbor_node_ids(shape, inactive=BAD_INDEX_VALUE):
    """Matrix of four neighbor nodes for each node."""
    return linked_neighbor_node_ids(shape, [], inactive=inactive)


def linked_neighbor_node_ids(
    shape, closed_boundary_nodes, open_boundary_nodes=None, inactive=BAD_INDEX_VALUE
):
    """Matrix of four neighbor nodes for each node."""
    if open_boundary_nodes is None:
        open_boundary_nodes = []

    ids_with_halo = node_index_with_halo(shape, halo_indices=inactive)

    # Everything that touches a closed boundary is inactive
    if len(closed_boundary_nodes) > 0:
        ids = _centered_node_ids(ids_with_halo)
        ids.flat[closed_boundary_nodes] = inactive

    neighbors = _neighbor_node_ids(ids_with_halo)

    # Everything that a closed boundary touches is inactive
    if len(closed_boundary_nodes) > 0:
        neighbors[:, closed_boundary_nodes] = inactive

    if len(open_boundary_nodes) > 0:
        _set_open_boundary_neighbors(neighbors, open_boundary_nodes, inactive)

    return neighbors


def _set_open_boundary_neighbors(neighbors, open_boundary_nodes, value):
    """Set values for open-boundary neighbor-nodes."""
    open_boundary_neighbors = neighbors[:, open_boundary_nodes]
    is_open_boundary_neighbor = _find_open_boundary_neighbors(
        neighbors, open_boundary_nodes
    )
    nodes = np.choose(is_open_boundary_neighbor, (open_boundary_neighbors, value))
    neighbors[:, open_boundary_nodes] = nodes


def _find_open_boundary_neighbors(neighbors, open_boundary_nodes):
    """Array of booleans that indicate if a neighbor is an open boundary."""
    open_boundary_neighbors = neighbors[:, open_boundary_nodes]
    is_open_boundary_neighbor = np.isin(open_boundary_neighbors, open_boundary_nodes)
    is_open_boundary_neighbor.shape = (neighbors.shape[0], len(open_boundary_nodes))
    return is_open_boundary_neighbor


def neighbor_node_array(shape, **kwds):
    """Array of neighbor nodes.

    Examples
    --------
    >>> from landlab.utils.structured_grid import neighbor_node_array
    >>> neighbors = neighbor_node_array((2, 3), inactive=-1)
    >>> neighbors.T
    array([[ 1,  3, -1, -1],
           [ 2,  4,  0, -1],
           [-1,  5,  1, -1],
           [ 4, -1, -1,  0],
           [ 5, -1,  3,  1],
           [-1, -1,  4,  2]])
    """
    closed_boundary_nodes = kwds.pop("closed_boundary_nodes", [])
    open_boundary_nodes = kwds.get("open_boundary_nodes", [])

    if len(closed_boundary_nodes) > 0 or len(open_boundary_nodes):
        neighbors = linked_neighbor_node_ids(shape, closed_boundary_nodes, **kwds)
    else:
        neighbors = neighbor_node_ids(shape, **kwds)

    return neighbors


def neighbor_cell_array(shape, out_of_bounds=BAD_INDEX_VALUE, contiguous=True):
    """Array of neighbor cells.

    Examples
    --------
    >>> from landlab.utils.structured_grid import neighbor_cell_array
    >>> neighbors = neighbor_cell_array((2, 3), out_of_bounds=-1)
    >>> len(neighbors) == 0
    True

    >>> neighbors = neighbor_cell_array((3, 3), out_of_bounds=-1)
    >>> neighbors
    array([[-1, -1, -1, -1]])

    >>> neighbors = neighbor_cell_array((5, 4), out_of_bounds=-1)
    >>> neighbors
    array([[ 1,  2, -1, -1], [-1,  3,  0, -1],
           [ 3,  4, -1,  0], [-1,  5,  2,  1],
           [ 5, -1, -1,  2], [-1, -1,  4,  3]])
    """
    if cell_count(shape) > 0:
        shape = np.array(shape) - 2
        ids = node_index_with_halo(shape, halo_indices=out_of_bounds)

        neighbors = np.vstack(
            (
                ids[1 : shape[0] + 1, 2:].flat,
                ids[2:, 1 : shape[1] + 1].flat,
                ids[1 : shape[0] + 1, : shape[1]].flat,
                ids[: shape[0], 1 : shape[1] + 1].flat,
            )
        ).T
        if contiguous:
            return neighbors.copy()
        else:
            return neighbors
    else:
        return np.array([], dtype=int)


def diagonal_node_array(
    shape, out_of_bounds=BAD_INDEX_VALUE, contiguous=True, boundary_node_mask=None
):
    """Array of diagonal nodes.

    Creates a list of IDs of the diagonal cells to each cell, as a 2D array.
    Only interior cells are assigned neighbors; boundary cells get -1 for
    each neighbor.  The order of the diagonal cells is [topright, topleft,
    bottomleft, bottomright].

    Examples
    --------
    >>> from landlab.utils.structured_grid import diagonal_node_array
    >>> diags = diagonal_node_array((2, 3), out_of_bounds=-1)
    >>> diags
    array([[ 4, -1, -1, -1],
           [ 5,  3, -1, -1],
           [-1,  4, -1, -1],
           [-1, -1, -1,  1],
           [-1, -1,  0,  2],
           [-1, -1,  1, -1]])
    >>> diags.flags["C_CONTIGUOUS"]
    True
    >>> diags = diagonal_node_array((2, 3), out_of_bounds=-1, contiguous=False)
    >>> diags.flags["C_CONTIGUOUS"]
    False
    """
    # NG didn't touch this, but she thinks this should be nodes, not cells.
    ids = node_index_with_halo(shape, halo_indices=out_of_bounds)

    diags = np.vstack(
        (
            ids[2:, 2:].flat,
            ids[2:, : shape[1]].flat,
            ids[: shape[0], : shape[1]].flat,
            ids[: shape[0], 2:].flat,
        )
    ).T

    if boundary_node_mask is not None:
        boundaries = np.empty(4, dtype=int)
        boundaries.fill(boundary_node_mask)
        diags[perimeter_nodes(shape)] = boundaries

    if contiguous:
        return diags.copy()
    else:
        return diags


def diagonal_cell_array(shape, out_of_bounds=BAD_INDEX_VALUE, contiguous=True):
    """Array of diagonal cells.

    Construct a matrix of cell indices to each diagonally adjacent cell of a
    structured grid. If a cell does not have a diagonal neighbor, set the
    index for that neighbor to *out_of_bounds*.

    Examples
    --------
    A grid without any cells returns an empty array.

    >>> from landlab.utils.structured_grid import diagonal_cell_array
    >>> diags = diagonal_cell_array((2, 3), out_of_bounds=-1)
    >>> len(diags) == 0
    True

    A grid that has only one cell does not have any neighbors so all of its
    diagonals are set to *out_of_bounds*.
    >>> diags = diagonal_cell_array((3, 3), out_of_bounds=-1)
    >>> diags
    array([[-1, -1, -1, -1]])

    >>> diags = diagonal_cell_array((4, 4), out_of_bounds=-1)
    >>> diags
    array([[ 3, -1, -1, -1], [-1,  2, -1, -1],
           [-1, -1, -1,  1], [-1, -1,  0, -1]])

    >>> diags = diagonal_cell_array((4, 5), out_of_bounds=-1)
    >>> diags
    array([[ 4, -1, -1, -1], [ 5,  3, -1, -1], [-1,  4, -1, -1],
           [-1, -1, -1,  1], [-1, -1,  0,  2], [-1, -1,  1, -1]])
    """
    if cell_count(shape) > 0:
        shape = np.array(shape) - 2
        ids = node_index_with_halo(shape, halo_indices=out_of_bounds)

        diags = np.vstack(
            (
                ids[2:, 2:].flat,
                ids[2:, : shape[1]].flat,
                ids[: shape[0], : shape[1]].flat,
                ids[: shape[0], 2:].flat,
            )
        ).T
        if contiguous:
            return diags.copy()
        else:
            return diags
    else:
        return np.array([], dtype=int)


def node_has_boundary_neighbor(neighbors, diagonals, out_of_bounds=BAD_INDEX_VALUE):
    """Array of booleans that indicate if a node has a boundary neighbor.

    .. note::

        DEJH thinks this method is broken since terminology update: it returns
        closed neighbors, not boundary neighbors.
    """
    return out_of_bounds in neighbors | out_of_bounds in diagonals


def reshape_array(shape, array, flip_vertically=False, copy=False):
    """Reshape a flat array.

    Examples
    --------
    >>> from landlab.utils.structured_grid import reshape_array
    >>> x = np.arange(12.0)
    >>> y = reshape_array((3, 4), x)
    >>> y.shape == (3, 4)
    True
    >>> y
    array([[  0.,   1.,   2.,   3.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.]])
    >>> y.flags["C_CONTIGUOUS"]
    True
    >>> x[0] = -1
    >>> y[0, 0]
    -1.0

    >>> x = np.arange(12.0)
    >>> y = reshape_array((3, 4), x, flip_vertically=True)
    >>> y
    array([[  8.,   9.,  10.,  11.],
           [  4.,   5.,   6.,   7.],
           [  0.,   1.,   2.,   3.]])
    >>> y.flags["C_CONTIGUOUS"]
    False
    >>> x[0] = -1
    >>> y[-1, 0]
    -1.0
    """
    reshaped_array = array.view()

    try:
        reshaped_array.shape = shape
    except ValueError:
        raise

    if flip_vertically:
        flipped_array = reshaped_array[::-1, :]
        if copy:
            return flipped_array.copy()
        else:
            return flipped_array
    else:
        if copy:
            return reshaped_array.copy()
        else:
            return reshaped_array


def nodes_around_points_on_unit_grid(shape, coords, mode="raise"):
    """Array of nodes around x, y points on a grid of unit spacing.

    Returns the nodes around a point on a structured grid with unit spacing
    and zero origin.

    Examples
    --------
    >>> from landlab.utils.structured_grid import nodes_around_points_on_unit_grid
    >>> nodes_around_points_on_unit_grid((3, 3), (0.1, 0.1))
    array([0, 3, 4, 1])

    >>> nodes_around_points_on_unit_grid((3, 3), (1.0, 1.0))
    array([4, 7, 8, 5])
    """
    if isinstance(coords[0], np.ndarray):
        (rows, cols) = (as_id_array(coords[0]), as_id_array(coords[1]))
    else:
        (rows, cols) = (int(coords[0]), int(coords[1]))

    return as_id_array(
        np.ravel_multi_index(
            ((rows, rows + 1, rows + 1, rows), (cols, cols, cols + 1, cols + 1)),
            shape,
            mode=mode,
        ).T
    )


def nodes_around_points(shape, coords, spacing=(1.0, 1.0), origin=(0.0, 0.0)):
    """Array of nodes around x, y points on a grid of non-unit spacing.

    Returns the nodes around a point on a structured grid with row and column
    *spacing*, and *origin*.

    Examples
    --------
    >>> from landlab.utils.structured_grid import nodes_around_points
    >>> x = np.array([0.9, 1.0])
    >>> y = np.array([0.1, 1.0])
    >>> nodes_around_points((3, 3), (y, x))
    array([[0, 3, 4, 1],
           [4, 7, 8, 5]])

    >>> nodes_around_points((3, 3), (2.0, 1.0))
    Traceback (most recent call last):
        ...
    ValueError: invalid entry in coordinates array
    """
    return as_id_array(
        nodes_around_points_on_unit_grid(
            shape,
            (
                (coords[0] - origin[0]) / spacing[0],
                (coords[1] - origin[1]) / spacing[1],
            ),
        )
    )


def nodes_around_point(shape, coords, spacing=(1.0, 1.0)):
    """Array of nodes around a single point on a grid of non-unit spacing."""
    node_id = int(coords[0] // spacing[0] * shape[1] + coords[1] // spacing[1])
    if node_id + shape[1] + 1 >= shape[0] * shape[1] or node_id < 0:
        raise ValueError("invalid entry in coordinates array")

    return np.array([node_id, node_id + shape[1], node_id + shape[1] + 1, node_id + 1])



================================================
File: src/landlab/utils/suppress_output.py
================================================
import contextlib
import os


@contextlib.contextmanager
def suppress_output(out=True, err=True):
    """Suppress output from both stdout and stderr.

    Parameters
    ----------
    out : bool, optional
        Suppress stdout.
    err : bool, optional
        Suppress stderr.
    """
    null_fds, save_fds = {}, {}
    if out:
        null_fds["out"] = os.open(os.devnull, os.O_RDWR)
        save_fds["out"] = os.dup(1)
        os.dup2(null_fds["out"], 1)
    if err:
        null_fds["err"] = os.open(os.devnull, os.O_RDWR)
        save_fds["err"] = os.dup(2)
        os.dup2(null_fds["err"], 2)

    yield

    # Re-assign the real stdout/stderr back to (1) and (2)
    out and os.dup2(save_fds["out"], 1)
    err and os.dup2(save_fds["err"], 2)

    # Close the null files
    for fd in list(null_fds.values()) + list(save_fds.values()):
        os.close(fd)



================================================
File: src/landlab/utils/watershed.py
================================================
#! /usr/bin/env python
"""Functions to work with watersheds of model grids."""

import numpy as np

from landlab import FieldError


def get_watershed_mask(grid, outlet_id):
    """Get the watershed of an outlet returned as a boolean array.

    Parameters
    ----------
    grid : RasterModelGrid
        A landlab RasterModelGrid.
    outlet_id : integer
        The id of the outlet node.

    Returns
    -------
    watershed_mask : boolean ndarray
        True elements of this array correspond to nodes with flow that is
        received by the outlet. The length of the array is equal to the grid
        number of nodes.

    Examples
    --------

    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils import get_watershed_mask

    >>> rmg = RasterModelGrid((7, 7))
    >>> rmg.at_node["topographic__elevation"] = [
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ...     [-9999.0, 26.0, 0.0, 30.0, 32.0, 34.0, -9999.0],
    ...     [-9999.0, 28.0, 1.0, 25.0, 28.0, 32.0, -9999.0],
    ...     [-9999.0, 30.0, 3.0, 3.0, 11.0, 34.0, -9999.0],
    ...     [-9999.0, 32.0, 11.0, 25.0, 18.0, 38.0, -9999.0],
    ...     [-9999.0, 34.0, 32.0, 34.0, 36.0, 40.0, -9999.0],
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ... ]

    Only the bottom boundary is set to open.
    >>> rmg.set_closed_boundaries_at_grid_edges(True, True, True, False)
    >>> rmg.set_fixed_value_boundaries_at_grid_edges(False, False, False, True)

    Route flow.
    >>> fr = FlowAccumulator(rmg, flow_director="D8")
    >>> fr.run_one_step()

    >>> get_watershed_mask(rmg, 2).reshape(rmg.shape)
    array([[False, False,  True, False, False, False, False],
           [False, False,  True, False, False, False, False],
           [False,  True,  True,  True, True,  True,  False],
           [False,  True,  True,  True,  True,  True, False],
           [False,  True,  True,  True,  True,  True, False],
           [False,  True,  True,  True,  True,  True, False],
           [False, False, False, False, False, False, False]])
    """
    if "flow__receiver_node" not in grid.at_node:
        raise FieldError(
            "A 'flow__receiver_node' field is required at the "
            "nodes of the input grid."
        )

    if grid.at_node["flow__receiver_node"].size != grid.size("node"):
        raise NotImplementedError(
            "A route-to-multiple flow director has been "
            "run on this grid. The landlab development team has not "
            "verified that get_watershed_mask is compatible with "
            "route-to-multiple methods. Please open a GitHub Issue "
            "to start this process."
        )

    receiver_at_node = grid.at_node["flow__receiver_node"]
    upstream_node_order = grid.at_node["flow__upstream_node_order"]

    # Prepare output.
    watershed_mask = np.zeros(grid.number_of_nodes, dtype=bool)

    # loop through all nodes once based on upstream node order. This means we
    # only need to loop through the nodes once.
    for node in upstream_node_order:
        # when the outlet_id is encountered, mark it as true, and set
        # outlet_found to True.

        if node == outlet_id:
            watershed_mask[node] = True

        # once the outlet is found, set the watershed mask to the value of
        # the reciever at node, this will paint the watershed in as we move
        # upstream.
        if watershed_mask[receiver_at_node[node]]:
            watershed_mask[node] = True

    return watershed_mask


def get_watershed_nodes(grid, outlet_id):
    """Get the watershed of an outlet returned as a list of nodes.

    Parameters
    ----------
    grid : RasterModelGrid
        A landlab RasterModelGrid.
    outlet_id : integer
        The id of the outlet node.

    Returns
    -------
    watershed_nodes : integer ndarray
        The ids of the nodes that flow to the node with the id, outlet_id.

    Examples
    --------

    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils import get_watershed_nodes

    >>> rmg = RasterModelGrid((7, 7))

    >>> rmg.at_node["topographic__elevation"] = [
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ...     [-9999.0, 26.0, 0.0, 30.0, 32.0, 34.0, -9999.0],
    ...     [-9999.0, 28.0, 1.0, 25.0, 28.0, 32.0, -9999.0],
    ...     [-9999.0, 30.0, 3.0, 3.0, 11.0, 34.0, -9999.0],
    ...     [-9999.0, 32.0, 11.0, 25.0, 18.0, 38.0, -9999.0],
    ...     [-9999.0, 34.0, 32.0, 34.0, 36.0, 40.0, -9999.0],
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ... ]
    >>> rmg.set_watershed_boundary_condition_outlet_id(
    ...     2, rmg.at_node["topographic__elevation"], nodata_value=-9999.0
    ... )

    Route flow.
    >>> fr = FlowAccumulator(rmg, flow_director="D8")
    >>> fr.run_one_step()

    Get the nodes of two watersheds.
    >>> mainstem_watershed_nodes = get_watershed_nodes(rmg, 2)
    >>> tributary_watershed_nodes = get_watershed_nodes(rmg, 24)

    Given the watershed boundary conditions, the number of mainstem watershed
    nodes should be equal to the number of core nodes plus the outlet node.
    >>> len(mainstem_watershed_nodes) == rmg.number_of_core_nodes + 1
    True
    """
    ws_mask = get_watershed_mask(grid, outlet_id)
    ws_nodes = np.where(ws_mask)[0]

    return ws_nodes


def get_watershed_masks(grid):
    """Assign the watershed outlet id to all nodes in the grid.

    Parameters
    ----------
    grid : RasterModelGrid
        A landlab RasterModelGrid.

    Returns
    -------
    watershed_masks : integer ndarray
        The length of the array is equal to the grid number of nodes. Values of
        this array are the watershed ids. The value of a watershed id is the
        node id of the watershed outlet.

    Examples
    --------

    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils import get_watershed_masks

    Create a grid with a node spacing of 200 meter.
    >>> rmg = RasterModelGrid((7, 7), xy_spacing=200)
    >>> rmg.at_node["topographic__elevation"] = [
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ...     [-9999.0, 26.0, 0.0, 26.0, 30.0, 34.0, -9999.0],
    ...     [-9999.0, 28.0, 1.0, 28.0, 5.0, 32.0, -9999.0],
    ...     [-9999.0, 30.0, 3.0, 30.0, 10.0, 34.0, -9999.0],
    ...     [-9999.0, 32.0, 11.0, 32.0, 15.0, 38.0, -9999.0],
    ...     [-9999.0, 34.0, 32.0, 34.0, 36.0, 40.0, -9999.0],
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ... ]
    >>> rmg.set_closed_boundaries_at_grid_edges(True, True, True, False)

    Route flow.

    >>> fr = FlowAccumulator(rmg, flow_director="D8")
    >>> fr.run_one_step()

    Assign mask.

    >>> mask = get_watershed_masks(rmg)
    >>> mask.reshape(rmg.shape)
    array([[ 0,  1,  2,  3,  4,  5,  6],
           [ 7,  1,  2,  3,  4,  5, 13],
           [14,  2,  2,  2, 18, 18, 20],
           [21,  2,  2,  2, 18, 18, 27],
           [28,  2,  2,  2, 18, 18, 34],
           [35,  2,  2,  2, 18, 18, 41],
           [42, 43, 44, 45, 46, 47, 48]])
    """
    upstream_node_order = grid.at_node["flow__upstream_node_order"]
    flow__receiver_node = grid.at_node["flow__receiver_node"]
    watershed_mask = np.arange(grid.size("node"), dtype=int)

    for node_id in upstream_node_order:
        watershed_mask[node_id] = watershed_mask[flow__receiver_node[node_id]]

    return watershed_mask


def get_watershed_masks_with_area_threshold(grid, critical_area):
    """Get masks of all of the watersheds with a minimum drainage area size.

    Parameters
    ----------
    grid : RasterModelGrid
        A landlab RasterModelGrid.
    critical_area : integer or float
        The minimum drainage area of the watersheds to identify.

    Returns
    -------
    watershed_masks : integer ndarray
        The length of the array is equal to the grid number of nodes. Values of
        this array are the watershed ids. The value of a watershed id is the
        node id of the watershed outlet. Nodes with a value of -1 have only
        downstream nodes with drainage areas below `critical_area`.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils import get_watershed_masks_with_area_threshold

    Create a grid with a node spacing of 200 meter.

    >>> rmg = RasterModelGrid((7, 7), xy_spacing=200)
    >>> rmg.at_node["topographic__elevation"] = [
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ...     [-9999.0, 26.0, 0.0, 26.0, 30.0, 34.0, -9999.0],
    ...     [-9999.0, 28.0, 1.0, 28.0, 5.0, 32.0, -9999.0],
    ...     [-9999.0, 30.0, 3.0, 30.0, 10.0, 34.0, -9999.0],
    ...     [-9999.0, 32.0, 11.0, 32.0, 15.0, 38.0, -9999.0],
    ...     [-9999.0, 34.0, 32.0, 34.0, 36.0, 40.0, -9999.0],
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ... ]
    >>> rmg.set_closed_boundaries_at_grid_edges(True, True, True, False)

    Route flow.

    >>> fr = FlowAccumulator(rmg, flow_director="D8")
    >>> fr.run_one_step()

    Get the masks of watersheds greater than or equal to 80,000 square-meters.

    >>> critical_area = 80000
    >>> mask = get_watershed_masks_with_area_threshold(rmg, critical_area)

    Verify that all mask null nodes have a drainage area below critical area.

    >>> null_nodes = np.where(mask == -1)[0]
    >>> A = rmg.at_node["drainage_area"][null_nodes]
    >>> below_critical_area_nodes = A < critical_area
    >>> np.all(below_critical_area_nodes)
    True
    """
    watershed_masks = get_watershed_masks(grid)
    area = grid.at_node["drainage_area"]

    area_of_watersheds = area[watershed_masks]
    too_small = area_of_watersheds < critical_area

    watershed_masks[too_small] = -1

    return watershed_masks


def get_watershed_outlet(grid, source_node_id):
    """Get the downstream-most node (the outlet) of the source node.

    Parameters
    ----------
    grid : RasterModelGrid
        A landlab RasterModelGrid.
    source_node_id : integer
        The id of the node in which to identify its outlet.

    Returns
    -------
    outlet_node : integer
        The id of the node that is the downstream-most node (the outlet) of the
        source node.

    Examples
    --------

    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.components import FlowAccumulator
    >>> from landlab.utils import get_watershed_outlet

    >>> rmg = RasterModelGrid((7, 7))

    >>> rmg.at_node["topographic__elevation"] = [
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ...     [-9999.0, 26.0, 0.0, 30.0, 32.0, 34.0, -9999.0],
    ...     [-9999.0, 28.0, 1.0, 25.0, 28.0, 32.0, -9999.0],
    ...     [-9999.0, 30.0, 3.0, 3.0, 11.0, 34.0, -9999.0],
    ...     [-9999.0, 32.0, 11.0, 25.0, 18.0, 38.0, -9999.0],
    ...     [-9999.0, 34.0, 32.0, 34.0, 36.0, 40.0, -9999.0],
    ...     [-9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0, -9999.0],
    ... ]
    >>> imposed_outlet = 2
    >>> rmg.set_watershed_boundary_condition_outlet_id(
    ...     imposed_outlet, rmg.at_node["topographic__elevation"], nodata_value=-9999.0
    ... )

    Route flow.
    >>> fr = FlowAccumulator(rmg, flow_director="D8")
    >>> fr.run_one_step()

    Get the grid watershed outlet.
    >>> determined_outlet = get_watershed_outlet(rmg, 40)
    >>> determined_outlet == imposed_outlet
    True
    """
    if "flow__receiver_node" not in grid.at_node:
        raise FieldError(
            "A 'flow__receiver_node' field is required at the "
            "nodes of the input grid."
        )

    if grid.at_node["flow__receiver_node"].size != grid.size("node"):
        raise NotImplementedError(
            "A route-to-multiple flow director has been "
            "run on this grid. The landlab development team has not "
            "verified that get_watershed_outlet is compatible with "
            "route-to-multiple methods. Please open a GitHub Issue "
            "to start this process."
        )

    receiver_at_node = grid.at_node["flow__receiver_node"]
    receiver_node = receiver_at_node[source_node_id]
    outlet_not_found = True

    while outlet_not_found:
        node_is_outlet = receiver_node == source_node_id
        node_is_boundary = grid.node_is_boundary(receiver_node)
        node_is_pit = receiver_node == receiver_at_node[receiver_node]

        if node_is_outlet or node_is_boundary or node_is_pit:
            outlet_not_found = False
            outlet_node = receiver_node
        else:
            receiver_node = receiver_at_node[receiver_node]

    return outlet_node



================================================
File: src/landlab/utils/window_statistic.py
================================================
"""Function to calculate node statistics in a moving window."""

import numpy as np

from landlab import FieldError


def calculate_window_statistic(
    grid, field, func, search_radius, calc_on_closed_nodes=True, **kwargs
):
    """Calculate a statistic using a function within a search window.

    .. note::

        This only works on grid **nodes** (not other grid elements e.g. links) for
        any :class:`~.ModelGrid` type.

    This utility outputs an array of length equal to the grid's number of
    nodes. Each element of the output array represents the node location in
    the grid. The value of each element is a function of the nodes within the
    search window surrounding that node location (see the model grid diagram
    below).

    The grid below contains six columns and five rows with cell spacing set
    to 10 distance units. This utility iteratively evaluates all nodes in the
    grid. The diagram shows evaluation of node ID 15 (marked ``x``). If the
    search radius is set to 20, twice the cell spacing, each node marked with
    a ``*`` is within the search window.
    ::

        · · * · · ·
        · * * * · ·
        * * x * * ·
        · * * * · ·
        · · * · · ·

    Increasing the search radius to 25 results in the following search window.
    ::

        · * * * · ·
        * * * * * ·
        * * x * * ·
        * * * * * ·
        · * * * · ·

    Decreasing the search radius to 15 results in the following search window.
    ::

        · · · · · ·
        · * * * · ·
        · * x * · ·
        · * * * · ·
        · · · · · ·

    The input field can be any field assigned to grid nodes (e.g.
    "topographic__elevation") and the input function can be any function that
    acts on the input field (e.g. "np.min" to find the minimum). The input
    function may be user defined and may contain any number of inputs, which
    are input as ``kwargs``.

    For example, if the input field is "topographic__elevation" and the input
    function is ``np.ptp`` (peak-to-peak, meaning max minus min value), then the
    output at node 15 will be the maximum elevation within the search window
    minus the minimum elevation within the search window (also known as relief).
    The ``np.percentile`` function, however, requires not only the input field,
    but also an input value to define the "q-th percentile" to be calculated.
    This second input would be added as a ``kwarg`` (e.g. ``q=90``) at the end of
    the inputs for :func:`~calculate_window_statistic`. Both of these scenarios are
    shown in the examples below.

    Parameters
    ----------
    grid : ModelGrid
        A Landlab ModelGrid.
    field : string
        An existing grid field on which to calculate the statistic of interest.
        Must exist in grid.
    func : function
        The function that calculates the window statistic of *field*.
        The first parameter of the function must be the values at nodes within
        the window, which are used used to calculate the statistic for the
        node under evaluation. Additional parameters of the function can be
        passed with ``kwargs``.
    search_radius : float
        Radius of window within which the statistic is calculated.
    calc_on_closed_nodes : boolean, optional
        Toggle calculation over all nodes including closed nodes (``True``) or all
        nodes except closed nodes (``False``).
    kwargs : optional
        Keyword arguments passed to *func* that are additional to the array of
        node values within the search window.

    Returns
    -------
    output : ndarray
        Output array containing the calculated values of the statistic. Same
        length as input field.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.utils import window_statistic

    >>> grid = RasterModelGrid((5, 6), xy_spacing=10.0)
    >>> grid.set_closed_boundaries_at_grid_edges(False, True, False, True)
    >>> z = grid.add_zeros("topographic__elevation", at="node")
    >>> z += np.arange(len(z))

    Calculate relief using ``np.ptp`` function.

    >>> relief = calculate_window_statistic(
    ...     grid, "topographic__elevation", np.ptp, search_radius=15
    ... )
    >>> grid.at_node["topographic__elevation"]
    array([ 0.,   1.,   2.,   3.,   4.,   5.,
            6.,   7.,   8.,   9.,  10.,  11.,
           12.,  13.,  14.,  15.,  16.,  17.,
           18.,  19.,  20.,  21.,  22.,  23.,
           24.,  25.,  26.,  27.,  28.,  29.])
    >>> relief
    array([ 7.,   8.,   8.,   8.,   8.,   7.,
           13.,  14.,  14.,  14.,  14.,  13.,
           13.,  14.,  14.,  14.,  14.,  13.,
           13.,  14.,  14.,  14.,  14.,  13.,
            7.,   8.,   8.,   8.,   8.,   7.])

    Calculate relief using ``np.ptp`` function excluding closed nodes.

    >>> relief = calculate_window_statistic(
    ...     grid,
    ...     "topographic__elevation",
    ...     np.ptp,
    ...     search_radius=15,
    ...     calc_on_closed_nodes=False,
    ... )
    >>> grid.at_node["topographic__elevation"]
    array([ 0.,   1.,   2.,   3.,   4.,   5.,
            6.,   7.,   8.,   9.,  10.,  11.,
           12.,  13.,  14.,  15.,  16.,  17.,
           18.,  19.,  20.,  21.,  22.,  23.,
           24.,  25.,  26.,  27.,  28.,  29.])
    >>> relief
    array([nan,  nan,  nan,  nan,  nan,  nan,
            7.,   8.,   8.,   8.,   8.,   7.,
           13.,  14.,  14.,  14.,  14.,  13.,
            7.,   8.,   8.,   8.,   8.,   7.,
           nan,  nan,  nan,  nan,  nan,  nan])

    Calculate 90th percentile using ``np.percentile`` function and ``kwargs``.

    >>> perc_90 = calculate_window_statistic(
    ...     grid,
    ...     "topographic__elevation",
    ...     np.percentile,
    ...     search_radius=15,
    ...     calc_on_closed_nodes=False,
    ...     q=90,
    ... )
    >>> grid.at_node["topographic__elevation"]
    array([ 0.,   1.,   2.,   3.,   4.,   5.,
            6.,   7.,   8.,   9.,  10.,  11.,
           12.,  13.,  14.,  15.,  16.,  17.,
           18.,  19.,  20.,  21.,  22.,  23.,
           24.,  25.,  26.,  27.,  28.,  29.])
    >>> perc_90
    array([ nan,  nan,  nan,  nan,  nan,  nan,
           12.7, 13.5, 14.5, 15.5, 16.5, 16.7,
           18.5, 19.2, 20.2, 21.2, 22.2, 22.5,
           18.7, 19.5, 20.5, 21.5, 22.5, 22.7,
            nan,  nan,  nan,  nan,  nan,  nan])

    Calculate relief above 90th percentile elevation using a user-defined
    function and ``kwargs``.

    >>> def max_minus_percentile(elev, q):
    ...     output = np.max(elev) - np.percentile(elev, q)
    ...     return output
    ...
    >>> rel_above_90th_perc = calculate_window_statistic(
    ...     grid,
    ...     "topographic__elevation",
    ...     max_minus_percentile,
    ...     search_radius=15,
    ...     calc_on_closed_nodes=False,
    ...     q=90,
    ... )
    >>> grid.at_node["topographic__elevation"]
    array([ 0.,   1.,   2.,   3.,   4.,   5.,
            6.,   7.,   8.,   9.,  10.,  11.,
           12.,  13.,  14.,  15.,  16.,  17.,
           18.,  19.,  20.,  21.,  22.,  23.,
           24.,  25.,  26.,  27.,  28.,  29.])
    >>> rel_above_90th_perc
    array([nan,  nan,  nan,  nan,  nan,  nan,
           0.3,  0.5,  0.5,  0.5,  0.5,  0.3,
           0.5,  0.8,  0.8,  0.8,  0.8,  0.5,
           0.3,  0.5,  0.5,  0.5,  0.5,  0.3,
           nan,  nan,  nan,  nan,  nan,  nan])
    """
    if field not in grid.at_node:
        raise FieldError(f"A {field} field is required at the nodes of the input grid.")

    # Create output array
    output = np.zeros(grid.number_of_nodes)

    # Create arrays of x and y coords for input to "distance to point' calc
    x_coord = grid.x_of_node
    y_coord = grid.y_of_node

    nodes_in_loop = grid.nodes.flatten()
    nodes_to_include = np.ones(grid.number_of_nodes, dtype=bool)

    if calc_on_closed_nodes is False:
        closed_nodes = grid.status_at_node == grid.BC_NODE_IS_CLOSED
        nodes_in_loop = nodes_in_loop[~closed_nodes]
        nodes_to_include[closed_nodes] = False
        output[closed_nodes] = np.nan

    # Calculate "dist to point" then local value at nodes within window.
    for node in nodes_in_loop:
        node_dist_to_point = grid.calc_distances_of_nodes_to_point(
            (x_coord[node], y_coord[node])
        )
        nodes_in_window = np.all(
            [node_dist_to_point <= search_radius, nodes_to_include], 0
        )
        values_in_window = grid.at_node[field][nodes_in_window]
        output[node] = func(values_in_window, **kwargs)

    return output



================================================
File: src/landlab/utils/ext/__init__.py
================================================



================================================
File: src/landlab/utils/ext/jaggedarray.pyx
================================================
cimport cython

from cython.parallel import prange

# https://cython.readthedocs.io/en/stable/src/userguide/fusedtypes.html
ctypedef fused id_t:
    cython.integral
    long long


ctypedef fused float_or_int:
    cython.integral
    long long
    cython.floating


@cython.boundscheck(False)
@cython.wraparound(False)
def unravel(
    float_or_int [:] data,
    const id_t [:] offset,
    float_or_int [:, :] out,
):
    cdef long n_rows = len(offset) - 1
    cdef long col
    cdef long row
    cdef long offset_to_row
    cdef long values_per_row

    for row in prange(n_rows, nogil=True, schedule="static"):
        offset_to_row = offset[row]
        values_per_row = offset[row + 1] - offset[row]
        for col in range(values_per_row):
            out[row, col] = data[offset_to_row + col]



================================================
File: src/landlab/utils/geometry/spherical.py
================================================
"""
spherical_geometry: routines for various spherical geometry calculations,
such as cartesian-spherical coordinate conversion, arc length,
triangle area, etc.

Greg Tucker, University of Colorado Boulder, first version October 2023
"""

import numpy as np


def arc_length(p1, p2, r):
    """
    Calculate and return great-circle arc length in radians between two points p1 & p2.

    Parameters
    ----------
    p1, p2 : array of float (3, )
        (x, y, z) coordinates of each point
    r : float
        Radius
    """
    return np.arccos(np.dot(p1, p2) / r**2)


def cartesian_to_spherical(x, y, z):
    """
    Return spherical coordinates corresponding to given (x,y,z) coordinates.

    Parameters
    ----------
    x, y, z : ndarray of float
        Cartesian coordinates

    Examples
    --------
    >>> import numpy as np
    >>> x = np.array([0, 1, 1, 2, 0, -1, -1, 0])
    >>> y = np.array([1, 0, 1, 0, 1, 0, -1, 0])
    >>> z = np.array([1, 1, 0, 0, -1, 1, 0, 1])
    >>> r, p, t = cartesian_to_spherical(x, y, z)
    >>> np.round(r, 2)
    array([1.41, 1.41, 1.41, 2.  , 1.41, 1.41, 1.41, 1.  ])
    >>> np.round(p / np.pi, 2)
    array([0.5 , 0.  , 0.25, 0.  , 0.5 , 1.  , 1.25, 0.  ])
    >>> np.round(t / np.pi, 2)
    array([0.25, 0.25, 0.5 , 0.5 , 0.75, 0.25, 0.5 , 0.  ])
    """
    r = np.sqrt(x * x + y * y + z * z)
    nonzero = np.logical_or(x != 0.0, y != 0.0)
    phi = np.zeros(len(x))
    phi[nonzero] = np.arccos(x[nonzero] / np.sqrt(x[nonzero] ** 2 + y[nonzero] ** 2))
    phi[y < 0.0] = 2 * np.pi - phi[y < 0.0]
    theta = np.arccos(z / r)
    return r, phi, theta


def rotate_around_y_axis(x, z, angle):
    """
    Calculate positions of points with given (x,z) coordinates after rotation around
    y axis by given angle.

    Parameters
    ----------
    x, z : float or ndarray of float
        (x, z) coordinates of one or points
    angle : float
        angle of rotation, radians

    Examples
    --------
    >>> import numpy as np
    >>> x = np.array([1.0, 1.0, 2.0, -1.0, -1.0])
    >>> z = np.array([1.0, 0.0, 0.0, 1.0, 0.0])
    >>> ang = np.array([-np.pi / 4, -np.pi / 2, -np.pi / 2, np.pi / 4, np.pi / 2])
    >>> xr, zr = rotate_around_y_axis(x, z, ang)
    >>> np.round(np.abs(xr), 2)
    array([0., 0., 0., 0., 0.])
    >>> np.round(zr, 2)
    array([1.41, 1.  , 2.  , 1.41, 1.  ])
    """
    xry = x * np.cos(angle) + z * np.sin(angle)
    zry = -x * np.sin(angle) + z * np.cos(angle)
    return xry, zry


def rotate_around_z_axis(x, y, angle):
    """
    Calculate positions of points with given (x,y) coordinates after rotation around
    z axis by given angle.

    Parameters
    ----------
    x, y : float or ndarray of float
        (x, y) coordinates of one or points
    angle : float
        angle of rotation, radians

    Examples
    --------
    >>> import numpy as np
    >>> x = np.array([0.0, 1.0, 2.0, -1.0])
    >>> y = np.array([1.0, 0.0, 0.0, -1.0])
    >>> ang = np.array([-np.pi / 2, -np.pi / 2, np.pi / 2, 3 * np.pi / 4])
    >>> xr, yr = rotate_around_z_axis(x, y, ang)
    >>> np.round(np.abs(xr), 2)
    array([1.  , 0. , 0.  , 1.41])
    >>> np.round(yr, 2)
    array([ 0., -1.,  2., -0.])
    """
    xrz = x * np.cos(angle) - y * np.sin(angle)
    yrz = x * np.sin(angle) + y * np.cos(angle)
    return xrz, yrz


def rotate_zy(x, y, z, phi, theta):
    """
    Rotate points around z axis then y axis.

    Parameters
    ----------
    x, y, z : ndarray of float
        (x,y,z) coordinates of points to be rotated
    phi : float
        Angle for rotation about z axis, radians
    theta : float
        Angle for rotation about y axis, radians

    Examples
    --------
    >>> import numpy as np
    >>> x = np.array([1.0, -1.0])
    >>> y = np.array([1.0, 0.0])
    >>> z = np.array([0.0, 1.0])
    >>> phi = np.array([-np.pi / 4, np.pi])
    >>> theta = np.array([-np.pi / 2, -np.pi / 4])
    >>> xr, yr, zr = rotate_zy(x, y, z, phi, theta)
    >>> np.round(xr, 2)
    array([0., 0.])
    >>> np.abs(np.round(yr, 2))
    array([0., 0.])
    >>> np.round(zr, 2)
    array([1.41, 1.41])
    """
    xrz, yrz = rotate_around_z_axis(x, y, phi)
    xrzy, zry = rotate_around_y_axis(xrz, z, theta)
    return xrzy, yrz, zry


def radial_length_of_sphertri_sides(p0, p1, p2, r=1.0):
    """
    Calculate and return the radial length of the 3 sides of a spherical triangle
    with given cartesian coords.

    Parameters
    ----------
    p0, p1, p2 : ndarray of float (3, )
        (x,y,z) coordinates of spherical triangle's three points
    r : float (optional)
        Sphere radius (default 1.0)

    Examples
    --------

    A triangular patch on an icosahedron

    >>> import numpy as np
    >>> t = (1.0 + 5.0**0.5) / 2.0
    >>> p0 = np.array([-1.0, t, 0.0])
    >>> p1 = np.array([-t, 0.0, 1.0])
    >>> p2 = np.array([0.0, 1.0, t])
    >>> a, b, c = radial_length_of_sphertri_sides(p0, p1, p2, np.sqrt(np.sum(p0**2)))
    >>> (int(10 * a), int(10 * b), int(10 * c))
    (11, 11, 11)
    """
    if r != 1.0:
        p0 = p0.copy() / r
        p1 = p1.copy() / r
        p2 = p2.copy() / r
    a = np.arccos(np.dot(p1, p2))
    b = np.arccos(np.dot(p0, p2))
    c = np.arccos(np.dot(p0, p1))
    return a, b, c


def spher_angle_from_sides(s, a, b):
    """
    Calculate and return the angle between two 2 sides of a spherical
    triangle with semiperimeter (half sum of radial side lengths) s, and
    radial lengths of the adjacent sides a and b.

    Uses the half-sine rule of spherical trigonometry.

    Parameters
    ----------
    s : float
        Semiperimeter
    a, b : float
        Radial lengths of two sides, radians

    Examples
    --------

    Sides of a spherical triangle in an icosahedron:

    >>> a = 1.1071487177940904
    >>> int(10 * spher_angle_from_sides(1.5 * a, a, a) / np.pi)
    4
    """
    return 2.0 * np.arcsin(
        np.sqrt((np.sin(s - a) * np.sin(s - b)) / (np.sin(a) * np.sin(b)))
    )


def angles_of_sphertri(a, b, c):
    """
    Calculate and return angles of the spherical triangle with radial side lengths a, b, and c.

    Parameters
    ----------
    a, b, c : float
        Lengths of 3 sides of triangle, radians

    Examples
    --------
    >>> import numpy as np
    >>> a = b = c = 1.1071487177940904
    >>> A, B, C = angles_of_sphertri(a, b, c)
    >>> (int(10 * A / np.pi), int(10 * B / np.pi), int(10 * C / np.pi))
    (4, 4, 4)
    """
    s = 0.5 * (a + b + c)
    A = spher_angle_from_sides(s, b, c)
    B = spher_angle_from_sides(s, a, c)
    C = spher_angle_from_sides(s, a, b)
    return A, B, C


def area_of_sphertri(p0, p1, p2, R):
    """
    Calculate and return area of a spherical triangle with 3D coordinates p0, p1, p2,
    and radius R.

    Uses Girard's Theorem for the area of a spherical triangle (equal to the
    "spherical excess" times R^2).

    Parameters
    ----------
    p0, p1, p2 : array of float (3, )
        (x, y, z) coordinates for each of three points
    R : float
        Radius

    Examples
    --------

    Triangle on an icosahedron should be 1/20th of the total area of 4 pi R^2

    >>> import numpy as np
    >>> t = (1.0 + 5.0**0.5) / 2.0
    >>> R0 = np.sqrt(1 + t**2)
    >>> p0 = np.array([-1.0, t, 0.0]) / R0
    >>> p1 = np.array([-t, 0.0, 1.0]) / R0
    >>> p2 = np.array([0.0, 1.0, t]) / R0
    >>> 20 * area_of_sphertri(p0, p1, p2, 1.0) / np.pi
    4.0
    """
    a, b, c = radial_length_of_sphertri_sides(p0, p1, p2, R)
    A, B, C = angles_of_sphertri(a, b, c)
    return (A + B + C - np.pi) * R * R



================================================
File: src/landlab/values/__init__.py
================================================
from .synthetic import constant
from .synthetic import plane
from .synthetic import random
from .synthetic import sine
from .synthetic import units

__all__ = ["random", "plane", "constant", "sine", "units"]



================================================
File: src/landlab/values/synthetic.py
================================================
"""Add synthetic values to a model grid.

Values can be added to any valid grid element (e.g. link or node). If no field
exists, a field of float zeros will be initialized.

All functions add values to the field---this means that multiple functions can
be chained together.

All functions support adding values to only portions of the grid, based on the
``status_at_link`` and ``status_at_node`` attributes.

For example, if one wanted to construct an initial topographic elevation
represented by a tetrahedron and add normally distributed noise only to core
nodes, this could be acomplished as follows:

Examples
--------
>>> import numpy as np
>>> from landlab import NodeStatus, RasterModelGrid
>>> from landlab.values import random, plane
>>> np.random.seed(42)

Create the grid.

>>> mg = RasterModelGrid((7, 7))

Create a tetrahedron by adding planes selectively using ``where``.

>>> southwest = plane(
...     mg,
...     "topographic__elevation",
...     where=((mg.x_of_node <= 3) & (mg.y_of_node <= 3)),
...     point=(0, 0, 0),
...     normal=(-1, -1, 1),
... )
>>> southeast = plane(
...     mg,
...     "topographic__elevation",
...     where=((mg.x_of_node > 3) & (mg.y_of_node <= 3)),
...     point=(6, 0, 0),
...     normal=(1, -1, 1),
... )
>>> northeast = plane(
...     mg,
...     "topographic__elevation",
...     where=((mg.x_of_node > 3) & (mg.y_of_node > 3)),
...     point=(6, 6, 0),
...     normal=(1, 1, 1),
... )
>>> northwest = plane(
...     mg,
...     "topographic__elevation",
...     where=((mg.x_of_node <= 3) & (mg.y_of_node > 3)),
...     point=(0, 6, 0),
...     normal=(-1, 1, 1),
... )
>>> mg.at_node["topographic__elevation"]
array([0.,  1.,  2.,  3.,  2.,  1.,  0.,
       1.,  2.,  3.,  4.,  3.,  2.,  1.,
       2.,  3.,  4.,  5.,  4.,  3.,  2.,
       3.,  4.,  5.,  6.,  5.,  4.,  3.,
       2.,  3.,  4.,  5.,  4.,  3.,  2.,
       1.,  2.,  3.,  4., 3.,   2.,  1.,
       0.,  1.,  2.,  3.,  2.,  1.,  0.])

Next add uniformly distributed noise.

>>> noise = random(
...     mg, "topographic__elevation", where=NodeStatus.CORE, distribution="uniform"
... )
>>> np.round(mg.at_node["topographic__elevation"], decimals=3)
array([0.   ,  1.   ,  2.   ,  3.   ,  2.   ,  1.   ,  0.   ,
       1.   ,  2.375,  3.951,  4.732,  3.599,  2.156,  1.   ,
       2.   ,  3.156,  4.058,  5.866,  4.601,  3.708,  2.   ,
       3.   ,  4.021,  5.97 ,  6.832,  5.212,  4.182,  3.   ,
       2.   ,  3.183,  4.304,  5.525,  4.432,  3.291,  2.   ,
       1.   ,  2.612,  3.139,  4.292,  3.366,  2.456,  1.   ,
       0.   ,  1.   ,  2.   ,  3.   ,  2.   ,  1.   ,  0.   ])

At present only a small selection of possible synthetic functions exist. If
your research requires additional functions, consider contributing one back to
the main landlab repository. If you have questions on how to proceed, please
create a GitHub issue.

All public functions from this submodule should have a common format. They
take as the first two arguments a model grid, and the name of the field.
They all take two keyword arguments: ``at``, which specifies which grid element
values are placed, and ``where``, which indicates where the values are placed.
Additional keyword arguments are required as needed by each function.
"""

from collections import defaultdict

import numpy as np

from landlab.grid.linkstatus import LinkStatus
from landlab.grid.network import NetworkModelGrid
from landlab.grid.nodestatus import NodeStatus

_STATUS = defaultdict(
    dict,
    {
        "link": {
            "ACTIVE_LINK": LinkStatus.ACTIVE,
            "FIXED_LINK": LinkStatus.FIXED,
            "INACTIVE_LINK": LinkStatus.INACTIVE,
        },
        "node": {
            "CLOSED_BOUNDARY": NodeStatus.CLOSED,
            "CORE_NODE": NodeStatus.CORE,
            "FIXED_GRADIENT_BOUNDARY": NodeStatus.FIXED_GRADIENT,
            "FIXED_VALUE_BOUNDARY": NodeStatus.FIXED_VALUE,
            "LOOPED_BOUNDARY": NodeStatus.LOOPED,
        },
    },
)


def _create_missing_field(grid, name, at):
    """Create field of zeros if missing."""
    if name not in grid[at]:
        grid.add_zeros(name, at=at)


def _where_to_add_values(grid, at, where):
    """Determine where to put values.

    Parameters
    ----------
    grid : ModelGrid-like
        A landlab ModelGrid.
    at : str
        Name of location where values are defined.
    where : array-like or str or int or None
        Ids where values are to be placed. If *None*, values will
        be placed on all elements. If *str*, *int* or list of *str* or *int*,
        *where* is interpreted as a boundary condition.

    Returns
    -------
    ndarray
        IDs that indicate where values are to be placed.
    """
    if isinstance(where, (str, int)):
        where = [where]

    if isinstance(where, (list, tuple)):
        where = [_convert_where(_w, at) for _w in where]

    if where is None:
        where = np.full(grid.size(at), True, dtype=bool)
    elif isinstance(where, (tuple, list)):
        where = np.isin(getattr(grid, f"status_at_{at}"), where)
    else:
        where = np.asarray(where, dtype=bool)
        if where.size != grid.size(at):
            raise ValueError(f"array size mismatch ({where.size} != {grid.size(at)})")

    return where


def _convert_where(where, at):
    if at not in _STATUS:
        raise AttributeError(f"boundary conditions are not defined at {at!r}")

    if isinstance(where, str):
        try:
            return _STATUS[at][where]
        except KeyError as exc:
            raise ValueError(f"{where!r} status does not exists for {at!r}.") from exc
    else:
        return where


def units(grid, name, at="node", units=None):
    """Add units to a field."""
    _create_missing_field(grid, name, at)
    if units is not None:
        grid[at].set_units(name, units)
    return grid[at][name]


def random(grid, name, at="node", where=None, distribution="uniform", **kwargs):
    """Add random values to a grid.

    This function supports all distributions provided in the
    `numpy.random submodule
    <https://docs.scipy.org/doc/numpy-1.15.1/reference/routines.random.html#distributions>`_.

    Parameters
    ----------
    grid : ModelGrid
    name : str
        Name of the field.
    at : str, optional
        Grid location to store values. If not given, values are
        assumed to be on `node`.
    where : optional
        The keyword ``where`` indicates where synthetic values
        should be placed. It is either (1) a single value or list
        of values indicating a grid-element status (e.g. `NodeStatus.CORE`),
        or (2) a (number-of-grid-element,) sized boolean array.
    distribution : str, optional
        Name of the distribution provided by the np.random
        submodule.
    kwargs : dict
        Keyword arguments to pass to the ``np.random`` distribution
        function.

    Returns
    -------
    values : array
        Array of the values added to the field.

    Examples
    --------
    >>> import numpy as np
    >>> from landlab import RasterModelGrid
    >>> from landlab.values import random
    >>> np.random.seed(42)
    >>> mg = RasterModelGrid((4, 4))
    >>> values = random(
    ...     mg,
    ...     "soil__depth",
    ...     "node",
    ...     where="CORE_NODE",
    ...     distribution="uniform",
    ...     high=3.0,
    ...     low=2.0,
    ... )
    >>> mg.at_node["soil__depth"]
    array([0.        ,  0.        ,  0.        ,  0.        ,
           0.        ,  2.37454012,  2.95071431,  0.        ,
           0.        ,  2.73199394,  2.59865848,  0.        ,
           0.        ,  0.        ,  0.        ,  0.        ])
    """
    where = _where_to_add_values(grid, at, where)
    _create_missing_field(grid, name, at)
    values = np.zeros(grid.size(at))

    if distribution not in np.random.__dict__:
        raise ValueError("")

    function = np.random.__dict__[distribution]
    values[where] += function(size=np.sum(where), **kwargs)
    grid[at][name][:] += values
    return values


def plane(
    grid, name, at="node", where=None, point=(0.0, 0.0, 0), normal=(0.0, 0.0, 1.0)
):
    """Add a single plane defined by a point and a normal to a grid.

    Parameters
    ----------
    grid : ModelGrid
    name : str
        Name of the field.
    at : str, optional
        Grid location to store values. If not given, values are
        assumed to be on `node`.
    where : optional
        The keyword ``where`` indicates where synthetic values
        should be placed. It is either (1) a single value or list
        of values indicating a grid-element status (e.g. `NodeStatus.CORE`),
        or (2) a (number-of-grid-element,) sized boolean array.
    point : tuple, optional
        A tuple defining a point the plane goes through in the
        format (x, y, z). Default is (0., 0., 0.)
    normal : tuple, optional
        A tuple defining the normal to the plane in the format
        (dx, dy, dz). Must not be verticaly oriented. Default
        is a horizontal plane (0., 0., 1.).

    Returns
    -------
    values : array
        Array of the values added to the field.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.values import plane
    >>> mg = RasterModelGrid((4, 4))
    >>> values = plane(
    ...     mg, "soil__depth", "node", point=(0.0, 0.0, 0.0), normal=(-1.0, -1.0, 1.0)
    ... )
    >>> mg.at_node["soil__depth"]
    array([0.,  1.,  2.,  3.,
           1.,  2.,  3.,  4.,
           2.,  3.,  4.,  5.,
           3.,  4.,  5.,  6.])
    """
    x, y = _get_x_and_y(grid, at)

    where = _where_to_add_values(grid, at, where)
    _create_missing_field(grid, name, at)
    values = _plane_function(x, y, point, normal)
    grid[at][name][where] += values[where]

    return values


def _plane_function(x, y, point, normal):
    """calculate the plane function."""
    if np.isclose(normal[2], 0):
        raise ValueError("")

    constant = point[0] * normal[0] + point[1] * normal[1] + point[2] * normal[2]
    values = (constant - (normal[0] * x) - (normal[1] * y)) / normal[2]

    return values


def _get_x_and_y(grid, at):
    if isinstance(grid, NetworkModelGrid) and at != "node":
        raise ValueError(
            "Synthetic fields based on x and y values at grid elements "
            "(e.g. sine, plane) are supported for NetworkModelGrid "
            "only at node. If you need this at other grid elements, "
            "open a GitHub issue to learn how to contribute this "
            "functionality."
        )
    if at == "node":
        x, y = grid.xy_of_node[:, 0], grid.xy_of_node[:, 1]
    elif at == "link":
        x, y = grid.xy_of_link[:, 0], grid.xy_of_link[:, 1]
    elif at == "cell":
        x, y = grid.xy_of_cell[:, 0], grid.xy_of_cell[:, 1]
    elif at == "face":
        x, y = grid.xy_of_face[:, 0], grid.xy_of_face[:, 1]
    else:
        raise ValueError(
            "landlab.values.synthetic: ",
            "X and Y values are require for the requested synthetic field "
            "but do not exist for the grid-element provided: " + at,
        )
    return x, y


def constant(grid, name, at="node", where=None, value=0.0, dtype=None):
    """Add a constant to a grid.

    Parameters
    ----------
    grid : ModelGrid
    name : str
        Name of the field.
    at : str, optional
        Grid location to store values. If not given, values are
        assumed to be on `node`.
    where : optional
        The keyword ``where`` indicates where synthetic values
        should be placed. It is either (1) a single value or list
        of values indicating a grid-element status (e.g. `NodeStatus.CORE`),
        or (2) a (number-of-grid-element,) sized boolean array.
    value : float, optional
        Constant value to add to the grid. Default is 0.
    dtype : str, optional
        The type of the newly created field. If not provided, the
        type will be determined based on the type of *value*.

    Returns
    -------
    values : array
        Array of the values added to the field.

    Examples
    --------
    >>> from landlab import RasterModelGrid
    >>> from landlab.values import constant
    >>> mg = RasterModelGrid((4, 4))
    >>> values = constant(mg, "some_flux", "link", where="ACTIVE_LINK", value=10.0)
    >>> mg.at_link["some_flux"]
    array([  0.,   0.,   0.,   0.,  10.,  10.,   0.,  10.,  10.,  10.,   0.,
            10.,  10.,   0.,  10.,  10.,  10.,   0.,  10.,  10.,   0.,   0.,
             0.,   0.])
    """
    dtype = dtype or type(value)
    where = _where_to_add_values(grid, at, where)
    try:
        values = grid[at][name]
    except KeyError:
        values = grid.add_zeros(name, at=at, dtype=dtype)
    values[where] += value
    return values


def sine(
    grid,
    name,
    at="node",
    where=None,
    amplitude=1.0,
    wavelength=1.0,
    a=1.0,
    b=1.0,
    point=(0.0, 0.0),
):
    r"""Add a sin wave to a grid.

    Add a sine wave :math:`z` defined as:

    .. math::
        z = A * sin ( \\frac{2\pi v}{\lambda} )
        v = a(x-x_0) + b(y-y_0)

    where :math:`A` is the amplitude and :math:`\lambda` is the wavelength.
    The values :math:`a`, :math:`b`, and the point :math:`(x_0, y_0)` permit
    the sin wave to be oriented arbitrarily in the x-y plane.

    Parameters
    ----------
    grid : ModelGrid
    name : str
        Name of the field.
    at : str, optional
        Grid location to store values. If not given, values are
        assumed to be on `node`.
    where : optional
        The keyword ``where`` indicates where synthetic values
        should be placed. It is either (1) a single value or list
        of values indicating a grid-element status (e.g. `NodeStatus.CORE`),
        or (2) a (number-of-grid-element,) sized boolean array.
    amplitude : p
    wavelength :
    a :
    b :
    point :

    Returns
    -------
    values : array
        Array of the values added to the field.

    Examples
    --------
    >>> from numpy.testing import assert_array_almost_equal
    >>> from landlab import RasterModelGrid
    >>> from landlab.values import sine
    >>> mg = RasterModelGrid((5, 5))
    >>> values = sine(mg, "topographic__elevation", amplitude=2, wavelength=4, a=1, b=0)
    >>> new_field = mg.at_node["topographic__elevation"].reshape(mg.shape)
    >>> truth = np.array(
    ...     [
    ...         [0.0, 2.0, 0.0, -2.0, -0.0],
    ...         [0.0, 2.0, 0.0, -2.0, -0.0],
    ...         [0.0, 2.0, 0.0, -2.0, -0.0],
    ...         [0.0, 2.0, 0.0, -2.0, -0.0],
    ...         [0.0, 2.0, 0.0, -2.0, -0.0],
    ...     ]
    ... )
    >>> assert_array_almost_equal(new_field, truth)
    """
    x, y = _get_x_and_y(grid, at)

    where = _where_to_add_values(grid, at, where)
    _create_missing_field(grid, name, at)
    values = np.zeros(grid.size(at))
    v = (a * (x - point[0])) + (b * (y - point[1]))
    values[where] += amplitude * np.sin(2.0 * np.pi * v / wavelength)
    grid[at][name][:] += values
    return values



================================================
File: src/landlab/.qodo/history.sqlite
================================================
[Non-text file]



